{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT STATEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.3)\n",
      "Requirement already satisfied: sklearn in ./.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: xgboost in ./.local/lib/python3.6/site-packages (1.3.1)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.6/site-packages (3.3.3)\n",
      "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0+nv)\n",
      "Requirement already satisfied: keras==2.2.4 in ./.local/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: fastai in ./.local/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (2.8.1)\n",
      "Requirement already satisfied: scikit-optimize in ./.local/lib/python3.6/site-packages (0.8.1)\n",
      "Requirement already satisfied: scikit-learn==0.21 in ./.local/lib/python3.6/site-packages (0.21.0)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.6/site-packages (0.16)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./.local/lib/python3.6/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.6/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.local/lib/python3.6/site-packages (from matplotlib) (8.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./.local/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.11.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastai) (20.0.2)\n",
      "Requirement already satisfied: spacy in ./.local/lib/python3.6/site-packages (from fastai) (2.3.5)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.8 in ./.local/lib/python3.6/site-packages (from fastai) (1.3.18)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.6/site-packages (from fastai) (20.8)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in ./.local/lib/python3.6/site-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
      "Requirement already satisfied: torch<1.8,>=1.7.0 in ./.local/lib/python3.6/site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: torchvision<0.9,>=0.8 in ./.local/lib/python3.6/site-packages (from fastai) (0.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.6/site-packages (from scikit-optimize) (1.0.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in ./.local/lib/python3.6/site-packages (from scikit-optimize) (20.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (46.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.11.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (7.4.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (0.8.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (2.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (4.43.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (0.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (3.0.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.11.28)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.6/site-packages (from torch<1.8,>=1.7.0->fastai) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in ./.local/lib/python3.6/site-packages (from torch<1.8,>=1.7.0->fastai) (0.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai) (1.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!TMPDIR=/home/mgill/ pip install --cache-dir=/home/mgill/ --build /home/mgill/ pandas numpy sklearn xgboost matplotlib tensorflow==2.1.0 keras==2.2.4 fastai python-dateutil scikit-optimize scikit-learn==0.21 graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from fastai.tabular.all import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Activation\n",
    "from math import sqrt\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt \n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import interp\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data, Prepare OHE, Prepare Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the 2 phenos in the files\n",
    "#only 3 samples, won't create an accurate model, so its better to treat it as a binary classification\n",
    "def del_2(vcf, pheno):\n",
    "    i = 0\n",
    "    rm_idx = []\n",
    "    print(pheno.shape)\n",
    "    print(vcf.shape)\n",
    "    while (i < pheno.shape[0]):\n",
    "        if (pheno[i] == 2.0):\n",
    "            print(\"found 2\")\n",
    "            rm_idx.append(i)\n",
    "        i = i + 1\n",
    "    pheno = np.delete(pheno, rm_idx, 0)\n",
    "    vcf = vcf.drop((vcf.index[rm_idx]))\n",
    "    print(pheno.shape)\n",
    "    print(vcf.shape)\n",
    "    return vcf, pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_prep_data(tt_file, ho_file):\n",
    "    imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "    my_list = []\n",
    "    x = 0 \n",
    "    for chunk in pd.read_csv(tt_file, chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "        x=x+10000\n",
    "        chunk = chunk.T\n",
    "        if 'Value' in chunk.columns:\n",
    "            #does the selecting of pheno array for application ML\n",
    "            chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "            tt_pheno = chunk[\"Value\"].to_numpy()\n",
    "            #reshapes it so its not a 1D array\n",
    "            print(tt_pheno.shape)\n",
    "            tt_pheno = np.reshape(tt_pheno,(len(tt_pheno),1))\n",
    "            print(tt_pheno.shape)\n",
    "            chunk = chunk.drop(columns=['Value'])\n",
    "        headers = chunk.columns\n",
    "        row_idx = chunk.index\n",
    "        chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "        #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "        chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "        my_list.append(chunk)\n",
    "        print(x)\n",
    "    tt_vcf = pd.concat(my_list, axis = 1)\n",
    "    my_list = []\n",
    "    x=0\n",
    "    for chunk in pd.read_csv(ho_file, chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "        x=x+10000\n",
    "        chunk = chunk.T\n",
    "        if 'Value' in chunk.columns:\n",
    "            #does the selecting of pheno array for application ML\n",
    "            chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "            ho_pheno = chunk[\"Value\"].to_numpy()\n",
    "            #reshapes it so its not a 1D array\n",
    "            print(ho_pheno.shape)\n",
    "            ho_pheno = np.reshape(ho_pheno,(len(ho_pheno),1))\n",
    "            print(ho_pheno.shape)\n",
    "            chunk = chunk.drop(columns=['Value'])\n",
    "        headers = chunk.columns\n",
    "        row_idx = chunk.index\n",
    "        chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "        #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "        chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "        my_list.append(chunk)\n",
    "        print(x)\n",
    "    ho_vcf = pd.concat(my_list, axis = 1)\n",
    "    tt_vcf,tt_pheno = del_2(tt_vcf, tt_pheno)\n",
    "    ho_vcf,ho_pheno = del_2(ho_vcf, ho_pheno)\n",
    "    print(tt_vcf.shape)\n",
    "    print(ho_vcf.shape)\n",
    "    print(tt_pheno.shape)\n",
    "    print(ho_pheno.shape)\n",
    "    return tt_vcf, ho_vcf, tt_pheno, ho_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617,)\n",
      "(617, 1)\n",
      "10000\n",
      "(155,)\n",
      "(155, 1)\n",
      "10000\n",
      "(617, 1)\n",
      "(617, 9258)\n",
      "found 2\n",
      "found 2\n",
      "(615, 1)\n",
      "(615, 9258)\n",
      "(155, 1)\n",
      "(155, 9258)\n",
      "found 2\n",
      "(154, 1)\n",
      "(154, 9258)\n",
      "(615, 9258)\n",
      "(154, 9258)\n",
      "(615, 1)\n",
      "(154, 1)\n"
     ]
    }
   ],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data(\"PuD_Merged_filtered.csv_train_testQTL_SNPS.csv\", \"PuD_Merged_filtered.csv_holdoutQTL_SNPS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only if it hasn't been done yet otherweise skip to load\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "ohe = ohe.fit(tt_vcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ohe, open(\"PuD_QTL_ohe.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if need or have new holdout data etc.\n",
    "ohe = pickle.load(open(\"PuD_QTL_ohe.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 9258)\n",
      "(615, 27061)\n",
      "(154, 9258)\n",
      "(154, 27061)\n"
     ]
    }
   ],
   "source": [
    "print(tt_vcf.shape)\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_snp_from_header(ohe,snp_num):\n",
    "    count = 0\n",
    "    snp = \"Not found\"\n",
    "    found = False\n",
    "    i = 0\n",
    "    while i < len(ohe.categories_) and (found == False):\n",
    "        j = 0\n",
    "        while j < len(ohe.categories_[i]):\n",
    "            if(count == snp_num):\n",
    "                snp = ohe.categories_[i][j]\n",
    "                found = True\n",
    "                break\n",
    "            count = count + 1\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    return snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T/T\n"
     ]
    }
   ],
   "source": [
    "## TESTING IF IT WORKS\n",
    "my_snp = find_snp_from_header(ohe, 10805)\n",
    "print(my_snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the model building data, one hot encoding and creating a label set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 27061)\n",
      "(615, 1)\n",
      "(123, 27061)\n",
      "(492, 27061)\n",
      "seed is 4793\n"
     ]
    }
   ],
   "source": [
    "#for optimising the parameters, dont need to run if going straight to k-fold eval\n",
    "print(tt_vcf.shape)\n",
    "print(tt_pheno.shape)\n",
    "seed = randint(0,5000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tt_vcf, tt_pheno, test_size=0.2, random_state=seed)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(\"seed is \" + str(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Space to Optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space ={'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'max_depth': Integer(0, 50),\n",
    "        'max_delta_step': Integer(0, 20),\n",
    "        'subsample': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': Real(0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': Real(1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 5),\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'scale_pos_weight': Real(1e-6, 500, 'log-uniform')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stops the optimising if above 98% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    \"\"\"\n",
    "    Callback meant to view scores after\n",
    "    each iteration while performing Bayesian\n",
    "    Optimization in Skopt\"\"\"\n",
    "    score = xgb_bayes_search.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "    if score >= 0.98:\n",
    "        print('Interrupting!')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for optimium parameters from the defined space and print best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:41:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216, score=0.192, total=   5.6s\n",
      "[CV] colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:41:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216, score=0.192, total=   5.4s\n",
      "[CV] colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216 \n",
      "[15:41:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216, score=0.194, total=   3.1s\n",
      "[CV] colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216 \n",
      "[15:41:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216, score=0.194, total=   5.2s\n",
      "[CV] colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216 \n",
      "[15:41:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.4160029192647807, colsample_bytree=0.7304484857455519, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=13, max_depth=21, min_child_weight=2, n_estimators=161, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, scale_pos_weight=0.060830282487222144, subsample=0.13556548021189216, score=0.194, total=   5.1s\n",
      "[CV] colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859 \n",
      "[15:41:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859, score=0.859, total=   6.1s\n",
      "[CV] colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859 \n",
      "[15:41:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859, score=0.838, total=   6.0s\n",
      "[CV] colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859 \n",
      "[15:41:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859, score=0.827, total=   5.9s\n",
      "[CV] colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859 \n",
      "[15:41:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859, score=0.888, total=   5.8s\n",
      "[CV] colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859 \n",
      "[15:41:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.18630307921210337, colsample_bytree=0.6357746718688816, gamma=4.759632988007942e-09, learning_rate=0.21560448660617149, max_delta_step=14, max_depth=39, min_child_weight=0, n_estimators=198, reg_alpha=1.307103676304351e-05, reg_lambda=1.1326211354138217e-09, scale_pos_weight=22.356393886375308, subsample=0.7121579996266859, score=0.857, total=   5.6s\n",
      "[CV] colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597 \n",
      "[15:41:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597, score=0.889, total=   2.2s\n",
      "[CV] colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597 \n",
      "[15:41:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597, score=0.909, total=   1.9s\n",
      "[CV] colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597 \n",
      "[15:41:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597, score=0.888, total=   1.9s\n",
      "[CV] colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597 \n",
      "[15:42:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597, score=0.898, total=   2.0s\n",
      "[CV] colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597 \n",
      "[15:42:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.25617325301227906, colsample_bytree=0.7083937150495909, gamma=2.41812432168581e-07, learning_rate=0.13965555720269418, max_delta_step=10, max_depth=27, min_child_weight=1, n_estimators=76, reg_alpha=3.178148842971562e-08, reg_lambda=0.005381781269387993, scale_pos_weight=0.23835043249575294, subsample=0.9559763235078597, score=0.878, total=   2.2s\n",
      "[CV] colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827 \n",
      "[15:42:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827, score=0.192, total=   1.7s\n",
      "[CV] colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827 \n",
      "[15:42:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827, score=0.192, total=   1.4s\n",
      "[CV] colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827 \n",
      "[15:42:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827, score=0.194, total=   2.6s\n",
      "[CV] colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827 \n",
      "[15:42:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827, score=0.194, total=   1.5s\n",
      "[CV] colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827 \n",
      "[15:42:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7711308526006485, colsample_bytree=0.07988300914246868, gamma=1.3877597085692663e-08, learning_rate=0.15021004353467043, max_delta_step=6, max_depth=3, min_child_weight=3, n_estimators=77, reg_alpha=0.006097622112520179, reg_lambda=1.9368851099909265e-09, scale_pos_weight=6.97020795804701e-06, subsample=0.46717487628832827, score=0.194, total=   2.0s\n",
      "[CV] colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085 \n",
      "[15:42:13] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085, score=0.192, total=   4.2s\n",
      "[CV] colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085 \n",
      "[15:42:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085, score=0.192, total=   3.9s\n",
      "[CV] colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085 \n",
      "[15:42:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085, score=0.194, total=   4.6s\n",
      "[CV] colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085 \n",
      "[15:42:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085, score=0.194, total=   6.1s\n",
      "[CV] colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085 \n",
      "[15:42:32] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.9132100359267209, colsample_bytree=0.7679711803126804, gamma=2.428808912219129e-07, learning_rate=0.03511167856740689, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=197, reg_alpha=0.023358352781682152, reg_lambda=2.1396512525873352e-07, scale_pos_weight=0.001760608876847004, subsample=0.15990388740095085, score=0.194, total=   6.6s\n",
      "[CV] colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985 \n",
      "[15:42:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985, score=0.788, total=   1.7s\n",
      "[CV] colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985 \n",
      "[15:42:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985, score=0.646, total=   1.3s\n",
      "[CV] colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985 \n",
      "[15:42:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985, score=0.806, total=   2.3s\n",
      "[CV] colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985 \n",
      "[15:42:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985, score=0.898, total=   1.8s\n",
      "[CV] colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985 \n",
      "[15:42:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.3569079180734289, colsample_bytree=0.1120289995668169, gamma=0.05034432042804318, learning_rate=0.7467518194835729, max_delta_step=7, max_depth=47, min_child_weight=1, n_estimators=67, reg_alpha=0.005500281359785164, reg_lambda=6.3166999939833564e-06, scale_pos_weight=0.4420166988445819, subsample=0.037978567417966985, score=0.888, total=   2.3s\n",
      "[CV] colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774 \n",
      "[15:42:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774, score=0.192, total=   3.3s\n",
      "[CV] colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774 \n",
      "[15:42:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774, score=0.192, total=   2.1s\n",
      "[CV] colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774 \n",
      "[15:42:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774, score=0.194, total=   2.0s\n",
      "[CV] colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774 \n",
      "[15:42:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774, score=0.194, total=   1.9s\n",
      "[CV] colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774 \n",
      "[15:42:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.3173884684879576, colsample_bytree=0.9154083808190769, gamma=0.37957777315906627, learning_rate=0.046564465205051725, max_delta_step=5, max_depth=25, min_child_weight=4, n_estimators=98, reg_alpha=1.8932210348902655e-05, reg_lambda=10.393593598030753, scale_pos_weight=0.019183460268621746, subsample=0.6299477217301774, score=0.194, total=   1.9s\n",
      "[CV] colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868 \n",
      "[15:42:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868, score=0.192, total=   3.2s\n",
      "[CV] colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868 \n",
      "[15:43:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868, score=0.192, total=   2.9s\n",
      "[CV] colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868 \n",
      "[15:43:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868, score=0.194, total=   3.0s\n",
      "[CV] colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868 \n",
      "[15:43:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868, score=0.194, total=   2.9s\n",
      "[CV] colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868 \n",
      "[15:43:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.19358622710388942, colsample_bytree=0.9236239290551462, gamma=6.242737149649543e-09, learning_rate=0.5839290998374393, max_delta_step=9, max_depth=2, min_child_weight=1, n_estimators=157, reg_alpha=0.32247446903004606, reg_lambda=5.7439751766594195e-06, scale_pos_weight=1.6287615199535114e-06, subsample=0.9872483677632868, score=0.194, total=   2.9s\n",
      "[CV] colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377 \n",
      "[15:43:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377, score=0.848, total=   2.7s\n",
      "[CV] colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377 \n",
      "[15:43:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377, score=0.818, total=   2.6s\n",
      "[CV] colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377 \n",
      "[15:43:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377, score=0.837, total=   3.1s\n",
      "[CV] colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377 \n",
      "[15:43:23] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377, score=0.816, total=   2.9s\n",
      "[CV] colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377 \n",
      "[15:43:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.06936552953088004, colsample_bytree=0.5708703891954323, gamma=1.9956389638103137e-08, learning_rate=0.09010297955022104, max_delta_step=9, max_depth=25, min_child_weight=2, n_estimators=139, reg_alpha=0.9824119669778386, reg_lambda=0.00017577858139476563, scale_pos_weight=261.4450653749918, subsample=0.14242164035537377, score=0.837, total=   2.6s\n",
      "[CV] colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144 \n",
      "[15:43:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144, score=0.192, total=   1.8s\n",
      "[CV] colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144 \n",
      "[15:43:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144, score=0.192, total=   1.8s\n",
      "[CV] colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144 \n",
      "[15:43:32] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144, score=0.194, total=   1.8s\n",
      "[CV] colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144 \n",
      "[15:43:34] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144, score=0.194, total=   1.9s\n",
      "[CV] colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144 \n",
      "[15:43:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.1798648261515349, colsample_bytree=0.1536154650973617, gamma=2.692171045057089e-07, learning_rate=0.031045751168128115, max_delta_step=12, max_depth=24, min_child_weight=3, n_estimators=113, reg_alpha=0.0011518554964803237, reg_lambda=3.9270934206560135e-05, scale_pos_weight=0.036328353682153036, subsample=0.5123744729843144, score=0.194, total=   1.9s\n",
      "[CV] colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086 \n",
      "[15:43:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086, score=0.192, total=   1.6s\n",
      "[CV] colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086 \n",
      "[15:43:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086, score=0.192, total=   2.2s\n",
      "[CV] colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086 \n",
      "[15:43:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086, score=0.194, total=   2.5s\n",
      "[CV] colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086 \n",
      "[15:43:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086, score=0.194, total=   2.5s\n",
      "[CV] colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086 \n",
      "[15:43:47] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8477171831834894, colsample_bytree=0.9590782028716157, gamma=0.4419705200245942, learning_rate=0.010068534554171981, max_delta_step=18, max_depth=46, min_child_weight=5, n_estimators=66, reg_alpha=1.3396471230171212e-09, reg_lambda=0.1502689667792386, scale_pos_weight=5.68219069233494e-06, subsample=0.3682037565911086, score=0.194, total=   1.9s\n",
      "[CV] colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889 \n",
      "[15:43:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889, score=0.889, total=   3.7s\n",
      "[CV] colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889 \n",
      "[15:43:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889, score=0.899, total=   3.5s\n",
      "[CV] colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889 \n",
      "[15:43:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889, score=0.847, total=   3.6s\n",
      "[CV] colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889 \n",
      "[15:43:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889, score=0.918, total=   3.9s\n",
      "[CV] colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889 \n",
      "[15:44:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.88542798001491, colsample_bytree=0.15107725561517718, gamma=0.09274068410384222, learning_rate=0.11437510345794359, max_delta_step=0, max_depth=6, min_child_weight=5, n_estimators=200, reg_alpha=1.2952579279714691e-08, reg_lambda=0.45707493844512304, scale_pos_weight=10.561837873121673, subsample=0.9105119208713889, score=0.857, total=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.8922764227642277\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133 \n",
      "[15:44:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133, score=0.859, total=   1.0s\n",
      "[CV] colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133 \n",
      "[15:44:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133, score=0.899, total=   1.0s\n",
      "[CV] colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133 \n",
      "[15:44:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133, score=0.847, total=   1.2s\n",
      "[CV] colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133 \n",
      "[15:44:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133, score=0.867, total=   1.0s\n",
      "[CV] colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133 \n",
      "[15:44:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.06827503415025202, colsample_bytree=0.01, gamma=6.201646382342046e-08, learning_rate=0.17446474110118035, max_delta_step=0, max_depth=38, min_child_weight=5, n_estimators=50, reg_alpha=0.1130106780220491, reg_lambda=2.620738670142872e-06, scale_pos_weight=0.9869705414087024, subsample=0.2202398046751133, score=0.878, total=   1.0s\n",
      "[CV] colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629 \n",
      "[15:44:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629, score=0.909, total=   2.4s\n",
      "[CV] colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629 \n",
      "[15:44:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629, score=0.899, total=   2.4s\n",
      "[CV] colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629 \n",
      "[15:44:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629, score=0.867, total=   2.4s\n",
      "[CV] colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629 \n",
      "[15:44:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629, score=0.908, total=   2.6s\n",
      "[CV] colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629 \n",
      "[15:44:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.32402651400912147, colsample_bytree=0.6066525455165047, gamma=3.5579162758207883e-07, learning_rate=0.14659178047471733, max_delta_step=9, max_depth=26, min_child_weight=1, n_estimators=95, reg_alpha=5.080977599711997e-08, reg_lambda=0.0033124891398589058, scale_pos_weight=0.9055301324207258, subsample=0.9439223978557629, score=0.867, total=   2.2s\n",
      "[CV] colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304 \n",
      "[15:44:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304, score=0.848, total=   1.8s\n",
      "[CV] colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304 \n",
      "[15:44:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304, score=0.838, total=   1.9s\n",
      "[CV] colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304 \n",
      "[15:44:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304, score=0.847, total=   1.9s\n",
      "[CV] colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304 \n",
      "[15:44:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304, score=0.898, total=   2.5s\n",
      "[CV] colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304 \n",
      "[15:44:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7644483441463623, colsample_bytree=0.01, gamma=0.0002205228508088852, learning_rate=0.8207368438419831, max_delta_step=0, max_depth=32, min_child_weight=5, n_estimators=116, reg_alpha=1.0, reg_lambda=0.024443959049826852, scale_pos_weight=499.99999999999994, subsample=0.6589435102986304, score=0.837, total=   2.0s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01 \n",
      "[15:44:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01, score=0.808, total=   1.4s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01 \n",
      "[15:44:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01, score=0.808, total=   1.3s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01 \n",
      "[15:44:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01, score=0.806, total=   1.2s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01 \n",
      "[15:44:47] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01, score=0.806, total=   1.2s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01 \n",
      "[15:44:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.03662454625189434, learning_rate=0.5138471913239572, max_delta_step=11, max_depth=0, min_child_weight=4, n_estimators=50, reg_alpha=0.0008361886423077453, reg_lambda=1.3471608754397973e-06, scale_pos_weight=99.79449288299413, subsample=0.01, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01 \n",
      "[15:44:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01, score=0.808, total=   1.0s\n",
      "[CV] colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01 \n",
      "[15:44:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01, score=0.808, total=   1.0s\n",
      "[CV] colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01 \n",
      "[15:44:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01 \n",
      "[15:44:53] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01 \n",
      "[15:44:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.5159500334864179, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.6719562479839406, max_delta_step=0, max_depth=21, min_child_weight=5, n_estimators=50, reg_alpha=1.0, reg_lambda=0.04987064846940078, scale_pos_weight=129.85621922306987, subsample=0.01, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121 \n",
      "[15:44:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121, score=0.899, total=   2.6s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121 \n",
      "[15:44:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121, score=0.899, total=   2.8s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121 \n",
      "[15:45:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121, score=0.888, total=   3.9s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121 \n",
      "[15:45:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121, score=0.908, total=   5.8s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121 \n",
      "[15:45:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.13097857282144737, gamma=2.149075742499797e-06, learning_rate=0.16275833008397378, max_delta_step=0, max_depth=30, min_child_weight=5, n_estimators=146, reg_alpha=0.009340835783247008, reg_lambda=0.1502734489902232, scale_pos_weight=0.27283849230425683, subsample=0.7660570387373121, score=0.867, total=   2.6s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174 \n",
      "[15:45:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174, score=0.808, total=   1.0s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174 \n",
      "[15:45:13] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174, score=0.808, total=   1.0s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174 \n",
      "[15:45:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174 \n",
      "[15:45:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174 \n",
      "[15:45:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=1e-09, learning_rate=0.5907440003962897, max_delta_step=0, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=1.0, reg_lambda=1.61128747307602e-07, scale_pos_weight=499.99999999999994, subsample=0.011858625638756174, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01 \n",
      "[15:45:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01, score=0.808, total=   1.1s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01 \n",
      "[15:45:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01, score=0.808, total=   1.3s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01 \n",
      "[15:45:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01, score=0.806, total=   1.3s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01 \n",
      "[15:45:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01, score=0.806, total=   1.4s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01 \n",
      "[15:45:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.14079093235127624, max_delta_step=0, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=0.6623056241323955, reg_lambda=3.125706333399983, scale_pos_weight=499.99999999999994, subsample=0.01, score=0.806, total=   1.3s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0 \n",
      "[15:45:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0, score=0.808, total=   4.4s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0 \n",
      "[15:45:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0, score=0.808, total=   4.5s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0 \n",
      "[15:45:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0, score=0.806, total=   4.5s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0 \n",
      "[15:45:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0, score=0.806, total=   4.5s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0 \n",
      "[15:45:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1.3770078283915654e-08, learning_rate=0.1004585822069077, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1e-09, reg_lambda=14.305009068676906, scale_pos_weight=5.525013305034832, subsample=1.0, score=0.806, total=   4.4s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112 \n",
      "[15:45:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112, score=0.808, total=   4.3s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112 \n",
      "[15:45:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112, score=0.808, total=   4.3s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112 \n",
      "[15:45:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112, score=0.806, total=   3.5s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112 \n",
      "[15:45:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112, score=0.806, total=   4.0s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112 \n",
      "[15:46:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=0.01, max_delta_step=20, max_depth=0, min_child_weight=0, n_estimators=200, reg_alpha=1.0, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=0.22184379250849112, score=0.806, total=   4.3s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01 \n",
      "[15:46:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01, score=0.808, total=   1.3s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01 \n",
      "[15:46:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01, score=0.808, total=   1.3s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01 \n",
      "[15:46:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01 \n",
      "[15:46:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01 \n",
      "[15:46:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.01, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=20, max_depth=0, min_child_weight=5, n_estimators=50, reg_alpha=1e-09, reg_lambda=46.85025938470161, scale_pos_weight=35.21313331296706, subsample=0.01, score=0.806, total=   1.0s\n",
      "[CV] colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296 \n",
      "[15:46:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296, score=0.808, total=   1.3s\n",
      "[CV] colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296 \n",
      "[15:46:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296, score=0.808, total=   1.4s\n",
      "[CV] colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296 \n",
      "[15:46:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296, score=0.806, total=   1.2s\n",
      "[CV] colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296 \n",
      "[15:46:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296, score=0.806, total=   1.3s\n",
      "[CV] colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296 \n",
      "[15:46:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6812570945712288, colsample_bytree=0.9255542126305193, gamma=1e-09, learning_rate=0.11347077143689566, max_delta_step=20, max_depth=0, min_child_weight=2, n_estimators=50, reg_alpha=9.407353465872943e-07, reg_lambda=0.0029014165305388303, scale_pos_weight=4.033072102102875, subsample=0.31343170673176296, score=0.806, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.8922764227642277\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0 \n",
      "[15:46:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0, score=0.909, total=   2.9s\n",
      "[CV] colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0 \n",
      "[15:46:29] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0, score=0.919, total=   2.9s\n",
      "[CV] colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:32] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0, score=0.867, total=   2.7s\n",
      "[CV] colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0 \n",
      "[15:46:34] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0, score=0.908, total=   2.7s\n",
      "[CV] colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0 \n",
      "[15:46:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.32952260024826985, colsample_bytree=0.06043227642193734, gamma=1.3076804628164894e-06, learning_rate=0.15844528454152426, max_delta_step=0, max_depth=35, min_child_weight=2, n_estimators=148, reg_alpha=1e-09, reg_lambda=4.810314289380104, scale_pos_weight=0.3665043935813407, subsample=1.0, score=0.878, total=   2.9s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0 \n",
      "[15:46:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0, score=0.808, total=   2.5s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0 \n",
      "[15:46:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0, score=0.808, total=   2.5s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0 \n",
      "[15:46:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0, score=0.806, total=   2.5s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0 \n",
      "[15:46:47] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0, score=0.806, total=   2.4s\n",
      "[CV] colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0 \n",
      "[15:46:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=1.0, colsample_bytree=0.2992200650587729, gamma=0.49999999999999994, learning_rate=0.030487491798147477, max_delta_step=0, max_depth=0, min_child_weight=4, n_estimators=108, reg_alpha=0.0006070131179256017, reg_lambda=1e-09, scale_pos_weight=499.99999999999994, subsample=1.0, score=0.806, total=   2.4s\n",
      "[CV] colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0 \n",
      "[15:46:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0, score=0.192, total=   1.9s\n",
      "[CV] colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0 \n",
      "[15:46:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0, score=0.192, total=   1.9s\n",
      "[CV] colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0 \n",
      "[15:46:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0, score=0.194, total=   1.5s\n",
      "[CV] colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0 \n",
      "[15:46:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0, score=0.194, total=   1.1s\n",
      "[CV] colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0 \n",
      "[15:46:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.35741069051885505, colsample_bytree=1.0, gamma=2.178932790999233e-07, learning_rate=0.01, max_delta_step=4, max_depth=47, min_child_weight=2, n_estimators=50, reg_alpha=4.3879979044321935e-08, reg_lambda=1000.0, scale_pos_weight=0.0001303927919489785, subsample=1.0, score=0.194, total=   1.8s\n",
      "[CV] colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968 \n",
      "[15:47:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968, score=0.869, total=   1.5s\n",
      "[CV] colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968 \n",
      "[15:47:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968, score=0.859, total=   1.6s\n",
      "[CV] colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968 \n",
      "[15:47:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968, score=0.857, total=   1.4s\n",
      "[CV] colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968 \n",
      "[15:47:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968, score=0.918, total=   1.5s\n",
      "[CV] colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968 \n",
      "[15:47:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.31689306457112004, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.1337452497560447, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=73, reg_alpha=1.0349082724231928e-05, reg_lambda=2.4467291387860016e-05, scale_pos_weight=19.08510916336744, subsample=0.7792315003552968, score=0.847, total=   1.8s\n",
      "[CV] colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0 \n",
      "[15:47:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0, score=0.909, total=   3.1s\n",
      "[CV] colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0 \n",
      "[15:47:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0, score=0.909, total=   3.2s\n",
      "[CV] colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0 \n",
      "[15:47:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0, score=0.857, total=   3.0s\n",
      "[CV] colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0 \n",
      "[15:47:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0, score=0.908, total=   3.0s\n",
      "[CV] colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0 \n",
      "[15:47:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.8334188356048486, colsample_bytree=0.44042004571838084, gamma=3.305283648712307e-05, learning_rate=0.06782508534975051, max_delta_step=6, max_depth=13, min_child_weight=3, n_estimators=127, reg_alpha=7.603252202420129e-06, reg_lambda=0.004819075740673885, scale_pos_weight=0.2765835986785136, subsample=1.0, score=0.867, total=   3.1s\n",
      "[CV] colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01 \n",
      "[15:47:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01, score=0.192, total=   6.4s\n",
      "[CV] colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01 \n",
      "[15:47:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01, score=0.192, total=   4.3s\n",
      "[CV] colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01 \n",
      "[15:47:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01, score=0.194, total=   6.5s\n",
      "[CV] colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01 \n",
      "[15:47:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01, score=0.194, total=   3.7s\n",
      "[CV] colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01 \n",
      "[15:47:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.7351685882237311, colsample_bytree=0.6282173601611164, gamma=0.021280254429092534, learning_rate=0.03501061593379533, max_delta_step=13, max_depth=41, min_child_weight=1, n_estimators=200, reg_alpha=1e-09, reg_lambda=0.0001728372112897385, scale_pos_weight=6.872297570550146e-05, subsample=0.01, score=0.194, total=   5.9s\n",
      "[CV] colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291 \n",
      "[15:47:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291, score=0.192, total=   4.1s\n",
      "[CV] colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291 \n",
      "[15:47:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291, score=0.192, total=   4.6s\n",
      "[CV] colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291 \n",
      "[15:47:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291, score=0.194, total=   2.7s\n",
      "[CV] colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291 \n",
      "[15:48:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291, score=0.194, total=   4.2s\n",
      "[CV] colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291 \n",
      "[15:48:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6786079903997393, colsample_bytree=0.5904296003940921, gamma=0.000908694416474599, learning_rate=0.07049744363189675, max_delta_step=12, max_depth=46, min_child_weight=2, n_estimators=138, reg_alpha=6.324048435929487e-05, reg_lambda=17.1004858577675, scale_pos_weight=9.263806022187338e-05, subsample=0.3631219774028291, score=0.194, total=   2.6s\n",
      "[CV] colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0 \n",
      "[15:48:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0, score=0.889, total=   2.6s\n",
      "[CV] colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0 \n",
      "[15:48:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0, score=0.919, total=   2.7s\n",
      "[CV] colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0 \n",
      "[15:48:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0, score=0.847, total=   3.3s\n",
      "[CV] colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0 \n",
      "[15:48:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0, score=0.898, total=   3.1s\n",
      "[CV] colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0 \n",
      "[15:48:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  colsample_bylevel=0.6126118258298363, colsample_bytree=0.046176404743748685, gamma=1.0634094096078316e-09, learning_rate=0.19091804791137235, max_delta_step=0, max_depth=50, min_child_weight=3, n_estimators=164, reg_alpha=0.0005190953070978562, reg_lambda=0.05762564927505769, scale_pos_weight=0.28391869110500917, subsample=1.0, score=0.867, total=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.8963414634146342\n",
      "[15:48:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('colsample_bylevel', 0.32952260024826985), ('colsample_bytree', 0.06043227642193734), ('gamma', 1.3076804628164894e-06), ('learning_rate', 0.15844528454152426), ('max_delta_step', 0), ('max_depth', 35), ('min_child_weight', 2), ('n_estimators', 148), ('reg_alpha', 1e-09), ('reg_lambda', 4.810314289380104), ('scale_pos_weight', 0.3665043935813407), ('subsample', 1.0)])\n"
     ]
    }
   ],
   "source": [
    "xgbcl = xgb.XGBClassifier()\n",
    "xgb_bayes_search = BayesSearchCV(xgbcl, space, n_iter=32, # specify how many iterations\n",
    "                                    scoring=None, n_jobs=1, cv=5, verbose=3, random_state=42, n_points=12,\n",
    "                                 refit=True)\n",
    "xgb_bayes_search.fit(X_train, y_train.ravel(), callback = on_step)\n",
    "print(xgb_bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Best Model from the Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#either print out from the optimisation or run the ordered dict.\n",
    "#print(xgb_bayes_search.best_params_)\n",
    "best_params = OrderedDict([('colsample_bylevel', 1.0), ('colsample_bytree', 1.0), ('gamma', 0.07059904760306446), ('learning_rate', 0.011073929920126888), ('max_delta_step', 20), ('max_depth', 29), ('min_child_weight', 4), ('n_estimators', 52), ('reg_alpha', 1e-09), ('reg_lambda', 1000.0), ('scale_pos_weight', 0.2860271078350677), ('subsample', 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(**xgb_bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.ravel(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this model to predict the test set and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "#sees how accurate the model was when testing the test set\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "pcent = accuracy * 100.0\n",
    "print(\"The accuracy of this model is\" + str(pcent))\n",
    "xgb_predictions = model.predict(X_test)\n",
    "xgb_probs = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Function to create ROC Score and AUROC Graph\n",
    "#from matplotlib.pyplot import figure\n",
    "#figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "def evaluate_model(predictions, probs, y_pheno):\n",
    "   #Computes statistics and shows ROC curve.\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['recall'] = recall_score(y_pheno, predictions)\n",
    "    results['precision'] = precision_score(y_pheno, predictions)\n",
    "    results['roc'] = roc_auc_score(y_pheno, probs)\n",
    "    my_roccy = (\"(ROC SCORE: %.2f)\" % (roc_auc_score(y_pheno, probs)))\n",
    "    \n",
    "    # Calculate false positive rates and true positive rates\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_pheno, probs)\n",
    "    return model_fpr, model_tpr, my_roccy\n",
    "\n",
    "    #plt.figure(figsize = (8, 6))\n",
    "   # plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Plot both curves\n",
    "   # plt.plot(model_fpr, model_tpr, 'r', label = 'Holdout Data'+my_roccy)\n",
    "   # plt.legend();\n",
    "   # plt.xlabel('False Positive Rate'); \n",
    "   # plt.ylabel('True Positive Rate'); plt.title('AUROC Curve for Xgboost Classification of Flower Colour');\n",
    "   # plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(xgb_predictions, xgb_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold cross validation on training / holdout data, evaluation and AUROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model from best parameters and then evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_k_fold(m, x, y, k, hx, hy):\n",
    "    #model: xgboost model, should be with the best params available\n",
    "    #x: input data (eg. all samples and SNPS)\n",
    "    #y: labels\n",
    "    #k: number of folds for cross validation\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    fig1 = plt.figure(figsize=[12,12])\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    results = []\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    high = 0\n",
    "    best = m\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        prediction = m.fit(x[train],y[train].ravel()).predict_proba(x[test])\n",
    "        print(\"variables for auroc curve done. Processing fold accuracy + checking best model\")\n",
    "        y_pred = m.predict(x[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        print(\"The accuracy of this model is\" + str(pcent))\n",
    "        if(pcent > high):\n",
    "            high = pcent\n",
    "            best = m\n",
    "        fpr, tpr, t = roc_curve(y[test], prediction[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        results.append(pcent)\n",
    "        plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        i= i+1\n",
    "\n",
    "    plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "    \n",
    "    holdout_pred = best.predict(hx)\n",
    "    predictions = [round(value) for value in holdout_pred]\n",
    "    #sees how accurate the model was when testing the test set\n",
    "    accuracy = accuracy_score(hy, predictions)\n",
    "    pcent = accuracy * 100.0\n",
    "    print(pcent)\n",
    "    xgb_predictions = best.predict(hx)\n",
    "    xgb_probs = best.predict_proba(hx)[:, 1]\n",
    "    model_fpr, model_tpr, my_roccy = evaluate_model(xgb_predictions, xgb_probs, hy)\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'Holdout Data'+my_roccy, lw=2)\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Pubescence Density Training Model & Holdout Data')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    print(\"Holdout Accuracy: %.2f%%\" % (pcent))\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 27061)\n",
      "(615, 1)\n",
      "(154, 27061)\n",
      "(154, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is79.03225806451613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is93.54838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is96.7741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is95.16129032258065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is83.87096774193549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is83.60655737704919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is85.24590163934425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is85.24590163934425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is90.1639344262295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/mgill/.local/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is91.80327868852459\n",
      "88.31168831168831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Testing Accuracy: 88.45% (5.55%)\n",
      "Holdout Accuracy: 88.31%\n"
     ]
    }
   ],
   "source": [
    "#THESE ARE THE BEST PARAMETERS\n",
    "best_params = xgb_bayes_search.best_params_\n",
    "#best_params = OrderedDict([('colsample_bylevel', 1.0), ('colsample_bytree', 1.0), ('gamma', 0.07059904760306446), ('learning_rate', 0.011073929920126888), ('max_delta_step', 20), ('max_depth', 29), ('min_child_weight', 4), ('n_estimators', 52), ('reg_alpha', 1e-09), ('reg_lambda', 1000.0), ('scale_pos_weight', 0.2860271078350677), ('subsample', 1.0)])\n",
    "#load holdout data\n",
    "print(tt_vcf.shape)\n",
    "print(tt_pheno.shape)\n",
    "print(ho_vcf.shape)\n",
    "print(ho_pheno.shape)\n",
    "model_2 = xgb.XGBClassifier(**best_params) #if optimised in same session, other enter manually below\n",
    "#this function should average out 10 folds and training, with inital params optimised\n",
    "#average accuracy and std should be calculated along with a nice AUROC graph of train/test models\n",
    "#best model should be extracted for use on holdout set\n",
    "best_model = eval_k_fold(model_2, tt_vcf, tt_pheno, 10, ho_vcf, ho_pheno)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_model, open(\"PuD_kfold_10_XGB_QTL.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only load if not generated in same session\n",
    "best_model = pickle.load(open(\"PuD_kfold_10_XGB_QTL.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPS of Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "#best_model = pickle.load(open(\"FC_kfold_10_tt_from_all.pickle.dat\", \"rb\"))\n",
    "plt.figure(figsize = (20, 20))\n",
    "plot_importance(best_model, max_num_features=15, importance_type='gain', height=0.3)\n",
    "pyplot.show()\n",
    "\n",
    "##WTF???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping value so it doesn't include that in headers\n",
      "my X value is: 27061\n",
      "(617, 27061)\n",
      "my header list is: 27061\n",
      "27061\n"
     ]
    }
   ],
   "source": [
    "#This function essentially returns an array of dataframe headers the length of OHE'd input SNPs for training data\n",
    "#EG. It will be able to determine that feature 357310 is Gm13_17683957 but not what allele it is\n",
    "#eg. feature 357309 357310 and 357311 may all be one hot encoded versions of all possible values of Gm13_17683957\n",
    "#iterating through the saved OHE will by able to determine what specific allele the feature is but cannot determine\n",
    "#what SNP header it belongs to. Therefore combining these two methods you can determine both allele and SNP\n",
    "snp = []\n",
    "imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "fs_ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "x = 0\n",
    "n_headers = []\n",
    "le = LabelEncoder()\n",
    "#while (i < 10):\n",
    "for chunk in pd.read_csv(\"PuD_Merged_filtered.csv_train_testQTL_SNPS.csv\", chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "    chunk = chunk.T\n",
    "    if 'Value' in chunk.columns:\n",
    "        print(\"dropping value so it doesn't include that in headers\")\n",
    "        chunk = chunk.drop(columns=['Value'])\n",
    "    headers = chunk.columns\n",
    "    row_idx = chunk.index\n",
    "    chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "    #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "    chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "    chunk = chunk.apply(lambda col: le.fit_transform(col))\n",
    "    c_headers = chunk.columns\n",
    "    y = 0\n",
    "    for column in chunk:\n",
    "        d = (chunk[column].nunique())\n",
    "        n_headers.extend([c_headers[y] for i in range(d)])\n",
    "        #print(n_headers)\n",
    "        #print(l)\n",
    "        #n_headers.append(c_headers[y] * d)\n",
    "        #print(n_headers)\n",
    "        y = y + 1\n",
    "    #to double check that it would indeed be one hot encoded with this amount of columns\n",
    "    chunk = fs_ohe.fit_transform(chunk)\n",
    "    x = x + chunk.shape[1]\n",
    "    print(\"my X value is: \" + str(x))\n",
    "    print(chunk.shape)\n",
    "    print(\"my header list is: \" + str(len(n_headers)))\n",
    "print(len(n_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gm12_37598781 (T/G)\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "fs = [343112]\n",
    "scores = [3.2]\n",
    "snp_label = []\n",
    "for jj in fs:\n",
    "    jj_allele = find_snp_from_header(ohe, jj)\n",
    "    this_snp = (n_headers[jj] + ' ('+str(jj_allele)+')')\n",
    "    print(this_snp)\n",
    "    snp_label.append(this_snp)\n",
    "snp_label.reverse()\n",
    "scores.reverse()\n",
    "print(len(scores))\n",
    "print(len(snp_label))\n",
    "plt.barh(snp_label,scores)\n",
    "plt.title('SNP Importance XGBoost Pubescence Density')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = best_model.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f343109': 14.395666129999999, 'f211081': 1.472371292, 'f471230': 0.388008118, 'f485559': 0.619194031, 'f287101': 0.348964691, 'f150486': 0.0958331823, 'f468789': 0.8511053706666667, 'f246199': 1.11846352, 'f610468': 0.572887421, 'f299699': 0.138659477, 'f343077': 19.1088486, 'f343108': 3.1262145033333333, 'f230582': 0.113717332, 'f41142': 1.51198864, 'f307076': 0.358388901, 'f553864': 0.37010240549999995, 'f343126': 5.688968237625, 'f1220': 0.0118211508, 'f319274': 0.7404941915000001, 'f303711': 0.381921768, 'f92437': 0.126698971, 'f518819': 1.33851051, 'f41148': 1.1750324145, 'f79408': 0.177440643, 'f456715': 1.39748526, 'f315306': 0.546025753, 'f235321': 0.566467762, 'f612692': 0.17315423505, 'f474594': 1.1300297176666667, 'f471687': 0.95946312, 'f591400': 0.44310379, 'f174041': 0.257955551, 'f136380': 0.1684338, 'f42318': 0.569462776, 'f276733': 0.7903306182500001, 'f621274': 0.448719025, 'f199929': 0.172986031, 'f211083': 1.48188847425, 'f88106': 0.085868597, 'f490731': 0.95044899, 'f489465': 0.945051193, 'f579203': 0.510786057, 'f462910': 0.7457733765, 'f388553': 0.688879967, 'f577619': 0.455168724, 'f35079': 0.28383763125, 'f343113': 9.578489186999999, 'f153129': 0.75262226175, 'f586260': 0.170125484, 'f83580': 0.753277779, 'f371814': 0.506429672, 'f589622': 0.169477463, 'f463798': 0.437110901, 'f278696': 0.33147049, 'f33124': 0.122913361, 'f280378': 0.174890518, 'f153149': 0.90936023075, 'f612898': 0.276649445, 'f495814': 0.863825798, 'f40658': 0.286468506, 'f594311': 0.294021428, 'f264715': 0.5004634855, 'f569511': 0.158723831, 'f199835': 0.0973680168, 'f493771': 0.720705032, 'f241754': 0.8788290816666667, 'f349056': 0.353979111, 'f505169': 0.6482644085, 'f215513': 0.5739499925, 'f33213': 0.190024376, 'f153147': 1.17590094, 'f66757': 0.5801535451333334, 'f281006': 0.0473867692, 'f566476': 0.422401905, 'f299654': 0.2872262, 'f527771': 0.149353623, 'f131845': 0.169501558, 'f84868': 0.848562241, 'f548617': 0.354104996, 'f151953': 0.305786133, 'f197294': 0.0507473387, 'f29973': 0.976881981, 'f616032': 0.798044682, 'f54247': 0.284082413, 'f99689': 0.0245366096, 'f343112': 7.059740754555555, 'f525897': 0.814100266, 'f161162': 0.5168317953333333, 'f287209': 0.314266205, 'f62319': 0.0441775844, 'f248275': 0.7713210973333334, 'f512120': 0.132968619, 'f78198': 0.742370129, 'f154880': 0.193710327, 'f120787': 0.104186065, 'f427577': 1.0099563583333333, 'f215969': 0.473489285, 'f296487': 0.401325226, 'f341262': 0.099133938575, 'f147515': 0.383655548, 'f90309': 0.203166008, 'f199775': 0.0846046209, 'f299631': 0.824091196, 'f513187': 0.423369408, 'f385100': 0.370196342, 'f210599': 0.191656113, 'f469595': 1.11689854, 'f288955': 0.645895004, 'f250242': 0.366597176, 'f215631': 0.369214058, 'f194573': 0.18700628, 'f472856': 0.826586485, 'f197064': 0.169720531, 'f41546': 0.415993214, 'f457498': 0.293635845, 'f343129': 8.407975925, 'f545817': 0.810477257, 'f591402': 0.673508644, 'f238012': 0.158352837, 'f366007': 0.0603261478, 'f378260': 0.5917451583333333, 'f295848': 0.44810009, 'f144057': 0.273920536, 'f299729': 0.7136927845000001, 'f556529': 0.778807163, 'f523859': 0.655476093, 'f41146': 0.8075100835, 'f58851': 0.0621628053, 'f302916': 0.325336456, 'f343099': 4.3068292362000005, 'f215963': 0.6040117752499999, 'f299656': 0.81337142, 'f523792': 0.422065258, 'f349178': 0.285861015, 'f191621': 0.141004086, 'f235714': 0.0132994652, 'f465635': 0.6187769084, 'f321056': 0.133380815, 'f64688': 0.30784893, 'f544586': 0.224136353, 'f153131': 0.7094826705, 'f260338': 0.5003978609999999, 'f315066': 0.360331535, 'f64938': 0.183722496, 'f214945': 0.0733306482, 'f256876': 0.371767998, 'f365158': 0.117395386, 'f89044': 0.0645929202, 'f509785': 0.0596597157, 'f355400': 0.36790657, 'f64598': 0.425660133, 'f188052': 0.667216539, 'f504501': 0.534265995, 'f322440': 0.424627304, 'f622902': 0.36075147, 'f555660': 0.335357666, 'f38971': 0.125349075, 'f375379': 0.0202994645, 'f195757': 0.615815639, 'f217883': 0.356174469, 'f474595': 0.319473743, 'f497988': 0.0404005051, 'f254074': 0.829857349, 'f243661': 0.044727169, 'f61376': 0.47109103199999997, 'f490839': 0.352940559, 'f120695': 0.0609030686, 'f430839': 0.985045791, 'f190096': 0.202009052, 'f249516': 0.449760437, 'f46116': 0.0691566467, 'f307568': 0.920720577, 'f355144': 0.0420110375, 'f572124': 0.2225399015, 'f298802': 0.631680489, 'f312509': 0.386373281, 'f373747': 0.298731327, 'f474653': 0.107783556, 'f445651': 0.020414114, 'f344915': 1.01897478, 'f561076': 0.0985215157, 'f131483': 0.732370615, 'f540882': 0.623333454, 'f315307': 0.2258529665, 'f445132': 0.0209035873, 'f338732': 0.0260557272, 'f366501': 0.550418973, 'f168103': 0.293633461, 'f476286': 0.0407459773, 'f306864': 0.10690967, 'f382329': 0.691139698, 'f302861': 0.22149086, 'f588031': 0.0553845018, 'f248274': 0.5597845313333333, 'f446670': 0.449331284, 'f589778': 0.21296176325, 'f183302': 0.0180613995, 'f99129': 0.151484162, 'f307550': 1.00088882, 'f476389': 0.0524548404, 'f363189': 0.6784327029999999, 'f24335': 0.648421764, 'f567784': 0.354617596, 'f427963': 0.252915859, 'f167242': 0.0448773876, 'f347460': 0.57589674, 'f580214': 0.156125069, 'f430705': 0.141350985, 'f90577': 0.997555134, 'f179396': 0.879584789, 'f265956': 0.627162933, 'f157688': 0.0450450107, 'f308359': 0.0510805994, 'f215966': 0.562918425, 'f491651': 0.30770621075, 'f541885': 0.0994327068, 'f469625': 0.6464542154999999, 'f493634': 0.602637291, 'f191256': 0.59205389, 'f18066': 0.0800952464, 'f496260': 0.136483029, 'f491652': 0.586172938, 'f502840': 0.280259848, 'f296485': 0.0196847916, 'f259046': 0.146474056, 'f343127': 2.732318313, 'f485464': 0.8125669360000001, 'f253872': 0.211155131, 'f220093': 0.296811581, 'f612643': 0.334387302, 'f469631': 0.7963038684999999, 'f4816': 0.126955643, 'f332577': 0.613865852, 'f346384': 0.491283894, 'f91817': 0.0572556928, 'f358105': 0.693497896, 'f144063': 0.462998867, 'f136344': 0.2938634155, 'f320900': 0.188278437, 'f215075': 0.219510227, 'f406104': 0.514490843, 'f448131': 0.342570782, 'f10949': 0.568137169, 'f349976': 0.29582119, 'f245007': 0.0304808095, 'f363218': 0.946134329, 'f153208': 0.241057396, 'f364763': 0.778389931, 'f465637': 0.411220551, 'f72893': 0.4705514905, 'f17070': 0.449687481, 'f520860': 0.105506659, 'f506192': 0.5061112345000001, 'f264717': 0.748733759, 'f303249': 0.386570454, 'f13222': 0.159976944, 'f219904': 0.23982547955, 'f505187': 0.595214367, 'f364144': 0.536595821, 'f102963': 0.363110304, 'f430756': 0.250615597, 'f341326': 0.0646076202, 'f527867': 0.59950304, 'f120129': 0.181320667, 'f504067': 0.142042547, 'f598212': 0.0379581526, 'f553318': 0.0562381074, 'f150061': 0.244950056, 'f603012': 0.0205140114, 'f99131': 0.12745735, 'f375059': 0.747317672, 'f54617': 0.0231249854, 'f128513': 0.52317512, 'f43098': 0.3131872415, 'f323812': 0.149565458, 'f381807': 0.00378155708, 'f203929': 0.888664722, 'f608841': 0.318311691, 'f368409': 0.19269824, 'f292473': 0.24548649050000002, 'f343135': 1.0784531438307694, 'f217228': 0.6348929405, 'f220182': 0.748117924, 'f183893': 0.307529926, 'f561969': 0.00272607803, 'f218990': 0.188984692, 'f253169': 0.0896404684, 'f474401': 0.390909225, 'f553462': 0.282624483, 'f193892': 0.125243008, 'f409320': 0.376640558, 'f365964': 0.173664093, 'f263993': 0.199258089, 'f146802': 0.474320412, 'f343106': 2.73917913, 'f504916': 1.02047551, 'f56897': 0.273419678, 'f61651': 0.0135509372, 'f4064': 0.365722895, 'f553516': 0.181112051, 'f299555': 0.672183156, 'f35081': 0.29660964, 'f226172': 0.23415637, 'f244911': 0.507357359, 'f79837': 0.230879068, 'f392327': 0.0480275825, 'f391590': 0.00943175703, 'f111190': 0.325917006, 'f180488': 0.190074444, 'f184776': 0.191708326, 'f548428': 0.113973863, 'f614255': 0.649935365, 'f514860': 0.12861295, 'f25271': 0.388800919, 'f183955': 0.111778378, 'f509794': 0.0321648568, 'f377404': 0.0860861763, 'f343101': 2.6265111, 'f521951': 0.861501694, 'f86972': 0.461532593, 'f289751': 0.251592636, 'f501909': 0.0810998902, 'f98088': 0.621438622, 'f333276': 0.109800026, 'f402227': 0.6057024, 'f540339': 0.180105448, 'f140322': 0.0612475872, 'f504914': 0.941650746, 'f42442': 0.257366657, 'f225762': 0.21036379, 'f588191': 0.9752042365555555, 'f353440': 0.174668759, 'f65251': 0.307580233, 'f395857': 0.192878008, 'f575145': 0.679104388, 'f357642': 0.408239841, 'f189377': 0.0513441563, 'f146249': 0.48637104, 'f280392': 0.105318874, 'f250205': 0.178627729, 'f13555': 0.3633226755, 'f518973': 0.172285855, 'f12919': 0.199303105, 'f74968': 0.0606326163, 'f486410': 0.321621418, 'f338768': 0.212927222, 'f215700': 0.658938527, 'f82217': 0.224240229, 'f254227': 0.023601979, 'f65056': 0.333016515, 'f365689': 0.29843986, 'f358121': 0.549549818, 'f612634': 0.10060554, 'f83139': 0.73362422, 'f181124': 0.630015135, 'f500365': 0.371215343, 'f363807': 0.219915628, 'f173998': 0.0208365917, 'f130199': 0.0624448508, 'f41244': 0.125928909, 'f155879': 0.38978224, 'f235795': 0.343406558, 'f533858': 0.12513271, 'f535549': 0.2740666073333333, 'f260337': 0.391054749, 'f364917': 0.605239153, 'f546859': 0.165937364, 'f99505': 0.00551058352, 'f474612': 0.690862573, 'f471444': 0.904012084, 'f132289': 0.573583961, 'f103812': 0.0517517515, 'f14277': 0.318906069, 'f452490': 0.00287842751, 'f353024': 0.184155405, 'f63272': 0.060844779, 'f224241': 0.485788584, 'f481109': 0.159137011, 'f472706': 0.153184175, 'f600286': 0.0530032441, 'f209217': 0.0979481936, 'f366503': 0.42439848199999997, 'f283950': 0.154205412, 'f31352': 0.75962925, 'f356942': 0.368258953, 'f570128': 0.157978058, 'f253718': 0.115194559, 'f99150': 0.085480608, 'f113732': 0.0286713839, 'f343042': 0.31387960950000005, 'f56893': 0.210443333, 'f507417': 0.331194162, 'f614528': 0.101973981, 'f541887': 0.0316970348, 'f471534': 0.59360303, 'f363265': 0.618421316, 'f308970': 0.387684107, 'f588133': 0.133135319, 'f260518': 0.0192594528, 'f281452': 0.0318261795, 'f591055': 0.0951472595, 'f589111': 0.0367267579, 'f50707': 0.2564226293333333, 'f62032': 0.0073941946, 'f343090': 1.133588284, 'f505218': 0.62973249, 'f473412': 0.0534091741, 'f299660': 0.466089606, 'f503154': 0.265017271, 'f156724': 0.0405316353, 'f434875': 0.475562811, 'f203719': 0.283286095, 'f601986': 0.0513632298, 'f619187': 0.101152271, 'f356974': 0.630185485, 'f329246': 0.149698973, 'f85028': 0.055768013, 'f588200': 0.504350781, 'f77997': 0.0668220446, 'f554846': 0.2815186085, 'f447482': 0.0590587854, 'f147634': 0.0199165344, 'f469566': 0.7888817709999999, 'f222783': 0.5025241773333334, 'f179160': 0.48834765, 'f118925': 0.0688463449, 'f79184': 0.434180379, 'f277462': 0.178575516, 'f517303': 0.0633909702, 'f509734': 0.0233024973, 'f35686': 0.0791276395, 'f208882': 0.357433021, 'f227470': 0.208644331, 'f114463': 0.122739255, 'f608': 0.902649462, 'f514240': 0.387806058, 'f260796': 0.180057287, 'f175132': 0.11823082, 'f148309': 0.268679649, 'f489082': 0.145770669, 'f380064': 0.00979039073, 'f490948': 0.349242151, 'f378126': 0.033005476, 'f32146': 1.28511584, 'f365573': 0.700646579, 'f544960': 0.50360477, 'f495123': 0.260658264, 'f583440': 0.23658216, 'f377585': 0.057161808, 'f150766': 0.0440452993, 'f189635': 0.00802195817, 'f507478': 0.54773283, 'f246928': 0.286365986, 'f86658': 0.198707342, 'f166318': 0.029307723, 'f197795': 0.0114019103, 'f32091': 1.232488275, 'f506986': 0.458096385, 'f465890': 0.113686338, 'f190448': 0.208897591, 'f130734': 0.137157559, 'f343063': 0.771869421, 'f89469': 0.215340555, 'f248416': 0.0852950811, 'f497253': 0.475003242, 'f489253': 0.352145314, 'f508319': 0.289899588, 'f148917': 0.169193029, 'f577272': 0.0405266285, 'f365632': 0.66227138, 'f366018': 0.412392735, 'f411806': 0.116551764, 'f572439': 0.235716343, 'f500458': 0.095754385, 'f316214': 0.682696462, 'f545024': 0.442188382, 'f511412': 0.0141968094, 'f365533': 0.367156267, 'f580122': 0.211983562, 'f587574': 0.209445477, 'f382268': 0.117542744, 'f546189': 0.0234616902, 'f329211': 0.0362546816, 'f73602': 0.780511916, 'f437626': 0.562313557, 'f127690': 0.0186955966, 'f514129': 0.174602032, 'f470979': 0.0136327744, 'f249881': 0.164193556, 'f204423': 0.0509805381, 'f549817': 0.0352914035, 'f177028': 0.296501666, 'f349968': 0.198065817, 'f122642': 0.0280178189, 'f269753': 0.495651484, 'f621046': 0.218108043, 'f444511': 0.0482701957, 'f307615': 0.13135159, 'f189991': 0.424905598, 'f511565': 0.0762229264, 'f50251': 0.122226834, 'f240782': 0.0184664726, 'f227619': 0.986457963, 'f463435': 0.686155558, 'f40127': 0.470451713, 'f385297': 0.413205385, 'f227474': 0.054553628, 'f460651': 0.211895943, 'f323929': 0.0212933458, 'f593269': 0.100874536, 'f359240': 0.364912758, 'f349452': 0.108543277, 'f151906': 1.35930383, 'f507595': 0.419361502, 'f614258': 0.0854066908, 'f589206': 0.284481823, 'f615843': 0.103650212, 'f417207': 0.0186228752, 'f41180': 0.439275086, 'f523621': 0.342094183, 'f263672': 0.104501486, 'f506995': 0.105534419, 'f184462': 0.00884987414, 'f506935': 0.469680071, 'f330152': 0.166670322, 'f130731': 0.120764256, 'f223159': 0.136228085, 'f547372': 0.42935667899999996, 'f84847': 0.0995787531, 'f29469': 0.379588485, 'f13080': 0.0171190053, 'f123298': 0.127083778, 'f474198': 0.0702438354, 'f185198': 0.277120948, 'f251474': 0.100007057, 'f211898': 0.6175171134999999, 'f556306': 0.112343572, 'f485638': 0.444182277, 'f252278': 0.0349401161, 'f48112': 0.249224544, 'f53567': 0.154488921, 'f580119': 0.08682096, 'f64063': 0.0301607847, 'f227274': 0.24791491, 'f34754': 0.0283615589, 'f40970': 0.493454203, 'f89228': 0.0929541364, 'f160802': 0.0375119895, 'f449933': 0.511302829, 'f409475': 0.349339962, 'f500607': 0.229811668, 'f365539': 0.135535717, 'f349836': 0.650159836, 'f330802': 0.511345863, 'f368017': 0.203418612, 'f411592': 0.0080126524, 'f354951': 0.0187650435, 'f11766': 0.213483602, 'f241859': 0.000595826656, 'f199891': 0.122881293, 'f424864': 0.00970351696, 'f253171': 0.475600183, 'f254072': 0.192213178, 'f365091': 0.25265047, 'f343861': 0.089642331, 'f221473': 0.320650041, 'f207877': 0.160212517, 'f342999': 0.7899047905, 'f297757': 0.411525726, 'f259022': 0.121644616, 'f365048': 0.555494308, 'f613588': 0.0741965771, 'f505176': 0.353393018, 'f29596': 0.139309168, 'f472805': 0.00424993038, 'f256906': 0.284857094, 'f376478': 0.117592931, 'f256195': 0.0261257887, 'f444740': 0.520837188, 'f66755': 0.351593137, 'f554810': 0.316583872, 'f563696': 0.160694599, 'f17387': 0.0188661814, 'f34774': 0.14804846, 'f337492': 0.0385234803, 'f220550': 1.18115997, 'f516091': 0.576543212, 'f329806': 0.269289136, 'f240991': 0.221881866, 'f620219': 0.0936713219, 'f275987': 0.0175917149, 'f94295': 0.38605845, 'f375929': 0.0156488419, 'f160373': 0.0508419946, 'f588136': 1.24796891, 'f473411': 0.357585669, 'f454580': 0.119757652, 'f323208': 0.046072349, 'f445513': 0.112151071, 'f365408': 0.332522511, 'f219371': 0.226895869, 'f99212': 0.151721478, 'f63625': 0.0606548786, 'f275063': 1.16956413, 'f261991': 0.188073337, 'f223660': 0.075777173, 'f191052': 0.0489262901, 'f157897': 0.450623095, 'f217910': 0.387820482, 'f144236': 0.217594624, 'f19773': 0.127204537, 'f228130': 0.045394659, 'f125849': 0.6352585107500001, 'f377062': 0.48596554999999997, 'f287372': 0.18130397050000002, 'f476468': 0.119541168, 'f528307': 0.0969502926, 'f116': 0.0039645806, 'f547343': 0.342950955, 'f41387': 0.100643083, 'f480873': 0.22729106750000003, 'f589311': 0.312082767, 'f377310': 0.0459363461, 'f327672': 0.269146979, 'f502435': 0.126967192, 'f180349': 0.136719748, 'f365296': 0.00261151791, 'f318524': 0.1951031982, 'f378062': 0.215503395, 'f442226': 0.17549175, 'f535806': 0.109273612, 'f299687': 0.980579495, 'f219927': 0.259805799, 'f306155': 0.0534581617, 'f199612': 0.3005732895, 'f615402': 0.459100127, 'f66631': 0.277454734, 'f360177': 0.189823866, 'f621253': 0.146859527, 'f240803': 0.0290360451, 'f312325': 0.0665080696, 'f94316': 0.76526159, 'f90074': 0.364375472, 'f65992': 0.1924843195, 'f56971': 0.0613012314, 'f41369': 0.15968807, 'f194866': 0.0121290535, 'f165137': 0.160644472, 'f467355': 0.0325929523, 'f506147': 0.248222053, 'f613447': 0.107127607, 'f315915': 0.413917691, 'f32652': 0.42974174, 'f554848': 0.328692675, 'f141111': 0.175537229, 'f176085': 0.0370444059, 'f344300': 0.0413548797, 'f187537': 0.899895966, 'f335262': 0.262694716, 'f119260': 0.172924697, 'f12399': 0.0901611447, 'f372561': 0.502151012, 'f185414': 0.31768626, 'f589364': 0.34798797950000004, 'f333635': 0.122047305, 'f385692': 0.134090766, 'f397803': 0.265129209, 'f430815': 0.0188374519, 'f594219': 0.0642190576, 'f30329': 0.323518783, 'f78068': 0.101609305, 'f77663': 0.120413423, 'f559455': 0.0130676627, 'f365575': 0.70784013, 'f122192': 0.14561677, 'f11655': 0.0530815721, 'f272815': 0.805094838, 'f512577': 0.155968428, 'f145227': 0.366658568, 'f3122': 0.28709805, 'f377564': 0.180250287, 'f486142': 0.0641435385, 'f78103': 0.82449168, 'f471519': 0.4769025445, 'f599678': 0.342361331, 'f55135': 0.3336618245, 'f33306': 0.0507750511, 'f350800': 0.148669735, 'f140501': 0.172454745, 'f233662': 0.153879285, 'f343117': 0.964296401, 'f276807': 0.267306656, 'f416796': 0.0496076345, 'f372339': 0.637383819, 'f104720': 0.30777472250000004, 'f587003': 0.0496319532, 'f484831': 0.213821307, 'f547393': 0.0620806552, 'f622422': 0.261868119, 'f82897': 0.0674757212, 'f248477': 0.0433125272, 'f276151': 0.230963826, 'f218926': 0.190324485, 'f34622': 0.149010658, 'f264332': 0.5641192644999999, 'f56807': 0.431867719, 'f593194': 0.0268280804, 'f240959': 0.184618115, 'f66569': 0.152390063, 'f501901': 0.0680621862, 'f589472': 0.427261382, 'f235065': 0.231363416, 'f473804': 0.15029458699999998, 'f183789': 0.0616695881, 'f613690': 0.16782599294999997, 'f8472': 0.269726396, 'f125343': 0.09785196204999999, 'f240309': 0.0263043866, 'f177843': 0.0789286494, 'f53568': 0.334241986, 'f32645': 0.168299198, 'f285544': 0.0338858366, 'f343132': 0.6109107233333333, 'f471536': 0.438355565, 'f555140': 0.128131896, 'f64818': 0.358155429, 'f597681': 0.0794069767, 'f303971': 0.18692404, 'f70993': 0.0896357298, 'f621260': 0.736593068, 'f607170': 0.247478873, 'f372553': 0.383848965, 'f620199': 0.34403038, 'f65369': 0.280748129, 'f453650': 0.0284783952, 'f40112': 0.13455602023333332, 'f281584': 0.0577517301, 'f355507': 0.00175981224, 'f275047': 0.586707026, 'f323318': 0.339767456, 'f135831': 0.0788466334, 'f41183': 0.475898534, 'f469580': 0.112984963, 'f365135': 0.105936408, 'f364976': 0.40964371, 'f541531': 0.27376762050000003, 'f453405': 0.210670948, 'f26297': 0.0662271976, 'f238137': 0.149595544, 'f90265': 0.0280820876, 'f329063': 0.0196741335, 'f185098': 0.1994026305, 'f40946': 0.552149832, 'f308766': 0.31709376, 'f119584': 0.0977268219, 'f130729': 0.0780515075, 'f236999': 0.333286107, 'f270490': 0.0354973599, 'f338697': 0.301685631, 'f131940': 0.27238214, 'f201008': 0.0921145678, 'f587465': 0.0254555941, 'f211920': 0.766269743, 'f485602': 0.439605415, 'f409790': 0.175506115, 'f597421': 0.156258941, 'f402431': 0.0236733928, 'f11756': 0.283798665, 'f443821': 0.0308779292, 'f620359': 0.230052471, 'f588949': 0.0829440951, 'f222882': 0.2985673845, 'f185112': 0.0442965031, 'f542356': 0.0128458068, 'f270224': 0.422409296, 'f432908': 0.134490728, 'f444653': 0.313009322, 'f292200': 0.155181527, 'f32654': 0.0747851133, 'f306090': 0.702329218, 'f265560': 0.253331661, 'f17829': 0.112696826, 'f309885': 0.0263882875, 'f377422': 0.0132176839, 'f11757': 0.436793834, 'f355633': 0.289819002, 'f452945': 0.00973097607, 'f80932': 0.168190002, 'f616628': 0.0136256218, 'f386122': 0.0418171734, 'f151899': 0.687650144, 'f318619': 0.218399525, 'f297109': 0.104632616, 'f128072': 0.0400089659, 'f94153': 0.0141058564, 'f316509': 0.320491016, 'f472307': 0.016782999, 'f474683': 0.262084782, 'f303228': 0.11932826, 'f365801': 0.560073833, 'f223729': 0.322107047, 'f79327': 0.215887785, 'f508165': 0.0389268994, 'f376429': 0.0138902068, 'f374157': 0.433122993, 'f547330': 0.253153443, 'f93842': 0.09655654455000001, 'f34499': 0.5034529863333334, 'f409823': 0.235667929, 'f610441': 0.241650879, 'f79579': 0.0844451785, 'f621251': 0.383539036, 'f38609': 0.0198982731, 'f620294': 0.27579230050000003, 'f545018': 0.196325839, 'f183269': 0.216447234, 'f40945': 0.10368773326666665, 'f527589': 0.500268221, 'f343069': 0.0717098266, 'f5510': 0.1964432, 'f378853': 0.142329931, 'f271015': 0.0286438465, 'f588932': 0.51047653, 'f494038': 0.269379258, 'f188087': 0.119176745, 'f370055': 0.074511528, 'f291247': 0.487134308, 'f55556': 0.111954592, 'f514414': 0.291376352, 'f60413': 0.199524283, 'f580377': 0.06082654, 'f370325': 0.615790367, 'f78796': 0.455963403, 'f502972': 0.201273024, 'f392049': 0.115393281, 'f587148': 0.0415326357, 'f65621': 0.0347962901, 'f148288': 0.202775717, 'f62056': 0.0233062506, 'f220996': 0.662782848, 'f570267': 0.306698471, 'f590629': 0.00743649527, 'f609915': 0.240440905, 'f37372': 0.195211709, 'f368595': 0.101174831, 'f402763': 0.410923749, 'f40115': 0.24955933805, 'f366331': 0.0218247175, 'f151894': 0.721919268, 'f98089': 0.224322021, 'f469368': 0.0875650644, 'f550093': 0.0343898386, 'f240657': 0.0234179907, 'f85085': 0.286923826, 'f348037': 0.180962145, 'f530544': 0.061542511, 'f405528': 0.0255854372, 'f220494': 0.719078183, 'f131955': 0.238550484, 'f218453': 0.0702057481, 'f63302': 0.0303177238, 'f617253': 0.145906866, 'f171016': 0.0236202404, 'f588934': 0.164470971, 'f180963': 0.0749576688, 'f41064': 0.566898823, 'f41140': 0.459198594, 'f482977': 0.21998471, 'f226457': 0.158852935, 'f511943': 0.0728843212, 'f60307': 0.0214575417, 'f365078': 0.0302415192, 'f39669': 0.212307915, 'f385129': 0.125979096, 'f587898': 0.0946093202, 'f363040': 0.364340663, 'f67843': 0.190220594, 'f105135': 0.117137432, 'f470920': 0.00060871616, 'f189801': 0.316988349, 'f168777': 0.0437482335, 'f471813': 0.195432067, 'f593903': 0.191313624, 'f34485': 0.0302102566, 'f91333': 0.018031083, 'f535733': 0.296293616, 'f621271': 0.226422896, 'f12918': 0.00359284878, 'f496200': 0.278191954, 'f185171': 0.243731499, 'f188522': 0.125401497, 'f594818': 0.0662791729, 'f518733': 0.0243932866, 'f190341': 0.390024006, 'f357291': 0.00808025151, 'f30972': 0.183929801, 'f103098': 0.103366256, 'f220499': 0.630464435, 'f11145': 0.276186615, 'f402144': 0.0107095353, 'f190635': 0.273695827, 'f517834': 0.0771061182, 'f514435': 0.0618279576, 'f191022': 0.247496188, 'f243337': 0.102429986, 'f281667': 0.0278165936, 'f392103': 0.433790773, 'f181726': 0.0351217277, 'f174039': 0.206206083, 'f179327': 0.0546406209, 'f270209': 0.160254583, 'f93322': 0.106130213, 'f230707': 0.236411929, 'f608838': 0.229517281, 'f429576': 0.0749169588, 'f546917': 0.131175011, 'f554773': 0.0994442105, 'f237320': 0.0268414617, 'f351842': 0.086468786, 'f431587': 0.0534519851, 'f321319': 0.233594418, 'f589446': 0.22313893833333334, 'f100142': 0.0119872298, 'f223704': 0.290400445, 'f201973': 0.19679311649999998, 'f277926': 0.0770847201, 'f18149': 0.0195686221, 'f235784': 0.356220156, 'f188224': 0.017132163, 'f208698': 0.279059231, 'f58804': 0.0937379003, 'f128329': 0.0351742506, 'f398670': 0.131206423, 'f142475': 0.407395065, 'f155247': 0.0915503204, 'f363394': 0.00826781988, 'f155923': 0.264242232, 'f507182': 0.0159108285, 'f589443': 0.0984863043, 'f102893': 0.0359525681, 'f34455': 0.5397754410000001, 'f216317': 0.279851854, 'f39809': 0.206932127, 'f348940': 0.149629235, 'f158476': 0.0690541863, 'f220496': 0.303347826, 'f292287': 0.0488224924, 'f343239': 0.0582523532, 'f274377': 0.22914599383333334, 'f516728': 0.112002432, 'f122733': 0.169527888, 'f318127': 0.116649687, 'f237001': 0.0908626914, 'f248200': 0.178793758, 'f253877': 0.12362206, 'f473038': 0.0329877138, 'f614672': 0.253207892, 'f343251': 0.0533845499, 'f198581': 0.196788132, 'f685': 0.120612383, 'f182167': 0.0352242589, 'f224232': 0.1910189765, 'f498139': 0.113126218, 'f28783': 0.0555192828, 'f219921': 0.42575784, 'f603944': 0.221524119, 'f388689': 0.170185745, 'f545783': 0.0193106532, 'f78416': 0.0282053277, 'f58792': 0.193408251, 'f205508': 0.176953614, 'f399006': 0.0440820456, 'f222888': 0.177483499, 'f356789': 0.0344597101, 'f17882': 0.0368479267, 'f514331': 0.0663679689, 'f377666': 0.0054192245, 'f136698': 0.204329848, 'f368340': 0.10893154875, 'f134830': 0.255469739, 'f303258': 0.09218961, 'f619521': 0.0209100842, 'f313802': 0.0459514484, 'f326330': 0.141230494, 'f347975': 0.034332931, 'f158824': 0.253302574, 'f88326': 0.124339074, 'f209247': 0.056849122, 'f186740': 0.0274241641, 'f467697': 0.268369019, 'f46591': 0.228187203, 'f404480': 0.153749645, 'f442520': 0.0247022882, 'f563152': 0.129476309, 'f264331': 0.5058723293333334, 'f589201': 0.349214673, 'f480874': 0.152026594, 'f185397': 0.135420918, 'f305237': 0.0376315713, 'f546651': 0.248005033, 'f259047': 0.141645193, 'f104267': 0.0593928695, 'f375968': 0.0178372581, 'f282702': 0.199454546, 'f127745': 0.198572278, 'f414566': 0.131456405, 'f324628': 0.0790381879, 'f589398': 0.121739492, 'f546929': 0.00240564346, 'f68371': 0.4531122543333333, 'f220311': 0.2806801795, 'f317957': 0.217117906, 'f312976': 0.131764114, 'f356254': 0.0435967445, 'f621587': 0.0455304384, 'f282207': 0.1673167396666667, 'f148991': 0.0816520154, 'f487179': 0.19769913, 'f311604': 0.0559586883, 'f58987': 0.131087109, 'f363135': 0.0540655702, 'f589440': 0.10493052, 'f131939': 0.01016967, 'f506936': 0.471004397, 'f533220': 0.198318571, 'f349677': 0.0953063369, 'f619636': 0.0122775435, 'f343086': 0.0729574859, 'f444755': 0.215804756, 'f343138': 0.0390587524, 'f589400': 0.0909787118, 'f60415': 0.013286531, 'f445006': 0.0235834122, 'f218505': 0.254334867, 'f166573': 0.122887403, 'f576698': 0.10181424, 'f372676': 0.193879731, 'f511922': 0.135663003, 'f286569': 0.0526129603, 'f555455': 0.0256373361, 'f189870': 0.0383389778, 'f383467': 0.172099233, 'f621284': 0.109836817, 'f589353': 0.0137305856, 'f609773': 0.0626336038, 'f615185': 0.0134136081, 'f183304': 0.14784503, 'f240808': 0.0814437866, 'f583439': 0.0341451168, 'f40110': 0.469416231, 'f295500': 0.087463215, 'f545021': 0.357527524, 'f204475': 0.0112671852, 'f88266': 0.00841535255, 'f61619': 0.196318686, 'f589433': 0.170283794, 'f491976': 0.244788229, 'f217825': 0.159654945, 'f154772': 0.0739984289, 'f226856': 0.204353869, 'f465850': 0.0627521276, 'f390754': 0.0105622411, 'f443361': 0.043638669, 'f474610': 0.514958262, 'f66718': 0.0937622488, 'f592745': 0.0202325583, 'f461839': 0.238699093, 'f241401': 0.0958672613, 'f328095': 0.1136778, 'f251803': 0.124075055, 'f223511': 0.0434268117, 'f444483': 0.446573913, 'f549780': 0.33712703, 'f219080': 0.0684202909, 'f505268': 0.18277958, 'f410089': 0.147033036, 'f355491': 0.0201884508, 'f183861': 0.117582917, 'f553218': 0.0236659944, 'f57302': 0.0760551393, 'f271044': 0.0424818993, 'f99198': 0.197891206, 'f224351': 0.0831660032, 'f16118': 0.0277760029, 'f471530': 0.377796233, 'f434869': 0.220618784, 'f310614': 0.1387118995, 'f306977': 0.00388330221, 'f371887': 0.0136116045, 'f62998': 0.0585624464, 'f248742': 0.0879426003, 'f372544': 0.390346527, 'f458704': 0.138180047, 'f123073': 0.0471143723, 'f270441': 0.0210587867, 'f343118': 0.285820395, 'f587583': 0.166562587, 'f219155': 0.0296053551, 'f352529': 0.139737666, 'f465576': 0.0210648179, 'f549850': 0.0547057018, 'f363168': 0.11618571, 'f121732': 0.0905211568, 'f110260': 0.035344094, 'f36209': 0.253855824, 'f456608': 0.0352023691, 'f552751': 0.141271949, 'f363203': 0.0394600034, 'f316379': 0.0103992224, 'f247605': 0.373809099, 'f318620': 0.410222381, 'f104278': 0.247016788, 'f2530': 0.0977025628, 'f553711': 0.039437592, 'f184835': 0.118427634, 'f512317': 0.0742548555, 'f621283': 0.42704019, 'f466674': 0.0494543165, 'f622414': 0.348541975, 'f199614': 0.243198276, 'f364119': 0.11302799, 'f537420': 0.0884272009, 'f223405': 0.112608612, 'f2844': 0.0461540818, 'f402967': 0.166959882, 'f79326': 0.0704199374, 'f298792': 0.0436362475, 'f316221': 0.291816831, 'f286714': 0.159576416, 'f589233': 0.115600407, 'f292616': 0.0598803759, 'f229394': 0.0406955928, 'f521017': 0.20013696, 'f148876': 0.124333739, 'f275761': 0.0162600279, 'f529359': 0.133713454, 'f21780': 0.0056411624, 'f275029': 0.388891548, 'f204207': 0.17409569, 'f590159': 0.161702812, 'f35452': 0.148997009, 'f188582': 0.209488809, 'f509120': 0.0561266132, 'f379327': 0.156765133, 'f20472': 0.0169175863, 'f299662': 0.233753204, 'f267387': 0.145386457, 'f387613': 0.0484288931, 'f425055': 0.221109271, 'f131814': 0.103624761, 'f202116': 0.0611258708, 'f81820': 0.18515107, 'f368732': 0.11550355, 'f59155': 0.0124443183, 'f324491': 0.0389725491, 'f427656': 0.0888187885, 'f519137': 0.124875307, 'f251473': 0.0842778683, 'f29046': 0.00570493937, 'f90591': 0.0312634557, 'f577812': 0.0683748722, 'f221729': 0.011413157, 'f83049': 0.173408359, 'f223950': 0.112094939, 'f454621': 0.08298558, 'f529117': 0.064011961035, 'f479064': 0.0157428198, 'f166717': 0.0998825133, 'f379357': 0.0590813458, 'f543952': 0.00720308907, 'f240806': 0.381045252, 'f153450': 0.0283495188, 'f589236': 0.27053383, 'f266926': 0.0219411887, 'f528509': 0.244431198, 'f547955': 0.101102233, 'f256301': 0.0403975658, 'f28329': 0.393894523, 'f474628': 0.168806046, 'f234912': 0.0265840087, 'f34570': 0.0790906549, 'f52800': 0.0252165161, 'f355678': 0.113250673, 'f536320': 0.000798642635, 'f548160': 0.133286715, 'f100990': 0.114988327, 'f489902': 0.0552607179, 'f147587': 0.0350684524, 'f557088': 0.141402841, 'f73858': 0.0804755092, 'f185530': 0.0380598903, 'f355782': 0.370393326, 'f51168': 0.152525097, 'f198114': 0.0670998693, 'f526828': 0.0496253967, 'f621145': 0.156980276, 'f401166': 0.13839525, 'f326368': 0.102008581, 'f291842': 0.00557762384, 'f93849': 0.280486643, 'f351659': 0.0369349718, 'f158258': 0.18266955, 'f400082': 0.0974201262, 'f470392': 0.0626498759, 'f252991': 0.272663534, 'f159297': 0.0570955575, 'f228766': 0.152609617, 'f490102': 0.0324275494, 'f3143': 0.0999141932, 'f507741': 0.0517612398, 'f558011': 0.119372576, 'f270320': 0.0377193987, 'f220271': 0.0118485801, 'f547375': 0.13949421, 'f100083': 0.0740716457, 'f189615': 0.0161848888, 'f461821': 0.0962296724, 'f478357': 0.0169690251, 'f200245': 0.0551188104, 'f79942': 0.142364636, 'f409012': 0.0274019837, 'f297184': 0.0312602445, 'f452100': 0.0537593365, 'f58028': 0.00461558811, 'f272818': 0.221137881, 'f203981': 0.0370203033, 'f500631': 0.176119804, 'f292599': 0.0852358043, 'f52089': 0.175847739, 'f35932': 0.120530903, 'f568697': 0.00282806158, 'f130516': 0.00955120102, 'f39961': 0.171263903, 'f467520': 0.105454907, 'f55358': 0.0335718989, 'f203982': 0.040536847, 'f372559': 0.372483164, 'f236052': 0.0527325273, 'f293256': 0.215942591, 'f382543': 0.0302191246, 'f444472': 0.108443856, 'f357972': 0.0222271085, 'f222298': 0.131832659, 'f275971': 0.0496795177, 'f182159': 0.00743323565, 'f130447': 0.00787425786, 'f29637': 0.178193644, 'f152547': 0.0630939305, 'f380801': 0.00707144476, 'f26684': 0.114047348, 'f17844': 0.050091207, 'f63939': 0.0347838253, 'f189457': 0.108938485, 'f303970': 0.0851783752, 'f221448': 0.0019813478, 'f25444': 0.00619950332, 'f5801': 0.171494514, 'f509627': 0.0845651031, 'f56908': 0.00068116188, 'f589430': 0.206109568, 'f450970': 0.0208397284, 'f217489': 0.130672663, 'f502495': 0.0430480242, 'f190968': 0.308786303, 'f411694': 0.0141591541, 'f434287': 0.1556651, 'f545806': 0.0892112255, 'f518346': 0.0612459183, 'f296929': 0.0967329144, 'f554610': 0.0569033921, 'f197097': 0.0461882912, 'f533199': 0.121283412, 'f607313': 0.025391072, 'f370411': 0.319463223, 'f132309': 0.251483232, 'f495706': 0.143101513, 'f365786': 0.0128638744, 'f236969': 0.0673250183, 'f187558': 0.106090873, 'f312428': 0.0563833117, 'f302990': 0.113180503, 'f33452': 0.041436851, 'f472599': 0.220900133, 'f197349': 0.106587976, 'f62190': 0.0655683577, 'f219242': 0.188503623, 'f136765': 0.105543554, 'f306901': 0.0536180995, 'f252026': 0.106331035, 'f543147': 0.0423246026, 'f599203': 0.0910433531, 'f332503': 0.0517117381, 'f384218': 0.253295958, 'f497407': 0.235618174, 'f55984': 0.209421396, 'f79409': 0.0323163867, 'f244700': 0.23898302, 'f90771': 0.0527762808, 'f323000': 0.186838686, 'f391556': 0.100167036, 'f554914': 0.0376428366, 'f518074': 0.13518326, 'f502290': 0.040445596, 'f106523': 0.375457704, 'f365582': 0.146757513, 'f283807': 0.0320426226, 'f118589': 0.0239799004, 'f312378': 0.150421679, 'f240145': 0.0730081499, 'f513003': 0.0197549481, 'f218537': 0.330370516, 'f287373': 0.21985963, 'f555895': 0.0106426738, 'f379299': 0.134651572, 'f87501': 0.114720702, 'f414033': 0.00631058216, 'f109915': 0.0423670225, 'f611996': 0.0360681415, 'f465716': 0.247178584, 'f383678': 0.104588717, 'f169170': 0.049141258, 'f70176': 0.0707107186, 'f175309': 0.0260495469, 'f366734': 0.0711700618}\n"
     ]
    }
   ],
   "source": [
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_f_header(fn,n_headers,ohe):\n",
    "    fn = fn[1:]\n",
    "    fn = int(fn)\n",
    "    allele = find_snp_from_header(ohe, fn)\n",
    "    this_snp = (n_headers[fn] + ' ('+str(allele)+')')\n",
    "    return this_snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n"
     ]
    }
   ],
   "source": [
    "#convert feature to actual SNP name\n",
    "i = 0\n",
    "new_dict = {}\n",
    "for key in my_dict:\n",
    "    new_key = rename_f_header(key, n_headers, ohe)\n",
    "    new_dict[new_key] = my_dict[key]\n",
    "    i = i + 1\n",
    "    print(str(i))\n",
    "    if(my_dict):\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gm12_37604329 (G/A)    71.051202\n",
      "Gm08_413808 (T/T)       2.054504\n",
      "Gm12_37596718 (C/G)    82.083473\n",
      "Gm12_37597634 (A/A)     2.163986\n",
      "Gm08_134209 (C/G)       0.384732\n",
      "                         ...    \n",
      "Gm12_37218274 (C/T)     0.144848\n",
      "Gm01_58698804 (G/A)     0.131102\n",
      "Gm01_58496573 (A/A)     0.123063\n",
      "Gm12_37601252 (A/A)     0.008376\n",
      "Gm01_58549713 (T/T)     0.149449\n",
      "Length: 776, dtype: float64\n",
      "                     F_Score(GAIN)\n",
      "Gm12_37604329 (G/A)      71.051202\n",
      "Gm08_413808 (T/T)         2.054504\n",
      "Gm12_37596718 (C/G)      82.083473\n",
      "Gm12_37597634 (A/A)       2.163986\n",
      "Gm08_134209 (C/G)         0.384732\n",
      "...                            ...\n",
      "Gm12_37218274 (C/T)       0.144848\n",
      "Gm01_58698804 (G/A)       0.131102\n",
      "Gm01_58496573 (A/A)       0.123063\n",
      "Gm12_37601252 (A/A)       0.008376\n",
      "Gm01_58549713 (T/T)       0.149449\n",
      "\n",
      "[776 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "new_fi = pd.Series(new_dict)\n",
    "print(new_fi)\n",
    "df = new_fi.to_frame()\n",
    "df = df.rename(columns = {0:'F_Score(GAIN)'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "indexes = df.nlargest(20, \"F_Score(GAIN)\").index\n",
    "values = df.nlargest(20, \"F_Score(GAIN)\").values.ravel()\n",
    "indexes = indexes[::-1]\n",
    "values = values[::-1]\n",
    "plt.barh(indexes, values)\n",
    "plt.title('SNP Importance XGBoost Pubescence Density')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#generate figure object\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "#load in the 20 lardest values and their SNP label\n",
    "indexes = df.nlargest(20, \"F_Score(GAIN)\").index\n",
    "values = df.nlargest(20, \"F_Score(GAIN)\").values.ravel()\n",
    "#reverse to make the largest be at the front\n",
    "indexes = indexes[::-1]\n",
    "values = values[::-1]\n",
    "#for each different chromosome you want to colour add a index(*_i) and value (*_v) array\n",
    "#black would be colour for singular/notinteresting chromosomes\n",
    "r_i = []\n",
    "r_v = []\n",
    "b_i = []\n",
    "b_v = []\n",
    "g_i = []\n",
    "g_v = []\n",
    "y_i = []\n",
    "y_v = []\n",
    "bl_i = []\n",
    "bl_v = []\n",
    "p_i = []\n",
    "p_v = []\n",
    "br_i = []\n",
    "br_v = []\n",
    "pu_i = []\n",
    "pu_v = []\n",
    "#for each value in the top n (default 20) check which chromosome it belongs to and add it to the colour array\n",
    "i = 0\n",
    "while i < len(indexes):\n",
    "    if('Gm08' in indexes[i]):\n",
    "        r_i.append(indexes[i])\n",
    "        r_v.append(values[i])\n",
    "    elif('Gm12' in indexes[i]):\n",
    "        b_i.append(indexes[i])\n",
    "        b_v.append(values[i])\n",
    "    elif('Gm01' in indexes[i]):\n",
    "        g_i.append(indexes[i])\n",
    "        g_v.append(values[i])\n",
    "    #elif('Gm11' in indexes[i]):\n",
    "    #    y_i.append(indexes[i])\n",
    "    #    y_v.append(values[i])\n",
    "    #elif('Gm08' in indexes[i]):\n",
    "    #    p_i.append(indexes[i])\n",
    "    #    p_v.append(values[i])\n",
    "   # elif('Gm04' in indexes[i]):\n",
    "   #     br_i.append(indexes[i])\n",
    "   #     br_v.append(values[i])\n",
    "   # elif('Gm13' in indexes[i]):\n",
    "   #     pu_i.append(indexes[i])\n",
    "   #     pu_v.append(values[i])\n",
    "    else:\n",
    "        bl_i.append(indexes[i])\n",
    "        bl_v.append(values[i])\n",
    "    i = i + 1\n",
    "#plot each of the arrays with appropriate colour and label graph\n",
    "plt.barh(bl_i, bl_v, color=\"black\")\n",
    "plt.barh(br_i, br_v, color=\"brown\")\n",
    "plt.barh(pu_i, pu_v, color=\"purple\")\n",
    "plt.barh(y_i, y_v, color=\"yellow\")\n",
    "plt.barh(p_i, p_v, color=\"orange\")\n",
    "plt.barh(g_i, g_v, color=\"green\")\n",
    "plt.barh(r_i, r_v, color=\"red\")\n",
    "plt.barh(b_i, b_v, color=\"blue\")\n",
    "plt.title('SNP Importance XGBoost Pubescence Density')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617,)\n",
      "(617, 1)\n",
      "10000\n",
      "(155,)\n",
      "(155, 1)\n",
      "10000\n",
      "(617, 1)\n",
      "(617, 9258)\n",
      "found 2\n",
      "found 2\n",
      "(615, 1)\n",
      "(615, 9258)\n",
      "(155, 1)\n",
      "(155, 9258)\n",
      "found 2\n",
      "(154, 1)\n",
      "(154, 9258)\n",
      "(615, 9258)\n",
      "(154, 9258)\n",
      "(615, 1)\n",
      "(154, 1)\n"
     ]
    }
   ],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data('PuD_Merged_filtered.csv_train_testQTL_SNPS.csv', 'PuD_Merged_filtered.csv_holdoutQTL_SNPS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 27061)\n",
      "(154, 9258)\n",
      "(154, 27061)\n"
     ]
    }
   ],
   "source": [
    "ohe = pickle.load(open(\"PuD_QTL_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is85.48387096774194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is93.54838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is93.54838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is96.7741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is82.25806451612904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is80.32786885245902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is83.60655737704919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is85.24590163934425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is90.1639344262295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "The accuracy of this model is91.80327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.96103896103897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Testing Accuracy: 88.28% (5.31%)\n",
      "Holdout Accuracy: 88.96%\n"
     ]
    }
   ],
   "source": [
    "seed = randint(0,5000)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=seed, max_features = 'sqrt',n_jobs=-1, verbose = 1)\n",
    "best_rf_model = eval_k_fold(rf_model, tt_vcf, tt_pheno, 10, ho_vcf, ho_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_rf_model, open(\"PuD_kfold_10_RF_QTL.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(best_model.feature_importances_, index=n_headers)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'attributes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-6fa5ba9deb5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'attributes_'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model (based upon DL Primer)\n",
    "### one hot encode and train test split like you usually do but follow the primer for the actual model part\n",
    "### for BC and MC use primer, for regression use Philipps notebooks...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617,)\n",
      "(617, 1)\n",
      "10000\n",
      "(155,)\n",
      "(155, 1)\n",
      "10000\n",
      "(617, 1)\n",
      "(617, 9258)\n",
      "found 2\n",
      "found 2\n",
      "(615, 1)\n",
      "(615, 9258)\n",
      "(155, 1)\n",
      "(155, 9258)\n",
      "found 2\n",
      "(154, 1)\n",
      "(154, 9258)\n",
      "(615, 9258)\n",
      "(154, 9258)\n",
      "(615, 1)\n",
      "(154, 1)\n"
     ]
    }
   ],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data('PuD_Merged_filtered.csv_train_testQTL_SNPS.csv', 'PuD_Merged_filtered.csv_holdoutQTL_SNPS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 27061)\n",
      "(154, 9258)\n",
      "(154, 27061)\n"
     ]
    }
   ],
   "source": [
    "ohe = pickle.load(open(\"PuD_QTL_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN_model(x_len):    \n",
    "    #del model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=14, \n",
    "                     input_shape=(x_len, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=10, kernel_size=10, \n",
    "                     input_shape=(12, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=8, kernel_size=8, \n",
    "                     input_shape=(10, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(48, activation='linear'))\n",
    "    model.add(Dense(32, activation='linear'))\n",
    "    model.add(Dense(16, activation='linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, \n",
    "                  metrics=['binary_accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cnn(x,y,k):\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    best_model = []\n",
    "    results = []\n",
    "    highest = 0\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "        model = build_CNN_model(x[train].shape[1])\n",
    "        bs = ((x[train].shape[0])/40)\n",
    "        bs = round(bs)\n",
    "        history = model.fit(x[train], y[train], validation_data=(x[test], y[test]), epochs=100, batch_size=bs)\n",
    "        _, accuracy = model.evaluate(x[test], y[test], batch_size=bs, verbose=0)\n",
    "        accuracy = accuracy *100\n",
    "        print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "        if(accuracy > highest):\n",
    "            highest = accuracy\n",
    "            best_model = model\n",
    "        results.append(accuracy)\n",
    "        del model\n",
    "        i = i + 1\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results))) \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 5s 9ms/sample - loss: 0.6564 - binary_accuracy: 0.6727 - val_loss: 0.5618 - val_binary_accuracy: 0.7742\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 846us/sample - loss: 0.4282 - binary_accuracy: 0.8535 - val_loss: 0.4670 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.3563 - binary_accuracy: 0.8788 - val_loss: 0.4029 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 709us/sample - loss: 0.3185 - binary_accuracy: 0.9024 - val_loss: 0.3970 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 713us/sample - loss: 0.2677 - binary_accuracy: 0.9114 - val_loss: 0.3968 - val_binary_accuracy: 0.8226\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 709us/sample - loss: 0.2377 - binary_accuracy: 0.9295 - val_loss: 0.4142 - val_binary_accuracy: 0.8387\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.2080 - binary_accuracy: 0.9403 - val_loss: 0.3891 - val_binary_accuracy: 0.8548\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.1955 - binary_accuracy: 0.9458 - val_loss: 0.3788 - val_binary_accuracy: 0.8065\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.1817 - binary_accuracy: 0.9512 - val_loss: 0.4390 - val_binary_accuracy: 0.8226\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.1660 - binary_accuracy: 0.9458 - val_loss: 0.4335 - val_binary_accuracy: 0.8548\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 922us/sample - loss: 0.1628 - binary_accuracy: 0.9494 - val_loss: 0.4388 - val_binary_accuracy: 0.8548\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.1282 - binary_accuracy: 0.9602 - val_loss: 0.6236 - val_binary_accuracy: 0.7581\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.1204 - binary_accuracy: 0.9675 - val_loss: 1.0234 - val_binary_accuracy: 0.7097\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0957 - binary_accuracy: 0.9729 - val_loss: 0.6410 - val_binary_accuracy: 0.7581\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0809 - binary_accuracy: 0.9783 - val_loss: 0.7287 - val_binary_accuracy: 0.7419\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0971 - binary_accuracy: 0.9747 - val_loss: 0.7189 - val_binary_accuracy: 0.7742\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0588 - binary_accuracy: 0.9837 - val_loss: 0.8963 - val_binary_accuracy: 0.7258\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.0518 - binary_accuracy: 0.9855 - val_loss: 0.6645 - val_binary_accuracy: 0.8065\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0561 - binary_accuracy: 0.9855 - val_loss: 1.0771 - val_binary_accuracy: 0.7419\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0663 - binary_accuracy: 0.9783 - val_loss: 0.7233 - val_binary_accuracy: 0.8065\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0532 - binary_accuracy: 0.9837 - val_loss: 1.1459 - val_binary_accuracy: 0.7097\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0478 - binary_accuracy: 0.9928 - val_loss: 1.7252 - val_binary_accuracy: 0.6290\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0452 - binary_accuracy: 0.9873 - val_loss: 1.4890 - val_binary_accuracy: 0.6452\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 706us/sample - loss: 0.0455 - binary_accuracy: 0.9892 - val_loss: 0.6051 - val_binary_accuracy: 0.8548\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0471 - binary_accuracy: 0.9892 - val_loss: 0.7669 - val_binary_accuracy: 0.8065\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0393 - binary_accuracy: 0.9910 - val_loss: 0.9081 - val_binary_accuracy: 0.7097\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 699us/sample - loss: 0.0391 - binary_accuracy: 0.9910 - val_loss: 0.7565 - val_binary_accuracy: 0.8065\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 699us/sample - loss: 0.0296 - binary_accuracy: 0.9946 - val_loss: 0.9980 - val_binary_accuracy: 0.7581\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0391 - binary_accuracy: 0.9892 - val_loss: 1.4075 - val_binary_accuracy: 0.6935\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0236 - binary_accuracy: 0.9964 - val_loss: 1.0884 - val_binary_accuracy: 0.7258\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0275 - binary_accuracy: 0.9964 - val_loss: 0.7925 - val_binary_accuracy: 0.7742\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0171 - binary_accuracy: 0.9982 - val_loss: 0.9341 - val_binary_accuracy: 0.7419\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0328 - binary_accuracy: 0.9855 - val_loss: 0.7877 - val_binary_accuracy: 0.8065\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0473 - binary_accuracy: 0.9837 - val_loss: 0.8767 - val_binary_accuracy: 0.7419\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.0279 - binary_accuracy: 0.9910 - val_loss: 1.2711 - val_binary_accuracy: 0.7258\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0346 - binary_accuracy: 0.9910 - val_loss: 0.7931 - val_binary_accuracy: 0.7903\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 706us/sample - loss: 0.0281 - binary_accuracy: 0.9928 - val_loss: 3.7034 - val_binary_accuracy: 0.3065\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.0369 - binary_accuracy: 0.9873 - val_loss: 1.0629 - val_binary_accuracy: 0.7581\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0399 - binary_accuracy: 0.9892 - val_loss: 0.8697 - val_binary_accuracy: 0.7903\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0203 - binary_accuracy: 0.9964 - val_loss: 0.7553 - val_binary_accuracy: 0.8065\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0196 - binary_accuracy: 0.9946 - val_loss: 0.8957 - val_binary_accuracy: 0.7742\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0219 - binary_accuracy: 0.9964 - val_loss: 0.8978 - val_binary_accuracy: 0.7903\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0235 - binary_accuracy: 0.9928 - val_loss: 0.8450 - val_binary_accuracy: 0.8065\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0267 - binary_accuracy: 0.9928 - val_loss: 0.7904 - val_binary_accuracy: 0.8065\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0140 - binary_accuracy: 0.9982 - val_loss: 0.7610 - val_binary_accuracy: 0.8387\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0194 - binary_accuracy: 0.9928 - val_loss: 0.9922 - val_binary_accuracy: 0.7742\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0354 - binary_accuracy: 0.9855 - val_loss: 0.8650 - val_binary_accuracy: 0.8065\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0264 - binary_accuracy: 0.9910 - val_loss: 1.8324 - val_binary_accuracy: 0.6290\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0180 - binary_accuracy: 0.9964 - val_loss: 0.9698 - val_binary_accuracy: 0.7742\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0179 - binary_accuracy: 0.9946 - val_loss: 0.7654 - val_binary_accuracy: 0.8548\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0281 - binary_accuracy: 0.9928 - val_loss: 1.0021 - val_binary_accuracy: 0.7581\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0100 - binary_accuracy: 1.0000 - val_loss: 0.9292 - val_binary_accuracy: 0.7903\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0157 - binary_accuracy: 0.9964 - val_loss: 0.8986 - val_binary_accuracy: 0.8065\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 701us/sample - loss: 0.0154 - binary_accuracy: 0.9964 - val_loss: 0.9956 - val_binary_accuracy: 0.8387\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 705us/sample - loss: 0.0192 - binary_accuracy: 0.9928 - val_loss: 1.1556 - val_binary_accuracy: 0.7581\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 716us/sample - loss: 0.0172 - binary_accuracy: 0.9946 - val_loss: 1.1124 - val_binary_accuracy: 0.7903\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 705us/sample - loss: 0.0209 - binary_accuracy: 0.9946 - val_loss: 0.7563 - val_binary_accuracy: 0.8548\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0193 - binary_accuracy: 0.9928 - val_loss: 0.9133 - val_binary_accuracy: 0.8226\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0169 - binary_accuracy: 0.9964 - val_loss: 1.1513 - val_binary_accuracy: 0.7742\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0160 - binary_accuracy: 0.9910 - val_loss: 0.7884 - val_binary_accuracy: 0.8387\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0189 - binary_accuracy: 0.9928 - val_loss: 0.8758 - val_binary_accuracy: 0.7742\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0075 - binary_accuracy: 1.0000 - val_loss: 0.8533 - val_binary_accuracy: 0.7903\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 926us/sample - loss: 0.0117 - binary_accuracy: 0.9946 - val_loss: 0.9260 - val_binary_accuracy: 0.7903\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 709us/sample - loss: 0.0072 - binary_accuracy: 0.9982 - val_loss: 0.9523 - val_binary_accuracy: 0.7742\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0156 - binary_accuracy: 0.9946 - val_loss: 1.0012 - val_binary_accuracy: 0.8226\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0244 - binary_accuracy: 0.9910 - val_loss: 1.0709 - val_binary_accuracy: 0.7419\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0116 - binary_accuracy: 0.9982 - val_loss: 0.8349 - val_binary_accuracy: 0.7903\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0078 - binary_accuracy: 0.9982 - val_loss: 0.8201 - val_binary_accuracy: 0.8065\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0127 - binary_accuracy: 0.9964 - val_loss: 0.7201 - val_binary_accuracy: 0.8387\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.0067 - binary_accuracy: 1.0000 - val_loss: 0.8352 - val_binary_accuracy: 0.7903\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0101 - binary_accuracy: 0.9982 - val_loss: 0.8533 - val_binary_accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0065 - binary_accuracy: 1.0000 - val_loss: 0.8219 - val_binary_accuracy: 0.8387\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.0156 - binary_accuracy: 0.9964 - val_loss: 0.8893 - val_binary_accuracy: 0.8226\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 705us/sample - loss: 0.0110 - binary_accuracy: 0.9964 - val_loss: 1.0210 - val_binary_accuracy: 0.7903\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0251 - binary_accuracy: 0.9873 - val_loss: 1.3730 - val_binary_accuracy: 0.7742\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0192 - binary_accuracy: 0.9910 - val_loss: 0.7957 - val_binary_accuracy: 0.8226\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0199 - binary_accuracy: 0.9946 - val_loss: 0.9544 - val_binary_accuracy: 0.8065\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 713us/sample - loss: 0.0135 - binary_accuracy: 0.9964 - val_loss: 0.7763 - val_binary_accuracy: 0.8226\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 708us/sample - loss: 0.0096 - binary_accuracy: 0.9982 - val_loss: 0.8782 - val_binary_accuracy: 0.7742\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0140 - binary_accuracy: 0.9964 - val_loss: 1.0007 - val_binary_accuracy: 0.7742\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.0131 - binary_accuracy: 0.9982 - val_loss: 0.8901 - val_binary_accuracy: 0.8226\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 1.0296 - val_binary_accuracy: 0.8065\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0104 - binary_accuracy: 0.9982 - val_loss: 0.7784 - val_binary_accuracy: 0.8387\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.0146 - binary_accuracy: 0.9964 - val_loss: 0.8729 - val_binary_accuracy: 0.8065\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0097 - binary_accuracy: 1.0000 - val_loss: 1.3935 - val_binary_accuracy: 0.7419\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 0.9672 - val_binary_accuracy: 0.7742\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 712us/sample - loss: 0.0146 - binary_accuracy: 0.9946 - val_loss: 0.8676 - val_binary_accuracy: 0.7903\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 712us/sample - loss: 0.0122 - binary_accuracy: 0.9964 - val_loss: 1.0156 - val_binary_accuracy: 0.7903\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 702us/sample - loss: 0.0098 - binary_accuracy: 0.9964 - val_loss: 1.7010 - val_binary_accuracy: 0.7581\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0056 - binary_accuracy: 1.0000 - val_loss: 1.0531 - val_binary_accuracy: 0.7903\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 710us/sample - loss: 0.0063 - binary_accuracy: 1.0000 - val_loss: 0.9514 - val_binary_accuracy: 0.8065\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 1.0189 - val_binary_accuracy: 0.8065\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 709us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 0.9732 - val_binary_accuracy: 0.7742\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 705us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 0.8752 - val_binary_accuracy: 0.7903\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 709us/sample - loss: 0.0060 - binary_accuracy: 0.9982 - val_loss: 0.9599 - val_binary_accuracy: 0.8226\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 707us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.9740 - val_binary_accuracy: 0.8226\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0182 - binary_accuracy: 0.9928 - val_loss: 2.7691 - val_binary_accuracy: 0.5323\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 713us/sample - loss: 0.0610 - binary_accuracy: 0.9946 - val_loss: 1.0764 - val_binary_accuracy: 0.8226\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 1.1152 - val_binary_accuracy: 0.7581\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 699us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 1.0339 - val_binary_accuracy: 0.7581\n",
      "accuracy for model 1 is 75.80645084381104\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/sample - loss: 0.6295 - binary_accuracy: 0.7269 - val_loss: 0.4837 - val_binary_accuracy: 0.9032\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 699us/sample - loss: 0.4385 - binary_accuracy: 0.8282 - val_loss: 0.4190 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.3718 - binary_accuracy: 0.8734 - val_loss: 0.3668 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.3046 - binary_accuracy: 0.9024 - val_loss: 0.3624 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 704us/sample - loss: 0.3079 - binary_accuracy: 0.8897 - val_loss: 0.3472 - val_binary_accuracy: 0.8226\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 708us/sample - loss: 0.2771 - binary_accuracy: 0.9078 - val_loss: 0.2806 - val_binary_accuracy: 0.8548\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.2520 - binary_accuracy: 0.9150 - val_loss: 0.2656 - val_binary_accuracy: 0.8548\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.2473 - binary_accuracy: 0.9078 - val_loss: 0.2837 - val_binary_accuracy: 0.8548\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 701us/sample - loss: 0.2401 - binary_accuracy: 0.9078 - val_loss: 0.1993 - val_binary_accuracy: 0.9355\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.2026 - binary_accuracy: 0.9277 - val_loss: 0.2127 - val_binary_accuracy: 0.9355\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.1758 - binary_accuracy: 0.9349 - val_loss: 0.2797 - val_binary_accuracy: 0.8710\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.1645 - binary_accuracy: 0.9439 - val_loss: 0.2494 - val_binary_accuracy: 0.8871\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 667us/sample - loss: 0.1596 - binary_accuracy: 0.9385 - val_loss: 0.2293 - val_binary_accuracy: 0.9032\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.1349 - binary_accuracy: 0.9602 - val_loss: 0.3851 - val_binary_accuracy: 0.8065\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.1230 - binary_accuracy: 0.9638 - val_loss: 0.2079 - val_binary_accuracy: 0.9516\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.1226 - binary_accuracy: 0.9566 - val_loss: 0.2072 - val_binary_accuracy: 0.9355\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.1436 - binary_accuracy: 0.9512 - val_loss: 0.2155 - val_binary_accuracy: 0.9355\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0929 - binary_accuracy: 0.9819 - val_loss: 0.2982 - val_binary_accuracy: 0.8871\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0938 - binary_accuracy: 0.9693 - val_loss: 0.2450 - val_binary_accuracy: 0.9032\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.1075 - binary_accuracy: 0.9620 - val_loss: 0.2193 - val_binary_accuracy: 0.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 701us/sample - loss: 0.0766 - binary_accuracy: 0.9765 - val_loss: 0.2793 - val_binary_accuracy: 0.9194\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0770 - binary_accuracy: 0.9729 - val_loss: 0.6515 - val_binary_accuracy: 0.8226\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0624 - binary_accuracy: 0.9837 - val_loss: 0.2657 - val_binary_accuracy: 0.9355\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0618 - binary_accuracy: 0.9855 - val_loss: 0.4693 - val_binary_accuracy: 0.8871\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0777 - binary_accuracy: 0.9711 - val_loss: 0.2829 - val_binary_accuracy: 0.9355\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0616 - binary_accuracy: 0.9855 - val_loss: 0.3777 - val_binary_accuracy: 0.8871\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0653 - binary_accuracy: 0.9765 - val_loss: 2.1914 - val_binary_accuracy: 0.3871\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0421 - binary_accuracy: 0.9946 - val_loss: 0.3449 - val_binary_accuracy: 0.9194\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 713us/sample - loss: 0.0459 - binary_accuracy: 0.9892 - val_loss: 0.3088 - val_binary_accuracy: 0.9032\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0350 - binary_accuracy: 0.9946 - val_loss: 0.2991 - val_binary_accuracy: 0.9355\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0355 - binary_accuracy: 0.9855 - val_loss: 0.3118 - val_binary_accuracy: 0.9355\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0316 - binary_accuracy: 0.9946 - val_loss: 0.3275 - val_binary_accuracy: 0.9032\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.0348 - binary_accuracy: 0.9910 - val_loss: 0.4201 - val_binary_accuracy: 0.8871\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0418 - binary_accuracy: 0.9873 - val_loss: 0.3947 - val_binary_accuracy: 0.8710\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 711us/sample - loss: 0.0277 - binary_accuracy: 0.9964 - val_loss: 0.4129 - val_binary_accuracy: 0.9032\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 703us/sample - loss: 0.0391 - binary_accuracy: 0.9855 - val_loss: 0.2915 - val_binary_accuracy: 0.9194\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.0233 - binary_accuracy: 0.9964 - val_loss: 0.2960 - val_binary_accuracy: 0.9355\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0419 - binary_accuracy: 0.9855 - val_loss: 0.2677 - val_binary_accuracy: 0.9355\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0319 - binary_accuracy: 0.9910 - val_loss: 0.5313 - val_binary_accuracy: 0.8548\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.0369 - binary_accuracy: 0.9892 - val_loss: 0.8734 - val_binary_accuracy: 0.7903\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0359 - binary_accuracy: 0.9910 - val_loss: 1.0917 - val_binary_accuracy: 0.6774\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0491 - binary_accuracy: 0.9819 - val_loss: 0.3563 - val_binary_accuracy: 0.9032\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0540 - binary_accuracy: 0.9747 - val_loss: 0.3215 - val_binary_accuracy: 0.9032\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0449 - binary_accuracy: 0.9819 - val_loss: 0.3195 - val_binary_accuracy: 0.8871\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0286 - binary_accuracy: 0.9910 - val_loss: 0.3101 - val_binary_accuracy: 0.9194\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0420 - binary_accuracy: 0.9892 - val_loss: 0.4534 - val_binary_accuracy: 0.8710\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0323 - binary_accuracy: 0.9910 - val_loss: 0.2624 - val_binary_accuracy: 0.9194\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0281 - binary_accuracy: 0.9892 - val_loss: 0.2795 - val_binary_accuracy: 0.9355\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0116 - binary_accuracy: 0.9982 - val_loss: 0.2920 - val_binary_accuracy: 0.9032\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0354 - binary_accuracy: 0.9873 - val_loss: 0.4098 - val_binary_accuracy: 0.8710\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0257 - binary_accuracy: 0.9946 - val_loss: 0.3572 - val_binary_accuracy: 0.9355\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0140 - binary_accuracy: 0.9982 - val_loss: 0.3107 - val_binary_accuracy: 0.9032\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0164 - binary_accuracy: 0.9928 - val_loss: 0.2832 - val_binary_accuracy: 0.9355\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0138 - binary_accuracy: 1.0000 - val_loss: 0.2891 - val_binary_accuracy: 0.9355\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0107 - binary_accuracy: 0.9982 - val_loss: 0.3356 - val_binary_accuracy: 0.9194\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0140 - binary_accuracy: 0.9982 - val_loss: 0.3019 - val_binary_accuracy: 0.9355\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 0.3268 - val_binary_accuracy: 0.9032\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0272 - binary_accuracy: 0.9928 - val_loss: 0.2789 - val_binary_accuracy: 0.9194\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0090 - binary_accuracy: 1.0000 - val_loss: 0.9042 - val_binary_accuracy: 0.7258\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0240 - binary_accuracy: 0.9928 - val_loss: 0.3930 - val_binary_accuracy: 0.9032\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 878us/sample - loss: 0.0130 - binary_accuracy: 1.0000 - val_loss: 0.3779 - val_binary_accuracy: 0.8710\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 703us/sample - loss: 0.0106 - binary_accuracy: 1.0000 - val_loss: 0.3014 - val_binary_accuracy: 0.9194\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0164 - binary_accuracy: 0.9982 - val_loss: 0.4705 - val_binary_accuracy: 0.9032\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 701us/sample - loss: 0.0269 - binary_accuracy: 0.9892 - val_loss: 0.8714 - val_binary_accuracy: 0.7903\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0256 - binary_accuracy: 0.9946 - val_loss: 0.6995 - val_binary_accuracy: 0.8710\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.0158 - binary_accuracy: 0.9982 - val_loss: 0.3221 - val_binary_accuracy: 0.9194\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0144 - binary_accuracy: 0.9946 - val_loss: 0.3303 - val_binary_accuracy: 0.9194\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0281 - binary_accuracy: 0.9910 - val_loss: 0.4261 - val_binary_accuracy: 0.9032\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.0151 - binary_accuracy: 0.9964 - val_loss: 0.3737 - val_binary_accuracy: 0.9194\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0323 - binary_accuracy: 0.9873 - val_loss: 0.3774 - val_binary_accuracy: 0.9194\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0182 - binary_accuracy: 0.9964 - val_loss: 0.7687 - val_binary_accuracy: 0.8065\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0206 - binary_accuracy: 0.9964 - val_loss: 0.3354 - val_binary_accuracy: 0.8871\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.0129 - binary_accuracy: 1.0000 - val_loss: 0.2860 - val_binary_accuracy: 0.9355\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0234 - binary_accuracy: 0.9928 - val_loss: 0.3284 - val_binary_accuracy: 0.9032\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 714us/sample - loss: 0.0136 - binary_accuracy: 0.9964 - val_loss: 0.3426 - val_binary_accuracy: 0.9032\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 709us/sample - loss: 0.0286 - binary_accuracy: 0.9892 - val_loss: 0.3268 - val_binary_accuracy: 0.9032\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.0164 - binary_accuracy: 0.9928 - val_loss: 0.3710 - val_binary_accuracy: 0.9194\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0327 - binary_accuracy: 0.9855 - val_loss: 0.3250 - val_binary_accuracy: 0.9194\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0226 - binary_accuracy: 0.9946 - val_loss: 0.4590 - val_binary_accuracy: 0.8710\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0136 - binary_accuracy: 0.9964 - val_loss: 0.3063 - val_binary_accuracy: 0.9032\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 708us/sample - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 0.3846 - val_binary_accuracy: 0.8710\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 704us/sample - loss: 0.0097 - binary_accuracy: 0.9982 - val_loss: 0.2831 - val_binary_accuracy: 0.9032\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0107 - binary_accuracy: 0.9982 - val_loss: 0.2917 - val_binary_accuracy: 0.9355\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 0.3250 - val_binary_accuracy: 0.9032\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0159 - binary_accuracy: 0.9964 - val_loss: 0.3838 - val_binary_accuracy: 0.9032\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0134 - binary_accuracy: 0.9964 - val_loss: 0.3074 - val_binary_accuracy: 0.9355\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 709us/sample - loss: 0.0119 - binary_accuracy: 0.9964 - val_loss: 0.4332 - val_binary_accuracy: 0.8871\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0131 - binary_accuracy: 0.9964 - val_loss: 0.2736 - val_binary_accuracy: 0.9194\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.0196 - binary_accuracy: 0.9910 - val_loss: 0.3589 - val_binary_accuracy: 0.9355\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0239 - binary_accuracy: 0.9928 - val_loss: 0.3331 - val_binary_accuracy: 0.9032\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0208 - binary_accuracy: 0.9910 - val_loss: 0.2737 - val_binary_accuracy: 0.9032\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0141 - binary_accuracy: 0.9982 - val_loss: 0.2989 - val_binary_accuracy: 0.9355\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.0108 - binary_accuracy: 0.9964 - val_loss: 0.2529 - val_binary_accuracy: 0.9194\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0073 - binary_accuracy: 1.0000 - val_loss: 0.2936 - val_binary_accuracy: 0.9355\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0265 - binary_accuracy: 0.9928 - val_loss: 0.2888 - val_binary_accuracy: 0.9355\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 709us/sample - loss: 0.0270 - binary_accuracy: 0.9910 - val_loss: 0.3239 - val_binary_accuracy: 0.9194\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 704us/sample - loss: 0.0063 - binary_accuracy: 1.0000 - val_loss: 0.3097 - val_binary_accuracy: 0.9194\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.0085 - binary_accuracy: 1.0000 - val_loss: 0.3211 - val_binary_accuracy: 0.9194\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 704us/sample - loss: 0.0090 - binary_accuracy: 0.9982 - val_loss: 0.3547 - val_binary_accuracy: 0.9194\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 702us/sample - loss: 0.0115 - binary_accuracy: 0.9946 - val_loss: 0.3538 - val_binary_accuracy: 0.9194\n",
      "accuracy for model 2 is 91.93548560142517\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/sample - loss: 0.5696 - binary_accuracy: 0.7740 - val_loss: 0.4128 - val_binary_accuracy: 0.9032\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.4309 - binary_accuracy: 0.8553 - val_loss: 0.3721 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.3673 - binary_accuracy: 0.8788 - val_loss: 0.3779 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 673us/sample - loss: 0.3194 - binary_accuracy: 0.8933 - val_loss: 0.3553 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.2932 - binary_accuracy: 0.9060 - val_loss: 0.3090 - val_binary_accuracy: 0.8226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.2613 - binary_accuracy: 0.9114 - val_loss: 0.2928 - val_binary_accuracy: 0.8226\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 704us/sample - loss: 0.2215 - binary_accuracy: 0.9277 - val_loss: 0.2709 - val_binary_accuracy: 0.8710\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 703us/sample - loss: 0.2058 - binary_accuracy: 0.9222 - val_loss: 0.2120 - val_binary_accuracy: 0.9194\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.1943 - binary_accuracy: 0.9331 - val_loss: 0.2262 - val_binary_accuracy: 0.9355\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 708us/sample - loss: 0.1849 - binary_accuracy: 0.9458 - val_loss: 0.2073 - val_binary_accuracy: 0.9032\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.1754 - binary_accuracy: 0.9331 - val_loss: 0.1555 - val_binary_accuracy: 0.9516\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 706us/sample - loss: 0.1485 - binary_accuracy: 0.9476 - val_loss: 0.2016 - val_binary_accuracy: 0.9355\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.1294 - binary_accuracy: 0.9584 - val_loss: 0.2011 - val_binary_accuracy: 0.9194\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 713us/sample - loss: 0.1119 - binary_accuracy: 0.9566 - val_loss: 0.1554 - val_binary_accuracy: 0.9355\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 701us/sample - loss: 0.1361 - binary_accuracy: 0.9512 - val_loss: 0.2288 - val_binary_accuracy: 0.9032\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0884 - binary_accuracy: 0.9711 - val_loss: 0.2190 - val_binary_accuracy: 0.9032\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0775 - binary_accuracy: 0.9819 - val_loss: 0.2399 - val_binary_accuracy: 0.9355\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0889 - binary_accuracy: 0.9693 - val_loss: 0.2729 - val_binary_accuracy: 0.9355\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.0821 - binary_accuracy: 0.9765 - val_loss: 0.4052 - val_binary_accuracy: 0.8871\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0613 - binary_accuracy: 0.9873 - val_loss: 0.2117 - val_binary_accuracy: 0.9194\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 705us/sample - loss: 0.0538 - binary_accuracy: 0.9873 - val_loss: 0.2010 - val_binary_accuracy: 0.9194\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 716us/sample - loss: 0.0547 - binary_accuracy: 0.9855 - val_loss: 0.2355 - val_binary_accuracy: 0.9194\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0497 - binary_accuracy: 0.9910 - val_loss: 0.2923 - val_binary_accuracy: 0.9194\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0411 - binary_accuracy: 0.9892 - val_loss: 0.2349 - val_binary_accuracy: 0.9194\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0677 - binary_accuracy: 0.9819 - val_loss: 0.2501 - val_binary_accuracy: 0.9355\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0545 - binary_accuracy: 0.9819 - val_loss: 0.3509 - val_binary_accuracy: 0.9194\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0474 - binary_accuracy: 0.9855 - val_loss: 0.2703 - val_binary_accuracy: 0.9194\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 670us/sample - loss: 0.0335 - binary_accuracy: 0.9910 - val_loss: 0.2414 - val_binary_accuracy: 0.9355\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0326 - binary_accuracy: 0.9928 - val_loss: 0.2742 - val_binary_accuracy: 0.9194\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0337 - binary_accuracy: 0.9964 - val_loss: 0.3590 - val_binary_accuracy: 0.9355\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0591 - binary_accuracy: 0.9783 - val_loss: 0.3794 - val_binary_accuracy: 0.9355\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0452 - binary_accuracy: 0.9837 - val_loss: 0.4169 - val_binary_accuracy: 0.9194\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0304 - binary_accuracy: 0.9946 - val_loss: 0.3161 - val_binary_accuracy: 0.9355\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0386 - binary_accuracy: 0.9910 - val_loss: 0.2924 - val_binary_accuracy: 0.9194\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 705us/sample - loss: 0.0439 - binary_accuracy: 0.9892 - val_loss: 0.3018 - val_binary_accuracy: 0.9194\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0357 - binary_accuracy: 0.9928 - val_loss: 0.4703 - val_binary_accuracy: 0.8871\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0186 - binary_accuracy: 1.0000 - val_loss: 0.2825 - val_binary_accuracy: 0.9355\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0176 - binary_accuracy: 1.0000 - val_loss: 0.2732 - val_binary_accuracy: 0.9355\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0239 - binary_accuracy: 0.9982 - val_loss: 0.3819 - val_binary_accuracy: 0.9194\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0317 - binary_accuracy: 0.9892 - val_loss: 0.3574 - val_binary_accuracy: 0.9194\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 719us/sample - loss: 0.0290 - binary_accuracy: 0.9910 - val_loss: 0.2837 - val_binary_accuracy: 0.9355\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.0262 - binary_accuracy: 0.9946 - val_loss: 0.3425 - val_binary_accuracy: 0.9194\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0251 - binary_accuracy: 0.9964 - val_loss: 0.3332 - val_binary_accuracy: 0.9194\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0285 - binary_accuracy: 0.9928 - val_loss: 0.6206 - val_binary_accuracy: 0.7742\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0501 - binary_accuracy: 0.9819 - val_loss: 0.3347 - val_binary_accuracy: 0.9355\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0441 - binary_accuracy: 0.9801 - val_loss: 0.4616 - val_binary_accuracy: 0.9032\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0311 - binary_accuracy: 0.9910 - val_loss: 0.3475 - val_binary_accuracy: 0.9355\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0385 - binary_accuracy: 0.9837 - val_loss: 0.3965 - val_binary_accuracy: 0.9516\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.0255 - binary_accuracy: 0.9928 - val_loss: 0.3524 - val_binary_accuracy: 0.9355\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0507 - binary_accuracy: 0.9819 - val_loss: 0.3642 - val_binary_accuracy: 0.9194\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0240 - binary_accuracy: 0.9964 - val_loss: 0.3309 - val_binary_accuracy: 0.9355\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0157 - binary_accuracy: 0.9982 - val_loss: 0.4121 - val_binary_accuracy: 0.9355\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 701us/sample - loss: 0.0298 - binary_accuracy: 0.9892 - val_loss: 0.3466 - val_binary_accuracy: 0.9516\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 671us/sample - loss: 0.0151 - binary_accuracy: 0.9982 - val_loss: 0.3365 - val_binary_accuracy: 0.9355\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0163 - binary_accuracy: 0.9964 - val_loss: 0.4081 - val_binary_accuracy: 0.9355\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 677us/sample - loss: 0.0218 - binary_accuracy: 0.9964 - val_loss: 0.4303 - val_binary_accuracy: 0.9355\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0181 - binary_accuracy: 0.9946 - val_loss: 0.4241 - val_binary_accuracy: 0.9355\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 673us/sample - loss: 0.0202 - binary_accuracy: 0.9964 - val_loss: 0.3997 - val_binary_accuracy: 0.9355\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0140 - binary_accuracy: 0.9946 - val_loss: 0.3503 - val_binary_accuracy: 0.9355\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0202 - binary_accuracy: 0.9964 - val_loss: 0.3978 - val_binary_accuracy: 0.9355\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0283 - binary_accuracy: 0.9892 - val_loss: 0.3617 - val_binary_accuracy: 0.9355\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0324 - binary_accuracy: 0.9910 - val_loss: 0.3918 - val_binary_accuracy: 0.9194\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0161 - binary_accuracy: 0.9946 - val_loss: 0.3590 - val_binary_accuracy: 0.9355\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0244 - binary_accuracy: 0.9946 - val_loss: 0.3302 - val_binary_accuracy: 0.9194\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0215 - binary_accuracy: 0.9946 - val_loss: 0.3234 - val_binary_accuracy: 0.9355\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0132 - binary_accuracy: 0.9982 - val_loss: 0.4046 - val_binary_accuracy: 0.9355\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0155 - binary_accuracy: 0.9946 - val_loss: 0.3795 - val_binary_accuracy: 0.9355\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0121 - binary_accuracy: 0.9982 - val_loss: 0.3896 - val_binary_accuracy: 0.9355\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0193 - binary_accuracy: 0.9946 - val_loss: 0.4016 - val_binary_accuracy: 0.9355\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0212 - binary_accuracy: 0.9946 - val_loss: 0.3450 - val_binary_accuracy: 0.9355\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.0113 - binary_accuracy: 0.9982 - val_loss: 0.3507 - val_binary_accuracy: 0.9355\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0077 - binary_accuracy: 1.0000 - val_loss: 0.4282 - val_binary_accuracy: 0.9355\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0091 - binary_accuracy: 1.0000 - val_loss: 0.4551 - val_binary_accuracy: 0.9355\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.0156 - binary_accuracy: 0.9982 - val_loss: 0.4540 - val_binary_accuracy: 0.9194\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0132 - binary_accuracy: 0.9982 - val_loss: 0.4234 - val_binary_accuracy: 0.9355\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0254 - binary_accuracy: 0.9892 - val_loss: 0.4647 - val_binary_accuracy: 0.9355\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.0178 - binary_accuracy: 0.9946 - val_loss: 0.3512 - val_binary_accuracy: 0.9355\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0127 - binary_accuracy: 0.9946 - val_loss: 0.6453 - val_binary_accuracy: 0.8387\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0095 - binary_accuracy: 0.9982 - val_loss: 0.4439 - val_binary_accuracy: 0.9194\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0186 - binary_accuracy: 0.9928 - val_loss: 0.4396 - val_binary_accuracy: 0.9194\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0090 - binary_accuracy: 1.0000 - val_loss: 0.4352 - val_binary_accuracy: 0.9355\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0125 - binary_accuracy: 0.9964 - val_loss: 0.5215 - val_binary_accuracy: 0.9355\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 677us/sample - loss: 0.0126 - binary_accuracy: 1.0000 - val_loss: 0.4646 - val_binary_accuracy: 0.9355\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0086 - binary_accuracy: 0.9982 - val_loss: 0.4696 - val_binary_accuracy: 0.9355\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 703us/sample - loss: 0.0069 - binary_accuracy: 0.9982 - val_loss: 0.4600 - val_binary_accuracy: 0.9355\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0165 - binary_accuracy: 0.9910 - val_loss: 0.4346 - val_binary_accuracy: 0.9516\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 673us/sample - loss: 0.0234 - binary_accuracy: 0.9946 - val_loss: 0.6691 - val_binary_accuracy: 0.8387\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 0.5164 - val_binary_accuracy: 0.9355\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.5311 - val_binary_accuracy: 0.9355\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0195 - binary_accuracy: 0.9910 - val_loss: 0.5595 - val_binary_accuracy: 0.9355\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0207 - binary_accuracy: 0.9910 - val_loss: 0.5327 - val_binary_accuracy: 0.9355\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0134 - binary_accuracy: 0.9946 - val_loss: 0.5332 - val_binary_accuracy: 0.9355\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 670us/sample - loss: 0.0073 - binary_accuracy: 1.0000 - val_loss: 0.5105 - val_binary_accuracy: 0.9355\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 701us/sample - loss: 0.0199 - binary_accuracy: 0.9910 - val_loss: 0.4771 - val_binary_accuracy: 0.9355\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 677us/sample - loss: 0.0133 - binary_accuracy: 0.9982 - val_loss: 0.5301 - val_binary_accuracy: 0.9194\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0096 - binary_accuracy: 1.0000 - val_loss: 0.5192 - val_binary_accuracy: 0.9355\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0115 - binary_accuracy: 0.9982 - val_loss: 0.4837 - val_binary_accuracy: 0.9355\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 699us/sample - loss: 0.0102 - binary_accuracy: 0.9964 - val_loss: 0.4815 - val_binary_accuracy: 0.9516\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0094 - binary_accuracy: 0.9982 - val_loss: 0.5616 - val_binary_accuracy: 0.9194\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0080 - binary_accuracy: 0.9982 - val_loss: 0.4912 - val_binary_accuracy: 0.9355\n",
      "accuracy for model 3 is 93.54838728904724\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/sample - loss: 0.6311 - binary_accuracy: 0.7396 - val_loss: 0.4482 - val_binary_accuracy: 0.9516\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 667us/sample - loss: 0.4633 - binary_accuracy: 0.8210 - val_loss: 0.3853 - val_binary_accuracy: 0.8710\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 665us/sample - loss: 0.3854 - binary_accuracy: 0.8788 - val_loss: 0.3446 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.3314 - binary_accuracy: 0.8879 - val_loss: 0.2691 - val_binary_accuracy: 0.9677\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.3307 - binary_accuracy: 0.8770 - val_loss: 0.2445 - val_binary_accuracy: 0.9677\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 672us/sample - loss: 0.2797 - binary_accuracy: 0.9005 - val_loss: 0.1782 - val_binary_accuracy: 0.9677\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.2678 - binary_accuracy: 0.9042 - val_loss: 0.1842 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.2458 - binary_accuracy: 0.9096 - val_loss: 0.1583 - val_binary_accuracy: 0.9839\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.2113 - binary_accuracy: 0.9385 - val_loss: 0.2252 - val_binary_accuracy: 0.9516\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.1994 - binary_accuracy: 0.9385 - val_loss: 0.3046 - val_binary_accuracy: 0.9194\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.1975 - binary_accuracy: 0.9349 - val_loss: 0.1855 - val_binary_accuracy: 0.9516\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.1725 - binary_accuracy: 0.9439 - val_loss: 0.6916 - val_binary_accuracy: 0.6290\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.1790 - binary_accuracy: 0.9277 - val_loss: 0.3608 - val_binary_accuracy: 0.8871\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.1576 - binary_accuracy: 0.9494 - val_loss: 0.2574 - val_binary_accuracy: 0.8871\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 672us/sample - loss: 0.1362 - binary_accuracy: 0.9530 - val_loss: 0.1292 - val_binary_accuracy: 0.9516\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.1207 - binary_accuracy: 0.9638 - val_loss: 0.3332 - val_binary_accuracy: 0.8548\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.1300 - binary_accuracy: 0.9584 - val_loss: 0.2330 - val_binary_accuracy: 0.9194\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 673us/sample - loss: 0.1210 - binary_accuracy: 0.9675 - val_loss: 0.2658 - val_binary_accuracy: 0.8710\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0958 - binary_accuracy: 0.9693 - val_loss: 0.4058 - val_binary_accuracy: 0.8065\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 673us/sample - loss: 0.0901 - binary_accuracy: 0.9675 - val_loss: 0.2014 - val_binary_accuracy: 0.9516\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0514 - binary_accuracy: 0.9928 - val_loss: 0.1794 - val_binary_accuracy: 0.9032\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0621 - binary_accuracy: 0.9783 - val_loss: 0.3171 - val_binary_accuracy: 0.8871\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0638 - binary_accuracy: 0.9837 - val_loss: 0.1583 - val_binary_accuracy: 0.9194\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0640 - binary_accuracy: 0.9783 - val_loss: 0.2208 - val_binary_accuracy: 0.8871\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0691 - binary_accuracy: 0.9729 - val_loss: 0.5143 - val_binary_accuracy: 0.8387\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 666us/sample - loss: 0.0630 - binary_accuracy: 0.9873 - val_loss: 0.5350 - val_binary_accuracy: 0.8710\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0710 - binary_accuracy: 0.9729 - val_loss: 0.2052 - val_binary_accuracy: 0.8871\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0726 - binary_accuracy: 0.9729 - val_loss: 0.2518 - val_binary_accuracy: 0.9032\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 667us/sample - loss: 0.0545 - binary_accuracy: 0.9837 - val_loss: 0.2863 - val_binary_accuracy: 0.9194\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 671us/sample - loss: 0.0524 - binary_accuracy: 0.9801 - val_loss: 0.8662 - val_binary_accuracy: 0.6613\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 667us/sample - loss: 0.0533 - binary_accuracy: 0.9855 - val_loss: 0.4521 - val_binary_accuracy: 0.8710\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0731 - binary_accuracy: 0.9783 - val_loss: 3.3282 - val_binary_accuracy: 0.2903\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0339 - binary_accuracy: 0.9892 - val_loss: 0.3344 - val_binary_accuracy: 0.9194\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0344 - binary_accuracy: 0.9928 - val_loss: 0.3546 - val_binary_accuracy: 0.9032\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0475 - binary_accuracy: 0.9873 - val_loss: 1.0698 - val_binary_accuracy: 0.6290\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0235 - binary_accuracy: 0.9982 - val_loss: 0.2852 - val_binary_accuracy: 0.9516\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 671us/sample - loss: 0.0267 - binary_accuracy: 0.9910 - val_loss: 0.2711 - val_binary_accuracy: 0.9032\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0565 - binary_accuracy: 0.9819 - val_loss: 0.2910 - val_binary_accuracy: 0.9032\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 672us/sample - loss: 0.0483 - binary_accuracy: 0.9873 - val_loss: 0.9531 - val_binary_accuracy: 0.8226\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0446 - binary_accuracy: 0.9819 - val_loss: 0.2846 - val_binary_accuracy: 0.8710\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0263 - binary_accuracy: 0.9928 - val_loss: 0.6086 - val_binary_accuracy: 0.7581\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0299 - binary_accuracy: 0.9910 - val_loss: 0.3661 - val_binary_accuracy: 0.8871\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 707us/sample - loss: 0.0371 - binary_accuracy: 0.9928 - val_loss: 0.7607 - val_binary_accuracy: 0.7581\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.0234 - binary_accuracy: 0.9964 - val_loss: 0.6507 - val_binary_accuracy: 0.8548\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 696us/sample - loss: 0.0296 - binary_accuracy: 0.9892 - val_loss: 0.4184 - val_binary_accuracy: 0.8548\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0275 - binary_accuracy: 0.9928 - val_loss: 0.3255 - val_binary_accuracy: 0.8871\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0395 - binary_accuracy: 0.9819 - val_loss: 1.2878 - val_binary_accuracy: 0.8226\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 699us/sample - loss: 0.0261 - binary_accuracy: 0.9910 - val_loss: 0.4885 - val_binary_accuracy: 0.8710\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0210 - binary_accuracy: 0.9964 - val_loss: 0.4612 - val_binary_accuracy: 0.9032\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0356 - binary_accuracy: 0.9892 - val_loss: 0.2941 - val_binary_accuracy: 0.8871\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0479 - binary_accuracy: 0.9873 - val_loss: 0.2946 - val_binary_accuracy: 0.9355\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 668us/sample - loss: 0.0265 - binary_accuracy: 0.9928 - val_loss: 1.8211 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 702us/sample - loss: 0.0226 - binary_accuracy: 0.9964 - val_loss: 0.3397 - val_binary_accuracy: 0.8871\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0189 - binary_accuracy: 0.9964 - val_loss: 0.3048 - val_binary_accuracy: 0.8871\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0156 - binary_accuracy: 1.0000 - val_loss: 0.2565 - val_binary_accuracy: 0.9355\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0168 - binary_accuracy: 0.9964 - val_loss: 0.2557 - val_binary_accuracy: 0.9194\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0126 - binary_accuracy: 0.9982 - val_loss: 0.3518 - val_binary_accuracy: 0.9032\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0126 - binary_accuracy: 0.9946 - val_loss: 0.5996 - val_binary_accuracy: 0.8710\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0131 - binary_accuracy: 0.9964 - val_loss: 0.5342 - val_binary_accuracy: 0.8226\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0143 - binary_accuracy: 0.9964 - val_loss: 0.3719 - val_binary_accuracy: 0.8871\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0068 - binary_accuracy: 1.0000 - val_loss: 0.2388 - val_binary_accuracy: 0.9032\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0116 - binary_accuracy: 0.9964 - val_loss: 0.2264 - val_binary_accuracy: 0.9194\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 0.2805 - val_binary_accuracy: 0.8871\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0130 - binary_accuracy: 0.9964 - val_loss: 0.3818 - val_binary_accuracy: 0.8387\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0286 - binary_accuracy: 0.9892 - val_loss: 0.6648 - val_binary_accuracy: 0.8871\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0171 - binary_accuracy: 0.9964 - val_loss: 0.5082 - val_binary_accuracy: 0.8871\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0274 - binary_accuracy: 0.9910 - val_loss: 0.3149 - val_binary_accuracy: 0.8871\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0274 - binary_accuracy: 0.9910 - val_loss: 0.3345 - val_binary_accuracy: 0.9194\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0209 - binary_accuracy: 0.9946 - val_loss: 0.9114 - val_binary_accuracy: 0.8548\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0277 - binary_accuracy: 0.9873 - val_loss: 0.3679 - val_binary_accuracy: 0.8710\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0134 - binary_accuracy: 0.9982 - val_loss: 0.4836 - val_binary_accuracy: 0.9032\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 671us/sample - loss: 0.0254 - binary_accuracy: 0.9910 - val_loss: 2.3243 - val_binary_accuracy: 0.5161\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0103 - binary_accuracy: 1.0000 - val_loss: 0.3211 - val_binary_accuracy: 0.9032\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0259 - binary_accuracy: 0.9928 - val_loss: 0.7623 - val_binary_accuracy: 0.8548\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0469 - binary_accuracy: 0.9873 - val_loss: 0.3220 - val_binary_accuracy: 0.9355\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 671us/sample - loss: 0.0260 - binary_accuracy: 0.9910 - val_loss: 0.2739 - val_binary_accuracy: 0.8871\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0193 - binary_accuracy: 0.9928 - val_loss: 0.3349 - val_binary_accuracy: 0.9194\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0149 - binary_accuracy: 0.9964 - val_loss: 0.4970 - val_binary_accuracy: 0.8871\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0163 - binary_accuracy: 0.9982 - val_loss: 0.4335 - val_binary_accuracy: 0.8387\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0192 - binary_accuracy: 0.9946 - val_loss: 0.3862 - val_binary_accuracy: 0.8548\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 672us/sample - loss: 0.0131 - binary_accuracy: 0.9964 - val_loss: 0.4577 - val_binary_accuracy: 0.9194\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0167 - binary_accuracy: 0.9946 - val_loss: 0.3771 - val_binary_accuracy: 0.9194\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0139 - binary_accuracy: 0.9964 - val_loss: 0.3536 - val_binary_accuracy: 0.9194\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0071 - binary_accuracy: 0.9964 - val_loss: 0.7515 - val_binary_accuracy: 0.8548\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 695us/sample - loss: 0.0102 - binary_accuracy: 1.0000 - val_loss: 0.3647 - val_binary_accuracy: 0.9355\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0148 - binary_accuracy: 0.9910 - val_loss: 0.4094 - val_binary_accuracy: 0.8871\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 677us/sample - loss: 0.0096 - binary_accuracy: 0.9982 - val_loss: 0.5219 - val_binary_accuracy: 0.8871\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 672us/sample - loss: 0.0103 - binary_accuracy: 0.9982 - val_loss: 0.6966 - val_binary_accuracy: 0.8871\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 670us/sample - loss: 0.0128 - binary_accuracy: 0.9928 - val_loss: 0.5879 - val_binary_accuracy: 0.8226\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0074 - binary_accuracy: 0.9982 - val_loss: 0.5714 - val_binary_accuracy: 0.8226\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 664us/sample - loss: 0.0073 - binary_accuracy: 1.0000 - val_loss: 0.4735 - val_binary_accuracy: 0.8548\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 665us/sample - loss: 0.0206 - binary_accuracy: 0.9928 - val_loss: 0.3552 - val_binary_accuracy: 0.8710\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 664us/sample - loss: 0.0241 - binary_accuracy: 0.9928 - val_loss: 0.3172 - val_binary_accuracy: 0.9355\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 665us/sample - loss: 0.0111 - binary_accuracy: 0.9982 - val_loss: 0.3613 - val_binary_accuracy: 0.9032\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 664us/sample - loss: 0.0175 - binary_accuracy: 0.9946 - val_loss: 1.4197 - val_binary_accuracy: 0.6129\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 666us/sample - loss: 0.0135 - binary_accuracy: 0.9964 - val_loss: 0.7385 - val_binary_accuracy: 0.8871\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0091 - binary_accuracy: 1.0000 - val_loss: 0.3654 - val_binary_accuracy: 0.9032\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0078 - binary_accuracy: 1.0000 - val_loss: 0.7363 - val_binary_accuracy: 0.8710\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0130 - binary_accuracy: 0.9946 - val_loss: 0.4459 - val_binary_accuracy: 0.9194\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0140 - binary_accuracy: 0.9946 - val_loss: 1.0132 - val_binary_accuracy: 0.7258\n",
      "accuracy for model 4 is 72.5806474685669\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/sample - loss: 0.5879 - binary_accuracy: 0.7776 - val_loss: 0.5601 - val_binary_accuracy: 0.7903\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.4050 - binary_accuracy: 0.8662 - val_loss: 0.4436 - val_binary_accuracy: 0.8387\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.3576 - binary_accuracy: 0.8915 - val_loss: 0.4462 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 666us/sample - loss: 0.2944 - binary_accuracy: 0.9078 - val_loss: 0.4100 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 671us/sample - loss: 0.2753 - binary_accuracy: 0.9204 - val_loss: 0.3811 - val_binary_accuracy: 0.8226\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 707us/sample - loss: 0.2644 - binary_accuracy: 0.9060 - val_loss: 0.3857 - val_binary_accuracy: 0.8226\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 845us/sample - loss: 0.2375 - binary_accuracy: 0.9150 - val_loss: 0.3835 - val_binary_accuracy: 0.8548\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.2073 - binary_accuracy: 0.9385 - val_loss: 0.4194 - val_binary_accuracy: 0.8226\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.2055 - binary_accuracy: 0.9313 - val_loss: 0.3900 - val_binary_accuracy: 0.8226\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.1782 - binary_accuracy: 0.9439 - val_loss: 0.4656 - val_binary_accuracy: 0.8226\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 705us/sample - loss: 0.1712 - binary_accuracy: 0.9385 - val_loss: 0.4192 - val_binary_accuracy: 0.8226\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 670us/sample - loss: 0.1583 - binary_accuracy: 0.9512 - val_loss: 0.5397 - val_binary_accuracy: 0.8226\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.1479 - binary_accuracy: 0.9620 - val_loss: 0.4064 - val_binary_accuracy: 0.8548\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.1300 - binary_accuracy: 0.9548 - val_loss: 0.4734 - val_binary_accuracy: 0.8548\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 673us/sample - loss: 0.1171 - binary_accuracy: 0.9602 - val_loss: 0.5220 - val_binary_accuracy: 0.8548\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.1180 - binary_accuracy: 0.9656 - val_loss: 0.8008 - val_binary_accuracy: 0.6290\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.1084 - binary_accuracy: 0.9711 - val_loss: 0.5084 - val_binary_accuracy: 0.8387\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.1014 - binary_accuracy: 0.9638 - val_loss: 0.6968 - val_binary_accuracy: 0.8065\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 677us/sample - loss: 0.1050 - binary_accuracy: 0.9693 - val_loss: 0.8970 - val_binary_accuracy: 0.7742\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 672us/sample - loss: 0.0779 - binary_accuracy: 0.9711 - val_loss: 0.6347 - val_binary_accuracy: 0.8387\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0933 - binary_accuracy: 0.9693 - val_loss: 0.7316 - val_binary_accuracy: 0.8065\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0723 - binary_accuracy: 0.9765 - val_loss: 0.6451 - val_binary_accuracy: 0.8065\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 677us/sample - loss: 0.0620 - binary_accuracy: 0.9801 - val_loss: 0.6278 - val_binary_accuracy: 0.8226\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0735 - binary_accuracy: 0.9801 - val_loss: 0.9201 - val_binary_accuracy: 0.7258\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0560 - binary_accuracy: 0.9801 - val_loss: 0.6514 - val_binary_accuracy: 0.8065\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.0445 - binary_accuracy: 0.9910 - val_loss: 0.8267 - val_binary_accuracy: 0.7903\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.0387 - binary_accuracy: 0.9873 - val_loss: 0.7434 - val_binary_accuracy: 0.8226\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 668us/sample - loss: 0.0546 - binary_accuracy: 0.9855 - val_loss: 0.8134 - val_binary_accuracy: 0.8387\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0605 - binary_accuracy: 0.9855 - val_loss: 1.0369 - val_binary_accuracy: 0.7742\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 693us/sample - loss: 0.0470 - binary_accuracy: 0.9837 - val_loss: 1.0360 - val_binary_accuracy: 0.8065\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0363 - binary_accuracy: 0.9910 - val_loss: 0.8018 - val_binary_accuracy: 0.8226\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0436 - binary_accuracy: 0.9855 - val_loss: 0.7065 - val_binary_accuracy: 0.8387\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0446 - binary_accuracy: 0.9837 - val_loss: 0.9159 - val_binary_accuracy: 0.8065\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 688us/sample - loss: 0.0362 - binary_accuracy: 0.9873 - val_loss: 0.8840 - val_binary_accuracy: 0.8226\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0310 - binary_accuracy: 0.9910 - val_loss: 0.7872 - val_binary_accuracy: 0.8387\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 673us/sample - loss: 0.0221 - binary_accuracy: 0.9964 - val_loss: 0.8817 - val_binary_accuracy: 0.8065\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0244 - binary_accuracy: 0.9910 - val_loss: 0.8873 - val_binary_accuracy: 0.8065\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 700us/sample - loss: 0.0306 - binary_accuracy: 0.9928 - val_loss: 0.9113 - val_binary_accuracy: 0.8065\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0137 - binary_accuracy: 0.9982 - val_loss: 0.9515 - val_binary_accuracy: 0.8065\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0299 - binary_accuracy: 0.9892 - val_loss: 0.8749 - val_binary_accuracy: 0.8065\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0380 - binary_accuracy: 0.9873 - val_loss: 2.0409 - val_binary_accuracy: 0.5645\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 686us/sample - loss: 0.0225 - binary_accuracy: 0.9964 - val_loss: 0.9687 - val_binary_accuracy: 0.8065\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0196 - binary_accuracy: 0.9964 - val_loss: 1.1101 - val_binary_accuracy: 0.7419\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0478 - binary_accuracy: 0.9873 - val_loss: 0.9947 - val_binary_accuracy: 0.7742\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.0197 - binary_accuracy: 0.9964 - val_loss: 1.1177 - val_binary_accuracy: 0.7903\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0120 - binary_accuracy: 0.9982 - val_loss: 0.8650 - val_binary_accuracy: 0.8548\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0391 - binary_accuracy: 0.9873 - val_loss: 0.8375 - val_binary_accuracy: 0.8065\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 697us/sample - loss: 0.0367 - binary_accuracy: 0.9910 - val_loss: 0.7939 - val_binary_accuracy: 0.8226\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.0239 - binary_accuracy: 0.9946 - val_loss: 1.2006 - val_binary_accuracy: 0.7581\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0186 - binary_accuracy: 0.9946 - val_loss: 0.9160 - val_binary_accuracy: 0.8226\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0275 - binary_accuracy: 0.9873 - val_loss: 1.1557 - val_binary_accuracy: 0.8065\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0538 - binary_accuracy: 0.9855 - val_loss: 1.7283 - val_binary_accuracy: 0.6129\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 672us/sample - loss: 0.0221 - binary_accuracy: 0.9964 - val_loss: 1.0469 - val_binary_accuracy: 0.7903\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 694us/sample - loss: 0.0278 - binary_accuracy: 0.9873 - val_loss: 1.0795 - val_binary_accuracy: 0.8226\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0276 - binary_accuracy: 0.9928 - val_loss: 0.8940 - val_binary_accuracy: 0.7903\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0164 - binary_accuracy: 0.9982 - val_loss: 0.9230 - val_binary_accuracy: 0.8065\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 692us/sample - loss: 0.0199 - binary_accuracy: 0.9964 - val_loss: 0.7830 - val_binary_accuracy: 0.8548\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0205 - binary_accuracy: 0.9964 - val_loss: 1.2841 - val_binary_accuracy: 0.7581\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0143 - binary_accuracy: 0.9982 - val_loss: 0.9700 - val_binary_accuracy: 0.8548\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 691us/sample - loss: 0.0224 - binary_accuracy: 0.9928 - val_loss: 0.9111 - val_binary_accuracy: 0.8226\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 698us/sample - loss: 0.0115 - binary_accuracy: 0.9982 - val_loss: 0.9753 - val_binary_accuracy: 0.8226\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 679us/sample - loss: 0.0104 - binary_accuracy: 0.9982 - val_loss: 1.1304 - val_binary_accuracy: 0.8387\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 701us/sample - loss: 0.0464 - binary_accuracy: 0.9819 - val_loss: 1.2050 - val_binary_accuracy: 0.8387\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0439 - binary_accuracy: 0.9819 - val_loss: 1.8464 - val_binary_accuracy: 0.5806\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0157 - binary_accuracy: 0.9964 - val_loss: 1.4125 - val_binary_accuracy: 0.7742\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0168 - binary_accuracy: 0.9946 - val_loss: 0.9776 - val_binary_accuracy: 0.8226\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0134 - binary_accuracy: 1.0000 - val_loss: 1.1689 - val_binary_accuracy: 0.7903\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 676us/sample - loss: 0.0132 - binary_accuracy: 0.9982 - val_loss: 0.9469 - val_binary_accuracy: 0.8387\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 666us/sample - loss: 0.0231 - binary_accuracy: 0.9910 - val_loss: 1.0113 - val_binary_accuracy: 0.8226\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0087 - binary_accuracy: 1.0000 - val_loss: 1.1357 - val_binary_accuracy: 0.8387\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0119 - binary_accuracy: 0.9982 - val_loss: 1.0582 - val_binary_accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 690us/sample - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 1.1257 - val_binary_accuracy: 0.8065\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 681us/sample - loss: 0.0105 - binary_accuracy: 0.9982 - val_loss: 1.1795 - val_binary_accuracy: 0.8226\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 712us/sample - loss: 0.0093 - binary_accuracy: 1.0000 - val_loss: 1.1040 - val_binary_accuracy: 0.8226\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 668us/sample - loss: 0.0067 - binary_accuracy: 0.9982 - val_loss: 1.2000 - val_binary_accuracy: 0.8065\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 687us/sample - loss: 0.0190 - binary_accuracy: 0.9982 - val_loss: 1.1628 - val_binary_accuracy: 0.7903\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 1.1242 - val_binary_accuracy: 0.8065\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0198 - binary_accuracy: 0.9910 - val_loss: 1.0082 - val_binary_accuracy: 0.8226\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0235 - binary_accuracy: 0.9928 - val_loss: 1.0294 - val_binary_accuracy: 0.8226\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 684us/sample - loss: 0.0068 - binary_accuracy: 1.0000 - val_loss: 1.1339 - val_binary_accuracy: 0.8226\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0094 - binary_accuracy: 1.0000 - val_loss: 1.1796 - val_binary_accuracy: 0.8226\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0082 - binary_accuracy: 0.9982 - val_loss: 1.1773 - val_binary_accuracy: 0.8065\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 1.1533 - val_binary_accuracy: 0.8065\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 671us/sample - loss: 0.0087 - binary_accuracy: 1.0000 - val_loss: 1.0619 - val_binary_accuracy: 0.8065\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 682us/sample - loss: 0.0110 - binary_accuracy: 0.9982 - val_loss: 1.1567 - val_binary_accuracy: 0.8065\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0057 - binary_accuracy: 0.9982 - val_loss: 1.0296 - val_binary_accuracy: 0.8065\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 685us/sample - loss: 0.0097 - binary_accuracy: 0.9982 - val_loss: 1.1060 - val_binary_accuracy: 0.7742\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.0159 - binary_accuracy: 0.9946 - val_loss: 1.1127 - val_binary_accuracy: 0.8226\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 667us/sample - loss: 0.0146 - binary_accuracy: 0.9946 - val_loss: 1.0515 - val_binary_accuracy: 0.8226\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 675us/sample - loss: 0.0212 - binary_accuracy: 0.9928 - val_loss: 1.0516 - val_binary_accuracy: 0.8065\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 677us/sample - loss: 0.0228 - binary_accuracy: 0.9946 - val_loss: 1.0377 - val_binary_accuracy: 0.8065\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 683us/sample - loss: 0.0112 - binary_accuracy: 0.9982 - val_loss: 0.9401 - val_binary_accuracy: 0.8065\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 667us/sample - loss: 0.0170 - binary_accuracy: 0.9946 - val_loss: 1.0251 - val_binary_accuracy: 0.7742\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 704us/sample - loss: 0.0182 - binary_accuracy: 0.9928 - val_loss: 0.9686 - val_binary_accuracy: 0.8548\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 674us/sample - loss: 0.0291 - binary_accuracy: 0.9892 - val_loss: 1.2874 - val_binary_accuracy: 0.8065\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 689us/sample - loss: 0.0156 - binary_accuracy: 0.9946 - val_loss: 1.0304 - val_binary_accuracy: 0.7903\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 680us/sample - loss: 0.0125 - binary_accuracy: 0.9982 - val_loss: 1.3275 - val_binary_accuracy: 0.7742\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 678us/sample - loss: 0.0124 - binary_accuracy: 0.9964 - val_loss: 1.1677 - val_binary_accuracy: 0.7742\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 669us/sample - loss: 0.0140 - binary_accuracy: 0.9982 - val_loss: 1.1642 - val_binary_accuracy: 0.8226\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 668us/sample - loss: 0.0134 - binary_accuracy: 0.9964 - val_loss: 1.2253 - val_binary_accuracy: 0.7903\n",
      "accuracy for model 5 is 79.03226017951965\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 2ms/sample - loss: 0.5591 - binary_accuracy: 0.7726 - val_loss: 0.5208 - val_binary_accuracy: 0.7705\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 841us/sample - loss: 0.4144 - binary_accuracy: 0.8574 - val_loss: 0.4577 - val_binary_accuracy: 0.8689\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 698us/sample - loss: 0.3445 - binary_accuracy: 0.8845 - val_loss: 0.4066 - val_binary_accuracy: 0.8361\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 697us/sample - loss: 0.3048 - binary_accuracy: 0.8971 - val_loss: 0.3732 - val_binary_accuracy: 0.8361\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.2816 - binary_accuracy: 0.8989 - val_loss: 0.3602 - val_binary_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 693us/sample - loss: 0.2660 - binary_accuracy: 0.9079 - val_loss: 0.3603 - val_binary_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 689us/sample - loss: 0.2300 - binary_accuracy: 0.9314 - val_loss: 0.3373 - val_binary_accuracy: 0.8525\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.2195 - binary_accuracy: 0.9242 - val_loss: 0.3214 - val_binary_accuracy: 0.8525\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.2065 - binary_accuracy: 0.9278 - val_loss: 0.3313 - val_binary_accuracy: 0.8852\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.1992 - binary_accuracy: 0.9260 - val_loss: 0.3607 - val_binary_accuracy: 0.8852\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.1972 - binary_accuracy: 0.9350 - val_loss: 0.3636 - val_binary_accuracy: 0.8525\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 663us/sample - loss: 0.1725 - binary_accuracy: 0.9260 - val_loss: 0.3450 - val_binary_accuracy: 0.8525\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.1477 - binary_accuracy: 0.9495 - val_loss: 0.3933 - val_binary_accuracy: 0.8525\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.1679 - binary_accuracy: 0.9386 - val_loss: 0.4024 - val_binary_accuracy: 0.8689\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.1359 - binary_accuracy: 0.9549 - val_loss: 0.4279 - val_binary_accuracy: 0.8361\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.1097 - binary_accuracy: 0.9639 - val_loss: 0.4719 - val_binary_accuracy: 0.8361\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0970 - binary_accuracy: 0.9657 - val_loss: 0.4733 - val_binary_accuracy: 0.8689\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0728 - binary_accuracy: 0.9819 - val_loss: 0.6205 - val_binary_accuracy: 0.8852\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0782 - binary_accuracy: 0.9801 - val_loss: 0.4729 - val_binary_accuracy: 0.8197\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 706us/sample - loss: 0.0669 - binary_accuracy: 0.9783 - val_loss: 0.8178 - val_binary_accuracy: 0.7541\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0830 - binary_accuracy: 0.9765 - val_loss: 0.6311 - val_binary_accuracy: 0.7705\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 659us/sample - loss: 0.0599 - binary_accuracy: 0.9892 - val_loss: 0.5154 - val_binary_accuracy: 0.8361\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 662us/sample - loss: 0.0849 - binary_accuracy: 0.9711 - val_loss: 0.7254 - val_binary_accuracy: 0.7869\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0688 - binary_accuracy: 0.9783 - val_loss: 0.5042 - val_binary_accuracy: 0.8852\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0867 - binary_accuracy: 0.9693 - val_loss: 0.6663 - val_binary_accuracy: 0.7705\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0639 - binary_accuracy: 0.9874 - val_loss: 0.5670 - val_binary_accuracy: 0.8361\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0447 - binary_accuracy: 0.9856 - val_loss: 0.6165 - val_binary_accuracy: 0.8525\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0481 - binary_accuracy: 0.9838 - val_loss: 0.5657 - val_binary_accuracy: 0.8525\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0408 - binary_accuracy: 0.9910 - val_loss: 0.6611 - val_binary_accuracy: 0.8689\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0509 - binary_accuracy: 0.9856 - val_loss: 0.4901 - val_binary_accuracy: 0.8525\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.0380 - binary_accuracy: 0.9946 - val_loss: 0.5740 - val_binary_accuracy: 0.8361\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0213 - binary_accuracy: 0.9946 - val_loss: 0.6310 - val_binary_accuracy: 0.8852\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0347 - binary_accuracy: 0.9946 - val_loss: 0.7628 - val_binary_accuracy: 0.8525\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 663us/sample - loss: 0.0401 - binary_accuracy: 0.9874 - val_loss: 0.6225 - val_binary_accuracy: 0.8525\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0486 - binary_accuracy: 0.9892 - val_loss: 0.7108 - val_binary_accuracy: 0.8197\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0327 - binary_accuracy: 0.9874 - val_loss: 0.9895 - val_binary_accuracy: 0.7541\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0386 - binary_accuracy: 0.9874 - val_loss: 0.9846 - val_binary_accuracy: 0.8033\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0282 - binary_accuracy: 0.9928 - val_loss: 0.6790 - val_binary_accuracy: 0.8197\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0240 - binary_accuracy: 0.9964 - val_loss: 0.6554 - val_binary_accuracy: 0.8525\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 688us/sample - loss: 0.0228 - binary_accuracy: 0.9982 - val_loss: 0.7681 - val_binary_accuracy: 0.8033\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 700us/sample - loss: 0.0256 - binary_accuracy: 0.9910 - val_loss: 0.6685 - val_binary_accuracy: 0.8525\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0278 - binary_accuracy: 0.9910 - val_loss: 0.5821 - val_binary_accuracy: 0.8689\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0318 - binary_accuracy: 0.9892 - val_loss: 0.6568 - val_binary_accuracy: 0.8361\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0224 - binary_accuracy: 0.9946 - val_loss: 0.6291 - val_binary_accuracy: 0.8525\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0226 - binary_accuracy: 0.9946 - val_loss: 0.6944 - val_binary_accuracy: 0.8361\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0131 - binary_accuracy: 0.9982 - val_loss: 0.7537 - val_binary_accuracy: 0.8689\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0324 - binary_accuracy: 0.9892 - val_loss: 0.6801 - val_binary_accuracy: 0.8197\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 694us/sample - loss: 0.0158 - binary_accuracy: 0.9982 - val_loss: 0.7564 - val_binary_accuracy: 0.8361\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 720us/sample - loss: 0.0172 - binary_accuracy: 0.9964 - val_loss: 0.6409 - val_binary_accuracy: 0.8525\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 694us/sample - loss: 0.0222 - binary_accuracy: 0.9946 - val_loss: 3.9786 - val_binary_accuracy: 0.2623\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0234 - binary_accuracy: 0.9964 - val_loss: 0.6064 - val_binary_accuracy: 0.8525\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0146 - binary_accuracy: 0.9982 - val_loss: 0.6681 - val_binary_accuracy: 0.8361\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0165 - binary_accuracy: 0.9964 - val_loss: 0.6468 - val_binary_accuracy: 0.8197\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0250 - binary_accuracy: 0.9928 - val_loss: 0.6912 - val_binary_accuracy: 0.8852\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0274 - binary_accuracy: 0.9946 - val_loss: 0.6738 - val_binary_accuracy: 0.8525\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0351 - binary_accuracy: 0.9874 - val_loss: 0.7215 - val_binary_accuracy: 0.8689\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0091 - binary_accuracy: 0.9982 - val_loss: 0.6485 - val_binary_accuracy: 0.8525\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0155 - binary_accuracy: 0.9946 - val_loss: 0.7928 - val_binary_accuracy: 0.8852\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0089 - binary_accuracy: 0.9982 - val_loss: 0.6301 - val_binary_accuracy: 0.8361\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0106 - binary_accuracy: 0.9982 - val_loss: 0.7868 - val_binary_accuracy: 0.8361\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0308 - binary_accuracy: 0.9910 - val_loss: 0.7363 - val_binary_accuracy: 0.8197\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 0.6896 - val_binary_accuracy: 0.8525\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0157 - binary_accuracy: 0.9910 - val_loss: 0.6172 - val_binary_accuracy: 0.8525\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0115 - binary_accuracy: 0.9982 - val_loss: 0.6297 - val_binary_accuracy: 0.8197\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0139 - binary_accuracy: 0.9964 - val_loss: 0.7043 - val_binary_accuracy: 0.8197\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 667us/sample - loss: 0.0151 - binary_accuracy: 0.9928 - val_loss: 0.7864 - val_binary_accuracy: 0.8525\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.0144 - binary_accuracy: 0.9964 - val_loss: 1.2745 - val_binary_accuracy: 0.8033\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0176 - binary_accuracy: 0.9964 - val_loss: 0.6278 - val_binary_accuracy: 0.8525\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0216 - binary_accuracy: 0.9892 - val_loss: 0.7017 - val_binary_accuracy: 0.8689\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0268 - binary_accuracy: 0.9892 - val_loss: 0.8554 - val_binary_accuracy: 0.8361\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0216 - binary_accuracy: 0.9946 - val_loss: 0.6501 - val_binary_accuracy: 0.8852\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0199 - binary_accuracy: 0.9928 - val_loss: 0.7818 - val_binary_accuracy: 0.8361\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 0.6473 - val_binary_accuracy: 0.8689\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 689us/sample - loss: 0.0076 - binary_accuracy: 0.9982 - val_loss: 0.8181 - val_binary_accuracy: 0.8525\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 693us/sample - loss: 0.0153 - binary_accuracy: 0.9964 - val_loss: 0.7560 - val_binary_accuracy: 0.8197\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.0091 - binary_accuracy: 1.0000 - val_loss: 0.7731 - val_binary_accuracy: 0.8361\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0111 - binary_accuracy: 0.9982 - val_loss: 0.7224 - val_binary_accuracy: 0.8689\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.0082 - binary_accuracy: 0.9982 - val_loss: 0.7531 - val_binary_accuracy: 0.8689\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 697us/sample - loss: 0.0208 - binary_accuracy: 0.9910 - val_loss: 0.7834 - val_binary_accuracy: 0.8361\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.0200 - binary_accuracy: 0.9964 - val_loss: 0.6398 - val_binary_accuracy: 0.8689\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0169 - binary_accuracy: 0.9964 - val_loss: 0.5932 - val_binary_accuracy: 0.8525\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0180 - binary_accuracy: 0.9928 - val_loss: 0.7338 - val_binary_accuracy: 0.8525\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0148 - binary_accuracy: 0.9964 - val_loss: 0.7071 - val_binary_accuracy: 0.8525\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 0.7594 - val_binary_accuracy: 0.8361\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0080 - binary_accuracy: 0.9982 - val_loss: 0.7644 - val_binary_accuracy: 0.8689\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0076 - binary_accuracy: 1.0000 - val_loss: 0.8518 - val_binary_accuracy: 0.8525\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0105 - binary_accuracy: 0.9982 - val_loss: 0.8142 - val_binary_accuracy: 0.8525\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.7652 - val_binary_accuracy: 0.8689\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 0.8070 - val_binary_accuracy: 0.8525\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 0.7505 - val_binary_accuracy: 0.8852\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - val_loss: 0.7543 - val_binary_accuracy: 0.8525\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 0.7802 - val_binary_accuracy: 0.8525\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0070 - binary_accuracy: 0.9982 - val_loss: 0.8582 - val_binary_accuracy: 0.8197\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 0.9181 - val_binary_accuracy: 0.8525\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 0.8982 - val_binary_accuracy: 0.8525\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 0.8310 - val_binary_accuracy: 0.8689\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 0.8300 - val_binary_accuracy: 0.8689\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0110 - binary_accuracy: 1.0000 - val_loss: 1.0847 - val_binary_accuracy: 0.8033\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0090 - binary_accuracy: 0.9982 - val_loss: 0.9586 - val_binary_accuracy: 0.8689\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0065 - binary_accuracy: 0.9982 - val_loss: 0.9901 - val_binary_accuracy: 0.8525\n",
      "accuracy for model 6 is 85.24590134620667\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 2ms/sample - loss: 0.5707 - binary_accuracy: 0.7527 - val_loss: 0.5615 - val_binary_accuracy: 0.8033\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.4387 - binary_accuracy: 0.8394 - val_loss: 0.4877 - val_binary_accuracy: 0.8033\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.3578 - binary_accuracy: 0.8845 - val_loss: 0.4199 - val_binary_accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.2962 - binary_accuracy: 0.9206 - val_loss: 0.3850 - val_binary_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 667us/sample - loss: 0.2766 - binary_accuracy: 0.9134 - val_loss: 0.3973 - val_binary_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.2300 - binary_accuracy: 0.9242 - val_loss: 0.3858 - val_binary_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 697us/sample - loss: 0.2152 - binary_accuracy: 0.9332 - val_loss: 0.3718 - val_binary_accuracy: 0.8033\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.1827 - binary_accuracy: 0.9350 - val_loss: 0.3909 - val_binary_accuracy: 0.8033\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.1441 - binary_accuracy: 0.9567 - val_loss: 0.3909 - val_binary_accuracy: 0.8361\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.1324 - binary_accuracy: 0.9621 - val_loss: 0.4003 - val_binary_accuracy: 0.8197\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.1267 - binary_accuracy: 0.9639 - val_loss: 0.4781 - val_binary_accuracy: 0.8525\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0993 - binary_accuracy: 0.9783 - val_loss: 0.4275 - val_binary_accuracy: 0.8361\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0596 - binary_accuracy: 0.9892 - val_loss: 0.4765 - val_binary_accuracy: 0.8525\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0607 - binary_accuracy: 0.9874 - val_loss: 0.8653 - val_binary_accuracy: 0.7541\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0652 - binary_accuracy: 0.9819 - val_loss: 0.9756 - val_binary_accuracy: 0.7705\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0863 - binary_accuracy: 0.9729 - val_loss: 0.8954 - val_binary_accuracy: 0.7049\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 1s 1ms/sample - loss: 0.0689 - binary_accuracy: 0.9765 - val_loss: 1.0080 - val_binary_accuracy: 0.7213\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0589 - binary_accuracy: 0.9783 - val_loss: 0.5856 - val_binary_accuracy: 0.8525\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0534 - binary_accuracy: 0.9874 - val_loss: 0.9060 - val_binary_accuracy: 0.7377\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0418 - binary_accuracy: 0.9856 - val_loss: 0.6880 - val_binary_accuracy: 0.8033\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0365 - binary_accuracy: 0.9928 - val_loss: 0.8488 - val_binary_accuracy: 0.7705\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 702us/sample - loss: 0.0347 - binary_accuracy: 0.9892 - val_loss: 0.5697 - val_binary_accuracy: 0.8197\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 663us/sample - loss: 0.0482 - binary_accuracy: 0.9874 - val_loss: 0.6874 - val_binary_accuracy: 0.8197\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0401 - binary_accuracy: 0.9856 - val_loss: 1.2688 - val_binary_accuracy: 0.6557\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0502 - binary_accuracy: 0.9765 - val_loss: 0.5219 - val_binary_accuracy: 0.8033\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0607 - binary_accuracy: 0.9838 - val_loss: 0.5885 - val_binary_accuracy: 0.8361\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0474 - binary_accuracy: 0.9892 - val_loss: 0.9900 - val_binary_accuracy: 0.7869\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0396 - binary_accuracy: 0.9910 - val_loss: 1.1213 - val_binary_accuracy: 0.7377\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.0319 - binary_accuracy: 0.9910 - val_loss: 0.7735 - val_binary_accuracy: 0.8033\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0359 - binary_accuracy: 0.9928 - val_loss: 0.6702 - val_binary_accuracy: 0.8033\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0361 - binary_accuracy: 0.9910 - val_loss: 0.8092 - val_binary_accuracy: 0.7869\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0396 - binary_accuracy: 0.9874 - val_loss: 1.0010 - val_binary_accuracy: 0.7541\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0255 - binary_accuracy: 0.9946 - val_loss: 0.6623 - val_binary_accuracy: 0.8197\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.0193 - binary_accuracy: 0.9946 - val_loss: 0.9244 - val_binary_accuracy: 0.8197\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0333 - binary_accuracy: 0.9874 - val_loss: 0.8891 - val_binary_accuracy: 0.7869\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0159 - binary_accuracy: 0.9964 - val_loss: 0.7560 - val_binary_accuracy: 0.8361\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0135 - binary_accuracy: 0.9982 - val_loss: 0.7939 - val_binary_accuracy: 0.8197\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0172 - binary_accuracy: 0.9928 - val_loss: 0.9623 - val_binary_accuracy: 0.7705\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0153 - binary_accuracy: 0.9982 - val_loss: 0.6953 - val_binary_accuracy: 0.8197\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.0174 - binary_accuracy: 0.9946 - val_loss: 0.9212 - val_binary_accuracy: 0.8033\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0232 - binary_accuracy: 0.9946 - val_loss: 0.8892 - val_binary_accuracy: 0.8197\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.0352 - binary_accuracy: 0.9856 - val_loss: 0.6875 - val_binary_accuracy: 0.8361\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0194 - binary_accuracy: 0.9964 - val_loss: 0.9106 - val_binary_accuracy: 0.8197\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0289 - binary_accuracy: 0.9892 - val_loss: 1.0508 - val_binary_accuracy: 0.7869\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0185 - binary_accuracy: 0.9964 - val_loss: 0.8542 - val_binary_accuracy: 0.7869\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0158 - binary_accuracy: 0.9982 - val_loss: 0.7744 - val_binary_accuracy: 0.8197\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0328 - binary_accuracy: 0.9892 - val_loss: 1.6895 - val_binary_accuracy: 0.6721\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0139 - binary_accuracy: 1.0000 - val_loss: 0.9885 - val_binary_accuracy: 0.7869\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0249 - binary_accuracy: 0.9928 - val_loss: 0.8288 - val_binary_accuracy: 0.8033\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0220 - binary_accuracy: 0.9928 - val_loss: 0.6811 - val_binary_accuracy: 0.8525\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0111 - binary_accuracy: 0.9964 - val_loss: 0.7137 - val_binary_accuracy: 0.8361\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0166 - binary_accuracy: 0.9946 - val_loss: 0.7440 - val_binary_accuracy: 0.8197\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0224 - binary_accuracy: 0.9982 - val_loss: 0.8155 - val_binary_accuracy: 0.8033\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0093 - binary_accuracy: 1.0000 - val_loss: 1.0025 - val_binary_accuracy: 0.8033\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0109 - binary_accuracy: 0.9982 - val_loss: 0.9128 - val_binary_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 0.8446 - val_binary_accuracy: 0.8361\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0078 - binary_accuracy: 1.0000 - val_loss: 0.7847 - val_binary_accuracy: 0.8197\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.0124 - binary_accuracy: 0.9964 - val_loss: 0.7654 - val_binary_accuracy: 0.8361\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0124 - binary_accuracy: 1.0000 - val_loss: 0.7571 - val_binary_accuracy: 0.8361\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 695us/sample - loss: 0.0101 - binary_accuracy: 1.0000 - val_loss: 0.9299 - val_binary_accuracy: 0.8197\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 0.8113 - val_binary_accuracy: 0.8197\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 0.7912 - val_binary_accuracy: 0.8197\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0107 - binary_accuracy: 0.9982 - val_loss: 0.9713 - val_binary_accuracy: 0.8361\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0109 - binary_accuracy: 0.9946 - val_loss: 0.7147 - val_binary_accuracy: 0.8197\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0086 - binary_accuracy: 1.0000 - val_loss: 0.8824 - val_binary_accuracy: 0.8361\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0124 - binary_accuracy: 0.9964 - val_loss: 0.9208 - val_binary_accuracy: 0.8361\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0098 - binary_accuracy: 0.9982 - val_loss: 1.0005 - val_binary_accuracy: 0.8361\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0099 - binary_accuracy: 0.9982 - val_loss: 0.9082 - val_binary_accuracy: 0.8197\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 663us/sample - loss: 0.0091 - binary_accuracy: 0.9982 - val_loss: 0.9082 - val_binary_accuracy: 0.8197\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0177 - binary_accuracy: 0.9946 - val_loss: 0.9250 - val_binary_accuracy: 0.8197\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0305 - binary_accuracy: 0.9910 - val_loss: 0.8190 - val_binary_accuracy: 0.7705\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 667us/sample - loss: 0.0142 - binary_accuracy: 0.9946 - val_loss: 0.8684 - val_binary_accuracy: 0.8361\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0168 - binary_accuracy: 0.9964 - val_loss: 0.8483 - val_binary_accuracy: 0.8197\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 667us/sample - loss: 0.0056 - binary_accuracy: 0.9982 - val_loss: 0.8437 - val_binary_accuracy: 0.8361\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0110 - binary_accuracy: 0.9964 - val_loss: 0.7944 - val_binary_accuracy: 0.8361\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 701us/sample - loss: 0.0088 - binary_accuracy: 0.9982 - val_loss: 0.9737 - val_binary_accuracy: 0.8033\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 711us/sample - loss: 0.0126 - binary_accuracy: 0.9946 - val_loss: 0.8537 - val_binary_accuracy: 0.8197\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 704us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 1.0508 - val_binary_accuracy: 0.8197\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0078 - binary_accuracy: 0.9982 - val_loss: 1.0089 - val_binary_accuracy: 0.8197\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0108 - binary_accuracy: 0.9982 - val_loss: 1.1155 - val_binary_accuracy: 0.8197\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0128 - binary_accuracy: 0.9964 - val_loss: 1.0529 - val_binary_accuracy: 0.8033\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 1.0764 - val_binary_accuracy: 0.8033\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.0115 - binary_accuracy: 0.9946 - val_loss: 1.3281 - val_binary_accuracy: 0.8033\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 1.1989 - val_binary_accuracy: 0.8033\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0133 - binary_accuracy: 0.9964 - val_loss: 0.8699 - val_binary_accuracy: 0.8197\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0071 - binary_accuracy: 1.0000 - val_loss: 0.8609 - val_binary_accuracy: 0.8197\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 0.9404 - val_binary_accuracy: 0.8197\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0137 - binary_accuracy: 0.9982 - val_loss: 0.9892 - val_binary_accuracy: 0.8033\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 693us/sample - loss: 0.0083 - binary_accuracy: 0.9964 - val_loss: 0.9769 - val_binary_accuracy: 0.8033\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.9699 - val_binary_accuracy: 0.8197\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 0.9118 - val_binary_accuracy: 0.8197\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0084 - binary_accuracy: 0.9982 - val_loss: 0.8483 - val_binary_accuracy: 0.8197\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 703us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 1.0740 - val_binary_accuracy: 0.8033\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 667us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.9234 - val_binary_accuracy: 0.8361\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0139 - binary_accuracy: 0.9946 - val_loss: 0.9170 - val_binary_accuracy: 0.8197\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0056 - binary_accuracy: 0.9982 - val_loss: 0.9372 - val_binary_accuracy: 0.8197\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0088 - binary_accuracy: 0.9964 - val_loss: 0.9750 - val_binary_accuracy: 0.8525\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.8268 - val_binary_accuracy: 0.8525\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0062 - binary_accuracy: 0.9982 - val_loss: 1.0528 - val_binary_accuracy: 0.8197\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 661us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 0.9010 - val_binary_accuracy: 0.8361\n",
      "accuracy for model 7 is 83.60655903816223\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 2ms/sample - loss: 0.6314 - binary_accuracy: 0.7076 - val_loss: 0.5235 - val_binary_accuracy: 0.9016\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.4338 - binary_accuracy: 0.8466 - val_loss: 0.4724 - val_binary_accuracy: 0.8525\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.3526 - binary_accuracy: 0.8953 - val_loss: 0.4427 - val_binary_accuracy: 0.8361\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.3125 - binary_accuracy: 0.8989 - val_loss: 0.4020 - val_binary_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.2992 - binary_accuracy: 0.9079 - val_loss: 0.3985 - val_binary_accuracy: 0.8361\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 689us/sample - loss: 0.2608 - binary_accuracy: 0.9116 - val_loss: 0.4194 - val_binary_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.2278 - binary_accuracy: 0.9260 - val_loss: 0.3845 - val_binary_accuracy: 0.8525\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.2303 - binary_accuracy: 0.9170 - val_loss: 0.3928 - val_binary_accuracy: 0.8525\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.2066 - binary_accuracy: 0.9188 - val_loss: 0.4173 - val_binary_accuracy: 0.8361\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.2145 - binary_accuracy: 0.9278 - val_loss: 0.3779 - val_binary_accuracy: 0.8689\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.1947 - binary_accuracy: 0.9278 - val_loss: 0.4861 - val_binary_accuracy: 0.8197\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.1848 - binary_accuracy: 0.9296 - val_loss: 0.4277 - val_binary_accuracy: 0.8525\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 658us/sample - loss: 0.1484 - binary_accuracy: 0.9495 - val_loss: 0.3998 - val_binary_accuracy: 0.8525\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 658us/sample - loss: 0.1370 - binary_accuracy: 0.9495 - val_loss: 0.5048 - val_binary_accuracy: 0.7541\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 896us/sample - loss: 0.1673 - binary_accuracy: 0.9477 - val_loss: 0.4771 - val_binary_accuracy: 0.8033\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.1355 - binary_accuracy: 0.9458 - val_loss: 0.4965 - val_binary_accuracy: 0.8361\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.1209 - binary_accuracy: 0.9639 - val_loss: 0.5864 - val_binary_accuracy: 0.7049\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.1132 - binary_accuracy: 0.9603 - val_loss: 0.4723 - val_binary_accuracy: 0.8197\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.1258 - binary_accuracy: 0.9549 - val_loss: 0.4898 - val_binary_accuracy: 0.8361\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.0966 - binary_accuracy: 0.9711 - val_loss: 0.5200 - val_binary_accuracy: 0.8525\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0807 - binary_accuracy: 0.9801 - val_loss: 0.5142 - val_binary_accuracy: 0.7869\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0874 - binary_accuracy: 0.9639 - val_loss: 0.3316 - val_binary_accuracy: 0.8525\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0559 - binary_accuracy: 0.9856 - val_loss: 0.4344 - val_binary_accuracy: 0.8361\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0736 - binary_accuracy: 0.9783 - val_loss: 0.4863 - val_binary_accuracy: 0.8361\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0836 - binary_accuracy: 0.9657 - val_loss: 0.5603 - val_binary_accuracy: 0.8361\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0672 - binary_accuracy: 0.9801 - val_loss: 0.7770 - val_binary_accuracy: 0.6885\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0479 - binary_accuracy: 0.9928 - val_loss: 0.4372 - val_binary_accuracy: 0.8197\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0532 - binary_accuracy: 0.9856 - val_loss: 1.0842 - val_binary_accuracy: 0.8197\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0546 - binary_accuracy: 0.9819 - val_loss: 0.4791 - val_binary_accuracy: 0.8361\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0693 - binary_accuracy: 0.9838 - val_loss: 6.7094 - val_binary_accuracy: 0.2131\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0597 - binary_accuracy: 0.9856 - val_loss: 0.6216 - val_binary_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0752 - binary_accuracy: 0.9747 - val_loss: 0.4466 - val_binary_accuracy: 0.8361\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.0580 - binary_accuracy: 0.9856 - val_loss: 0.4013 - val_binary_accuracy: 0.8689\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0450 - binary_accuracy: 0.9874 - val_loss: 0.7958 - val_binary_accuracy: 0.8525\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0390 - binary_accuracy: 0.9946 - val_loss: 0.4956 - val_binary_accuracy: 0.8525\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0344 - binary_accuracy: 0.9928 - val_loss: 0.6596 - val_binary_accuracy: 0.8525\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0413 - binary_accuracy: 0.9856 - val_loss: 0.6655 - val_binary_accuracy: 0.8525\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.0350 - binary_accuracy: 0.9892 - val_loss: 0.7338 - val_binary_accuracy: 0.8525\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0355 - binary_accuracy: 0.9874 - val_loss: 0.5137 - val_binary_accuracy: 0.8689\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.0392 - binary_accuracy: 0.9874 - val_loss: 0.5663 - val_binary_accuracy: 0.8852\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0262 - binary_accuracy: 0.9928 - val_loss: 0.4780 - val_binary_accuracy: 0.8525\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 694us/sample - loss: 0.0496 - binary_accuracy: 0.9856 - val_loss: 0.4136 - val_binary_accuracy: 0.8197\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0423 - binary_accuracy: 0.9874 - val_loss: 0.4961 - val_binary_accuracy: 0.8033\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0239 - binary_accuracy: 0.9946 - val_loss: 0.7804 - val_binary_accuracy: 0.8525\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0389 - binary_accuracy: 0.9856 - val_loss: 0.3959 - val_binary_accuracy: 0.8689\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0527 - binary_accuracy: 0.9801 - val_loss: 0.5721 - val_binary_accuracy: 0.8525\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0527 - binary_accuracy: 0.9801 - val_loss: 0.5252 - val_binary_accuracy: 0.7869\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0292 - binary_accuracy: 0.9928 - val_loss: 0.4773 - val_binary_accuracy: 0.7869\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0228 - binary_accuracy: 0.9946 - val_loss: 0.7180 - val_binary_accuracy: 0.8689\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0310 - binary_accuracy: 0.9946 - val_loss: 0.7242 - val_binary_accuracy: 0.7213\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0225 - binary_accuracy: 0.9928 - val_loss: 0.5399 - val_binary_accuracy: 0.8689\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0216 - binary_accuracy: 0.9982 - val_loss: 0.5964 - val_binary_accuracy: 0.8689\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0166 - binary_accuracy: 0.9982 - val_loss: 0.6346 - val_binary_accuracy: 0.8525\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0205 - binary_accuracy: 0.9964 - val_loss: 0.4110 - val_binary_accuracy: 0.8525\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0394 - binary_accuracy: 0.9892 - val_loss: 0.9052 - val_binary_accuracy: 0.8525\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0152 - binary_accuracy: 0.9982 - val_loss: 0.6979 - val_binary_accuracy: 0.7213\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0261 - binary_accuracy: 0.9910 - val_loss: 0.5781 - val_binary_accuracy: 0.7705\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0510 - binary_accuracy: 0.9838 - val_loss: 0.5174 - val_binary_accuracy: 0.7705\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0470 - binary_accuracy: 0.9856 - val_loss: 0.4988 - val_binary_accuracy: 0.8852\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0146 - binary_accuracy: 0.9982 - val_loss: 0.7000 - val_binary_accuracy: 0.8525\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0200 - binary_accuracy: 0.9964 - val_loss: 0.7658 - val_binary_accuracy: 0.8689\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0196 - binary_accuracy: 0.9964 - val_loss: 0.5399 - val_binary_accuracy: 0.8689\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.0141 - binary_accuracy: 0.9946 - val_loss: 0.4803 - val_binary_accuracy: 0.8525\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0107 - binary_accuracy: 0.9964 - val_loss: 0.4258 - val_binary_accuracy: 0.9180\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0205 - binary_accuracy: 0.9928 - val_loss: 0.5592 - val_binary_accuracy: 0.7869\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0426 - binary_accuracy: 0.9838 - val_loss: 0.4776 - val_binary_accuracy: 0.8852\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0227 - binary_accuracy: 0.9964 - val_loss: 0.4410 - val_binary_accuracy: 0.8852\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0131 - binary_accuracy: 0.9982 - val_loss: 0.4938 - val_binary_accuracy: 0.8033\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0144 - binary_accuracy: 0.9982 - val_loss: 1.0160 - val_binary_accuracy: 0.8361\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0095 - binary_accuracy: 0.9982 - val_loss: 0.4615 - val_binary_accuracy: 0.8852\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0078 - binary_accuracy: 1.0000 - val_loss: 0.3732 - val_binary_accuracy: 0.8689\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0144 - binary_accuracy: 0.9946 - val_loss: 0.4536 - val_binary_accuracy: 0.9016\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0150 - binary_accuracy: 0.9964 - val_loss: 0.5315 - val_binary_accuracy: 0.8852\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0119 - binary_accuracy: 0.9982 - val_loss: 2.0846 - val_binary_accuracy: 0.4754\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0171 - binary_accuracy: 0.9946 - val_loss: 0.5280 - val_binary_accuracy: 0.8361\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0147 - binary_accuracy: 0.9964 - val_loss: 0.8254 - val_binary_accuracy: 0.8525\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 694us/sample - loss: 0.0138 - binary_accuracy: 0.9964 - val_loss: 0.6036 - val_binary_accuracy: 0.8852\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0129 - binary_accuracy: 0.9964 - val_loss: 0.6610 - val_binary_accuracy: 0.8852\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0059 - binary_accuracy: 1.0000 - val_loss: 0.5345 - val_binary_accuracy: 0.8852\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0287 - binary_accuracy: 0.9910 - val_loss: 0.9426 - val_binary_accuracy: 0.6721\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 688us/sample - loss: 0.0086 - binary_accuracy: 0.9982 - val_loss: 0.5193 - val_binary_accuracy: 0.8361\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 693us/sample - loss: 0.0074 - binary_accuracy: 0.9982 - val_loss: 0.6097 - val_binary_accuracy: 0.8852\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0056 - binary_accuracy: 1.0000 - val_loss: 0.5730 - val_binary_accuracy: 0.8852\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0156 - binary_accuracy: 0.9964 - val_loss: 0.7909 - val_binary_accuracy: 0.8689\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0603 - binary_accuracy: 0.9801 - val_loss: 4.7517 - val_binary_accuracy: 0.2295\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 694us/sample - loss: 0.0110 - binary_accuracy: 1.0000 - val_loss: 0.4797 - val_binary_accuracy: 0.8689\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0189 - binary_accuracy: 0.9946 - val_loss: 0.5291 - val_binary_accuracy: 0.8525\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0181 - binary_accuracy: 0.9910 - val_loss: 0.4634 - val_binary_accuracy: 0.8361\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0140 - binary_accuracy: 0.9964 - val_loss: 0.4523 - val_binary_accuracy: 0.8361\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.5016 - val_binary_accuracy: 0.8689\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0176 - binary_accuracy: 0.9928 - val_loss: 0.4591 - val_binary_accuracy: 0.8361\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0224 - binary_accuracy: 0.9928 - val_loss: 1.1731 - val_binary_accuracy: 0.8361\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 694us/sample - loss: 0.0160 - binary_accuracy: 0.9928 - val_loss: 0.6413 - val_binary_accuracy: 0.8689\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 703us/sample - loss: 0.0144 - binary_accuracy: 0.9964 - val_loss: 0.5811 - val_binary_accuracy: 0.8689\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0137 - binary_accuracy: 0.9928 - val_loss: 0.5794 - val_binary_accuracy: 0.8361\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 0.6306 - val_binary_accuracy: 0.8689\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0218 - binary_accuracy: 0.9946 - val_loss: 0.4451 - val_binary_accuracy: 0.8197\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 693us/sample - loss: 0.0107 - binary_accuracy: 0.9964 - val_loss: 0.6088 - val_binary_accuracy: 0.8689\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 710us/sample - loss: 0.0146 - binary_accuracy: 0.9964 - val_loss: 0.5893 - val_binary_accuracy: 0.8361\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 0.8290 - val_binary_accuracy: 0.8689\n",
      "accuracy for model 8 is 86.8852436542511\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 2ms/sample - loss: 0.5695 - binary_accuracy: 0.7383 - val_loss: 0.5040 - val_binary_accuracy: 0.9016\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.4297 - binary_accuracy: 0.8628 - val_loss: 0.4147 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.3617 - binary_accuracy: 0.8827 - val_loss: 0.3721 - val_binary_accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.3161 - binary_accuracy: 0.8953 - val_loss: 0.3640 - val_binary_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 688us/sample - loss: 0.2874 - binary_accuracy: 0.9061 - val_loss: 0.3162 - val_binary_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.2560 - binary_accuracy: 0.9134 - val_loss: 0.2799 - val_binary_accuracy: 0.8525\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.2482 - binary_accuracy: 0.9152 - val_loss: 0.2821 - val_binary_accuracy: 0.8525\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.2326 - binary_accuracy: 0.9278 - val_loss: 0.2885 - val_binary_accuracy: 0.8525\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.2073 - binary_accuracy: 0.9368 - val_loss: 0.2708 - val_binary_accuracy: 0.9344\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.1949 - binary_accuracy: 0.9242 - val_loss: 0.3094 - val_binary_accuracy: 0.8361\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.1555 - binary_accuracy: 0.9458 - val_loss: 0.2275 - val_binary_accuracy: 0.9180\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.1564 - binary_accuracy: 0.9531 - val_loss: 0.2408 - val_binary_accuracy: 0.9180\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.1228 - binary_accuracy: 0.9621 - val_loss: 0.2791 - val_binary_accuracy: 0.9016\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.1128 - binary_accuracy: 0.9657 - val_loss: 0.2336 - val_binary_accuracy: 0.9344\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0926 - binary_accuracy: 0.9765 - val_loss: 0.2985 - val_binary_accuracy: 0.8852\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 695us/sample - loss: 0.0879 - binary_accuracy: 0.9747 - val_loss: 0.4937 - val_binary_accuracy: 0.8689\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 707us/sample - loss: 0.0787 - binary_accuracy: 0.9747 - val_loss: 0.2304 - val_binary_accuracy: 0.9016\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0952 - binary_accuracy: 0.9621 - val_loss: 0.3082 - val_binary_accuracy: 0.8852\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0595 - binary_accuracy: 0.9874 - val_loss: 0.4200 - val_binary_accuracy: 0.8361\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0833 - binary_accuracy: 0.9747 - val_loss: 0.5107 - val_binary_accuracy: 0.8689\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0606 - binary_accuracy: 0.9910 - val_loss: 0.5436 - val_binary_accuracy: 0.8689\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0485 - binary_accuracy: 0.9892 - val_loss: 0.6905 - val_binary_accuracy: 0.8361\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 694us/sample - loss: 0.0575 - binary_accuracy: 0.9801 - val_loss: 0.3832 - val_binary_accuracy: 0.8525\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.0592 - binary_accuracy: 0.9838 - val_loss: 0.5592 - val_binary_accuracy: 0.8361\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0492 - binary_accuracy: 0.9856 - val_loss: 0.3842 - val_binary_accuracy: 0.8197\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0668 - binary_accuracy: 0.9838 - val_loss: 0.6837 - val_binary_accuracy: 0.8197\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0649 - binary_accuracy: 0.9856 - val_loss: 0.5319 - val_binary_accuracy: 0.8525\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0373 - binary_accuracy: 0.9874 - val_loss: 0.3713 - val_binary_accuracy: 0.8525\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 693us/sample - loss: 0.0333 - binary_accuracy: 0.9946 - val_loss: 0.2890 - val_binary_accuracy: 0.9180\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.0242 - binary_accuracy: 0.9946 - val_loss: 1.0189 - val_binary_accuracy: 0.6721\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0212 - binary_accuracy: 0.9982 - val_loss: 0.5295 - val_binary_accuracy: 0.8689\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0231 - binary_accuracy: 0.9910 - val_loss: 0.4217 - val_binary_accuracy: 0.8852\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0314 - binary_accuracy: 0.9892 - val_loss: 0.5793 - val_binary_accuracy: 0.8852\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0360 - binary_accuracy: 0.9874 - val_loss: 0.4809 - val_binary_accuracy: 0.8852\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.0329 - binary_accuracy: 0.9892 - val_loss: 0.7200 - val_binary_accuracy: 0.8361\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0215 - binary_accuracy: 0.9964 - val_loss: 0.5335 - val_binary_accuracy: 0.8852\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0259 - binary_accuracy: 0.9910 - val_loss: 0.5030 - val_binary_accuracy: 0.8852\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 662us/sample - loss: 0.0281 - binary_accuracy: 0.9928 - val_loss: 0.7382 - val_binary_accuracy: 0.8361\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0298 - binary_accuracy: 0.9964 - val_loss: 0.7227 - val_binary_accuracy: 0.8525\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0266 - binary_accuracy: 0.9928 - val_loss: 0.7256 - val_binary_accuracy: 0.8197\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0267 - binary_accuracy: 0.9892 - val_loss: 0.5619 - val_binary_accuracy: 0.8852\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0156 - binary_accuracy: 0.9982 - val_loss: 0.6409 - val_binary_accuracy: 0.8361\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0364 - binary_accuracy: 0.9856 - val_loss: 0.7816 - val_binary_accuracy: 0.8852\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0583 - binary_accuracy: 0.9783 - val_loss: 1.4369 - val_binary_accuracy: 0.6066\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.0276 - binary_accuracy: 0.9892 - val_loss: 0.5445 - val_binary_accuracy: 0.8852\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0235 - binary_accuracy: 0.9928 - val_loss: 0.8636 - val_binary_accuracy: 0.7213\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0197 - binary_accuracy: 0.9982 - val_loss: 0.3648 - val_binary_accuracy: 0.8852\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0262 - binary_accuracy: 0.9892 - val_loss: 0.4259 - val_binary_accuracy: 0.8852\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0188 - binary_accuracy: 0.9964 - val_loss: 0.2881 - val_binary_accuracy: 0.9016\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0186 - binary_accuracy: 0.9964 - val_loss: 0.3661 - val_binary_accuracy: 0.8852\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0087 - binary_accuracy: 1.0000 - val_loss: 0.3703 - val_binary_accuracy: 0.8852\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0155 - binary_accuracy: 0.9982 - val_loss: 0.4215 - val_binary_accuracy: 0.8852\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0111 - binary_accuracy: 0.9964 - val_loss: 0.4178 - val_binary_accuracy: 0.8852\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0135 - binary_accuracy: 0.9982 - val_loss: 0.6269 - val_binary_accuracy: 0.8361\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0309 - binary_accuracy: 0.9838 - val_loss: 0.3219 - val_binary_accuracy: 0.8852\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0543 - binary_accuracy: 0.9838 - val_loss: 0.5516 - val_binary_accuracy: 0.9016\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.0199 - binary_accuracy: 0.9964 - val_loss: 0.4985 - val_binary_accuracy: 0.8689\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0192 - binary_accuracy: 0.9946 - val_loss: 0.4695 - val_binary_accuracy: 0.8525\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0168 - binary_accuracy: 0.9964 - val_loss: 0.4437 - val_binary_accuracy: 0.9180\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0228 - binary_accuracy: 0.9928 - val_loss: 0.3472 - val_binary_accuracy: 0.9180\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0112 - binary_accuracy: 1.0000 - val_loss: 0.3830 - val_binary_accuracy: 0.8852\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0203 - binary_accuracy: 0.9928 - val_loss: 0.4355 - val_binary_accuracy: 0.8525\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0091 - binary_accuracy: 1.0000 - val_loss: 0.3367 - val_binary_accuracy: 0.9016\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0193 - binary_accuracy: 0.9892 - val_loss: 0.3141 - val_binary_accuracy: 0.8852\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0285 - binary_accuracy: 0.9910 - val_loss: 0.3240 - val_binary_accuracy: 0.9180\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0208 - binary_accuracy: 0.9892 - val_loss: 0.4141 - val_binary_accuracy: 0.8852\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0190 - binary_accuracy: 0.9928 - val_loss: 0.3248 - val_binary_accuracy: 0.9016\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 699us/sample - loss: 0.0139 - binary_accuracy: 0.9964 - val_loss: 0.2800 - val_binary_accuracy: 0.9180\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0153 - binary_accuracy: 0.9928 - val_loss: 0.4516 - val_binary_accuracy: 0.8525\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0275 - binary_accuracy: 0.9910 - val_loss: 0.4222 - val_binary_accuracy: 0.8689\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0186 - binary_accuracy: 0.9946 - val_loss: 0.2643 - val_binary_accuracy: 0.9344\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0093 - binary_accuracy: 0.9982 - val_loss: 0.3164 - val_binary_accuracy: 0.9016\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0085 - binary_accuracy: 0.9982 - val_loss: 0.4558 - val_binary_accuracy: 0.8689\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 0.3818 - val_binary_accuracy: 0.9180\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0119 - binary_accuracy: 0.9964 - val_loss: 0.3099 - val_binary_accuracy: 0.9016\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0126 - binary_accuracy: 0.9946 - val_loss: 3.4223 - val_binary_accuracy: 0.2951\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0179 - binary_accuracy: 0.9964 - val_loss: 0.5470 - val_binary_accuracy: 0.8525\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0164 - binary_accuracy: 0.9928 - val_loss: 0.5222 - val_binary_accuracy: 0.9016\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0179 - binary_accuracy: 0.9964 - val_loss: 0.3495 - val_binary_accuracy: 0.9344\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0171 - binary_accuracy: 0.9964 - val_loss: 0.3139 - val_binary_accuracy: 0.9344\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0152 - binary_accuracy: 0.9964 - val_loss: 0.2878 - val_binary_accuracy: 0.9016\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 667us/sample - loss: 0.0155 - binary_accuracy: 0.9946 - val_loss: 0.3336 - val_binary_accuracy: 0.9344\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 695us/sample - loss: 0.0074 - binary_accuracy: 0.9982 - val_loss: 0.3438 - val_binary_accuracy: 0.9180\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.3275 - val_binary_accuracy: 0.9180\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0155 - binary_accuracy: 0.9982 - val_loss: 0.7951 - val_binary_accuracy: 0.8361\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0121 - binary_accuracy: 0.9964 - val_loss: 0.5332 - val_binary_accuracy: 0.9016\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 695us/sample - loss: 0.0067 - binary_accuracy: 1.0000 - val_loss: 0.7758 - val_binary_accuracy: 0.8361\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 0.3651 - val_binary_accuracy: 0.9180\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.3513 - val_binary_accuracy: 0.9344\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 688us/sample - loss: 0.0062 - binary_accuracy: 0.9964 - val_loss: 0.3699 - val_binary_accuracy: 0.9180\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.3881 - val_binary_accuracy: 0.9344\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 672us/sample - loss: 0.0143 - binary_accuracy: 0.9946 - val_loss: 0.3008 - val_binary_accuracy: 0.9016\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0129 - binary_accuracy: 0.9964 - val_loss: 0.3714 - val_binary_accuracy: 0.9180\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0093 - binary_accuracy: 0.9982 - val_loss: 0.4150 - val_binary_accuracy: 0.9016\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0083 - binary_accuracy: 1.0000 - val_loss: 0.3828 - val_binary_accuracy: 0.9180\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 706us/sample - loss: 0.0169 - binary_accuracy: 0.9964 - val_loss: 0.4049 - val_binary_accuracy: 0.9344\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 0.3799 - val_binary_accuracy: 0.9016\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0168 - binary_accuracy: 0.9964 - val_loss: 0.4164 - val_binary_accuracy: 0.8689\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.2911 - val_binary_accuracy: 0.9016\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.0076 - binary_accuracy: 0.9982 - val_loss: 0.2880 - val_binary_accuracy: 0.9180\n",
      "accuracy for model 9 is 91.80327653884888\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 27048, 12)         180       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 27048, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 27039, 10)         1210      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 27039, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 27032, 8)          648       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 27032, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 13516, 8)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 13516, 8)          32        \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 108128)            0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 48)                5190192   \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,194,439\n",
      "Trainable params: 5,194,391\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 2ms/sample - loss: 0.5770 - binary_accuracy: 0.7671 - val_loss: 0.5252 - val_binary_accuracy: 0.8689\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.4339 - binary_accuracy: 0.8430 - val_loss: 0.4048 - val_binary_accuracy: 0.8361\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 692us/sample - loss: 0.3589 - binary_accuracy: 0.8809 - val_loss: 0.3705 - val_binary_accuracy: 0.8361\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 688us/sample - loss: 0.3176 - binary_accuracy: 0.8953 - val_loss: 0.3252 - val_binary_accuracy: 0.8361\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 688us/sample - loss: 0.2965 - binary_accuracy: 0.8971 - val_loss: 0.3036 - val_binary_accuracy: 0.8361\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.2631 - binary_accuracy: 0.9079 - val_loss: 0.3135 - val_binary_accuracy: 0.8525\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.2426 - binary_accuracy: 0.9260 - val_loss: 0.2374 - val_binary_accuracy: 0.9180\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.2469 - binary_accuracy: 0.9134 - val_loss: 0.2333 - val_binary_accuracy: 0.9180\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.2189 - binary_accuracy: 0.9152 - val_loss: 0.3245 - val_binary_accuracy: 0.8197\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.2137 - binary_accuracy: 0.9134 - val_loss: 0.2204 - val_binary_accuracy: 0.9508\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 705us/sample - loss: 0.2070 - binary_accuracy: 0.9097 - val_loss: 0.2869 - val_binary_accuracy: 0.9016\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.1805 - binary_accuracy: 0.9458 - val_loss: 0.4985 - val_binary_accuracy: 0.7213\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.1662 - binary_accuracy: 0.9458 - val_loss: 0.2148 - val_binary_accuracy: 0.9508\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.1494 - binary_accuracy: 0.9440 - val_loss: 0.2973 - val_binary_accuracy: 0.9180\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.1456 - binary_accuracy: 0.9513 - val_loss: 0.2108 - val_binary_accuracy: 0.9344\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.1160 - binary_accuracy: 0.9567 - val_loss: 2.3760 - val_binary_accuracy: 0.2623\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.0959 - binary_accuracy: 0.9693 - val_loss: 0.3781 - val_binary_accuracy: 0.8689\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.1064 - binary_accuracy: 0.9729 - val_loss: 0.3796 - val_binary_accuracy: 0.8689\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 699us/sample - loss: 0.0848 - binary_accuracy: 0.9729 - val_loss: 0.2527 - val_binary_accuracy: 0.9016\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 689us/sample - loss: 0.1001 - binary_accuracy: 0.9693 - val_loss: 0.4898 - val_binary_accuracy: 0.8525\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 667us/sample - loss: 0.0645 - binary_accuracy: 0.9838 - val_loss: 0.6397 - val_binary_accuracy: 0.7377\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0811 - binary_accuracy: 0.9711 - val_loss: 0.4229 - val_binary_accuracy: 0.7705\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 695us/sample - loss: 0.0548 - binary_accuracy: 0.9838 - val_loss: 0.2871 - val_binary_accuracy: 0.9016\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 702us/sample - loss: 0.0559 - binary_accuracy: 0.9838 - val_loss: 0.2707 - val_binary_accuracy: 0.9016\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0739 - binary_accuracy: 0.9819 - val_loss: 0.4557 - val_binary_accuracy: 0.8852\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0672 - binary_accuracy: 0.9801 - val_loss: 10.6055 - val_binary_accuracy: 0.1967\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0972 - binary_accuracy: 0.9693 - val_loss: 2.3077 - val_binary_accuracy: 0.3934\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.0657 - binary_accuracy: 0.9783 - val_loss: 1.0122 - val_binary_accuracy: 0.6230\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0553 - binary_accuracy: 0.9856 - val_loss: 0.4648 - val_binary_accuracy: 0.8689\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0562 - binary_accuracy: 0.9892 - val_loss: 0.2941 - val_binary_accuracy: 0.8852\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0509 - binary_accuracy: 0.9838 - val_loss: 0.2835 - val_binary_accuracy: 0.9180\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0555 - binary_accuracy: 0.9819 - val_loss: 0.2669 - val_binary_accuracy: 0.8852\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0532 - binary_accuracy: 0.9801 - val_loss: 0.3572 - val_binary_accuracy: 0.9016\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0504 - binary_accuracy: 0.9765 - val_loss: 0.3736 - val_binary_accuracy: 0.8852\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0371 - binary_accuracy: 0.9874 - val_loss: 0.8060 - val_binary_accuracy: 0.7213\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 684us/sample - loss: 0.0335 - binary_accuracy: 0.9892 - val_loss: 0.3312 - val_binary_accuracy: 0.8689\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0534 - binary_accuracy: 0.9838 - val_loss: 2.9291 - val_binary_accuracy: 0.2951\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0381 - binary_accuracy: 0.9874 - val_loss: 0.3527 - val_binary_accuracy: 0.9016\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0253 - binary_accuracy: 0.9982 - val_loss: 0.2917 - val_binary_accuracy: 0.9016\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 697us/sample - loss: 0.0341 - binary_accuracy: 0.9838 - val_loss: 0.3956 - val_binary_accuracy: 0.9016\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 706us/sample - loss: 0.0408 - binary_accuracy: 0.9874 - val_loss: 0.4946 - val_binary_accuracy: 0.8852\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 706us/sample - loss: 0.0625 - binary_accuracy: 0.9729 - val_loss: 0.8654 - val_binary_accuracy: 0.6557\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 686us/sample - loss: 0.0421 - binary_accuracy: 0.9856 - val_loss: 0.3381 - val_binary_accuracy: 0.9016\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0238 - binary_accuracy: 0.9946 - val_loss: 0.3211 - val_binary_accuracy: 0.8852\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.0406 - binary_accuracy: 0.9874 - val_loss: 0.4191 - val_binary_accuracy: 0.8689\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 674us/sample - loss: 0.0284 - binary_accuracy: 0.9892 - val_loss: 0.5807 - val_binary_accuracy: 0.8033\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 664us/sample - loss: 0.0262 - binary_accuracy: 0.9946 - val_loss: 0.5019 - val_binary_accuracy: 0.8852\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 678us/sample - loss: 0.0223 - binary_accuracy: 0.9928 - val_loss: 0.4402 - val_binary_accuracy: 0.8852\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 697us/sample - loss: 0.0361 - binary_accuracy: 0.9892 - val_loss: 0.3103 - val_binary_accuracy: 0.8852\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0360 - binary_accuracy: 0.9874 - val_loss: 0.3339 - val_binary_accuracy: 0.8852\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0278 - binary_accuracy: 0.9928 - val_loss: 0.2518 - val_binary_accuracy: 0.9344\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0340 - binary_accuracy: 0.9874 - val_loss: 0.3332 - val_binary_accuracy: 0.9180\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0385 - binary_accuracy: 0.9819 - val_loss: 0.6627 - val_binary_accuracy: 0.8689\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0501 - binary_accuracy: 0.9819 - val_loss: 0.8230 - val_binary_accuracy: 0.7213\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 693us/sample - loss: 0.0288 - binary_accuracy: 0.9928 - val_loss: 0.2985 - val_binary_accuracy: 0.9016\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0181 - binary_accuracy: 0.9946 - val_loss: 0.6415 - val_binary_accuracy: 0.8852\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0372 - binary_accuracy: 0.9819 - val_loss: 1.0180 - val_binary_accuracy: 0.6557\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0201 - binary_accuracy: 0.9982 - val_loss: 0.3079 - val_binary_accuracy: 0.9016\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0178 - binary_accuracy: 0.9946 - val_loss: 0.3572 - val_binary_accuracy: 0.9016\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0274 - binary_accuracy: 0.9928 - val_loss: 0.4402 - val_binary_accuracy: 0.8852\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0500 - binary_accuracy: 0.9892 - val_loss: 0.4472 - val_binary_accuracy: 0.8689\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 670us/sample - loss: 0.0141 - binary_accuracy: 0.9964 - val_loss: 0.3487 - val_binary_accuracy: 0.9016\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0222 - binary_accuracy: 0.9946 - val_loss: 0.3936 - val_binary_accuracy: 0.8361\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0200 - binary_accuracy: 0.9946 - val_loss: 0.3661 - val_binary_accuracy: 0.8525\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 680us/sample - loss: 0.0234 - binary_accuracy: 0.9910 - val_loss: 0.2887 - val_binary_accuracy: 0.8852\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 694us/sample - loss: 0.0282 - binary_accuracy: 0.9874 - val_loss: 0.4367 - val_binary_accuracy: 0.8361\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0249 - binary_accuracy: 0.9892 - val_loss: 0.3822 - val_binary_accuracy: 0.8525\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 689us/sample - loss: 0.0247 - binary_accuracy: 0.9910 - val_loss: 0.3845 - val_binary_accuracy: 0.8689\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0268 - binary_accuracy: 0.9892 - val_loss: 0.4284 - val_binary_accuracy: 0.8525\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 705us/sample - loss: 0.0214 - binary_accuracy: 0.9946 - val_loss: 0.3680 - val_binary_accuracy: 0.8852\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0196 - binary_accuracy: 0.9964 - val_loss: 0.5078 - val_binary_accuracy: 0.9180\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0163 - binary_accuracy: 0.9964 - val_loss: 0.7038 - val_binary_accuracy: 0.7541\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 699us/sample - loss: 0.0143 - binary_accuracy: 0.9964 - val_loss: 1.0141 - val_binary_accuracy: 0.8525\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 669us/sample - loss: 0.0111 - binary_accuracy: 1.0000 - val_loss: 0.7918 - val_binary_accuracy: 0.7705\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 681us/sample - loss: 0.0146 - binary_accuracy: 0.9982 - val_loss: 0.4258 - val_binary_accuracy: 0.8852\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0643 - binary_accuracy: 0.9819 - val_loss: 0.8397 - val_binary_accuracy: 0.7213\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0250 - binary_accuracy: 0.9928 - val_loss: 0.7056 - val_binary_accuracy: 0.8852\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 690us/sample - loss: 0.0153 - binary_accuracy: 0.9946 - val_loss: 0.4387 - val_binary_accuracy: 0.9016\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0171 - binary_accuracy: 0.9964 - val_loss: 0.6056 - val_binary_accuracy: 0.8852\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 696us/sample - loss: 0.0105 - binary_accuracy: 0.9964 - val_loss: 0.4924 - val_binary_accuracy: 0.9016\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0269 - binary_accuracy: 0.9874 - val_loss: 0.4222 - val_binary_accuracy: 0.8852\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 688us/sample - loss: 0.0331 - binary_accuracy: 0.9874 - val_loss: 0.6536 - val_binary_accuracy: 0.8852\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 671us/sample - loss: 0.0464 - binary_accuracy: 0.9838 - val_loss: 0.6053 - val_binary_accuracy: 0.8361\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0124 - binary_accuracy: 0.9964 - val_loss: 0.3813 - val_binary_accuracy: 0.8689\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 689us/sample - loss: 0.0124 - binary_accuracy: 0.9964 - val_loss: 0.4321 - val_binary_accuracy: 0.8852\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 683us/sample - loss: 0.0127 - binary_accuracy: 0.9946 - val_loss: 0.4859 - val_binary_accuracy: 0.9016\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 691us/sample - loss: 0.0238 - binary_accuracy: 0.9928 - val_loss: 0.4267 - val_binary_accuracy: 0.8689\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0178 - binary_accuracy: 0.9928 - val_loss: 0.4622 - val_binary_accuracy: 0.8361\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 675us/sample - loss: 0.0191 - binary_accuracy: 0.9964 - val_loss: 0.6198 - val_binary_accuracy: 0.9016\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 673us/sample - loss: 0.0110 - binary_accuracy: 1.0000 - val_loss: 0.8529 - val_binary_accuracy: 0.7705\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 682us/sample - loss: 0.0252 - binary_accuracy: 0.9910 - val_loss: 0.5526 - val_binary_accuracy: 0.7869\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0208 - binary_accuracy: 0.9928 - val_loss: 0.5068 - val_binary_accuracy: 0.9180\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 665us/sample - loss: 0.0197 - binary_accuracy: 0.9910 - val_loss: 1.1428 - val_binary_accuracy: 0.6557\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 685us/sample - loss: 0.0159 - binary_accuracy: 0.9964 - val_loss: 0.4407 - val_binary_accuracy: 0.9016\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 668us/sample - loss: 0.0144 - binary_accuracy: 0.9964 - val_loss: 0.7420 - val_binary_accuracy: 0.8852\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 687us/sample - loss: 0.0170 - binary_accuracy: 0.9946 - val_loss: 0.4294 - val_binary_accuracy: 0.9016\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 666us/sample - loss: 0.0295 - binary_accuracy: 0.9928 - val_loss: 0.5352 - val_binary_accuracy: 0.8197\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 676us/sample - loss: 0.0084 - binary_accuracy: 1.0000 - val_loss: 0.4982 - val_binary_accuracy: 0.8852\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 677us/sample - loss: 0.0099 - binary_accuracy: 0.9982 - val_loss: 0.4595 - val_binary_accuracy: 0.9016\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 679us/sample - loss: 0.0118 - binary_accuracy: 0.9982 - val_loss: 1.3921 - val_binary_accuracy: 0.6066\n",
      "accuracy for model 10 is 60.65573692321777\n",
      "Training Testing Accuracy: 82.11% (9.78%)\n"
     ]
    }
   ],
   "source": [
    "best_CNN = eval_cnn(tt_vcf, tt_pheno, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout accuracy is 87.01298832893372\n"
     ]
    }
   ],
   "source": [
    "bs = ((ho_vcf.shape[0])/40)\n",
    "bs = round(bs)\n",
    "ho_vcf = ho_vcf.reshape(ho_vcf.shape[0], ho_vcf.shape[1],1)\n",
    "_, accuracy = best_CNN.evaluate(ho_vcf, ho_pheno, batch_size=bs, verbose=0)\n",
    "print(\"Holdout accuracy is \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e10fecfe88bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PuD_kfold_10_CNN_QTL.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(best_CNN, open(\"PuD_kfold_10_CNN_QTL.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617,)\n",
      "(617, 1)\n",
      "10000\n",
      "(155,)\n",
      "(155, 1)\n",
      "10000\n",
      "(617, 1)\n",
      "(617, 9258)\n",
      "found 2\n",
      "found 2\n",
      "(615, 1)\n",
      "(615, 9258)\n",
      "(155, 1)\n",
      "(155, 9258)\n",
      "found 2\n",
      "(154, 1)\n",
      "(154, 9258)\n",
      "(615, 9258)\n",
      "(154, 9258)\n",
      "(615, 1)\n",
      "(154, 1)\n"
     ]
    }
   ],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data('PuD_Merged_filtered.csv_train_testQTL_SNPS.csv', 'PuD_Merged_filtered.csv_holdoutQTL_SNPS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 27061)\n",
      "(154, 9258)\n",
      "(154, 27061)\n"
     ]
    }
   ],
   "source": [
    "ohe = pickle.load(open(\"PuD_QTL_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, tt_pheno, ho_vcf, ho_pheno, all_vcf = prep_data('FlC_Merged_filtered.csv_train_test.csv_5pcnt.csv', 'FlC_Merged_filtered.csv_holdout.csv_5pcnt.csv')\n",
    "#even though its binary, its still good to one hot encode it\n",
    "mlb = MultiLabelBinarizer()\n",
    "tt_pheno = mlb.fit_transform(tt_pheno)\n",
    "ho_pheno = mlb.fit_transform(ho_pheno)\n",
    "print(tt_pheno.shape)\n",
    "print(ho_pheno.shape)\n",
    "del all_vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My own DNN model based upon paper\n",
    "#del model #incase its stored a previous model\n",
    "#del history #for redoing shit\n",
    "\n",
    "#do batch size as 64\n",
    "#reduce the inputs by half when you read it in\n",
    "#add XGboost and RF to the one notebook\n",
    "def build_DNN_model(x_len):\n",
    "    model = Sequential()\n",
    "\n",
    "    #add first input layer, with no normalization\n",
    "    model.add(Dense(256, input_dim = x_len))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.03))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.02))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    #add output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dnn(x,y,k): \n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    best_model = []\n",
    "    results = []\n",
    "    highest = 0\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        model = build_DNN_model(x[train].shape[1])\n",
    "        bs = ((x[train].shape[0])/40)\n",
    "        bs = round(bs)\n",
    "        history = model.fit(x[train], y[train], validation_data=(x[test], y[test]), epochs = 100, batch_size=bs)\n",
    "        _, accuracy = model.evaluate(x[test], y[test], batch_size=bs, verbose=0)\n",
    "        accuracy = accuracy * 100\n",
    "        print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "        if(accuracy > highest):\n",
    "            highest = accuracy\n",
    "            best_model = model\n",
    "        results.append(accuracy)\n",
    "        i = i + 1\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results))) \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 1ms/sample - loss: 0.4147 - binary_accuracy: 0.8156 - val_loss: 1.2997 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 377us/sample - loss: 0.3258 - binary_accuracy: 0.8626 - val_loss: 0.3716 - val_binary_accuracy: 0.8710\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.3036 - binary_accuracy: 0.8752 - val_loss: 0.4556 - val_binary_accuracy: 0.8387\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 374us/sample - loss: 0.2849 - binary_accuracy: 0.8770 - val_loss: 0.4253 - val_binary_accuracy: 0.8387\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 375us/sample - loss: 0.2708 - binary_accuracy: 0.8752 - val_loss: 0.3865 - val_binary_accuracy: 0.8548\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.2643 - binary_accuracy: 0.9078 - val_loss: 0.5094 - val_binary_accuracy: 0.7258\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.2600 - binary_accuracy: 0.8770 - val_loss: 0.4684 - val_binary_accuracy: 0.7258\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.2473 - binary_accuracy: 0.9060 - val_loss: 0.3872 - val_binary_accuracy: 0.8548\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 376us/sample - loss: 0.2490 - binary_accuracy: 0.9005 - val_loss: 0.4204 - val_binary_accuracy: 0.7742\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.2242 - binary_accuracy: 0.9168 - val_loss: 0.4072 - val_binary_accuracy: 0.8226\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 375us/sample - loss: 0.2244 - binary_accuracy: 0.9096 - val_loss: 0.5203 - val_binary_accuracy: 0.7581\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.2181 - binary_accuracy: 0.8987 - val_loss: 0.5192 - val_binary_accuracy: 0.7419\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 376us/sample - loss: 0.2090 - binary_accuracy: 0.9259 - val_loss: 0.4686 - val_binary_accuracy: 0.7903\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1879 - binary_accuracy: 0.9349 - val_loss: 0.4356 - val_binary_accuracy: 0.8065\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1848 - binary_accuracy: 0.9259 - val_loss: 0.3772 - val_binary_accuracy: 0.8710\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.2041 - binary_accuracy: 0.9168 - val_loss: 0.3849 - val_binary_accuracy: 0.8548\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.1807 - binary_accuracy: 0.9349 - val_loss: 0.3764 - val_binary_accuracy: 0.8548\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1676 - binary_accuracy: 0.9277 - val_loss: 0.4568 - val_binary_accuracy: 0.7903\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 374us/sample - loss: 0.1726 - binary_accuracy: 0.9313 - val_loss: 0.4323 - val_binary_accuracy: 0.8387\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.1703 - binary_accuracy: 0.9349 - val_loss: 0.4507 - val_binary_accuracy: 0.8387\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1595 - binary_accuracy: 0.9385 - val_loss: 0.4616 - val_binary_accuracy: 0.8387\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1595 - binary_accuracy: 0.9512 - val_loss: 0.4899 - val_binary_accuracy: 0.8226\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1698 - binary_accuracy: 0.9421 - val_loss: 0.6001 - val_binary_accuracy: 0.7097\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1408 - binary_accuracy: 0.9512 - val_loss: 0.6570 - val_binary_accuracy: 0.8548\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1179 - binary_accuracy: 0.9584 - val_loss: 0.5632 - val_binary_accuracy: 0.8387\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1261 - binary_accuracy: 0.9548 - val_loss: 0.5583 - val_binary_accuracy: 0.8226\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1433 - binary_accuracy: 0.9494 - val_loss: 0.7791 - val_binary_accuracy: 0.6935\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1595 - binary_accuracy: 0.9439 - val_loss: 0.6873 - val_binary_accuracy: 0.7742\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1408 - binary_accuracy: 0.9494 - val_loss: 0.5765 - val_binary_accuracy: 0.8226\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1262 - binary_accuracy: 0.9530 - val_loss: 0.6472 - val_binary_accuracy: 0.7903\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1090 - binary_accuracy: 0.9638 - val_loss: 0.6382 - val_binary_accuracy: 0.7742\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1117 - binary_accuracy: 0.9656 - val_loss: 0.6780 - val_binary_accuracy: 0.7419\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0903 - binary_accuracy: 0.9747 - val_loss: 0.6619 - val_binary_accuracy: 0.8226\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0937 - binary_accuracy: 0.9693 - val_loss: 0.6081 - val_binary_accuracy: 0.8548\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0861 - binary_accuracy: 0.9656 - val_loss: 0.7257 - val_binary_accuracy: 0.8387\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0971 - binary_accuracy: 0.9693 - val_loss: 0.6668 - val_binary_accuracy: 0.7903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.1081 - binary_accuracy: 0.9602 - val_loss: 0.8189 - val_binary_accuracy: 0.7742\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0974 - binary_accuracy: 0.9711 - val_loss: 0.6267 - val_binary_accuracy: 0.8548\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 374us/sample - loss: 0.0877 - binary_accuracy: 0.9675 - val_loss: 0.7173 - val_binary_accuracy: 0.8548\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0887 - binary_accuracy: 0.9711 - val_loss: 0.5715 - val_binary_accuracy: 0.8226\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1030 - binary_accuracy: 0.9620 - val_loss: 0.7073 - val_binary_accuracy: 0.6774\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1367 - binary_accuracy: 0.9494 - val_loss: 0.7257 - val_binary_accuracy: 0.7419\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0755 - binary_accuracy: 0.9765 - val_loss: 0.6691 - val_binary_accuracy: 0.8548\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1020 - binary_accuracy: 0.9620 - val_loss: 0.5944 - val_binary_accuracy: 0.8548\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0967 - binary_accuracy: 0.9656 - val_loss: 0.7281 - val_binary_accuracy: 0.8387\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0863 - binary_accuracy: 0.9729 - val_loss: 0.7514 - val_binary_accuracy: 0.8226\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0670 - binary_accuracy: 0.9783 - val_loss: 0.7086 - val_binary_accuracy: 0.8226\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0774 - binary_accuracy: 0.9729 - val_loss: 0.6582 - val_binary_accuracy: 0.8226\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0750 - binary_accuracy: 0.9693 - val_loss: 0.7737 - val_binary_accuracy: 0.8226\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0789 - binary_accuracy: 0.9675 - val_loss: 0.6129 - val_binary_accuracy: 0.8226\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0865 - binary_accuracy: 0.9584 - val_loss: 0.8529 - val_binary_accuracy: 0.7581\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0782 - binary_accuracy: 0.9656 - val_loss: 0.6625 - val_binary_accuracy: 0.8548\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0698 - binary_accuracy: 0.9783 - val_loss: 0.7839 - val_binary_accuracy: 0.8548\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.0648 - binary_accuracy: 0.9711 - val_loss: 0.6958 - val_binary_accuracy: 0.8226\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0434 - binary_accuracy: 0.9910 - val_loss: 0.7738 - val_binary_accuracy: 0.8226\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0616 - binary_accuracy: 0.9801 - val_loss: 0.7272 - val_binary_accuracy: 0.8548\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0638 - binary_accuracy: 0.9783 - val_loss: 0.6486 - val_binary_accuracy: 0.8548\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0502 - binary_accuracy: 0.9855 - val_loss: 0.8505 - val_binary_accuracy: 0.8226\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0357 - binary_accuracy: 0.9892 - val_loss: 0.6955 - val_binary_accuracy: 0.8226\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0486 - binary_accuracy: 0.9819 - val_loss: 0.8060 - val_binary_accuracy: 0.8065\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0245 - binary_accuracy: 0.9964 - val_loss: 0.7699 - val_binary_accuracy: 0.8548\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0413 - binary_accuracy: 0.9855 - val_loss: 0.8729 - val_binary_accuracy: 0.8065\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0357 - binary_accuracy: 0.9910 - val_loss: 0.8177 - val_binary_accuracy: 0.8065\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0525 - binary_accuracy: 0.9801 - val_loss: 1.1093 - val_binary_accuracy: 0.8065\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0502 - binary_accuracy: 0.9819 - val_loss: 0.6816 - val_binary_accuracy: 0.8548\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0312 - binary_accuracy: 0.9892 - val_loss: 0.7660 - val_binary_accuracy: 0.8065\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0342 - binary_accuracy: 0.9837 - val_loss: 0.7800 - val_binary_accuracy: 0.8065\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0414 - binary_accuracy: 0.9873 - val_loss: 1.0354 - val_binary_accuracy: 0.7742\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0488 - binary_accuracy: 0.9783 - val_loss: 0.8184 - val_binary_accuracy: 0.8226\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0305 - binary_accuracy: 0.9873 - val_loss: 1.0161 - val_binary_accuracy: 0.8387\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0508 - binary_accuracy: 0.9819 - val_loss: 1.2647 - val_binary_accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0387 - binary_accuracy: 0.9873 - val_loss: 0.8987 - val_binary_accuracy: 0.8387\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0487 - binary_accuracy: 0.9819 - val_loss: 0.9613 - val_binary_accuracy: 0.8065\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0480 - binary_accuracy: 0.9837 - val_loss: 0.9107 - val_binary_accuracy: 0.8065\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0410 - binary_accuracy: 0.9892 - val_loss: 0.8278 - val_binary_accuracy: 0.8226\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0410 - binary_accuracy: 0.9819 - val_loss: 0.9857 - val_binary_accuracy: 0.8387\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0172 - binary_accuracy: 0.9964 - val_loss: 0.8885 - val_binary_accuracy: 0.8387\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0191 - binary_accuracy: 0.9928 - val_loss: 0.8133 - val_binary_accuracy: 0.8387\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0254 - binary_accuracy: 0.9910 - val_loss: 0.9256 - val_binary_accuracy: 0.8387\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0257 - binary_accuracy: 0.9910 - val_loss: 1.0747 - val_binary_accuracy: 0.8065\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0220 - binary_accuracy: 0.9946 - val_loss: 1.0551 - val_binary_accuracy: 0.8065\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0394 - binary_accuracy: 0.9873 - val_loss: 0.9962 - val_binary_accuracy: 0.8226\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0236 - binary_accuracy: 0.9892 - val_loss: 0.8855 - val_binary_accuracy: 0.8065\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0250 - binary_accuracy: 0.9910 - val_loss: 0.9630 - val_binary_accuracy: 0.8065\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0211 - binary_accuracy: 0.9910 - val_loss: 1.2060 - val_binary_accuracy: 0.7419\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0590 - binary_accuracy: 0.9801 - val_loss: 1.1207 - val_binary_accuracy: 0.7903\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0297 - binary_accuracy: 0.9928 - val_loss: 0.9445 - val_binary_accuracy: 0.8226\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0250 - binary_accuracy: 0.9910 - val_loss: 1.1638 - val_binary_accuracy: 0.7903\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0423 - binary_accuracy: 0.9837 - val_loss: 0.8656 - val_binary_accuracy: 0.8548\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0261 - binary_accuracy: 0.9928 - val_loss: 0.8872 - val_binary_accuracy: 0.8387\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0155 - binary_accuracy: 0.9928 - val_loss: 1.0223 - val_binary_accuracy: 0.8226\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0194 - binary_accuracy: 0.9946 - val_loss: 1.2519 - val_binary_accuracy: 0.8065\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0341 - binary_accuracy: 0.9873 - val_loss: 0.8563 - val_binary_accuracy: 0.8387\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0281 - binary_accuracy: 0.9910 - val_loss: 1.1259 - val_binary_accuracy: 0.8387\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0297 - binary_accuracy: 0.9910 - val_loss: 1.0767 - val_binary_accuracy: 0.8226\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 374us/sample - loss: 0.0441 - binary_accuracy: 0.9892 - val_loss: 1.0417 - val_binary_accuracy: 0.8387\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0392 - binary_accuracy: 0.9873 - val_loss: 1.5424 - val_binary_accuracy: 0.7742\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0169 - binary_accuracy: 0.9946 - val_loss: 1.0143 - val_binary_accuracy: 0.8065\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0247 - binary_accuracy: 0.9928 - val_loss: 0.9215 - val_binary_accuracy: 0.8387\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0514 - binary_accuracy: 0.9819 - val_loss: 1.2128 - val_binary_accuracy: 0.8065\n",
      "accuracy for model 1 is 80.64516186714172\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 1ms/sample - loss: 0.5254 - binary_accuracy: 0.7505 - val_loss: 0.3221 - val_binary_accuracy: 0.9194\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.3360 - binary_accuracy: 0.8499 - val_loss: 0.2825 - val_binary_accuracy: 0.9032\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.2914 - binary_accuracy: 0.8807 - val_loss: 0.5016 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.2998 - binary_accuracy: 0.8680 - val_loss: 0.2250 - val_binary_accuracy: 0.9355\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.2835 - binary_accuracy: 0.8951 - val_loss: 0.2157 - val_binary_accuracy: 0.9194\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.2481 - binary_accuracy: 0.9150 - val_loss: 0.1964 - val_binary_accuracy: 0.9355\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2406 - binary_accuracy: 0.9024 - val_loss: 0.2346 - val_binary_accuracy: 0.9355\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.2308 - binary_accuracy: 0.9150 - val_loss: 0.2048 - val_binary_accuracy: 0.9194\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2249 - binary_accuracy: 0.9259 - val_loss: 0.2341 - val_binary_accuracy: 0.9194\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2295 - binary_accuracy: 0.9150 - val_loss: 0.2013 - val_binary_accuracy: 0.9355\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.2114 - binary_accuracy: 0.9132 - val_loss: 0.2046 - val_binary_accuracy: 0.9355\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1864 - binary_accuracy: 0.9349 - val_loss: 0.1966 - val_binary_accuracy: 0.9355\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.2116 - binary_accuracy: 0.9186 - val_loss: 0.1813 - val_binary_accuracy: 0.9516\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1959 - binary_accuracy: 0.9259 - val_loss: 0.1800 - val_binary_accuracy: 0.9355\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2023 - binary_accuracy: 0.9313 - val_loss: 0.1688 - val_binary_accuracy: 0.9516\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1988 - binary_accuracy: 0.9259 - val_loss: 0.1916 - val_binary_accuracy: 0.9194\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1777 - binary_accuracy: 0.9331 - val_loss: 0.2264 - val_binary_accuracy: 0.9194\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1616 - binary_accuracy: 0.9421 - val_loss: 0.1728 - val_binary_accuracy: 0.9355\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1645 - binary_accuracy: 0.9530 - val_loss: 0.2225 - val_binary_accuracy: 0.9032\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1672 - binary_accuracy: 0.9421 - val_loss: 0.1621 - val_binary_accuracy: 0.9516\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1432 - binary_accuracy: 0.9548 - val_loss: 0.1918 - val_binary_accuracy: 0.9194\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1654 - binary_accuracy: 0.9295 - val_loss: 0.1969 - val_binary_accuracy: 0.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1449 - binary_accuracy: 0.9476 - val_loss: 0.1929 - val_binary_accuracy: 0.9355\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1515 - binary_accuracy: 0.9512 - val_loss: 0.2281 - val_binary_accuracy: 0.9194\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1664 - binary_accuracy: 0.9367 - val_loss: 0.2149 - val_binary_accuracy: 0.9355\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1331 - binary_accuracy: 0.9530 - val_loss: 0.2279 - val_binary_accuracy: 0.9355\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1611 - binary_accuracy: 0.9439 - val_loss: 0.1877 - val_binary_accuracy: 0.9194\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1281 - binary_accuracy: 0.9494 - val_loss: 0.2122 - val_binary_accuracy: 0.9194\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1294 - binary_accuracy: 0.9476 - val_loss: 0.2379 - val_binary_accuracy: 0.9194\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 374us/sample - loss: 0.1281 - binary_accuracy: 0.9476 - val_loss: 0.2559 - val_binary_accuracy: 0.9355\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1382 - binary_accuracy: 0.9548 - val_loss: 0.2364 - val_binary_accuracy: 0.9194\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1061 - binary_accuracy: 0.9638 - val_loss: 0.2163 - val_binary_accuracy: 0.9355\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.1282 - binary_accuracy: 0.9512 - val_loss: 0.2463 - val_binary_accuracy: 0.9032\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0959 - binary_accuracy: 0.9711 - val_loss: 0.2714 - val_binary_accuracy: 0.9355\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0790 - binary_accuracy: 0.9693 - val_loss: 0.1950 - val_binary_accuracy: 0.9194\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1152 - binary_accuracy: 0.9620 - val_loss: 0.1953 - val_binary_accuracy: 0.9355\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0800 - binary_accuracy: 0.9783 - val_loss: 0.2359 - val_binary_accuracy: 0.9355\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0810 - binary_accuracy: 0.9837 - val_loss: 0.2062 - val_binary_accuracy: 0.9194\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0715 - binary_accuracy: 0.9729 - val_loss: 0.2526 - val_binary_accuracy: 0.9355\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0920 - binary_accuracy: 0.9602 - val_loss: 0.2242 - val_binary_accuracy: 0.9194\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0677 - binary_accuracy: 0.9711 - val_loss: 0.1892 - val_binary_accuracy: 0.9516\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0666 - binary_accuracy: 0.9783 - val_loss: 0.3857 - val_binary_accuracy: 0.8710\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0580 - binary_accuracy: 0.9765 - val_loss: 0.2115 - val_binary_accuracy: 0.9355\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0617 - binary_accuracy: 0.9783 - val_loss: 0.2678 - val_binary_accuracy: 0.9355\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0558 - binary_accuracy: 0.9801 - val_loss: 0.2592 - val_binary_accuracy: 0.9355\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0693 - binary_accuracy: 0.9675 - val_loss: 0.2169 - val_binary_accuracy: 0.9355\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0780 - binary_accuracy: 0.9693 - val_loss: 0.2434 - val_binary_accuracy: 0.9677\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0447 - binary_accuracy: 0.9873 - val_loss: 0.2440 - val_binary_accuracy: 0.9194\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0458 - binary_accuracy: 0.9837 - val_loss: 0.2103 - val_binary_accuracy: 0.9677\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0503 - binary_accuracy: 0.9819 - val_loss: 0.2224 - val_binary_accuracy: 0.9516\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0447 - binary_accuracy: 0.9837 - val_loss: 0.2099 - val_binary_accuracy: 0.9516\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0528 - binary_accuracy: 0.9819 - val_loss: 0.2693 - val_binary_accuracy: 0.8871\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1055 - binary_accuracy: 0.9693 - val_loss: 0.2522 - val_binary_accuracy: 0.9355\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.0460 - binary_accuracy: 0.9855 - val_loss: 0.3274 - val_binary_accuracy: 0.9032\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0560 - binary_accuracy: 0.9837 - val_loss: 0.1573 - val_binary_accuracy: 0.9355\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0563 - binary_accuracy: 0.9783 - val_loss: 0.2742 - val_binary_accuracy: 0.9355\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0677 - binary_accuracy: 0.9747 - val_loss: 0.2868 - val_binary_accuracy: 0.9355\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0678 - binary_accuracy: 0.9765 - val_loss: 0.1792 - val_binary_accuracy: 0.9355\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0490 - binary_accuracy: 0.9819 - val_loss: 0.2948 - val_binary_accuracy: 0.8871\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0464 - binary_accuracy: 0.9855 - val_loss: 0.2557 - val_binary_accuracy: 0.9516\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0560 - binary_accuracy: 0.9729 - val_loss: 0.3067 - val_binary_accuracy: 0.9355\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0835 - binary_accuracy: 0.9765 - val_loss: 0.2635 - val_binary_accuracy: 0.9355\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0459 - binary_accuracy: 0.9873 - val_loss: 0.2284 - val_binary_accuracy: 0.9032\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0278 - binary_accuracy: 0.9928 - val_loss: 0.2609 - val_binary_accuracy: 0.9355\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0559 - binary_accuracy: 0.9801 - val_loss: 0.2662 - val_binary_accuracy: 0.9355\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0615 - binary_accuracy: 0.9765 - val_loss: 0.5985 - val_binary_accuracy: 0.8871\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0847 - binary_accuracy: 0.9765 - val_loss: 0.2895 - val_binary_accuracy: 0.9355\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0543 - binary_accuracy: 0.9783 - val_loss: 0.2740 - val_binary_accuracy: 0.9194\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0345 - binary_accuracy: 0.9837 - val_loss: 0.2789 - val_binary_accuracy: 0.9516\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0578 - binary_accuracy: 0.9765 - val_loss: 0.2148 - val_binary_accuracy: 0.9355\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0493 - binary_accuracy: 0.9819 - val_loss: 0.2412 - val_binary_accuracy: 0.9194\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0288 - binary_accuracy: 0.9910 - val_loss: 0.3663 - val_binary_accuracy: 0.9194\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0190 - binary_accuracy: 0.9928 - val_loss: 0.2534 - val_binary_accuracy: 0.9516\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0426 - binary_accuracy: 0.9873 - val_loss: 0.3296 - val_binary_accuracy: 0.9194\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0340 - binary_accuracy: 0.9801 - val_loss: 0.2097 - val_binary_accuracy: 0.9355\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0535 - binary_accuracy: 0.9747 - val_loss: 0.5270 - val_binary_accuracy: 0.8548\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0453 - binary_accuracy: 0.9873 - val_loss: 0.3285 - val_binary_accuracy: 0.9194\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0613 - binary_accuracy: 0.9747 - val_loss: 0.3930 - val_binary_accuracy: 0.9516\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0516 - binary_accuracy: 0.9783 - val_loss: 0.2224 - val_binary_accuracy: 0.9194\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0565 - binary_accuracy: 0.9801 - val_loss: 0.3380 - val_binary_accuracy: 0.9516\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0272 - binary_accuracy: 0.9928 - val_loss: 0.3288 - val_binary_accuracy: 0.9355\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0246 - binary_accuracy: 0.9910 - val_loss: 0.2355 - val_binary_accuracy: 0.9355\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0750 - binary_accuracy: 0.9675 - val_loss: 0.1867 - val_binary_accuracy: 0.9355\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0366 - binary_accuracy: 0.9892 - val_loss: 0.3567 - val_binary_accuracy: 0.9032\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0545 - binary_accuracy: 0.9837 - val_loss: 0.3825 - val_binary_accuracy: 0.9355\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0657 - binary_accuracy: 0.9819 - val_loss: 0.3577 - val_binary_accuracy: 0.9355\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0704 - binary_accuracy: 0.9801 - val_loss: 0.6738 - val_binary_accuracy: 0.7419\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0496 - binary_accuracy: 0.9855 - val_loss: 0.4054 - val_binary_accuracy: 0.8710\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0255 - binary_accuracy: 0.9928 - val_loss: 0.4012 - val_binary_accuracy: 0.8710\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0352 - binary_accuracy: 0.9837 - val_loss: 0.4464 - val_binary_accuracy: 0.9194\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0535 - binary_accuracy: 0.9819 - val_loss: 0.3151 - val_binary_accuracy: 0.9194\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0624 - binary_accuracy: 0.9783 - val_loss: 0.4579 - val_binary_accuracy: 0.9194\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0557 - binary_accuracy: 0.9747 - val_loss: 0.2610 - val_binary_accuracy: 0.9355\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0248 - binary_accuracy: 0.9946 - val_loss: 0.3512 - val_binary_accuracy: 0.9194\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0561 - binary_accuracy: 0.9819 - val_loss: 0.3185 - val_binary_accuracy: 0.9355\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0910 - binary_accuracy: 0.9693 - val_loss: 0.2848 - val_binary_accuracy: 0.9516\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0342 - binary_accuracy: 0.9873 - val_loss: 0.2693 - val_binary_accuracy: 0.9516\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0408 - binary_accuracy: 0.9873 - val_loss: 0.2372 - val_binary_accuracy: 0.9677\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0527 - binary_accuracy: 0.9801 - val_loss: 0.2503 - val_binary_accuracy: 0.9355\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0330 - binary_accuracy: 0.9892 - val_loss: 0.4448 - val_binary_accuracy: 0.8548\n",
      "accuracy for model 2 is 85.48387289047241\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 1ms/sample - loss: 0.4705 - binary_accuracy: 0.8065 - val_loss: 3.4368 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.3510 - binary_accuracy: 0.8571 - val_loss: 1.3124 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.3335 - binary_accuracy: 0.8608 - val_loss: 0.3428 - val_binary_accuracy: 0.8871\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.3126 - binary_accuracy: 0.8608 - val_loss: 0.1769 - val_binary_accuracy: 0.9194\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.2907 - binary_accuracy: 0.8807 - val_loss: 0.1893 - val_binary_accuracy: 0.9032\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.2771 - binary_accuracy: 0.8861 - val_loss: 0.2280 - val_binary_accuracy: 0.8871\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.2691 - binary_accuracy: 0.9042 - val_loss: 0.2001 - val_binary_accuracy: 0.9032\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2645 - binary_accuracy: 0.8933 - val_loss: 0.2151 - val_binary_accuracy: 0.8871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.2623 - binary_accuracy: 0.8987 - val_loss: 0.1458 - val_binary_accuracy: 0.9355\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.2525 - binary_accuracy: 0.9114 - val_loss: 0.1894 - val_binary_accuracy: 0.9194\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.2216 - binary_accuracy: 0.9114 - val_loss: 0.2388 - val_binary_accuracy: 0.9355\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.2093 - binary_accuracy: 0.9150 - val_loss: 0.1897 - val_binary_accuracy: 0.9355\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2326 - binary_accuracy: 0.8987 - val_loss: 0.2807 - val_binary_accuracy: 0.9194\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.2267 - binary_accuracy: 0.9078 - val_loss: 0.2913 - val_binary_accuracy: 0.9032\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2059 - binary_accuracy: 0.9204 - val_loss: 0.4081 - val_binary_accuracy: 0.8226\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.2276 - binary_accuracy: 0.9186 - val_loss: 0.2529 - val_binary_accuracy: 0.9032\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1903 - binary_accuracy: 0.9204 - val_loss: 0.2764 - val_binary_accuracy: 0.9032\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1998 - binary_accuracy: 0.9241 - val_loss: 0.1747 - val_binary_accuracy: 0.9355\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1894 - binary_accuracy: 0.9313 - val_loss: 0.1421 - val_binary_accuracy: 0.9355\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1727 - binary_accuracy: 0.9313 - val_loss: 0.2004 - val_binary_accuracy: 0.9194\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.1796 - binary_accuracy: 0.9349 - val_loss: 0.1821 - val_binary_accuracy: 0.9516\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1547 - binary_accuracy: 0.9458 - val_loss: 0.1832 - val_binary_accuracy: 0.9516\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1698 - binary_accuracy: 0.9367 - val_loss: 0.2030 - val_binary_accuracy: 0.9355\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1494 - binary_accuracy: 0.9367 - val_loss: 0.1526 - val_binary_accuracy: 0.9355\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1364 - binary_accuracy: 0.9512 - val_loss: 0.1525 - val_binary_accuracy: 0.9516\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1347 - binary_accuracy: 0.9566 - val_loss: 0.1719 - val_binary_accuracy: 0.9194\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1386 - binary_accuracy: 0.9512 - val_loss: 0.1736 - val_binary_accuracy: 0.9355\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1204 - binary_accuracy: 0.9566 - val_loss: 0.1585 - val_binary_accuracy: 0.9516\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1298 - binary_accuracy: 0.9385 - val_loss: 0.1704 - val_binary_accuracy: 0.9516\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1164 - binary_accuracy: 0.9602 - val_loss: 0.2343 - val_binary_accuracy: 0.9194\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1136 - binary_accuracy: 0.9620 - val_loss: 0.1915 - val_binary_accuracy: 0.9355\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1008 - binary_accuracy: 0.9566 - val_loss: 0.1997 - val_binary_accuracy: 0.9516\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1113 - binary_accuracy: 0.9620 - val_loss: 0.2125 - val_binary_accuracy: 0.9194\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1016 - binary_accuracy: 0.9638 - val_loss: 0.1953 - val_binary_accuracy: 0.9516\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0982 - binary_accuracy: 0.9675 - val_loss: 0.2255 - val_binary_accuracy: 0.9516\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0823 - binary_accuracy: 0.9693 - val_loss: 0.2550 - val_binary_accuracy: 0.9355\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0912 - binary_accuracy: 0.9638 - val_loss: 0.2884 - val_binary_accuracy: 0.9355\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0634 - binary_accuracy: 0.9873 - val_loss: 0.3097 - val_binary_accuracy: 0.9355\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0762 - binary_accuracy: 0.9783 - val_loss: 0.2235 - val_binary_accuracy: 0.9194\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0914 - binary_accuracy: 0.9656 - val_loss: 0.2292 - val_binary_accuracy: 0.9355\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0967 - binary_accuracy: 0.9729 - val_loss: 0.1679 - val_binary_accuracy: 0.9355\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0885 - binary_accuracy: 0.9711 - val_loss: 0.2711 - val_binary_accuracy: 0.9194\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0751 - binary_accuracy: 0.9765 - val_loss: 0.2154 - val_binary_accuracy: 0.9194\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0671 - binary_accuracy: 0.9765 - val_loss: 0.2637 - val_binary_accuracy: 0.9355\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1032 - binary_accuracy: 0.9620 - val_loss: 0.3870 - val_binary_accuracy: 0.9032\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1054 - binary_accuracy: 0.9638 - val_loss: 0.4203 - val_binary_accuracy: 0.9032\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0732 - binary_accuracy: 0.9747 - val_loss: 0.2778 - val_binary_accuracy: 0.9355\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0808 - binary_accuracy: 0.9693 - val_loss: 0.2854 - val_binary_accuracy: 0.9355\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0566 - binary_accuracy: 0.9765 - val_loss: 0.2583 - val_binary_accuracy: 0.9194\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0778 - binary_accuracy: 0.9765 - val_loss: 0.2381 - val_binary_accuracy: 0.9516\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 0s 382us/sample - loss: 0.0503 - binary_accuracy: 0.9873 - val_loss: 0.4346 - val_binary_accuracy: 0.9032\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0494 - binary_accuracy: 0.9765 - val_loss: 0.4188 - val_binary_accuracy: 0.9032\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0437 - binary_accuracy: 0.9819 - val_loss: 0.4304 - val_binary_accuracy: 0.9032\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0576 - binary_accuracy: 0.9783 - val_loss: 0.3620 - val_binary_accuracy: 0.9355\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0858 - binary_accuracy: 0.9638 - val_loss: 0.3749 - val_binary_accuracy: 0.9194\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0645 - binary_accuracy: 0.9675 - val_loss: 0.4167 - val_binary_accuracy: 0.9032\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0473 - binary_accuracy: 0.9819 - val_loss: 0.2983 - val_binary_accuracy: 0.9355\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0744 - binary_accuracy: 0.9783 - val_loss: 0.3278 - val_binary_accuracy: 0.9355\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0446 - binary_accuracy: 0.9819 - val_loss: 0.2731 - val_binary_accuracy: 0.9194\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0540 - binary_accuracy: 0.9783 - val_loss: 0.2609 - val_binary_accuracy: 0.9355\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.0355 - binary_accuracy: 0.9873 - val_loss: 0.2859 - val_binary_accuracy: 0.9355\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.0411 - binary_accuracy: 0.9855 - val_loss: 0.2935 - val_binary_accuracy: 0.9355\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0676 - binary_accuracy: 0.9729 - val_loss: 0.2686 - val_binary_accuracy: 0.9355\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0385 - binary_accuracy: 0.9855 - val_loss: 0.4209 - val_binary_accuracy: 0.9355\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0551 - binary_accuracy: 0.9783 - val_loss: 0.3926 - val_binary_accuracy: 0.9194\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0480 - binary_accuracy: 0.9873 - val_loss: 0.4508 - val_binary_accuracy: 0.9194\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0432 - binary_accuracy: 0.9855 - val_loss: 0.3296 - val_binary_accuracy: 0.9516\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0425 - binary_accuracy: 0.9873 - val_loss: 0.4066 - val_binary_accuracy: 0.9194\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0639 - binary_accuracy: 0.9765 - val_loss: 0.4494 - val_binary_accuracy: 0.9194\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0579 - binary_accuracy: 0.9765 - val_loss: 0.2030 - val_binary_accuracy: 0.9516\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0390 - binary_accuracy: 0.9837 - val_loss: 0.3780 - val_binary_accuracy: 0.9355\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0296 - binary_accuracy: 0.9910 - val_loss: 0.2709 - val_binary_accuracy: 0.9516\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0225 - binary_accuracy: 0.9928 - val_loss: 0.4324 - val_binary_accuracy: 0.9355\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0580 - binary_accuracy: 0.9819 - val_loss: 0.4066 - val_binary_accuracy: 0.9355\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0294 - binary_accuracy: 0.9892 - val_loss: 0.3797 - val_binary_accuracy: 0.9516\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0535 - binary_accuracy: 0.9837 - val_loss: 0.3806 - val_binary_accuracy: 0.9355\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0290 - binary_accuracy: 0.9892 - val_loss: 0.5624 - val_binary_accuracy: 0.9032\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0480 - binary_accuracy: 0.9837 - val_loss: 0.4125 - val_binary_accuracy: 0.9355\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0582 - binary_accuracy: 0.9801 - val_loss: 0.3567 - val_binary_accuracy: 0.9355\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0434 - binary_accuracy: 0.9819 - val_loss: 0.4298 - val_binary_accuracy: 0.9194\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0399 - binary_accuracy: 0.9855 - val_loss: 0.5552 - val_binary_accuracy: 0.8710\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 374us/sample - loss: 0.0575 - binary_accuracy: 0.9801 - val_loss: 0.3271 - val_binary_accuracy: 0.9194\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0246 - binary_accuracy: 0.9928 - val_loss: 0.2613 - val_binary_accuracy: 0.9355\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0205 - binary_accuracy: 0.9910 - val_loss: 0.2835 - val_binary_accuracy: 0.9355\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0360 - binary_accuracy: 0.9855 - val_loss: 0.3742 - val_binary_accuracy: 0.9194\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0537 - binary_accuracy: 0.9819 - val_loss: 0.4389 - val_binary_accuracy: 0.9194\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0578 - binary_accuracy: 0.9765 - val_loss: 0.2898 - val_binary_accuracy: 0.9355\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0652 - binary_accuracy: 0.9693 - val_loss: 0.2810 - val_binary_accuracy: 0.9516\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0327 - binary_accuracy: 0.9873 - val_loss: 0.2897 - val_binary_accuracy: 0.9355\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0466 - binary_accuracy: 0.9837 - val_loss: 0.3274 - val_binary_accuracy: 0.9355\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0228 - binary_accuracy: 0.9928 - val_loss: 0.4703 - val_binary_accuracy: 0.9355\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0314 - binary_accuracy: 0.9928 - val_loss: 0.4785 - val_binary_accuracy: 0.9194\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0336 - binary_accuracy: 0.9873 - val_loss: 0.4815 - val_binary_accuracy: 0.9194\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0491 - binary_accuracy: 0.9765 - val_loss: 0.2726 - val_binary_accuracy: 0.9355\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0428 - binary_accuracy: 0.9873 - val_loss: 0.3427 - val_binary_accuracy: 0.9355\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0659 - binary_accuracy: 0.9711 - val_loss: 0.3955 - val_binary_accuracy: 0.9032\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.0448 - binary_accuracy: 0.9819 - val_loss: 0.2932 - val_binary_accuracy: 0.9355\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0315 - binary_accuracy: 0.9892 - val_loss: 0.3366 - val_binary_accuracy: 0.9355\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0261 - binary_accuracy: 0.9910 - val_loss: 0.3335 - val_binary_accuracy: 0.9194\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0177 - binary_accuracy: 0.9928 - val_loss: 0.3242 - val_binary_accuracy: 0.9355\n",
      "accuracy for model 3 is 93.54838728904724\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 1ms/sample - loss: 0.4251 - binary_accuracy: 0.8083 - val_loss: 1.1130 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.3271 - binary_accuracy: 0.8517 - val_loss: 0.3718 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2990 - binary_accuracy: 0.8608 - val_loss: 0.2207 - val_binary_accuracy: 0.8871\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.2878 - binary_accuracy: 0.8752 - val_loss: 0.1463 - val_binary_accuracy: 0.9516\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.2601 - binary_accuracy: 0.8825 - val_loss: 0.1775 - val_binary_accuracy: 0.9677\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2555 - binary_accuracy: 0.8788 - val_loss: 0.1461 - val_binary_accuracy: 0.9194\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2520 - binary_accuracy: 0.8933 - val_loss: 0.2503 - val_binary_accuracy: 0.8387\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.2365 - binary_accuracy: 0.9060 - val_loss: 0.0817 - val_binary_accuracy: 0.9839\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.2250 - binary_accuracy: 0.9150 - val_loss: 0.0632 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 383us/sample - loss: 0.2223 - binary_accuracy: 0.9168 - val_loss: 0.0830 - val_binary_accuracy: 0.9839\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 593us/sample - loss: 0.2354 - binary_accuracy: 0.9259 - val_loss: 0.1302 - val_binary_accuracy: 0.9839\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 387us/sample - loss: 0.2395 - binary_accuracy: 0.9096 - val_loss: 0.2267 - val_binary_accuracy: 0.8871\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.2161 - binary_accuracy: 0.9150 - val_loss: 0.1251 - val_binary_accuracy: 0.9194\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1953 - binary_accuracy: 0.9277 - val_loss: 0.0718 - val_binary_accuracy: 0.9839\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1830 - binary_accuracy: 0.9222 - val_loss: 0.2035 - val_binary_accuracy: 0.9194\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1807 - binary_accuracy: 0.9313 - val_loss: 0.1007 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1725 - binary_accuracy: 0.9458 - val_loss: 0.1432 - val_binary_accuracy: 0.9355\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1813 - binary_accuracy: 0.9403 - val_loss: 0.0560 - val_binary_accuracy: 0.9839\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1741 - binary_accuracy: 0.9439 - val_loss: 0.0912 - val_binary_accuracy: 0.9839\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.1548 - binary_accuracy: 0.9403 - val_loss: 0.3876 - val_binary_accuracy: 0.8548\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1680 - binary_accuracy: 0.9385 - val_loss: 0.8277 - val_binary_accuracy: 0.9032\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1574 - binary_accuracy: 0.9458 - val_loss: 0.0726 - val_binary_accuracy: 0.9839\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.1217 - binary_accuracy: 0.9602 - val_loss: 0.1527 - val_binary_accuracy: 0.9516\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1398 - binary_accuracy: 0.9476 - val_loss: 0.2671 - val_binary_accuracy: 0.8871\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1382 - binary_accuracy: 0.9530 - val_loss: 0.1696 - val_binary_accuracy: 0.9677\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1226 - binary_accuracy: 0.9602 - val_loss: 0.3019 - val_binary_accuracy: 0.8548\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1200 - binary_accuracy: 0.9656 - val_loss: 0.1604 - val_binary_accuracy: 0.9194\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1112 - binary_accuracy: 0.9602 - val_loss: 0.3043 - val_binary_accuracy: 0.8710\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1360 - binary_accuracy: 0.9476 - val_loss: 0.7655 - val_binary_accuracy: 0.8226\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1002 - binary_accuracy: 0.9711 - val_loss: 0.1171 - val_binary_accuracy: 0.9355\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1198 - binary_accuracy: 0.9548 - val_loss: 0.2029 - val_binary_accuracy: 0.9032\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1076 - binary_accuracy: 0.9656 - val_loss: 0.2982 - val_binary_accuracy: 0.8871\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.1009 - binary_accuracy: 0.9656 - val_loss: 0.2871 - val_binary_accuracy: 0.9194\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.1014 - binary_accuracy: 0.9620 - val_loss: 0.1860 - val_binary_accuracy: 0.9194\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1054 - binary_accuracy: 0.9638 - val_loss: 0.1687 - val_binary_accuracy: 0.9516\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1222 - binary_accuracy: 0.9548 - val_loss: 0.2841 - val_binary_accuracy: 0.8871\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0811 - binary_accuracy: 0.9747 - val_loss: 0.5225 - val_binary_accuracy: 0.8710\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1122 - binary_accuracy: 0.9512 - val_loss: 0.2195 - val_binary_accuracy: 0.9355\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0891 - binary_accuracy: 0.9711 - val_loss: 0.1912 - val_binary_accuracy: 0.8871\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1014 - binary_accuracy: 0.9693 - val_loss: 0.1970 - val_binary_accuracy: 0.9355\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0731 - binary_accuracy: 0.9765 - val_loss: 0.1914 - val_binary_accuracy: 0.9194\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0811 - binary_accuracy: 0.9656 - val_loss: 0.1185 - val_binary_accuracy: 0.9516\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0743 - binary_accuracy: 0.9711 - val_loss: 0.4269 - val_binary_accuracy: 0.8548\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0805 - binary_accuracy: 0.9747 - val_loss: 1.0331 - val_binary_accuracy: 0.8065\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0979 - binary_accuracy: 0.9584 - val_loss: 0.6554 - val_binary_accuracy: 0.8548\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0726 - binary_accuracy: 0.9765 - val_loss: 0.8408 - val_binary_accuracy: 0.8226\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0868 - binary_accuracy: 0.9693 - val_loss: 0.7308 - val_binary_accuracy: 0.7903\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0589 - binary_accuracy: 0.9783 - val_loss: 0.1960 - val_binary_accuracy: 0.9355\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 364us/sample - loss: 0.0971 - binary_accuracy: 0.9656 - val_loss: 0.5683 - val_binary_accuracy: 0.8387\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0776 - binary_accuracy: 0.9765 - val_loss: 0.9240 - val_binary_accuracy: 0.8226\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0775 - binary_accuracy: 0.9819 - val_loss: 0.7387 - val_binary_accuracy: 0.8226\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0544 - binary_accuracy: 0.9892 - val_loss: 0.0913 - val_binary_accuracy: 0.9677\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0782 - binary_accuracy: 0.9711 - val_loss: 0.3956 - val_binary_accuracy: 0.8710\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0606 - binary_accuracy: 0.9765 - val_loss: 0.2013 - val_binary_accuracy: 0.9194\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.0616 - binary_accuracy: 0.9837 - val_loss: 1.0421 - val_binary_accuracy: 0.4677\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0561 - binary_accuracy: 0.9837 - val_loss: 0.3831 - val_binary_accuracy: 0.9032\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0426 - binary_accuracy: 0.9837 - val_loss: 0.3826 - val_binary_accuracy: 0.8226\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0480 - binary_accuracy: 0.9855 - val_loss: 0.2281 - val_binary_accuracy: 0.9194\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0443 - binary_accuracy: 0.9892 - val_loss: 0.2636 - val_binary_accuracy: 0.9194\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0357 - binary_accuracy: 0.9910 - val_loss: 0.1711 - val_binary_accuracy: 0.9516\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0299 - binary_accuracy: 0.9946 - val_loss: 0.1744 - val_binary_accuracy: 0.9516\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0239 - binary_accuracy: 0.9910 - val_loss: 0.2627 - val_binary_accuracy: 0.9194\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0279 - binary_accuracy: 0.9910 - val_loss: 0.2529 - val_binary_accuracy: 0.9355\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0643 - binary_accuracy: 0.9765 - val_loss: 0.4046 - val_binary_accuracy: 0.8065\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0340 - binary_accuracy: 0.9892 - val_loss: 0.2570 - val_binary_accuracy: 0.8710\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0140 - binary_accuracy: 0.9982 - val_loss: 0.2188 - val_binary_accuracy: 0.9355\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0419 - binary_accuracy: 0.9892 - val_loss: 0.1397 - val_binary_accuracy: 0.9516\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0316 - binary_accuracy: 0.9892 - val_loss: 0.2744 - val_binary_accuracy: 0.9032\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0592 - binary_accuracy: 0.9819 - val_loss: 1.3093 - val_binary_accuracy: 0.5161\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0218 - binary_accuracy: 0.9910 - val_loss: 0.2741 - val_binary_accuracy: 0.9032\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0147 - binary_accuracy: 0.9964 - val_loss: 0.2733 - val_binary_accuracy: 0.8871\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0298 - binary_accuracy: 0.9928 - val_loss: 0.3092 - val_binary_accuracy: 0.9032\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0366 - binary_accuracy: 0.9873 - val_loss: 0.2652 - val_binary_accuracy: 0.9355\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 374us/sample - loss: 0.0364 - binary_accuracy: 0.9928 - val_loss: 0.2872 - val_binary_accuracy: 0.9032\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0280 - binary_accuracy: 0.9873 - val_loss: 0.2961 - val_binary_accuracy: 0.8710\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0171 - binary_accuracy: 0.9964 - val_loss: 0.1930 - val_binary_accuracy: 0.9194\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0220 - binary_accuracy: 0.9910 - val_loss: 0.2313 - val_binary_accuracy: 0.9355\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0312 - binary_accuracy: 0.9928 - val_loss: 0.3188 - val_binary_accuracy: 0.8871\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0670 - binary_accuracy: 0.9711 - val_loss: 0.6002 - val_binary_accuracy: 0.8871\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0354 - binary_accuracy: 0.9855 - val_loss: 0.1425 - val_binary_accuracy: 0.9194\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0294 - binary_accuracy: 0.9928 - val_loss: 0.2450 - val_binary_accuracy: 0.8871\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0274 - binary_accuracy: 0.9928 - val_loss: 0.4060 - val_binary_accuracy: 0.9032\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0142 - binary_accuracy: 0.9964 - val_loss: 0.2317 - val_binary_accuracy: 0.8710\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 374us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.2238 - val_binary_accuracy: 0.9516\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0054 - binary_accuracy: 0.9982 - val_loss: 0.2313 - val_binary_accuracy: 0.9194\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0190 - binary_accuracy: 0.9928 - val_loss: 0.4645 - val_binary_accuracy: 0.8871\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0508 - binary_accuracy: 0.9873 - val_loss: 0.2421 - val_binary_accuracy: 0.9032\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0138 - binary_accuracy: 0.9964 - val_loss: 0.2859 - val_binary_accuracy: 0.9194\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0335 - binary_accuracy: 0.9910 - val_loss: 0.3389 - val_binary_accuracy: 0.9032\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0319 - binary_accuracy: 0.9946 - val_loss: 0.2648 - val_binary_accuracy: 0.9032\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0215 - binary_accuracy: 0.9910 - val_loss: 0.5027 - val_binary_accuracy: 0.8710\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0402 - binary_accuracy: 0.9819 - val_loss: 0.1549 - val_binary_accuracy: 0.9677\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0550 - binary_accuracy: 0.9819 - val_loss: 0.2577 - val_binary_accuracy: 0.9516\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0260 - binary_accuracy: 0.9873 - val_loss: 0.2235 - val_binary_accuracy: 0.9355\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0407 - binary_accuracy: 0.9855 - val_loss: 0.2510 - val_binary_accuracy: 0.9194\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0122 - binary_accuracy: 0.9964 - val_loss: 0.2893 - val_binary_accuracy: 0.9032\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0276 - binary_accuracy: 0.9928 - val_loss: 0.3000 - val_binary_accuracy: 0.9194\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0426 - binary_accuracy: 0.9837 - val_loss: 0.2520 - val_binary_accuracy: 0.9355\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 376us/sample - loss: 0.0320 - binary_accuracy: 0.9837 - val_loss: 0.2520 - val_binary_accuracy: 0.9032\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0159 - binary_accuracy: 0.9946 - val_loss: 0.2291 - val_binary_accuracy: 0.9194\n",
      "accuracy for model 4 is 91.93548560142517\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_53 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 1ms/sample - loss: 0.4245 - binary_accuracy: 0.8065 - val_loss: 0.6915 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.3076 - binary_accuracy: 0.8861 - val_loss: 0.4636 - val_binary_accuracy: 0.7903\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.2772 - binary_accuracy: 0.8788 - val_loss: 0.6215 - val_binary_accuracy: 0.7903\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 0s 376us/sample - loss: 0.2526 - binary_accuracy: 0.8969 - val_loss: 0.5695 - val_binary_accuracy: 0.7742\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.2270 - binary_accuracy: 0.9150 - val_loss: 0.5593 - val_binary_accuracy: 0.7903\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.2409 - binary_accuracy: 0.9024 - val_loss: 0.4717 - val_binary_accuracy: 0.8226\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.2163 - binary_accuracy: 0.9204 - val_loss: 0.5054 - val_binary_accuracy: 0.8226\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.2039 - binary_accuracy: 0.9096 - val_loss: 0.7451 - val_binary_accuracy: 0.8226\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.2153 - binary_accuracy: 0.9132 - val_loss: 0.5042 - val_binary_accuracy: 0.8226\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1916 - binary_accuracy: 0.9186 - val_loss: 0.8831 - val_binary_accuracy: 0.6290\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.1901 - binary_accuracy: 0.9222 - val_loss: 0.6752 - val_binary_accuracy: 0.7581\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.1865 - binary_accuracy: 0.9295 - val_loss: 0.5707 - val_binary_accuracy: 0.8226\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1875 - binary_accuracy: 0.9259 - val_loss: 0.4872 - val_binary_accuracy: 0.8387\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1701 - binary_accuracy: 0.9367 - val_loss: 0.5274 - val_binary_accuracy: 0.8226\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1877 - binary_accuracy: 0.9295 - val_loss: 0.5097 - val_binary_accuracy: 0.8226\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1540 - binary_accuracy: 0.9421 - val_loss: 0.6314 - val_binary_accuracy: 0.8065\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.1471 - binary_accuracy: 0.9494 - val_loss: 0.5484 - val_binary_accuracy: 0.8226\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1380 - binary_accuracy: 0.9458 - val_loss: 0.8770 - val_binary_accuracy: 0.7581\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1253 - binary_accuracy: 0.9584 - val_loss: 0.5669 - val_binary_accuracy: 0.8226\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1463 - binary_accuracy: 0.9512 - val_loss: 0.9074 - val_binary_accuracy: 0.7419\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.1316 - binary_accuracy: 0.9458 - val_loss: 0.6674 - val_binary_accuracy: 0.8065\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.1302 - binary_accuracy: 0.9458 - val_loss: 0.6837 - val_binary_accuracy: 0.8065\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1198 - binary_accuracy: 0.9566 - val_loss: 0.6556 - val_binary_accuracy: 0.8226\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1175 - binary_accuracy: 0.9620 - val_loss: 1.0034 - val_binary_accuracy: 0.7419\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.1332 - binary_accuracy: 0.9512 - val_loss: 0.6516 - val_binary_accuracy: 0.7903\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0952 - binary_accuracy: 0.9602 - val_loss: 0.7609 - val_binary_accuracy: 0.8226\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.1166 - binary_accuracy: 0.9530 - val_loss: 0.6990 - val_binary_accuracy: 0.8226\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1095 - binary_accuracy: 0.9620 - val_loss: 0.7354 - val_binary_accuracy: 0.7742\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0796 - binary_accuracy: 0.9765 - val_loss: 1.1393 - val_binary_accuracy: 0.7581\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0919 - binary_accuracy: 0.9638 - val_loss: 0.7399 - val_binary_accuracy: 0.8387\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.1146 - binary_accuracy: 0.9602 - val_loss: 1.0213 - val_binary_accuracy: 0.6452\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0899 - binary_accuracy: 0.9638 - val_loss: 0.6020 - val_binary_accuracy: 0.8710\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0753 - binary_accuracy: 0.9711 - val_loss: 0.7067 - val_binary_accuracy: 0.8065\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0666 - binary_accuracy: 0.9819 - val_loss: 0.7420 - val_binary_accuracy: 0.8065\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0699 - binary_accuracy: 0.9711 - val_loss: 0.8501 - val_binary_accuracy: 0.8065\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.1057 - binary_accuracy: 0.9620 - val_loss: 0.9479 - val_binary_accuracy: 0.7903\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0727 - binary_accuracy: 0.9675 - val_loss: 0.7211 - val_binary_accuracy: 0.8226\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0618 - binary_accuracy: 0.9801 - val_loss: 0.9966 - val_binary_accuracy: 0.7903\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0734 - binary_accuracy: 0.9675 - val_loss: 1.0419 - val_binary_accuracy: 0.7419\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0713 - binary_accuracy: 0.9765 - val_loss: 0.6872 - val_binary_accuracy: 0.8710\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0991 - binary_accuracy: 0.9656 - val_loss: 0.6229 - val_binary_accuracy: 0.8387\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 0s 370us/sample - loss: 0.0780 - binary_accuracy: 0.9729 - val_loss: 0.8024 - val_binary_accuracy: 0.8387\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0618 - binary_accuracy: 0.9783 - val_loss: 0.7378 - val_binary_accuracy: 0.8548\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0633 - binary_accuracy: 0.9765 - val_loss: 0.8402 - val_binary_accuracy: 0.8387\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0533 - binary_accuracy: 0.9801 - val_loss: 0.7200 - val_binary_accuracy: 0.8065\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0553 - binary_accuracy: 0.9783 - val_loss: 0.8367 - val_binary_accuracy: 0.8548\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0477 - binary_accuracy: 0.9855 - val_loss: 0.8042 - val_binary_accuracy: 0.8226\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0352 - binary_accuracy: 0.9855 - val_loss: 0.8509 - val_binary_accuracy: 0.8065\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0491 - binary_accuracy: 0.9837 - val_loss: 0.7672 - val_binary_accuracy: 0.8226\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0578 - binary_accuracy: 0.9819 - val_loss: 0.8926 - val_binary_accuracy: 0.7581\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0425 - binary_accuracy: 0.9892 - val_loss: 0.8830 - val_binary_accuracy: 0.8548\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0645 - binary_accuracy: 0.9765 - val_loss: 0.8795 - val_binary_accuracy: 0.8387\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0433 - binary_accuracy: 0.9873 - val_loss: 0.8257 - val_binary_accuracy: 0.8387\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.0492 - binary_accuracy: 0.9819 - val_loss: 1.0922 - val_binary_accuracy: 0.8065\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0488 - binary_accuracy: 0.9837 - val_loss: 1.0614 - val_binary_accuracy: 0.7903\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0676 - binary_accuracy: 0.9747 - val_loss: 1.0368 - val_binary_accuracy: 0.8226\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0471 - binary_accuracy: 0.9819 - val_loss: 1.0525 - val_binary_accuracy: 0.8226\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0427 - binary_accuracy: 0.9837 - val_loss: 0.9720 - val_binary_accuracy: 0.8226\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0348 - binary_accuracy: 0.9892 - val_loss: 0.8351 - val_binary_accuracy: 0.8387\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0357 - binary_accuracy: 0.9855 - val_loss: 0.8412 - val_binary_accuracy: 0.8548\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0327 - binary_accuracy: 0.9855 - val_loss: 1.0031 - val_binary_accuracy: 0.8387\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0588 - binary_accuracy: 0.9747 - val_loss: 1.1285 - val_binary_accuracy: 0.8065\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0284 - binary_accuracy: 0.9910 - val_loss: 0.9562 - val_binary_accuracy: 0.8387\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0453 - binary_accuracy: 0.9819 - val_loss: 0.9574 - val_binary_accuracy: 0.8226\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0394 - binary_accuracy: 0.9819 - val_loss: 0.9694 - val_binary_accuracy: 0.8226\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0480 - binary_accuracy: 0.9873 - val_loss: 0.8819 - val_binary_accuracy: 0.8226\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0580 - binary_accuracy: 0.9747 - val_loss: 0.9520 - val_binary_accuracy: 0.8065\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0253 - binary_accuracy: 0.9910 - val_loss: 0.8094 - val_binary_accuracy: 0.8548\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0316 - binary_accuracy: 0.9873 - val_loss: 1.3433 - val_binary_accuracy: 0.7903\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0395 - binary_accuracy: 0.9837 - val_loss: 1.0713 - val_binary_accuracy: 0.8226\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0284 - binary_accuracy: 0.9910 - val_loss: 0.9492 - val_binary_accuracy: 0.8065\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0327 - binary_accuracy: 0.9910 - val_loss: 1.0647 - val_binary_accuracy: 0.7742\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 0s 372us/sample - loss: 0.0288 - binary_accuracy: 0.9855 - val_loss: 1.0042 - val_binary_accuracy: 0.8226\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 0s 368us/sample - loss: 0.0581 - binary_accuracy: 0.9819 - val_loss: 1.2642 - val_binary_accuracy: 0.6774\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0272 - binary_accuracy: 0.9892 - val_loss: 1.0639 - val_binary_accuracy: 0.8226\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0254 - binary_accuracy: 0.9910 - val_loss: 0.9970 - val_binary_accuracy: 0.8226\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0213 - binary_accuracy: 0.9892 - val_loss: 0.9840 - val_binary_accuracy: 0.8387\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 1.3778 - val_binary_accuracy: 0.7742\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0307 - binary_accuracy: 0.9928 - val_loss: 1.2281 - val_binary_accuracy: 0.7903\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0107 - binary_accuracy: 0.9982 - val_loss: 1.2738 - val_binary_accuracy: 0.7903\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0083 - binary_accuracy: 1.0000 - val_loss: 1.0982 - val_binary_accuracy: 0.8548\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0481 - binary_accuracy: 0.9801 - val_loss: 1.0575 - val_binary_accuracy: 0.7742\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0299 - binary_accuracy: 0.9873 - val_loss: 1.6492 - val_binary_accuracy: 0.5968\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0346 - binary_accuracy: 0.9910 - val_loss: 0.8537 - val_binary_accuracy: 0.8226\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0424 - binary_accuracy: 0.9819 - val_loss: 1.1270 - val_binary_accuracy: 0.7903\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0325 - binary_accuracy: 0.9855 - val_loss: 1.6948 - val_binary_accuracy: 0.7419\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 0s 369us/sample - loss: 0.0249 - binary_accuracy: 0.9910 - val_loss: 1.1354 - val_binary_accuracy: 0.7903\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0240 - binary_accuracy: 0.9946 - val_loss: 0.9495 - val_binary_accuracy: 0.8387\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 0s 375us/sample - loss: 0.0115 - binary_accuracy: 1.0000 - val_loss: 1.0189 - val_binary_accuracy: 0.8226\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 1.1400 - val_binary_accuracy: 0.8065\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0115 - binary_accuracy: 0.9964 - val_loss: 1.2812 - val_binary_accuracy: 0.8226\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 0s 371us/sample - loss: 0.0354 - binary_accuracy: 0.9910 - val_loss: 1.3190 - val_binary_accuracy: 0.7258\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0317 - binary_accuracy: 0.9910 - val_loss: 1.2523 - val_binary_accuracy: 0.7258\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 0s 373us/sample - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 1.2800 - val_binary_accuracy: 0.8065\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 0s 364us/sample - loss: 0.0300 - binary_accuracy: 0.9855 - val_loss: 0.9909 - val_binary_accuracy: 0.8226\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 0s 365us/sample - loss: 0.0396 - binary_accuracy: 0.9855 - val_loss: 1.6631 - val_binary_accuracy: 0.8226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0114 - binary_accuracy: 1.0000 - val_loss: 1.4223 - val_binary_accuracy: 0.8226\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 0s 366us/sample - loss: 0.0137 - binary_accuracy: 0.9946 - val_loss: 1.0900 - val_binary_accuracy: 0.8065\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 0s 367us/sample - loss: 0.0302 - binary_accuracy: 0.9873 - val_loss: 0.9853 - val_binary_accuracy: 0.8387\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 0s 364us/sample - loss: 0.0271 - binary_accuracy: 0.9892 - val_loss: 1.3849 - val_binary_accuracy: 0.8065\n",
      "accuracy for model 5 is 80.64516186714172\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 1ms/sample - loss: 0.4935 - binary_accuracy: 0.7762 - val_loss: 0.8744 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.3240 - binary_accuracy: 0.8736 - val_loss: 0.8212 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2854 - binary_accuracy: 0.8827 - val_loss: 0.6766 - val_binary_accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2778 - binary_accuracy: 0.8881 - val_loss: 0.5570 - val_binary_accuracy: 0.8361\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2732 - binary_accuracy: 0.8773 - val_loss: 0.4085 - val_binary_accuracy: 0.8525\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2510 - binary_accuracy: 0.9097 - val_loss: 0.5151 - val_binary_accuracy: 0.8361\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.2474 - binary_accuracy: 0.8845 - val_loss: 0.4450 - val_binary_accuracy: 0.8361\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2654 - binary_accuracy: 0.8863 - val_loss: 0.4281 - val_binary_accuracy: 0.8689\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2522 - binary_accuracy: 0.8989 - val_loss: 0.4220 - val_binary_accuracy: 0.8525\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2407 - binary_accuracy: 0.9007 - val_loss: 0.3867 - val_binary_accuracy: 0.8525\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2213 - binary_accuracy: 0.9188 - val_loss: 0.3893 - val_binary_accuracy: 0.8689\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2384 - binary_accuracy: 0.9043 - val_loss: 0.3958 - val_binary_accuracy: 0.8525\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.2085 - binary_accuracy: 0.9152 - val_loss: 0.4023 - val_binary_accuracy: 0.8197\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2117 - binary_accuracy: 0.9278 - val_loss: 0.4829 - val_binary_accuracy: 0.8033\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2145 - binary_accuracy: 0.9043 - val_loss: 0.3834 - val_binary_accuracy: 0.8197\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1896 - binary_accuracy: 0.9188 - val_loss: 0.3901 - val_binary_accuracy: 0.8197\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1706 - binary_accuracy: 0.9422 - val_loss: 0.4090 - val_binary_accuracy: 0.8361\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1778 - binary_accuracy: 0.9296 - val_loss: 0.4672 - val_binary_accuracy: 0.8033\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2002 - binary_accuracy: 0.9206 - val_loss: 0.4399 - val_binary_accuracy: 0.8525\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.1662 - binary_accuracy: 0.9368 - val_loss: 0.4023 - val_binary_accuracy: 0.8525\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2045 - binary_accuracy: 0.9260 - val_loss: 0.4000 - val_binary_accuracy: 0.8689\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1776 - binary_accuracy: 0.9386 - val_loss: 0.4156 - val_binary_accuracy: 0.8525\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1455 - binary_accuracy: 0.9440 - val_loss: 0.5077 - val_binary_accuracy: 0.8197\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1394 - binary_accuracy: 0.9458 - val_loss: 0.4666 - val_binary_accuracy: 0.8525\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1449 - binary_accuracy: 0.9477 - val_loss: 0.4851 - val_binary_accuracy: 0.8689\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1641 - binary_accuracy: 0.9386 - val_loss: 0.4732 - val_binary_accuracy: 0.8361\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1301 - binary_accuracy: 0.9513 - val_loss: 0.5729 - val_binary_accuracy: 0.8033\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 376us/sample - loss: 0.1407 - binary_accuracy: 0.9422 - val_loss: 0.5039 - val_binary_accuracy: 0.8689\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 370us/sample - loss: 0.1232 - binary_accuracy: 0.9513 - val_loss: 0.5283 - val_binary_accuracy: 0.8197\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 370us/sample - loss: 0.1247 - binary_accuracy: 0.9549 - val_loss: 0.4567 - val_binary_accuracy: 0.8361\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.1110 - binary_accuracy: 0.9567 - val_loss: 0.7133 - val_binary_accuracy: 0.7705\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 368us/sample - loss: 0.1280 - binary_accuracy: 0.9477 - val_loss: 0.6550 - val_binary_accuracy: 0.8033\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1412 - binary_accuracy: 0.9477 - val_loss: 0.5415 - val_binary_accuracy: 0.8689\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1079 - binary_accuracy: 0.9621 - val_loss: 0.6049 - val_binary_accuracy: 0.8852\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1076 - binary_accuracy: 0.9621 - val_loss: 0.6476 - val_binary_accuracy: 0.8361\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1267 - binary_accuracy: 0.9495 - val_loss: 0.6537 - val_binary_accuracy: 0.8525\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0971 - binary_accuracy: 0.9693 - val_loss: 0.6757 - val_binary_accuracy: 0.8033\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1085 - binary_accuracy: 0.9549 - val_loss: 0.9878 - val_binary_accuracy: 0.8361\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1109 - binary_accuracy: 0.9513 - val_loss: 0.7177 - val_binary_accuracy: 0.7705\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0961 - binary_accuracy: 0.9729 - val_loss: 0.8278 - val_binary_accuracy: 0.7869\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0886 - binary_accuracy: 0.9711 - val_loss: 0.6713 - val_binary_accuracy: 0.8033\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0881 - binary_accuracy: 0.9729 - val_loss: 0.7176 - val_binary_accuracy: 0.8197\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0754 - binary_accuracy: 0.9675 - val_loss: 0.6768 - val_binary_accuracy: 0.8197\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0870 - binary_accuracy: 0.9693 - val_loss: 0.6338 - val_binary_accuracy: 0.8361\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0899 - binary_accuracy: 0.9711 - val_loss: 0.8165 - val_binary_accuracy: 0.7705\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0728 - binary_accuracy: 0.9783 - val_loss: 0.6638 - val_binary_accuracy: 0.8361\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0507 - binary_accuracy: 0.9856 - val_loss: 0.6576 - val_binary_accuracy: 0.8525\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 372us/sample - loss: 0.0592 - binary_accuracy: 0.9765 - val_loss: 0.6358 - val_binary_accuracy: 0.8852\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0794 - binary_accuracy: 0.9693 - val_loss: 0.6144 - val_binary_accuracy: 0.8525\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0606 - binary_accuracy: 0.9838 - val_loss: 0.7526 - val_binary_accuracy: 0.8525\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0564 - binary_accuracy: 0.9729 - val_loss: 0.7494 - val_binary_accuracy: 0.7705\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0397 - binary_accuracy: 0.9910 - val_loss: 0.7499 - val_binary_accuracy: 0.8361\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0479 - binary_accuracy: 0.9819 - val_loss: 0.6693 - val_binary_accuracy: 0.8689\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0382 - binary_accuracy: 0.9874 - val_loss: 0.6609 - val_binary_accuracy: 0.8361\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0628 - binary_accuracy: 0.9801 - val_loss: 0.6732 - val_binary_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0381 - binary_accuracy: 0.9856 - val_loss: 0.7554 - val_binary_accuracy: 0.8525\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0791 - binary_accuracy: 0.9711 - val_loss: 0.7754 - val_binary_accuracy: 0.8361\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 370us/sample - loss: 0.0691 - binary_accuracy: 0.9765 - val_loss: 0.7778 - val_binary_accuracy: 0.8361\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0420 - binary_accuracy: 0.9910 - val_loss: 0.8422 - val_binary_accuracy: 0.8197\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 372us/sample - loss: 0.0354 - binary_accuracy: 0.9910 - val_loss: 0.7674 - val_binary_accuracy: 0.8361\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0254 - binary_accuracy: 0.9928 - val_loss: 0.7248 - val_binary_accuracy: 0.8361\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0317 - binary_accuracy: 0.9874 - val_loss: 0.9465 - val_binary_accuracy: 0.8361\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0550 - binary_accuracy: 0.9838 - val_loss: 0.7506 - val_binary_accuracy: 0.8197\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0625 - binary_accuracy: 0.9747 - val_loss: 0.7701 - val_binary_accuracy: 0.8689\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0500 - binary_accuracy: 0.9819 - val_loss: 0.6806 - val_binary_accuracy: 0.8525\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 370us/sample - loss: 0.0387 - binary_accuracy: 0.9838 - val_loss: 0.9656 - val_binary_accuracy: 0.8525\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0430 - binary_accuracy: 0.9801 - val_loss: 0.7232 - val_binary_accuracy: 0.8689\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0536 - binary_accuracy: 0.9765 - val_loss: 0.7745 - val_binary_accuracy: 0.8361\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 370us/sample - loss: 0.0382 - binary_accuracy: 0.9838 - val_loss: 0.8063 - val_binary_accuracy: 0.8197\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0289 - binary_accuracy: 0.9874 - val_loss: 0.9796 - val_binary_accuracy: 0.8197\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0679 - binary_accuracy: 0.9693 - val_loss: 0.7900 - val_binary_accuracy: 0.8197\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0401 - binary_accuracy: 0.9856 - val_loss: 0.8249 - val_binary_accuracy: 0.8525\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0464 - binary_accuracy: 0.9819 - val_loss: 0.8538 - val_binary_accuracy: 0.8197\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0157 - binary_accuracy: 0.9964 - val_loss: 0.7572 - val_binary_accuracy: 0.8689\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0194 - binary_accuracy: 0.9928 - val_loss: 0.7794 - val_binary_accuracy: 0.8361\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0406 - binary_accuracy: 0.9856 - val_loss: 0.7950 - val_binary_accuracy: 0.8525\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0430 - binary_accuracy: 0.9838 - val_loss: 0.8790 - val_binary_accuracy: 0.8197\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0355 - binary_accuracy: 0.9874 - val_loss: 0.8015 - val_binary_accuracy: 0.8197\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0277 - binary_accuracy: 0.9946 - val_loss: 0.9684 - val_binary_accuracy: 0.8033\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 371us/sample - loss: 0.0162 - binary_accuracy: 0.9964 - val_loss: 0.8358 - val_binary_accuracy: 0.8197\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0299 - binary_accuracy: 0.9892 - val_loss: 0.7499 - val_binary_accuracy: 0.8033\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0248 - binary_accuracy: 0.9892 - val_loss: 0.6965 - val_binary_accuracy: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0234 - binary_accuracy: 0.9892 - val_loss: 0.7771 - val_binary_accuracy: 0.8525\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0155 - binary_accuracy: 0.9982 - val_loss: 0.9036 - val_binary_accuracy: 0.8525\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0211 - binary_accuracy: 0.9928 - val_loss: 0.6983 - val_binary_accuracy: 0.8525\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0289 - binary_accuracy: 0.9946 - val_loss: 0.8841 - val_binary_accuracy: 0.8361\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0254 - binary_accuracy: 0.9928 - val_loss: 0.8119 - val_binary_accuracy: 0.8361\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0116 - binary_accuracy: 0.9964 - val_loss: 0.7738 - val_binary_accuracy: 0.8361\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0273 - binary_accuracy: 0.9856 - val_loss: 0.8179 - val_binary_accuracy: 0.8525\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 373us/sample - loss: 0.0230 - binary_accuracy: 0.9928 - val_loss: 0.7849 - val_binary_accuracy: 0.8689\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0118 - binary_accuracy: 0.9964 - val_loss: 0.8897 - val_binary_accuracy: 0.8525\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0318 - binary_accuracy: 0.9874 - val_loss: 0.8404 - val_binary_accuracy: 0.8525\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0094 - binary_accuracy: 0.9982 - val_loss: 0.7694 - val_binary_accuracy: 0.8525\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0199 - binary_accuracy: 0.9964 - val_loss: 0.8824 - val_binary_accuracy: 0.8361\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 370us/sample - loss: 0.0043 - binary_accuracy: 0.9982 - val_loss: 0.8033 - val_binary_accuracy: 0.8525\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 0.8621 - val_binary_accuracy: 0.8525\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 372us/sample - loss: 0.0093 - binary_accuracy: 0.9964 - val_loss: 0.8140 - val_binary_accuracy: 0.8361\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0114 - binary_accuracy: 0.9964 - val_loss: 0.9131 - val_binary_accuracy: 0.8525\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0135 - binary_accuracy: 0.9946 - val_loss: 0.8248 - val_binary_accuracy: 0.8525\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0128 - binary_accuracy: 0.9964 - val_loss: 0.8092 - val_binary_accuracy: 0.8361\n",
      "accuracy for model 6 is 83.60655903816223\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 1ms/sample - loss: 0.4586 - binary_accuracy: 0.7906 - val_loss: 1.3681 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.3157 - binary_accuracy: 0.8700 - val_loss: 0.5872 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.2861 - binary_accuracy: 0.8736 - val_loss: 0.7014 - val_binary_accuracy: 0.7377\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2867 - binary_accuracy: 0.8755 - val_loss: 0.3948 - val_binary_accuracy: 0.8033\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2442 - binary_accuracy: 0.9116 - val_loss: 0.4920 - val_binary_accuracy: 0.7869\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2354 - binary_accuracy: 0.8953 - val_loss: 0.5151 - val_binary_accuracy: 0.8033\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2282 - binary_accuracy: 0.9152 - val_loss: 0.4738 - val_binary_accuracy: 0.8361\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 371us/sample - loss: 0.2237 - binary_accuracy: 0.9134 - val_loss: 0.4599 - val_binary_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1892 - binary_accuracy: 0.9278 - val_loss: 0.4798 - val_binary_accuracy: 0.8197\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2066 - binary_accuracy: 0.9170 - val_loss: 0.4753 - val_binary_accuracy: 0.8197\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1782 - binary_accuracy: 0.9314 - val_loss: 0.4975 - val_binary_accuracy: 0.8033\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1767 - binary_accuracy: 0.9260 - val_loss: 0.5181 - val_binary_accuracy: 0.8197\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1723 - binary_accuracy: 0.9332 - val_loss: 0.5168 - val_binary_accuracy: 0.8033\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.1577 - binary_accuracy: 0.9404 - val_loss: 0.4746 - val_binary_accuracy: 0.8525\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1620 - binary_accuracy: 0.9404 - val_loss: 0.6596 - val_binary_accuracy: 0.8197\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1659 - binary_accuracy: 0.9440 - val_loss: 0.5227 - val_binary_accuracy: 0.7869\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1697 - binary_accuracy: 0.9278 - val_loss: 0.5949 - val_binary_accuracy: 0.7869\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1577 - binary_accuracy: 0.9422 - val_loss: 0.6062 - val_binary_accuracy: 0.7705\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1438 - binary_accuracy: 0.9513 - val_loss: 0.6007 - val_binary_accuracy: 0.7705\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1183 - binary_accuracy: 0.9603 - val_loss: 0.7717 - val_binary_accuracy: 0.7869\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1522 - binary_accuracy: 0.9477 - val_loss: 0.6337 - val_binary_accuracy: 0.8361\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 370us/sample - loss: 0.1269 - binary_accuracy: 0.9567 - val_loss: 0.4449 - val_binary_accuracy: 0.8525\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1051 - binary_accuracy: 0.9639 - val_loss: 0.6271 - val_binary_accuracy: 0.8197\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1113 - binary_accuracy: 0.9657 - val_loss: 0.8227 - val_binary_accuracy: 0.8197\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1064 - binary_accuracy: 0.9603 - val_loss: 0.6395 - val_binary_accuracy: 0.7869\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1029 - binary_accuracy: 0.9639 - val_loss: 0.7594 - val_binary_accuracy: 0.7869\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0895 - binary_accuracy: 0.9639 - val_loss: 0.8054 - val_binary_accuracy: 0.8033\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0688 - binary_accuracy: 0.9783 - val_loss: 0.7642 - val_binary_accuracy: 0.8033\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0787 - binary_accuracy: 0.9729 - val_loss: 1.0987 - val_binary_accuracy: 0.7049\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0687 - binary_accuracy: 0.9801 - val_loss: 0.7925 - val_binary_accuracy: 0.7869\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 371us/sample - loss: 0.0771 - binary_accuracy: 0.9675 - val_loss: 0.8479 - val_binary_accuracy: 0.7705\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0787 - binary_accuracy: 0.9783 - val_loss: 0.7686 - val_binary_accuracy: 0.8197\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0850 - binary_accuracy: 0.9675 - val_loss: 1.0391 - val_binary_accuracy: 0.7049\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0825 - binary_accuracy: 0.9693 - val_loss: 0.8348 - val_binary_accuracy: 0.8033\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0783 - binary_accuracy: 0.9783 - val_loss: 0.8265 - val_binary_accuracy: 0.7705\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0618 - binary_accuracy: 0.9765 - val_loss: 0.8297 - val_binary_accuracy: 0.7869\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0638 - binary_accuracy: 0.9801 - val_loss: 0.8744 - val_binary_accuracy: 0.8033\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0559 - binary_accuracy: 0.9801 - val_loss: 0.8026 - val_binary_accuracy: 0.7869\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1038 - binary_accuracy: 0.9639 - val_loss: 0.9622 - val_binary_accuracy: 0.8033\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0491 - binary_accuracy: 0.9838 - val_loss: 0.7746 - val_binary_accuracy: 0.8033\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0499 - binary_accuracy: 0.9856 - val_loss: 0.9138 - val_binary_accuracy: 0.8033\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0374 - binary_accuracy: 0.9892 - val_loss: 0.8340 - val_binary_accuracy: 0.8033\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0536 - binary_accuracy: 0.9838 - val_loss: 1.0097 - val_binary_accuracy: 0.7541\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 371us/sample - loss: 0.0421 - binary_accuracy: 0.9819 - val_loss: 0.9403 - val_binary_accuracy: 0.8033\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0580 - binary_accuracy: 0.9801 - val_loss: 0.9924 - val_binary_accuracy: 0.7705\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0461 - binary_accuracy: 0.9838 - val_loss: 0.9272 - val_binary_accuracy: 0.7869\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.1050 - binary_accuracy: 0.9621 - val_loss: 0.7552 - val_binary_accuracy: 0.7869\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0578 - binary_accuracy: 0.9819 - val_loss: 0.9817 - val_binary_accuracy: 0.8033\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0395 - binary_accuracy: 0.9892 - val_loss: 0.9665 - val_binary_accuracy: 0.7869\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0511 - binary_accuracy: 0.9838 - val_loss: 0.8500 - val_binary_accuracy: 0.8033\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0854 - binary_accuracy: 0.9765 - val_loss: 0.9378 - val_binary_accuracy: 0.8033\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 371us/sample - loss: 0.0342 - binary_accuracy: 0.9874 - val_loss: 1.1555 - val_binary_accuracy: 0.8033\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0350 - binary_accuracy: 0.9892 - val_loss: 1.2297 - val_binary_accuracy: 0.7869\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0586 - binary_accuracy: 0.9801 - val_loss: 1.2185 - val_binary_accuracy: 0.7705\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0783 - binary_accuracy: 0.9711 - val_loss: 1.1495 - val_binary_accuracy: 0.8033\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0611 - binary_accuracy: 0.9783 - val_loss: 0.9576 - val_binary_accuracy: 0.8197\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0401 - binary_accuracy: 0.9874 - val_loss: 0.9798 - val_binary_accuracy: 0.7869\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 370us/sample - loss: 0.0382 - binary_accuracy: 0.9838 - val_loss: 0.8784 - val_binary_accuracy: 0.8197\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0468 - binary_accuracy: 0.9783 - val_loss: 0.9582 - val_binary_accuracy: 0.7869\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 371us/sample - loss: 0.0450 - binary_accuracy: 0.9838 - val_loss: 1.0345 - val_binary_accuracy: 0.8033\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0436 - binary_accuracy: 0.9819 - val_loss: 1.1132 - val_binary_accuracy: 0.7705\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0428 - binary_accuracy: 0.9874 - val_loss: 2.4050 - val_binary_accuracy: 0.5410\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0403 - binary_accuracy: 0.9856 - val_loss: 1.2169 - val_binary_accuracy: 0.7049\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0452 - binary_accuracy: 0.9838 - val_loss: 1.1721 - val_binary_accuracy: 0.7705\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0454 - binary_accuracy: 0.9838 - val_loss: 1.0867 - val_binary_accuracy: 0.8033\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0526 - binary_accuracy: 0.9819 - val_loss: 1.1185 - val_binary_accuracy: 0.7869\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0198 - binary_accuracy: 0.9928 - val_loss: 1.2794 - val_binary_accuracy: 0.8033\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0172 - binary_accuracy: 0.9964 - val_loss: 1.3630 - val_binary_accuracy: 0.7541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0260 - binary_accuracy: 0.9928 - val_loss: 1.1541 - val_binary_accuracy: 0.8033\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0338 - binary_accuracy: 0.9838 - val_loss: 1.0259 - val_binary_accuracy: 0.8197\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0206 - binary_accuracy: 0.9946 - val_loss: 1.2179 - val_binary_accuracy: 0.7705\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 371us/sample - loss: 0.0204 - binary_accuracy: 0.9928 - val_loss: 1.1764 - val_binary_accuracy: 0.8197\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0291 - binary_accuracy: 0.9892 - val_loss: 1.7026 - val_binary_accuracy: 0.6557\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0538 - binary_accuracy: 0.9783 - val_loss: 1.1419 - val_binary_accuracy: 0.7705\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0255 - binary_accuracy: 0.9892 - val_loss: 1.2152 - val_binary_accuracy: 0.7213\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0205 - binary_accuracy: 0.9892 - val_loss: 1.2451 - val_binary_accuracy: 0.7705\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0177 - binary_accuracy: 0.9946 - val_loss: 1.1181 - val_binary_accuracy: 0.7869\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0356 - binary_accuracy: 0.9910 - val_loss: 1.1328 - val_binary_accuracy: 0.8033\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0329 - binary_accuracy: 0.9928 - val_loss: 1.8026 - val_binary_accuracy: 0.6721\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0478 - binary_accuracy: 0.9892 - val_loss: 1.5945 - val_binary_accuracy: 0.7541\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0633 - binary_accuracy: 0.9711 - val_loss: 1.2201 - val_binary_accuracy: 0.8033\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0273 - binary_accuracy: 0.9910 - val_loss: 1.2005 - val_binary_accuracy: 0.7869\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0167 - binary_accuracy: 0.9946 - val_loss: 1.1861 - val_binary_accuracy: 0.8033\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 371us/sample - loss: 0.0093 - binary_accuracy: 0.9982 - val_loss: 1.1936 - val_binary_accuracy: 0.7541\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0071 - binary_accuracy: 0.9982 - val_loss: 1.1892 - val_binary_accuracy: 0.8033\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0255 - binary_accuracy: 0.9964 - val_loss: 1.2724 - val_binary_accuracy: 0.8033\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0206 - binary_accuracy: 0.9910 - val_loss: 1.0248 - val_binary_accuracy: 0.8033\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0118 - binary_accuracy: 0.9964 - val_loss: 1.1693 - val_binary_accuracy: 0.8197\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0290 - binary_accuracy: 0.9892 - val_loss: 1.1280 - val_binary_accuracy: 0.8197\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0123 - binary_accuracy: 0.9964 - val_loss: 1.3742 - val_binary_accuracy: 0.7377\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0260 - binary_accuracy: 0.9910 - val_loss: 1.4554 - val_binary_accuracy: 0.8033\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0343 - binary_accuracy: 0.9819 - val_loss: 1.1159 - val_binary_accuracy: 0.8197\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0236 - binary_accuracy: 0.9928 - val_loss: 1.0177 - val_binary_accuracy: 0.8197\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0115 - binary_accuracy: 0.9964 - val_loss: 1.1557 - val_binary_accuracy: 0.8033\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0189 - binary_accuracy: 0.9928 - val_loss: 1.3949 - val_binary_accuracy: 0.7377\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0275 - binary_accuracy: 0.9910 - val_loss: 1.1402 - val_binary_accuracy: 0.7869\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0210 - binary_accuracy: 0.9964 - val_loss: 1.3103 - val_binary_accuracy: 0.8033\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0163 - binary_accuracy: 0.9946 - val_loss: 1.4135 - val_binary_accuracy: 0.7705\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0211 - binary_accuracy: 0.9928 - val_loss: 1.3132 - val_binary_accuracy: 0.7705\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0288 - binary_accuracy: 0.9928 - val_loss: 1.2480 - val_binary_accuracy: 0.8033\n",
      "accuracy for model 7 is 80.32786846160889\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 1ms/sample - loss: 0.5089 - binary_accuracy: 0.7599 - val_loss: 1.1912 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.3337 - binary_accuracy: 0.8610 - val_loss: 0.6931 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2991 - binary_accuracy: 0.8736 - val_loss: 0.3893 - val_binary_accuracy: 0.8852\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2806 - binary_accuracy: 0.8700 - val_loss: 0.4991 - val_binary_accuracy: 0.8525\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2640 - binary_accuracy: 0.8935 - val_loss: 0.3928 - val_binary_accuracy: 0.8689\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2427 - binary_accuracy: 0.9061 - val_loss: 0.3155 - val_binary_accuracy: 0.8852\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2364 - binary_accuracy: 0.9025 - val_loss: 0.4628 - val_binary_accuracy: 0.8689\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2266 - binary_accuracy: 0.9224 - val_loss: 0.3705 - val_binary_accuracy: 0.8689\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2312 - binary_accuracy: 0.9043 - val_loss: 0.3791 - val_binary_accuracy: 0.8852\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.2251 - binary_accuracy: 0.9025 - val_loss: 0.3805 - val_binary_accuracy: 0.8689\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1948 - binary_accuracy: 0.9242 - val_loss: 0.4022 - val_binary_accuracy: 0.8689\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2061 - binary_accuracy: 0.9188 - val_loss: 0.4823 - val_binary_accuracy: 0.8689\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1919 - binary_accuracy: 0.9170 - val_loss: 0.3871 - val_binary_accuracy: 0.8689\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1873 - binary_accuracy: 0.9278 - val_loss: 0.3695 - val_binary_accuracy: 0.8689\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1934 - binary_accuracy: 0.9188 - val_loss: 0.3688 - val_binary_accuracy: 0.8689\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1772 - binary_accuracy: 0.9386 - val_loss: 0.5001 - val_binary_accuracy: 0.8525\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.2009 - binary_accuracy: 0.9242 - val_loss: 0.4054 - val_binary_accuracy: 0.8689\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1845 - binary_accuracy: 0.9242 - val_loss: 0.4178 - val_binary_accuracy: 0.8689\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1850 - binary_accuracy: 0.9260 - val_loss: 0.4502 - val_binary_accuracy: 0.8689\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1490 - binary_accuracy: 0.9458 - val_loss: 0.5465 - val_binary_accuracy: 0.8361\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1467 - binary_accuracy: 0.9495 - val_loss: 0.4609 - val_binary_accuracy: 0.8033\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1581 - binary_accuracy: 0.9495 - val_loss: 0.7619 - val_binary_accuracy: 0.8361\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1584 - binary_accuracy: 0.9404 - val_loss: 0.5104 - val_binary_accuracy: 0.8525\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1425 - binary_accuracy: 0.9567 - val_loss: 0.4916 - val_binary_accuracy: 0.8197\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1328 - binary_accuracy: 0.9386 - val_loss: 0.8410 - val_binary_accuracy: 0.6393\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1350 - binary_accuracy: 0.9477 - val_loss: 0.4870 - val_binary_accuracy: 0.8361\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.1131 - binary_accuracy: 0.9567 - val_loss: 0.5218 - val_binary_accuracy: 0.7541\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1242 - binary_accuracy: 0.9495 - val_loss: 0.6008 - val_binary_accuracy: 0.8197\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1518 - binary_accuracy: 0.9531 - val_loss: 0.8946 - val_binary_accuracy: 0.8197\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.1157 - binary_accuracy: 0.9567 - val_loss: 0.4311 - val_binary_accuracy: 0.8197\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.1149 - binary_accuracy: 0.9531 - val_loss: 0.5242 - val_binary_accuracy: 0.8197\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0867 - binary_accuracy: 0.9711 - val_loss: 0.5487 - val_binary_accuracy: 0.8197\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0996 - binary_accuracy: 0.9603 - val_loss: 0.4755 - val_binary_accuracy: 0.8361\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.1191 - binary_accuracy: 0.9549 - val_loss: 0.8210 - val_binary_accuracy: 0.6885\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0799 - binary_accuracy: 0.9729 - val_loss: 0.6621 - val_binary_accuracy: 0.8197\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0905 - binary_accuracy: 0.9657 - val_loss: 0.5160 - val_binary_accuracy: 0.8197\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0946 - binary_accuracy: 0.9621 - val_loss: 0.5794 - val_binary_accuracy: 0.8361\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0874 - binary_accuracy: 0.9729 - val_loss: 0.7619 - val_binary_accuracy: 0.7049\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0659 - binary_accuracy: 0.9765 - val_loss: 0.6602 - val_binary_accuracy: 0.8197\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1184 - binary_accuracy: 0.9585 - val_loss: 0.6140 - val_binary_accuracy: 0.7705\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0909 - binary_accuracy: 0.9603 - val_loss: 0.8011 - val_binary_accuracy: 0.8361\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0748 - binary_accuracy: 0.9711 - val_loss: 0.6759 - val_binary_accuracy: 0.8197\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0882 - binary_accuracy: 0.9657 - val_loss: 2.3843 - val_binary_accuracy: 0.4262\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1125 - binary_accuracy: 0.9603 - val_loss: 0.5280 - val_binary_accuracy: 0.8361\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0775 - binary_accuracy: 0.9693 - val_loss: 1.0792 - val_binary_accuracy: 0.8361\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0709 - binary_accuracy: 0.9747 - val_loss: 0.8731 - val_binary_accuracy: 0.6885\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0554 - binary_accuracy: 0.9801 - val_loss: 0.6089 - val_binary_accuracy: 0.8033\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0379 - binary_accuracy: 0.9874 - val_loss: 1.0162 - val_binary_accuracy: 0.8033\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0514 - binary_accuracy: 0.9765 - val_loss: 0.7379 - val_binary_accuracy: 0.8033\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0700 - binary_accuracy: 0.9765 - val_loss: 0.5600 - val_binary_accuracy: 0.8033\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0473 - binary_accuracy: 0.9801 - val_loss: 0.8954 - val_binary_accuracy: 0.8197\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0648 - binary_accuracy: 0.9747 - val_loss: 0.6020 - val_binary_accuracy: 0.8197\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0628 - binary_accuracy: 0.9801 - val_loss: 0.8916 - val_binary_accuracy: 0.8197\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0804 - binary_accuracy: 0.9693 - val_loss: 0.7029 - val_binary_accuracy: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0753 - binary_accuracy: 0.9729 - val_loss: 1.1314 - val_binary_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0682 - binary_accuracy: 0.9747 - val_loss: 0.6592 - val_binary_accuracy: 0.7377\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0931 - binary_accuracy: 0.9657 - val_loss: 0.6373 - val_binary_accuracy: 0.7377\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0319 - binary_accuracy: 0.9892 - val_loss: 0.6380 - val_binary_accuracy: 0.8361\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0263 - binary_accuracy: 0.9910 - val_loss: 0.8064 - val_binary_accuracy: 0.8197\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0420 - binary_accuracy: 0.9892 - val_loss: 0.7007 - val_binary_accuracy: 0.8033\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0768 - binary_accuracy: 0.9729 - val_loss: 0.6569 - val_binary_accuracy: 0.6885\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0535 - binary_accuracy: 0.9838 - val_loss: 0.5912 - val_binary_accuracy: 0.8197\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0751 - binary_accuracy: 0.9747 - val_loss: 0.5709 - val_binary_accuracy: 0.8033\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0236 - binary_accuracy: 0.9928 - val_loss: 1.1038 - val_binary_accuracy: 0.8525\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0528 - binary_accuracy: 0.9819 - val_loss: 0.9765 - val_binary_accuracy: 0.8197\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0330 - binary_accuracy: 0.9892 - val_loss: 0.7661 - val_binary_accuracy: 0.8033\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0267 - binary_accuracy: 0.9910 - val_loss: 1.1092 - val_binary_accuracy: 0.8361\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0331 - binary_accuracy: 0.9892 - val_loss: 0.8141 - val_binary_accuracy: 0.7869\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0246 - binary_accuracy: 0.9910 - val_loss: 1.0284 - val_binary_accuracy: 0.8361\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0233 - binary_accuracy: 0.9928 - val_loss: 0.7940 - val_binary_accuracy: 0.8361\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0422 - binary_accuracy: 0.9874 - val_loss: 0.5718 - val_binary_accuracy: 0.8033\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0582 - binary_accuracy: 0.9783 - val_loss: 0.5662 - val_binary_accuracy: 0.8033\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0593 - binary_accuracy: 0.9838 - val_loss: 0.5377 - val_binary_accuracy: 0.7541\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0161 - binary_accuracy: 0.9982 - val_loss: 0.6184 - val_binary_accuracy: 0.8033\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0145 - binary_accuracy: 0.9946 - val_loss: 0.6261 - val_binary_accuracy: 0.8197\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0146 - binary_accuracy: 0.9964 - val_loss: 0.8066 - val_binary_accuracy: 0.8197\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0145 - binary_accuracy: 0.9946 - val_loss: 0.8613 - val_binary_accuracy: 0.7869\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0329 - binary_accuracy: 0.9856 - val_loss: 1.0931 - val_binary_accuracy: 0.8361\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0513 - binary_accuracy: 0.9765 - val_loss: 0.9632 - val_binary_accuracy: 0.7049\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0587 - binary_accuracy: 0.9783 - val_loss: 1.2095 - val_binary_accuracy: 0.5574\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0527 - binary_accuracy: 0.9819 - val_loss: 0.7289 - val_binary_accuracy: 0.7869\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0284 - binary_accuracy: 0.9928 - val_loss: 0.8506 - val_binary_accuracy: 0.8197\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0405 - binary_accuracy: 0.9819 - val_loss: 0.7701 - val_binary_accuracy: 0.8197\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0226 - binary_accuracy: 0.9910 - val_loss: 0.7275 - val_binary_accuracy: 0.7869\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0313 - binary_accuracy: 0.9928 - val_loss: 0.7974 - val_binary_accuracy: 0.7869\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 0.8183 - val_binary_accuracy: 0.7705\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0207 - binary_accuracy: 0.9928 - val_loss: 1.0047 - val_binary_accuracy: 0.8525\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0607 - binary_accuracy: 0.9729 - val_loss: 0.6885 - val_binary_accuracy: 0.8033\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0431 - binary_accuracy: 0.9856 - val_loss: 0.7492 - val_binary_accuracy: 0.7869\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0278 - binary_accuracy: 0.9910 - val_loss: 0.5206 - val_binary_accuracy: 0.8361\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0271 - binary_accuracy: 0.9910 - val_loss: 0.5912 - val_binary_accuracy: 0.8361\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0556 - binary_accuracy: 0.9838 - val_loss: 0.7773 - val_binary_accuracy: 0.7541\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0565 - binary_accuracy: 0.9819 - val_loss: 0.8492 - val_binary_accuracy: 0.7869\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0463 - binary_accuracy: 0.9838 - val_loss: 1.1515 - val_binary_accuracy: 0.8197\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0185 - binary_accuracy: 0.9964 - val_loss: 1.0182 - val_binary_accuracy: 0.8033\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0119 - binary_accuracy: 0.9982 - val_loss: 1.0774 - val_binary_accuracy: 0.8033\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 0.7023 - val_binary_accuracy: 0.8197\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0223 - binary_accuracy: 0.9892 - val_loss: 1.0529 - val_binary_accuracy: 0.8361\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0376 - binary_accuracy: 0.9856 - val_loss: 0.9667 - val_binary_accuracy: 0.7377\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0275 - binary_accuracy: 0.9928 - val_loss: 0.5873 - val_binary_accuracy: 0.8361\n",
      "accuracy for model 8 is 83.60655903816223\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_74 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 1ms/sample - loss: 0.4049 - binary_accuracy: 0.8412 - val_loss: 1.5004 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.3363 - binary_accuracy: 0.8538 - val_loss: 0.6947 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.3032 - binary_accuracy: 0.8700 - val_loss: 0.2708 - val_binary_accuracy: 0.9016\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.2927 - binary_accuracy: 0.8718 - val_loss: 0.2951 - val_binary_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.2641 - binary_accuracy: 0.8845 - val_loss: 0.2640 - val_binary_accuracy: 0.8689\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.2661 - binary_accuracy: 0.8917 - val_loss: 0.2610 - val_binary_accuracy: 0.9016\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.2734 - binary_accuracy: 0.8827 - val_loss: 0.3434 - val_binary_accuracy: 0.8197\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2567 - binary_accuracy: 0.9079 - val_loss: 0.6394 - val_binary_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.2147 - binary_accuracy: 0.9134 - val_loss: 0.2497 - val_binary_accuracy: 0.8852\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.2274 - binary_accuracy: 0.9134 - val_loss: 0.2676 - val_binary_accuracy: 0.8852\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.2252 - binary_accuracy: 0.9170 - val_loss: 0.2732 - val_binary_accuracy: 0.9180\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.2272 - binary_accuracy: 0.8953 - val_loss: 0.7286 - val_binary_accuracy: 0.5574\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2201 - binary_accuracy: 0.9097 - val_loss: 0.4101 - val_binary_accuracy: 0.8852\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.2078 - binary_accuracy: 0.9242 - val_loss: 0.2665 - val_binary_accuracy: 0.9016\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.2011 - binary_accuracy: 0.9242 - val_loss: 0.2536 - val_binary_accuracy: 0.8852\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.2139 - binary_accuracy: 0.9170 - val_loss: 0.2507 - val_binary_accuracy: 0.8852\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1996 - binary_accuracy: 0.9116 - val_loss: 0.2629 - val_binary_accuracy: 0.9016\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1730 - binary_accuracy: 0.9206 - val_loss: 0.4142 - val_binary_accuracy: 0.8361\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1782 - binary_accuracy: 0.9296 - val_loss: 0.2643 - val_binary_accuracy: 0.9016\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1672 - binary_accuracy: 0.9350 - val_loss: 0.2522 - val_binary_accuracy: 0.9016\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1656 - binary_accuracy: 0.9332 - val_loss: 0.2115 - val_binary_accuracy: 0.9344\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1638 - binary_accuracy: 0.9386 - val_loss: 0.2868 - val_binary_accuracy: 0.8852\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1543 - binary_accuracy: 0.9422 - val_loss: 0.2875 - val_binary_accuracy: 0.9016\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.1444 - binary_accuracy: 0.9495 - val_loss: 0.2192 - val_binary_accuracy: 0.9016\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1484 - binary_accuracy: 0.9477 - val_loss: 0.2544 - val_binary_accuracy: 0.8689\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1466 - binary_accuracy: 0.9314 - val_loss: 0.3393 - val_binary_accuracy: 0.8525\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1536 - binary_accuracy: 0.9404 - val_loss: 0.3095 - val_binary_accuracy: 0.9180\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1437 - binary_accuracy: 0.9440 - val_loss: 0.2924 - val_binary_accuracy: 0.9016\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1195 - binary_accuracy: 0.9585 - val_loss: 0.2724 - val_binary_accuracy: 0.9016\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1220 - binary_accuracy: 0.9495 - val_loss: 0.4725 - val_binary_accuracy: 0.8197\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1138 - binary_accuracy: 0.9531 - val_loss: 0.2506 - val_binary_accuracy: 0.9180\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.1260 - binary_accuracy: 0.9549 - val_loss: 0.3214 - val_binary_accuracy: 0.9016\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0986 - binary_accuracy: 0.9657 - val_loss: 0.4499 - val_binary_accuracy: 0.8852\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1074 - binary_accuracy: 0.9711 - val_loss: 0.3051 - val_binary_accuracy: 0.9016\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1138 - binary_accuracy: 0.9549 - val_loss: 0.3490 - val_binary_accuracy: 0.9016\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 361us/sample - loss: 0.1138 - binary_accuracy: 0.9513 - val_loss: 0.6085 - val_binary_accuracy: 0.8525\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.1145 - binary_accuracy: 0.9603 - val_loss: 0.4277 - val_binary_accuracy: 0.8852\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1207 - binary_accuracy: 0.9639 - val_loss: 0.4093 - val_binary_accuracy: 0.9016\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1014 - binary_accuracy: 0.9639 - val_loss: 0.4464 - val_binary_accuracy: 0.8852\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1083 - binary_accuracy: 0.9440 - val_loss: 0.4147 - val_binary_accuracy: 0.8852\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0993 - binary_accuracy: 0.9693 - val_loss: 0.4627 - val_binary_accuracy: 0.8689\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0776 - binary_accuracy: 0.9693 - val_loss: 0.5649 - val_binary_accuracy: 0.8197\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0953 - binary_accuracy: 0.9603 - val_loss: 1.0023 - val_binary_accuracy: 0.8033\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0829 - binary_accuracy: 0.9657 - val_loss: 1.3112 - val_binary_accuracy: 0.8197\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1133 - binary_accuracy: 0.9585 - val_loss: 0.9005 - val_binary_accuracy: 0.8361\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0790 - binary_accuracy: 0.9657 - val_loss: 0.7645 - val_binary_accuracy: 0.7377\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0920 - binary_accuracy: 0.9657 - val_loss: 0.3362 - val_binary_accuracy: 0.8689\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0941 - binary_accuracy: 0.9657 - val_loss: 0.7278 - val_binary_accuracy: 0.7541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1101 - binary_accuracy: 0.9567 - val_loss: 0.3309 - val_binary_accuracy: 0.8852\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0756 - binary_accuracy: 0.9675 - val_loss: 0.2884 - val_binary_accuracy: 0.9180\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0840 - binary_accuracy: 0.9657 - val_loss: 0.4143 - val_binary_accuracy: 0.8852\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0763 - binary_accuracy: 0.9729 - val_loss: 0.5593 - val_binary_accuracy: 0.8361\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0567 - binary_accuracy: 0.9783 - val_loss: 0.5584 - val_binary_accuracy: 0.8852\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1351 - binary_accuracy: 0.9495 - val_loss: 0.3787 - val_binary_accuracy: 0.8852\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0719 - binary_accuracy: 0.9693 - val_loss: 0.3551 - val_binary_accuracy: 0.9016\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0825 - binary_accuracy: 0.9657 - val_loss: 0.3890 - val_binary_accuracy: 0.8852\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0637 - binary_accuracy: 0.9783 - val_loss: 0.4986 - val_binary_accuracy: 0.8525\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0564 - binary_accuracy: 0.9801 - val_loss: 0.3742 - val_binary_accuracy: 0.8852\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0609 - binary_accuracy: 0.9747 - val_loss: 0.5283 - val_binary_accuracy: 0.8525\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0457 - binary_accuracy: 0.9856 - val_loss: 0.4601 - val_binary_accuracy: 0.8689\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0449 - binary_accuracy: 0.9874 - val_loss: 0.4309 - val_binary_accuracy: 0.8525\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0428 - binary_accuracy: 0.9874 - val_loss: 0.4927 - val_binary_accuracy: 0.8525\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0588 - binary_accuracy: 0.9729 - val_loss: 0.6873 - val_binary_accuracy: 0.8525\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0345 - binary_accuracy: 0.9874 - val_loss: 0.8398 - val_binary_accuracy: 0.8197\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0380 - binary_accuracy: 0.9892 - val_loss: 0.6749 - val_binary_accuracy: 0.8689\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0364 - binary_accuracy: 0.9874 - val_loss: 0.6308 - val_binary_accuracy: 0.8525\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0322 - binary_accuracy: 0.9946 - val_loss: 0.4965 - val_binary_accuracy: 0.8525\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0402 - binary_accuracy: 0.9874 - val_loss: 0.6795 - val_binary_accuracy: 0.8852\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0532 - binary_accuracy: 0.9783 - val_loss: 0.7128 - val_binary_accuracy: 0.8525\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0317 - binary_accuracy: 0.9928 - val_loss: 0.5716 - val_binary_accuracy: 0.9016\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0435 - binary_accuracy: 0.9838 - val_loss: 0.6090 - val_binary_accuracy: 0.8689\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0421 - binary_accuracy: 0.9838 - val_loss: 0.6921 - val_binary_accuracy: 0.8689\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 377us/sample - loss: 0.0519 - binary_accuracy: 0.9801 - val_loss: 0.5904 - val_binary_accuracy: 0.8852\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 597us/sample - loss: 0.0423 - binary_accuracy: 0.9874 - val_loss: 0.4551 - val_binary_accuracy: 0.8852\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 397us/sample - loss: 0.0246 - binary_accuracy: 0.9928 - val_loss: 0.5605 - val_binary_accuracy: 0.8689\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0222 - binary_accuracy: 0.9910 - val_loss: 0.5760 - val_binary_accuracy: 0.9016\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0190 - binary_accuracy: 0.9928 - val_loss: 0.6371 - val_binary_accuracy: 0.8525\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0271 - binary_accuracy: 0.9892 - val_loss: 0.6073 - val_binary_accuracy: 0.8689\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0129 - binary_accuracy: 0.9964 - val_loss: 0.5520 - val_binary_accuracy: 0.8852\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0444 - binary_accuracy: 0.9910 - val_loss: 0.5224 - val_binary_accuracy: 0.8689\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0101 - binary_accuracy: 0.9982 - val_loss: 0.5755 - val_binary_accuracy: 0.9016\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0178 - binary_accuracy: 0.9928 - val_loss: 0.7033 - val_binary_accuracy: 0.8852\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0214 - binary_accuracy: 0.9910 - val_loss: 0.4552 - val_binary_accuracy: 0.9016\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0266 - binary_accuracy: 0.9946 - val_loss: 0.5617 - val_binary_accuracy: 0.9016\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0262 - binary_accuracy: 0.9874 - val_loss: 0.7174 - val_binary_accuracy: 0.8525\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0387 - binary_accuracy: 0.9874 - val_loss: 0.5010 - val_binary_accuracy: 0.9180\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0142 - binary_accuracy: 0.9964 - val_loss: 0.5132 - val_binary_accuracy: 0.9016\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0117 - binary_accuracy: 0.9982 - val_loss: 0.5498 - val_binary_accuracy: 0.8689\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0108 - binary_accuracy: 0.9964 - val_loss: 0.5159 - val_binary_accuracy: 0.8689\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0172 - binary_accuracy: 0.9910 - val_loss: 0.5732 - val_binary_accuracy: 0.8852\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0224 - binary_accuracy: 0.9928 - val_loss: 0.7001 - val_binary_accuracy: 0.9016\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0849 - binary_accuracy: 0.9711 - val_loss: 0.8715 - val_binary_accuracy: 0.8525\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0468 - binary_accuracy: 0.9838 - val_loss: 0.5305 - val_binary_accuracy: 0.9016\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 361us/sample - loss: 0.0556 - binary_accuracy: 0.9856 - val_loss: 0.6327 - val_binary_accuracy: 0.8852\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0460 - binary_accuracy: 0.9874 - val_loss: 0.6047 - val_binary_accuracy: 0.8689\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0439 - binary_accuracy: 0.9838 - val_loss: 0.6443 - val_binary_accuracy: 0.8689\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0151 - binary_accuracy: 0.9964 - val_loss: 0.5864 - val_binary_accuracy: 0.9016\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 0.5949 - val_binary_accuracy: 0.9016\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0127 - binary_accuracy: 0.9946 - val_loss: 0.5519 - val_binary_accuracy: 0.9016\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0445 - binary_accuracy: 0.9819 - val_loss: 0.6223 - val_binary_accuracy: 0.8525\n",
      "accuracy for model 9 is 85.24590134620667\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 256)               6927872   \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,971,777\n",
      "Trainable params: 6,971,713\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 1s 1ms/sample - loss: 0.4709 - binary_accuracy: 0.7852 - val_loss: 0.3354 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.3464 - binary_accuracy: 0.8556 - val_loss: 0.3552 - val_binary_accuracy: 0.8361\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.3072 - binary_accuracy: 0.8628 - val_loss: 0.3446 - val_binary_accuracy: 0.8033\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2835 - binary_accuracy: 0.8755 - val_loss: 0.3317 - val_binary_accuracy: 0.8525\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.2620 - binary_accuracy: 0.8917 - val_loss: 0.2699 - val_binary_accuracy: 0.8852\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.2657 - binary_accuracy: 0.8881 - val_loss: 0.2999 - val_binary_accuracy: 0.8852\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.2463 - binary_accuracy: 0.8971 - val_loss: 0.3064 - val_binary_accuracy: 0.8689\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.2400 - binary_accuracy: 0.9206 - val_loss: 0.5516 - val_binary_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2385 - binary_accuracy: 0.9079 - val_loss: 0.2549 - val_binary_accuracy: 0.9016\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2356 - binary_accuracy: 0.9025 - val_loss: 0.2931 - val_binary_accuracy: 0.8689\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2285 - binary_accuracy: 0.9170 - val_loss: 0.2101 - val_binary_accuracy: 0.9344\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.2111 - binary_accuracy: 0.9152 - val_loss: 0.2102 - val_binary_accuracy: 0.9508\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1908 - binary_accuracy: 0.9278 - val_loss: 0.2580 - val_binary_accuracy: 0.8852\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.2011 - binary_accuracy: 0.9206 - val_loss: 0.5862 - val_binary_accuracy: 0.7377\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1964 - binary_accuracy: 0.9368 - val_loss: 0.2313 - val_binary_accuracy: 0.9180\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1874 - binary_accuracy: 0.9224 - val_loss: 0.2245 - val_binary_accuracy: 0.9344\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1921 - binary_accuracy: 0.9332 - val_loss: 0.2263 - val_binary_accuracy: 0.9344\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1750 - binary_accuracy: 0.9350 - val_loss: 0.2577 - val_binary_accuracy: 0.9016\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1955 - binary_accuracy: 0.9422 - val_loss: 0.2346 - val_binary_accuracy: 0.9016\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1633 - binary_accuracy: 0.9386 - val_loss: 0.4438 - val_binary_accuracy: 0.8197\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1557 - binary_accuracy: 0.9404 - val_loss: 0.2903 - val_binary_accuracy: 0.9016\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1666 - binary_accuracy: 0.9422 - val_loss: 0.2404 - val_binary_accuracy: 0.9508\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1562 - binary_accuracy: 0.9206 - val_loss: 0.2684 - val_binary_accuracy: 0.9016\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1294 - binary_accuracy: 0.9567 - val_loss: 0.2677 - val_binary_accuracy: 0.9016\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1366 - binary_accuracy: 0.9368 - val_loss: 0.3167 - val_binary_accuracy: 0.8689\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1396 - binary_accuracy: 0.9440 - val_loss: 0.3166 - val_binary_accuracy: 0.9016\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1463 - binary_accuracy: 0.9422 - val_loss: 0.2796 - val_binary_accuracy: 0.9016\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1385 - binary_accuracy: 0.9513 - val_loss: 0.2545 - val_binary_accuracy: 0.9508\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.1185 - binary_accuracy: 0.9495 - val_loss: 0.2875 - val_binary_accuracy: 0.8689\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1072 - binary_accuracy: 0.9693 - val_loss: 0.2798 - val_binary_accuracy: 0.9016\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1028 - binary_accuracy: 0.9603 - val_loss: 0.6524 - val_binary_accuracy: 0.6885\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.1199 - binary_accuracy: 0.9513 - val_loss: 0.2574 - val_binary_accuracy: 0.9180\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0875 - binary_accuracy: 0.9675 - val_loss: 0.3018 - val_binary_accuracy: 0.8852\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1088 - binary_accuracy: 0.9549 - val_loss: 0.3486 - val_binary_accuracy: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0944 - binary_accuracy: 0.9585 - val_loss: 0.3358 - val_binary_accuracy: 0.8852\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 0s 361us/sample - loss: 0.0929 - binary_accuracy: 0.9603 - val_loss: 0.4936 - val_binary_accuracy: 0.8852\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1341 - binary_accuracy: 0.9477 - val_loss: 0.4056 - val_binary_accuracy: 0.8689\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.1206 - binary_accuracy: 0.9585 - val_loss: 0.4479 - val_binary_accuracy: 0.8689\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0823 - binary_accuracy: 0.9783 - val_loss: 0.3172 - val_binary_accuracy: 0.8852\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0757 - binary_accuracy: 0.9765 - val_loss: 0.4022 - val_binary_accuracy: 0.8852\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1260 - binary_accuracy: 0.9513 - val_loss: 0.3349 - val_binary_accuracy: 0.8361\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0942 - binary_accuracy: 0.9639 - val_loss: 0.3531 - val_binary_accuracy: 0.8689\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.1217 - binary_accuracy: 0.9621 - val_loss: 0.3878 - val_binary_accuracy: 0.8525\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1124 - binary_accuracy: 0.9531 - val_loss: 0.2586 - val_binary_accuracy: 0.9344\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0834 - binary_accuracy: 0.9639 - val_loss: 0.3158 - val_binary_accuracy: 0.8852\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0833 - binary_accuracy: 0.9657 - val_loss: 0.5260 - val_binary_accuracy: 0.8525\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0647 - binary_accuracy: 0.9783 - val_loss: 0.4695 - val_binary_accuracy: 0.8689\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0778 - binary_accuracy: 0.9657 - val_loss: 0.8631 - val_binary_accuracy: 0.7049\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 0s 367us/sample - loss: 0.0746 - binary_accuracy: 0.9711 - val_loss: 0.2231 - val_binary_accuracy: 0.9180\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0690 - binary_accuracy: 0.9711 - val_loss: 0.4162 - val_binary_accuracy: 0.8361\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0724 - binary_accuracy: 0.9747 - val_loss: 0.3588 - val_binary_accuracy: 0.8852\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0871 - binary_accuracy: 0.9729 - val_loss: 0.2969 - val_binary_accuracy: 0.9180\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0794 - binary_accuracy: 0.9675 - val_loss: 0.3876 - val_binary_accuracy: 0.8689\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0746 - binary_accuracy: 0.9747 - val_loss: 0.2953 - val_binary_accuracy: 0.9344\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0678 - binary_accuracy: 0.9747 - val_loss: 0.5379 - val_binary_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 0s 368us/sample - loss: 0.0830 - binary_accuracy: 0.9765 - val_loss: 0.3463 - val_binary_accuracy: 0.8689\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.1080 - binary_accuracy: 0.9639 - val_loss: 0.8262 - val_binary_accuracy: 0.8525\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0618 - binary_accuracy: 0.9765 - val_loss: 0.4028 - val_binary_accuracy: 0.8361\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0774 - binary_accuracy: 0.9729 - val_loss: 0.4786 - val_binary_accuracy: 0.8689\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0921 - binary_accuracy: 0.9621 - val_loss: 0.4849 - val_binary_accuracy: 0.8689\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0555 - binary_accuracy: 0.9838 - val_loss: 0.3448 - val_binary_accuracy: 0.9016\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0502 - binary_accuracy: 0.9892 - val_loss: 0.3044 - val_binary_accuracy: 0.8852\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0409 - binary_accuracy: 0.9838 - val_loss: 0.4668 - val_binary_accuracy: 0.8525\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0434 - binary_accuracy: 0.9928 - val_loss: 0.4053 - val_binary_accuracy: 0.8525\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0572 - binary_accuracy: 0.9819 - val_loss: 0.4066 - val_binary_accuracy: 0.9180\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0411 - binary_accuracy: 0.9892 - val_loss: 0.3724 - val_binary_accuracy: 0.8689\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0934 - binary_accuracy: 0.9657 - val_loss: 0.4818 - val_binary_accuracy: 0.8689\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0232 - binary_accuracy: 0.9928 - val_loss: 0.3874 - val_binary_accuracy: 0.8852\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0619 - binary_accuracy: 0.9747 - val_loss: 0.2550 - val_binary_accuracy: 0.9344\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0334 - binary_accuracy: 0.9892 - val_loss: 0.3415 - val_binary_accuracy: 0.8525\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0272 - binary_accuracy: 0.9928 - val_loss: 0.3019 - val_binary_accuracy: 0.9180\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0226 - binary_accuracy: 0.9928 - val_loss: 0.5564 - val_binary_accuracy: 0.8197\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0537 - binary_accuracy: 0.9801 - val_loss: 0.5284 - val_binary_accuracy: 0.8689\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0412 - binary_accuracy: 0.9856 - val_loss: 0.5125 - val_binary_accuracy: 0.8689\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0291 - binary_accuracy: 0.9946 - val_loss: 0.3480 - val_binary_accuracy: 0.9016\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0414 - binary_accuracy: 0.9819 - val_loss: 0.2696 - val_binary_accuracy: 0.9344\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0833 - binary_accuracy: 0.9639 - val_loss: 0.4644 - val_binary_accuracy: 0.9016\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0484 - binary_accuracy: 0.9838 - val_loss: 0.2735 - val_binary_accuracy: 0.9344\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0695 - binary_accuracy: 0.9765 - val_loss: 0.3604 - val_binary_accuracy: 0.9016\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0440 - binary_accuracy: 0.9838 - val_loss: 0.3062 - val_binary_accuracy: 0.9344\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0188 - binary_accuracy: 0.9964 - val_loss: 0.4116 - val_binary_accuracy: 0.8525\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0217 - binary_accuracy: 0.9946 - val_loss: 0.5176 - val_binary_accuracy: 0.8852\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0310 - binary_accuracy: 0.9928 - val_loss: 0.3491 - val_binary_accuracy: 0.9016\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 0s 366us/sample - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 0.3896 - val_binary_accuracy: 0.8852\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0099 - binary_accuracy: 0.9982 - val_loss: 0.3524 - val_binary_accuracy: 0.9016\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0317 - binary_accuracy: 0.9892 - val_loss: 0.3188 - val_binary_accuracy: 0.9180\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0407 - binary_accuracy: 0.9856 - val_loss: 0.4162 - val_binary_accuracy: 0.8852\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0636 - binary_accuracy: 0.9747 - val_loss: 0.2851 - val_binary_accuracy: 0.9016\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0467 - binary_accuracy: 0.9838 - val_loss: 0.5241 - val_binary_accuracy: 0.9016\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0180 - binary_accuracy: 0.9946 - val_loss: 0.3444 - val_binary_accuracy: 0.9344\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 0s 369us/sample - loss: 0.0300 - binary_accuracy: 0.9856 - val_loss: 0.4254 - val_binary_accuracy: 0.9016\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0930 - binary_accuracy: 0.9639 - val_loss: 0.3533 - val_binary_accuracy: 0.8852\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0339 - binary_accuracy: 0.9928 - val_loss: 0.5083 - val_binary_accuracy: 0.9016\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0305 - binary_accuracy: 0.9928 - val_loss: 0.5243 - val_binary_accuracy: 0.8361\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 0s 363us/sample - loss: 0.0094 - binary_accuracy: 0.9964 - val_loss: 0.4721 - val_binary_accuracy: 0.9016\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0296 - binary_accuracy: 0.9892 - val_loss: 0.6545 - val_binary_accuracy: 0.8361\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0457 - binary_accuracy: 0.9856 - val_loss: 0.6557 - val_binary_accuracy: 0.7869\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 0s 365us/sample - loss: 0.0690 - binary_accuracy: 0.9711 - val_loss: 0.4211 - val_binary_accuracy: 0.9016\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 0s 364us/sample - loss: 0.0390 - binary_accuracy: 0.9838 - val_loss: 0.3276 - val_binary_accuracy: 0.9016\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 0s 362us/sample - loss: 0.0353 - binary_accuracy: 0.9910 - val_loss: 0.3978 - val_binary_accuracy: 0.8361\n",
      "accuracy for model 10 is 83.60655903816223\n",
      "Training Testing Accuracy: 84.87% (4.32%)\n"
     ]
    }
   ],
   "source": [
    "best_DNN = eval_dnn(tt_vcf, tt_pheno, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout accuracy is 88.31169009208679\n"
     ]
    }
   ],
   "source": [
    "bs = ((ho_vcf.shape[0])/40)\n",
    "bs = round(bs)\n",
    "_, accuracy = best_DNN.evaluate(ho_vcf, ho_pheno, batch_size=bs, verbose=0)\n",
    "print(\"Holdout accuracy is \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = []\n",
    "results = []\n",
    "highest = 0\n",
    "i = 1\n",
    "while(i<6):\n",
    "    seed = randint(0,5000)\n",
    "    #divide up the training and testing data here\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tt_vcf, tt_pheno, test_size=0.2, random_state=seed)\n",
    "    #del my_list #to save memory\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "\n",
    "    #might need to reshape it??\n",
    "    #reshape into (examples, input snps, 1)\n",
    "    #A is x_train, B is x_test\n",
    "    # I think this is traditionally because CNNs are image data which use 3 dimensional input data?\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    model = build_DNN_model()\n",
    "    bs = ((X_train.shape[0])/20)\n",
    "    bs = round(bs)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=bs)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, batch_size=bs, verbose=0)\n",
    "    print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "    if(accuracy > highest):\n",
    "        highest = accuracy\n",
    "        best_model = model\n",
    "    results.append(accuracy)\n",
    "    i = i + 1\n",
    "print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results*100), np.std(results*100))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results)*100, np.std(results)*100)) \n",
    "bs = ((ho_vcf.shape[0])/20)\n",
    "bs = round(bs)\n",
    "_, accuracy = model.evaluate(ho_vcf, ho_pheno, batch_size=bs, verbose=0)\n",
    "print(\"Holdout accuracy is \" + str(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_DNN()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=my_DNN, epochs=50, batch_size=64, verbose=1)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, vcf, pheno, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
