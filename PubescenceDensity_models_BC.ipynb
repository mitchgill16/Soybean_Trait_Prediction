{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT STATEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.3)\n",
      "Requirement already satisfied: sklearn in ./.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: xgboost in ./.local/lib/python3.6/site-packages (1.3.1)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.6/site-packages (3.3.3)\n",
      "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0+nv)\n",
      "Requirement already satisfied: keras==2.2.4 in ./.local/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: fastai in ./.local/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (2.8.1)\n",
      "Requirement already satisfied: scikit-optimize in ./.local/lib/python3.6/site-packages (0.8.1)\n",
      "Requirement already satisfied: scikit-learn==0.21 in ./.local/lib/python3.6/site-packages (0.21.0)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.6/site-packages (0.16)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./.local/lib/python3.6/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.6/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.local/lib/python3.6/site-packages (from matplotlib) (8.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./.local/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.11.3)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in ./.local/lib/python3.6/site-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied: torch<1.8,>=1.7.0 in ./.local/lib/python3.6/site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: torchvision<0.9,>=0.8 in ./.local/lib/python3.6/site-packages (from fastai) (0.8.2)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastai) (20.0.2)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.8 in ./.local/lib/python3.6/site-packages (from fastai) (1.3.18)\n",
      "Requirement already satisfied: spacy in ./.local/lib/python3.6/site-packages (from fastai) (2.3.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.6/site-packages (from fastai) (20.8)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.6/site-packages (from scikit-optimize) (1.0.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in ./.local/lib/python3.6/site-packages (from scikit-optimize) (20.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (46.0.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.11.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in ./.local/lib/python3.6/site-packages (from torch<1.8,>=1.7.0->fastai) (0.8)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.6/site-packages (from torch<1.8,>=1.7.0->fastai) (3.7.4.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (4.43.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (0.8.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (0.7.4)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (7.4.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (2.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (3.0.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.11.28)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai) (1.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!TMPDIR=/home/mgill/ pip install --cache-dir=/home/mgill/ --build /home/mgill/ pandas numpy sklearn xgboost matplotlib tensorflow==2.1.0 keras==2.2.4 fastai python-dateutil scikit-optimize scikit-learn==0.21 graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from fastai.tabular.all import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Activation\n",
    "from math import sqrt\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt \n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import interp\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data, Prepare OHE, Prepare Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the 2 phenos in the files\n",
    "#only 3 samples, won't create an accurate model, so its better to treat it as a binary classification\n",
    "def del_2(vcf, pheno):\n",
    "    i = 0\n",
    "    rm_idx = []\n",
    "    print(pheno.shape)\n",
    "    print(vcf.shape)\n",
    "    while (i < pheno.shape[0]):\n",
    "        if (pheno[i] == 2.0):\n",
    "            print(\"found 2\")\n",
    "            rm_idx.append(i)\n",
    "        i = i + 1\n",
    "    pheno = np.delete(pheno, rm_idx, 0)\n",
    "    vcf = vcf.drop((vcf.index[rm_idx]))\n",
    "    print(pheno.shape)\n",
    "    print(vcf.shape)\n",
    "    return vcf, pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_prep_data(tt_file, ho_file):\n",
    "    imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "    my_list = []\n",
    "    x = 0 \n",
    "    for chunk in pd.read_csv(tt_file, chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "        x=x+10000\n",
    "        chunk = chunk.T\n",
    "        if 'Value' in chunk.columns:\n",
    "            #does the selecting of pheno array for application ML\n",
    "            chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "            tt_pheno = chunk[\"Value\"].to_numpy()\n",
    "            #reshapes it so its not a 1D array\n",
    "            print(tt_pheno.shape)\n",
    "            tt_pheno = np.reshape(tt_pheno,(len(tt_pheno),1))\n",
    "            print(tt_pheno.shape)\n",
    "            chunk = chunk.drop(columns=['Value'])\n",
    "        headers = chunk.columns\n",
    "        row_idx = chunk.index\n",
    "        chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "        #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "        chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "        my_list.append(chunk)\n",
    "        print(x)\n",
    "    tt_vcf = pd.concat(my_list, axis = 1)\n",
    "    my_list = []\n",
    "    x=0\n",
    "    for chunk in pd.read_csv(ho_file, chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "        x=x+10000\n",
    "        chunk = chunk.T\n",
    "        if 'Value' in chunk.columns:\n",
    "            #does the selecting of pheno array for application ML\n",
    "            chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "            ho_pheno = chunk[\"Value\"].to_numpy()\n",
    "            #reshapes it so its not a 1D array\n",
    "            print(ho_pheno.shape)\n",
    "            ho_pheno = np.reshape(ho_pheno,(len(ho_pheno),1))\n",
    "            print(ho_pheno.shape)\n",
    "            chunk = chunk.drop(columns=['Value'])\n",
    "        headers = chunk.columns\n",
    "        row_idx = chunk.index\n",
    "        chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "        #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "        chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "        my_list.append(chunk)\n",
    "        print(x)\n",
    "    ho_vcf = pd.concat(my_list, axis = 1)\n",
    "    tt_vcf,tt_pheno = del_2(tt_vcf, tt_pheno)\n",
    "    ho_vcf,ho_pheno = del_2(ho_vcf, ho_pheno)\n",
    "    print(tt_vcf.shape)\n",
    "    print(ho_vcf.shape)\n",
    "    print(tt_pheno.shape)\n",
    "    print(ho_pheno.shape)\n",
    "    return tt_vcf, ho_vcf, tt_pheno, ho_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data(\"PuD_Merged_filtered.csv_train_test.csv_5pcnt.csv\", \"PuD_Merged_filtered.csv_holdout.csv_5pcnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only if it hasn't been done yet otherweise skip to load\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "ohe = ohe.fit(tt_vcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ohe, open(\"PuD_ohe.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if need or have new holdout data etc.\n",
    "ohe = pickle.load(open(\"PuD_ohe.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_vcf.shape)\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_snp_from_header(ohe,snp_num):\n",
    "    count = 0\n",
    "    snp = \"Not found\"\n",
    "    found = False\n",
    "    i = 0\n",
    "    while i < len(ohe.categories_) and (found == False):\n",
    "        j = 0\n",
    "        while j < len(ohe.categories_[i]):\n",
    "            if(count == snp_num):\n",
    "                snp = ohe.categories_[i][j]\n",
    "                found = True\n",
    "                break\n",
    "            count = count + 1\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    return snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING IF IT WORKS\n",
    "my_snp = find_snp_from_header(ohe, 10805)\n",
    "print(my_snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the model building data, one hot encoding and creating a label set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for optimising the parameters, dont need to run if going straight to k-fold eval\n",
    "print(tt_vcf.shape)\n",
    "print(tt_pheno.shape)\n",
    "seed = randint(0,5000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tt_vcf, tt_pheno, test_size=0.2, random_state=seed)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(\"seed is \" + str(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Space to Optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space ={'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'max_depth': Integer(0, 50),\n",
    "        'max_delta_step': Integer(0, 20),\n",
    "        'subsample': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': Real(0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': Real(1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 5),\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'scale_pos_weight': Real(1e-6, 500, 'log-uniform')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stops the optimising if above 98% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    \"\"\"\n",
    "    Callback meant to view scores after\n",
    "    each iteration while performing Bayesian\n",
    "    Optimization in Skopt\"\"\"\n",
    "    score = xgb_bayes_search.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "    if score >= 0.98:\n",
    "        print('Interrupting!')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for optimium parameters from the defined space and print best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbcl = xgb.XGBClassifier()\n",
    "xgb_bayes_search = BayesSearchCV(xgbcl, space, n_iter=32, # specify how many iterations\n",
    "                                    scoring=None, n_jobs=1, cv=5, verbose=3, random_state=42, n_points=12,\n",
    "                                 refit=True)\n",
    "xgb_bayes_search.fit(X_train, y_train.ravel(), callback = on_step)\n",
    "print(xgb_bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Best Model from the Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#either print out from the optimisation or run the ordered dict.\n",
    "#print(xgb_bayes_search.best_params_)\n",
    "best_params = OrderedDict([('colsample_bylevel', 1.0), ('colsample_bytree', 1.0), ('gamma', 0.07059904760306446), ('learning_rate', 0.011073929920126888), ('max_delta_step', 20), ('max_depth', 29), ('min_child_weight', 4), ('n_estimators', 52), ('reg_alpha', 1e-09), ('reg_lambda', 1000.0), ('scale_pos_weight', 0.2860271078350677), ('subsample', 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(**xgb_bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.ravel(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this model to predict the test set and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "#sees how accurate the model was when testing the test set\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "pcent = accuracy * 100.0\n",
    "print(\"The accuracy of this model is\" + str(pcent))\n",
    "xgb_predictions = model.predict(X_test)\n",
    "xgb_probs = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Function to create ROC Score and AUROC Graph\n",
    "#from matplotlib.pyplot import figure\n",
    "#figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "def evaluate_model(predictions, probs, y_pheno):\n",
    "   #Computes statistics and shows ROC curve.\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['recall'] = recall_score(y_pheno, predictions)\n",
    "    results['precision'] = precision_score(y_pheno, predictions)\n",
    "    results['roc'] = roc_auc_score(y_pheno, probs)\n",
    "    my_roccy = (\"(ROC SCORE: %.2f)\" % (roc_auc_score(y_pheno, probs)))\n",
    "    \n",
    "    # Calculate false positive rates and true positive rates\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_pheno, probs)\n",
    "    return model_fpr, model_tpr, my_roccy\n",
    "\n",
    "    #plt.figure(figsize = (8, 6))\n",
    "   # plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Plot both curves\n",
    "   # plt.plot(model_fpr, model_tpr, 'r', label = 'Holdout Data'+my_roccy)\n",
    "   # plt.legend();\n",
    "   # plt.xlabel('False Positive Rate'); \n",
    "   # plt.ylabel('True Positive Rate'); plt.title('AUROC Curve for Xgboost Classification of Flower Colour');\n",
    "   # plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(xgb_predictions, xgb_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold cross validation on training / holdout data, evaluation and AUROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model from best parameters and then evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_k_fold(m, x, y, k, hx, hy):\n",
    "    #model: xgboost model, should be with the best params available\n",
    "    #x: input data (eg. all samples and SNPS)\n",
    "    #y: labels\n",
    "    #k: number of folds for cross validation\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    fig1 = plt.figure(figsize=[12,12])\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    results = []\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    high = 0\n",
    "    best = m\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        prediction = m.fit(x[train],y[train].ravel()).predict_proba(x[test])\n",
    "        print(\"variables for auroc curve done. Processing fold accuracy + checking best model\")\n",
    "        y_pred = m.predict(x[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        print(\"The accuracy of this model is\" + str(pcent))\n",
    "        if(pcent > high):\n",
    "            high = pcent\n",
    "            best = m\n",
    "        fpr, tpr, t = roc_curve(y[test], prediction[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        results.append(pcent)\n",
    "        plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        i= i+1\n",
    "\n",
    "    plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "    \n",
    "    holdout_pred = best.predict(hx)\n",
    "    predictions = [round(value) for value in holdout_pred]\n",
    "    #sees how accurate the model was when testing the test set\n",
    "    accuracy = accuracy_score(hy, predictions)\n",
    "    pcent = accuracy * 100.0\n",
    "    print(pcent)\n",
    "    xgb_predictions = best.predict(hx)\n",
    "    xgb_probs = best.predict_proba(hx)[:, 1]\n",
    "    model_fpr, model_tpr, my_roccy = evaluate_model(xgb_predictions, xgb_probs, hy)\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'Holdout Data'+my_roccy, lw=2)\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Pubescence Density Training Model & Holdout Data')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    print(\"Holdout Accuracy: %.2f%%\" % (pcent))\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#THESE ARE THE BEST PARAMETERS\n",
    "best_params = xgb_bayes_search.best_params_\n",
    "#best_params = OrderedDict([('colsample_bylevel', 1.0), ('colsample_bytree', 1.0), ('gamma', 0.07059904760306446), ('learning_rate', 0.011073929920126888), ('max_delta_step', 20), ('max_depth', 29), ('min_child_weight', 4), ('n_estimators', 52), ('reg_alpha', 1e-09), ('reg_lambda', 1000.0), ('scale_pos_weight', 0.2860271078350677), ('subsample', 1.0)])\n",
    "#load holdout data\n",
    "print(tt_vcf.shape)\n",
    "print(tt_pheno.shape)\n",
    "print(ho_vcf.shape)\n",
    "print(ho_pheno.shape)\n",
    "model_2 = xgb.XGBClassifier(**best_params) #if optimised in same session, other enter manually below\n",
    "#this function should average out 10 folds and training, with inital params optimised\n",
    "#average accuracy and std should be calculated along with a nice AUROC graph of train/test models\n",
    "#best model should be extracted for use on holdout set\n",
    "best_model = eval_k_fold(model_2, tt_vcf, tt_pheno, 10, ho_vcf, ho_pheno)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_model, open(\"PuD_kfold_10_XGB.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only load if not generated in same session\n",
    "best_model = pickle.load(open(\"PuD_kfold_10_XGB.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPS of Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "#best_model = pickle.load(open(\"FC_kfold_10_tt_from_all.pickle.dat\", \"rb\"))\n",
    "plt.figure(figsize = (20, 20))\n",
    "plot_importance(best_model, max_num_features=15, importance_type='gain', height=0.3)\n",
    "pyplot.show()\n",
    "\n",
    "##WTF???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function essentially returns an array of dataframe headers the length of OHE'd input SNPs for training data\n",
    "#EG. It will be able to determine that feature 357310 is Gm13_17683957 but not what allele it is\n",
    "#eg. feature 357309 357310 and 357311 may all be one hot encoded versions of all possible values of Gm13_17683957\n",
    "#iterating through the saved OHE will by able to determine what specific allele the feature is but cannot determine\n",
    "#what SNP header it belongs to. Therefore combining these two methods you can determine both allele and SNP\n",
    "snp = []\n",
    "imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "fs_ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "x = 0\n",
    "n_headers = []\n",
    "le = LabelEncoder()\n",
    "#while (i < 10):\n",
    "for chunk in pd.read_csv(\"PuD_Merged_filtered.csv_train_test.csv_5pcnt.csv\", chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "    chunk = chunk.T\n",
    "    if 'Value' in chunk.columns:\n",
    "        print(\"dropping value so it doesn't include that in headers\")\n",
    "        chunk = chunk.drop(columns=['Value'])\n",
    "    headers = chunk.columns\n",
    "    row_idx = chunk.index\n",
    "    chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "    #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "    chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "    chunk = chunk.apply(lambda col: le.fit_transform(col))\n",
    "    c_headers = chunk.columns\n",
    "    y = 0\n",
    "    for column in chunk:\n",
    "        d = (chunk[column].nunique())\n",
    "        n_headers.extend([c_headers[y] for i in range(d)])\n",
    "        #print(n_headers)\n",
    "        #print(l)\n",
    "        #n_headers.append(c_headers[y] * d)\n",
    "        #print(n_headers)\n",
    "        y = y + 1\n",
    "    #to double check that it would indeed be one hot encoded with this amount of columns\n",
    "    chunk = fs_ohe.fit_transform(chunk)\n",
    "    x = x + chunk.shape[1]\n",
    "    print(\"my X value is: \" + str(x))\n",
    "    print(chunk.shape)\n",
    "    print(\"my header list is: \" + str(len(n_headers)))\n",
    "print(len(n_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "fs = [343112]\n",
    "scores = [3.2]\n",
    "snp_label = []\n",
    "for jj in fs:\n",
    "    jj_allele = find_snp_from_header(ohe, jj)\n",
    "    this_snp = (n_headers[jj] + ' ('+str(jj_allele)+')')\n",
    "    print(this_snp)\n",
    "    snp_label.append(this_snp)\n",
    "snp_label.reverse()\n",
    "scores.reverse()\n",
    "print(len(scores))\n",
    "print(len(snp_label))\n",
    "plt.barh(snp_label,scores)\n",
    "plt.title('SNP Importance XGBoost Pubescence Density')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = best_model.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_f_header(fn,n_headers,ohe):\n",
    "    fn = fn[1:]\n",
    "    fn = int(fn)\n",
    "    allele = find_snp_from_header(ohe, fn)\n",
    "    this_snp = (n_headers[fn] + ' ('+str(allele)+')')\n",
    "    return this_snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert feature to actual SNP name\n",
    "i = 0\n",
    "new_dict = {}\n",
    "for key in my_dict:\n",
    "    new_key = rename_f_header(key, n_headers, ohe)\n",
    "    new_dict[new_key] = my_dict[key]\n",
    "    i = i + 1\n",
    "    print(str(i))\n",
    "    if(my_dict):\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fi = pd.Series(new_dict)\n",
    "print(new_fi)\n",
    "df = new_fi.to_frame()\n",
    "df = df.rename(columns = {0:'F_Score(GAIN)'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "indexes = df.nlargest(20, \"F_Score(GAIN)\").index\n",
    "values = df.nlargest(20, \"F_Score(GAIN)\").values.ravel()\n",
    "indexes = indexes[::-1]\n",
    "values = values[::-1]\n",
    "plt.barh(indexes, values)\n",
    "plt.title('SNP Importance XGBoost Pubescence Density')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate figure object\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "#load in the 20 lardest values and their SNP label\n",
    "indexes = df.nlargest(20, \"F_Score(GAIN)\").index\n",
    "values = df.nlargest(20, \"F_Score(GAIN)\").values.ravel()\n",
    "#reverse to make the largest be at the front\n",
    "indexes = indexes[::-1]\n",
    "values = values[::-1]\n",
    "#for each different chromosome you want to colour add a index(*_i) and value (*_v) array\n",
    "#black would be colour for singular/notinteresting chromosomes\n",
    "r_i = []\n",
    "r_v = []\n",
    "b_i = []\n",
    "b_v = []\n",
    "g_i = []\n",
    "g_v = []\n",
    "y_i = []\n",
    "y_v = []\n",
    "bl_i = []\n",
    "bl_v = []\n",
    "p_i = []\n",
    "p_v = []\n",
    "br_i = []\n",
    "br_v = []\n",
    "pu_i = []\n",
    "pu_v = []\n",
    "#for each value in the top n (default 20) check which chromosome it belongs to and add it to the colour array\n",
    "i = 0\n",
    "while i < len(indexes):\n",
    "    if('Gm08' in indexes[i]):\n",
    "        r_i.append(indexes[i])\n",
    "        r_v.append(values[i])\n",
    "    elif('Gm12' in indexes[i]):\n",
    "        b_i.append(indexes[i])\n",
    "        b_v.append(values[i])\n",
    "    elif('Gm01' in indexes[i]):\n",
    "        g_i.append(indexes[i])\n",
    "        g_v.append(values[i])\n",
    "    #elif('Gm11' in indexes[i]):\n",
    "    #    y_i.append(indexes[i])\n",
    "    #    y_v.append(values[i])\n",
    "    #elif('Gm08' in indexes[i]):\n",
    "    #    p_i.append(indexes[i])\n",
    "    #    p_v.append(values[i])\n",
    "   # elif('Gm04' in indexes[i]):\n",
    "   #     br_i.append(indexes[i])\n",
    "   #     br_v.append(values[i])\n",
    "   # elif('Gm13' in indexes[i]):\n",
    "   #     pu_i.append(indexes[i])\n",
    "   #     pu_v.append(values[i])\n",
    "    else:\n",
    "        bl_i.append(indexes[i])\n",
    "        bl_v.append(values[i])\n",
    "    i = i + 1\n",
    "#plot each of the arrays with appropriate colour and label graph\n",
    "plt.barh(bl_i, bl_v, color=\"black\")\n",
    "plt.barh(br_i, br_v, color=\"brown\")\n",
    "plt.barh(pu_i, pu_v, color=\"purple\")\n",
    "plt.barh(y_i, y_v, color=\"yellow\")\n",
    "plt.barh(p_i, p_v, color=\"orange\")\n",
    "plt.barh(g_i, g_v, color=\"green\")\n",
    "plt.barh(r_i, r_v, color=\"red\")\n",
    "plt.barh(b_i, b_v, color=\"blue\")\n",
    "plt.title('SNP Importance XGBoost Pubescence Density')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data('PuD_Merged_filtered.csv_train_test.csv_5pcnt.csv', 'PuD_Merged_filtered.csv_holdout.csv_5pcnt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pickle.load(open(\"PuD_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = randint(0,5000)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=seed, max_features = 'sqrt',n_jobs=-1, verbose = 1)\n",
    "best_rf_model = eval_k_fold(rf_model, tt_vcf, tt_pheno, 10, ho_vcf, ho_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_rf_model, open(\"PuD_kfold_10_RF.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(best_model.feature_importances_, index=n_headers)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model (based upon DL Primer)\n",
    "### one hot encode and train test split like you usually do but follow the primer for the actual model part\n",
    "### for BC and MC use primer, for regression use Philipps notebooks...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data('PuD_Merged_filtered.csv_train_test.csv_5pcnt.csv', 'PuD_Merged_filtered.csv_holdout.csv_5pcnt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pickle.load(open(\"PuD_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN_model(x_len):    \n",
    "    #del model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=14, \n",
    "                     input_shape=(x_len, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=10, kernel_size=10, \n",
    "                     input_shape=(12, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=8, kernel_size=8, \n",
    "                     input_shape=(10, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(48, activation='linear'))\n",
    "    model.add(Dense(32, activation='linear'))\n",
    "    model.add(Dense(16, activation='linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, \n",
    "                  metrics=['binary_accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cnn(x,y,k):\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    best_model = []\n",
    "    results = []\n",
    "    highest = 0\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "        model = build_CNN_model(x[train].shape[1])\n",
    "        bs = ((x[train].shape[0])/40)\n",
    "        bs = round(bs)\n",
    "        history = model.fit(x[train], y[train], validation_data=(x[test], y[test]), epochs=100, batch_size=bs)\n",
    "        _, accuracy = model.evaluate(x[test], y[test], batch_size=bs, verbose=0)\n",
    "        accuracy = accuracy *100\n",
    "        print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "        if(accuracy > highest):\n",
    "            highest = accuracy\n",
    "            best_model = model\n",
    "        results.append(accuracy)\n",
    "        del model\n",
    "        i = i + 1\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results))) \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_CNN = eval_cnn(tt_vcf, tt_pheno, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = ((ho_vcf.shape[0])/40)\n",
    "bs = round(bs)\n",
    "ho_vcf = ho_vcf.reshape(ho_vcf.shape[0], ho_vcf.shape[1],1)\n",
    "_, accuracy = best_CNN.evaluate(ho_vcf, ho_pheno, batch_size=bs, verbose=0)\n",
    "print(\"Holdout accuracy is \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_CNN, open(\"PuD_kfold_10_CNN.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "(617,)\n",
      "(617, 1)\n",
      "220000\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "(155,)\n",
      "(155, 1)\n",
      "220000\n",
      "(617, 1)\n",
      "(617, 214900)\n",
      "found 2\n",
      "found 2\n",
      "(615, 1)\n",
      "(615, 214900)\n",
      "(155, 1)\n",
      "(155, 214900)\n",
      "found 2\n",
      "(154, 1)\n",
      "(154, 214900)\n",
      "(615, 214900)\n",
      "(154, 214900)\n",
      "(615, 1)\n",
      "(154, 1)\n"
     ]
    }
   ],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data('PuD_Merged_filtered.csv_train_test.csv_5pcnt.csv', 'PuD_Merged_filtered.csv_holdout.csv_5pcnt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 623421)\n",
      "(154, 214900)\n",
      "(154, 623421)\n"
     ]
    }
   ],
   "source": [
    "ohe = pickle.load(open(\"PuD_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My own DNN model based upon paper\n",
    "#del model #incase its stored a previous model\n",
    "#del history #for redoing shit\n",
    "\n",
    "#do batch size as 64\n",
    "#reduce the inputs by half when you read it in\n",
    "#add XGboost and RF to the one notebook\n",
    "def build_DNN_model(x_len):\n",
    "    model = Sequential()\n",
    "\n",
    "    #add first input layer, with no normalization\n",
    "    model.add(Dense(256, input_dim = x_len))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.03))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.02))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    #add output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dnn(x,y,k): \n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    best_model = []\n",
    "    results = []\n",
    "    highest = 0\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        model = build_DNN_model(x[train].shape[1])\n",
    "        bs = ((x[train].shape[0])/40)\n",
    "        bs = round(bs)\n",
    "        history = model.fit(x[train], y[train], validation_data=(x[test], y[test]), epochs = 100, batch_size=bs)\n",
    "        _, accuracy = model.evaluate(x[test], y[test], batch_size=bs, verbose=0)\n",
    "        accuracy = accuracy * 100\n",
    "        print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "        if(accuracy > highest):\n",
    "            highest = accuracy\n",
    "            best_model = model\n",
    "        results.append(accuracy)\n",
    "        i = i + 1\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results))) \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 13s 24ms/sample - loss: 0.5884 - binary_accuracy: 0.7161 - val_loss: 0.5326 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.4455 - binary_accuracy: 0.8119 - val_loss: 0.5040 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.4013 - binary_accuracy: 0.8101 - val_loss: 0.4600 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.3377 - binary_accuracy: 0.8590 - val_loss: 0.3646 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2980 - binary_accuracy: 0.8788 - val_loss: 0.3263 - val_binary_accuracy: 0.8065\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2366 - binary_accuracy: 0.9168 - val_loss: 0.3088 - val_binary_accuracy: 0.8871\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1680 - binary_accuracy: 0.9476 - val_loss: 0.4365 - val_binary_accuracy: 0.8065\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1235 - binary_accuracy: 0.9602 - val_loss: 0.3936 - val_binary_accuracy: 0.8387\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1060 - binary_accuracy: 0.9656 - val_loss: 0.4043 - val_binary_accuracy: 0.8226\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0963 - binary_accuracy: 0.9693 - val_loss: 0.6534 - val_binary_accuracy: 0.8226\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0829 - binary_accuracy: 0.9729 - val_loss: 1.0381 - val_binary_accuracy: 0.8226\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0645 - binary_accuracy: 0.9783 - val_loss: 0.4924 - val_binary_accuracy: 0.8548\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0307 - binary_accuracy: 0.9946 - val_loss: 0.5697 - val_binary_accuracy: 0.8548\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0237 - binary_accuracy: 0.9946 - val_loss: 0.6871 - val_binary_accuracy: 0.7903\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0291 - binary_accuracy: 0.9910 - val_loss: 0.5367 - val_binary_accuracy: 0.8387\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0265 - binary_accuracy: 0.9910 - val_loss: 0.7043 - val_binary_accuracy: 0.8065\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0250 - binary_accuracy: 0.9946 - val_loss: 0.6027 - val_binary_accuracy: 0.8226\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0144 - binary_accuracy: 1.0000 - val_loss: 0.8414 - val_binary_accuracy: 0.8065\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0161 - binary_accuracy: 0.9982 - val_loss: 0.6438 - val_binary_accuracy: 0.8387\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0093 - binary_accuracy: 1.0000 - val_loss: 0.7221 - val_binary_accuracy: 0.8387\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0199 - binary_accuracy: 0.9928 - val_loss: 0.9558 - val_binary_accuracy: 0.7581\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0396 - binary_accuracy: 0.9873 - val_loss: 0.6174 - val_binary_accuracy: 0.8387\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0179 - binary_accuracy: 0.9964 - val_loss: 0.4969 - val_binary_accuracy: 0.8387\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0162 - binary_accuracy: 0.9982 - val_loss: 0.6461 - val_binary_accuracy: 0.8226\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0107 - binary_accuracy: 1.0000 - val_loss: 0.8418 - val_binary_accuracy: 0.8065\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0094 - binary_accuracy: 0.9964 - val_loss: 0.8841 - val_binary_accuracy: 0.8065\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0132 - binary_accuracy: 0.9946 - val_loss: 0.5463 - val_binary_accuracy: 0.8387\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0125 - binary_accuracy: 0.9964 - val_loss: 0.5990 - val_binary_accuracy: 0.8548\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0180 - binary_accuracy: 0.9946 - val_loss: 0.7400 - val_binary_accuracy: 0.8065\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0312 - binary_accuracy: 0.9873 - val_loss: 0.5261 - val_binary_accuracy: 0.8548\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0112 - binary_accuracy: 0.9982 - val_loss: 1.0343 - val_binary_accuracy: 0.8226\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0314 - binary_accuracy: 0.9855 - val_loss: 0.6927 - val_binary_accuracy: 0.8226\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0207 - binary_accuracy: 0.9946 - val_loss: 0.6266 - val_binary_accuracy: 0.8548\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0159 - binary_accuracy: 0.9946 - val_loss: 0.7888 - val_binary_accuracy: 0.8226\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0245 - binary_accuracy: 0.9928 - val_loss: 0.7120 - val_binary_accuracy: 0.8226\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0262 - binary_accuracy: 0.9910 - val_loss: 0.5408 - val_binary_accuracy: 0.8710\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0315 - binary_accuracy: 0.9892 - val_loss: 0.8086 - val_binary_accuracy: 0.8226\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0066 - binary_accuracy: 0.9982 - val_loss: 0.5484 - val_binary_accuracy: 0.8548\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0064 - binary_accuracy: 0.9982 - val_loss: 0.6051 - val_binary_accuracy: 0.8387\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.5553 - val_binary_accuracy: 0.8387\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 0.7185 - val_binary_accuracy: 0.8387\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 0.6682 - val_binary_accuracy: 0.8548\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0115 - binary_accuracy: 0.9964 - val_loss: 1.2995 - val_binary_accuracy: 0.8226\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0149 - binary_accuracy: 0.9964 - val_loss: 0.7385 - val_binary_accuracy: 0.8065\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0128 - binary_accuracy: 0.9982 - val_loss: 0.6610 - val_binary_accuracy: 0.8226\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0071 - binary_accuracy: 0.9964 - val_loss: 0.6327 - val_binary_accuracy: 0.8226\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0124 - binary_accuracy: 0.9946 - val_loss: 1.2105 - val_binary_accuracy: 0.7097\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0272 - binary_accuracy: 0.9910 - val_loss: 1.4923 - val_binary_accuracy: 0.6290\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0122 - binary_accuracy: 0.9928 - val_loss: 0.5542 - val_binary_accuracy: 0.8387\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0089 - binary_accuracy: 0.9982 - val_loss: 0.8888 - val_binary_accuracy: 0.8226\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0151 - binary_accuracy: 0.9964 - val_loss: 0.6093 - val_binary_accuracy: 0.8226\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0073 - binary_accuracy: 0.9982 - val_loss: 0.5272 - val_binary_accuracy: 0.8548\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0059 - binary_accuracy: 0.9982 - val_loss: 0.9146 - val_binary_accuracy: 0.8226\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 0.6789 - val_binary_accuracy: 0.8387\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 0.7965 - val_binary_accuracy: 0.8387\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0068 - binary_accuracy: 0.9982 - val_loss: 1.0575 - val_binary_accuracy: 0.8226\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0099 - binary_accuracy: 0.9964 - val_loss: 0.6489 - val_binary_accuracy: 0.8548\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0035 - binary_accuracy: 0.9982 - val_loss: 0.6635 - val_binary_accuracy: 0.8387\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 8.8368e-04 - binary_accuracy: 1.0000 - val_loss: 0.7484 - val_binary_accuracy: 0.8548\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0071 - binary_accuracy: 0.9982 - val_loss: 1.0155 - val_binary_accuracy: 0.8226\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0080 - binary_accuracy: 0.9982 - val_loss: 0.5217 - val_binary_accuracy: 0.8548\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 0.7535 - val_binary_accuracy: 0.8226\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 0.5292 - val_binary_accuracy: 0.8548\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0063 - binary_accuracy: 0.9982 - val_loss: 0.6729 - val_binary_accuracy: 0.8387\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 0.7313 - val_binary_accuracy: 0.8548\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 0.7859 - val_binary_accuracy: 0.8548\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 1.0109 - val_binary_accuracy: 0.8226\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 0.6833 - val_binary_accuracy: 0.8710\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 9.1004e-04 - binary_accuracy: 1.0000 - val_loss: 0.6807 - val_binary_accuracy: 0.8548\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0053 - binary_accuracy: 0.9982 - val_loss: 0.6663 - val_binary_accuracy: 0.8387\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0054 - binary_accuracy: 0.9982 - val_loss: 1.1514 - val_binary_accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0061 - binary_accuracy: 0.9982 - val_loss: 0.7285 - val_binary_accuracy: 0.8710\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 0.7237 - val_binary_accuracy: 0.8548\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 0.8413 - val_binary_accuracy: 0.8548\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 1.4509 - val_binary_accuracy: 0.8226\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 0.7208 - val_binary_accuracy: 0.8387\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 6.7472e-04 - binary_accuracy: 1.0000 - val_loss: 0.7361 - val_binary_accuracy: 0.8387\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.2985 - val_binary_accuracy: 0.8065\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 7.1646e-04 - binary_accuracy: 1.0000 - val_loss: 0.6903 - val_binary_accuracy: 0.8548\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 5.3047e-04 - binary_accuracy: 1.0000 - val_loss: 0.6968 - val_binary_accuracy: 0.8548\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0047 - binary_accuracy: 0.9964 - val_loss: 0.9396 - val_binary_accuracy: 0.8387\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.8387\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 1.3149 - val_binary_accuracy: 0.8226\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0109 - binary_accuracy: 0.9964 - val_loss: 0.6103 - val_binary_accuracy: 0.8548\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0168 - binary_accuracy: 0.9946 - val_loss: 1.3120 - val_binary_accuracy: 0.7097\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0066 - binary_accuracy: 0.9982 - val_loss: 0.9349 - val_binary_accuracy: 0.8065\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0255 - binary_accuracy: 0.9873 - val_loss: 0.7062 - val_binary_accuracy: 0.8387\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0067 - binary_accuracy: 0.9982 - val_loss: 1.2903 - val_binary_accuracy: 0.8226\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0058 - binary_accuracy: 0.9982 - val_loss: 1.6968 - val_binary_accuracy: 0.6774\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0054 - binary_accuracy: 0.9982 - val_loss: 1.2674 - val_binary_accuracy: 0.8065\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0096 - binary_accuracy: 0.9982 - val_loss: 0.6922 - val_binary_accuracy: 0.8548\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 1.0443 - val_binary_accuracy: 0.8065\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0212 - binary_accuracy: 0.9928 - val_loss: 1.2325 - val_binary_accuracy: 0.7581\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 0.8619 - val_binary_accuracy: 0.8387\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0032 - binary_accuracy: 1.0000 - val_loss: 1.4443 - val_binary_accuracy: 0.8226\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0137 - binary_accuracy: 0.9928 - val_loss: 1.3492 - val_binary_accuracy: 0.8065\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0072 - binary_accuracy: 0.9982 - val_loss: 0.7398 - val_binary_accuracy: 0.8065\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0076 - binary_accuracy: 0.9946 - val_loss: 0.8688 - val_binary_accuracy: 0.8226\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 0.8673 - val_binary_accuracy: 0.8226\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0085 - binary_accuracy: 0.9964 - val_loss: 0.7774 - val_binary_accuracy: 0.7903\n",
      "accuracy for model 1 is 79.03226017951965\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 10s 18ms/sample - loss: 0.5345 - binary_accuracy: 0.7559 - val_loss: 5.6693 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.4433 - binary_accuracy: 0.8119 - val_loss: 3.0899 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.3899 - binary_accuracy: 0.8192 - val_loss: 1.8079 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.3764 - binary_accuracy: 0.8246 - val_loss: 0.9221 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2882 - binary_accuracy: 0.8861 - val_loss: 0.3613 - val_binary_accuracy: 0.8387\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2380 - binary_accuracy: 0.9042 - val_loss: 0.2754 - val_binary_accuracy: 0.8226\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1676 - binary_accuracy: 0.9439 - val_loss: 0.7515 - val_binary_accuracy: 0.8226\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1366 - binary_accuracy: 0.9584 - val_loss: 0.4403 - val_binary_accuracy: 0.8387\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1126 - binary_accuracy: 0.9602 - val_loss: 0.2694 - val_binary_accuracy: 0.8226\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0879 - binary_accuracy: 0.9783 - val_loss: 0.4278 - val_binary_accuracy: 0.7903\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0670 - binary_accuracy: 0.9819 - val_loss: 0.6168 - val_binary_accuracy: 0.7742\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0792 - binary_accuracy: 0.9765 - val_loss: 0.3004 - val_binary_accuracy: 0.8387\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0524 - binary_accuracy: 0.9892 - val_loss: 0.4357 - val_binary_accuracy: 0.8226\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0694 - binary_accuracy: 0.9783 - val_loss: 0.4894 - val_binary_accuracy: 0.8710\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0365 - binary_accuracy: 0.9946 - val_loss: 0.3376 - val_binary_accuracy: 0.8387\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0288 - binary_accuracy: 0.9964 - val_loss: 0.3414 - val_binary_accuracy: 0.8871\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0283 - binary_accuracy: 0.9928 - val_loss: 0.2982 - val_binary_accuracy: 0.8710\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0447 - binary_accuracy: 0.9837 - val_loss: 0.3788 - val_binary_accuracy: 0.8387\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0336 - binary_accuracy: 0.9873 - val_loss: 0.4329 - val_binary_accuracy: 0.8710\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0221 - binary_accuracy: 0.9946 - val_loss: 0.5619 - val_binary_accuracy: 0.8387\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0402 - binary_accuracy: 0.9892 - val_loss: 0.6018 - val_binary_accuracy: 0.8710\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0249 - binary_accuracy: 0.9892 - val_loss: 1.1333 - val_binary_accuracy: 0.6129\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0303 - binary_accuracy: 0.9855 - val_loss: 0.7686 - val_binary_accuracy: 0.8226\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0214 - binary_accuracy: 0.9928 - val_loss: 0.4133 - val_binary_accuracy: 0.8065\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0157 - binary_accuracy: 0.9946 - val_loss: 0.4748 - val_binary_accuracy: 0.8871\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0181 - binary_accuracy: 0.9964 - val_loss: 0.5626 - val_binary_accuracy: 0.8387\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0146 - binary_accuracy: 0.9964 - val_loss: 0.4058 - val_binary_accuracy: 0.8871\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0131 - binary_accuracy: 0.9982 - val_loss: 0.4284 - val_binary_accuracy: 0.8387\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0172 - binary_accuracy: 0.9946 - val_loss: 0.5374 - val_binary_accuracy: 0.8548\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0133 - binary_accuracy: 0.9964 - val_loss: 0.5369 - val_binary_accuracy: 0.8710\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0168 - binary_accuracy: 0.9946 - val_loss: 0.9566 - val_binary_accuracy: 0.8226\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 0.5552 - val_binary_accuracy: 0.8871\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0108 - binary_accuracy: 0.9982 - val_loss: 0.7538 - val_binary_accuracy: 0.8387\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0126 - binary_accuracy: 0.9946 - val_loss: 0.5731 - val_binary_accuracy: 0.8387\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0089 - binary_accuracy: 0.9982 - val_loss: 0.5765 - val_binary_accuracy: 0.8871\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0158 - binary_accuracy: 0.9928 - val_loss: 0.5175 - val_binary_accuracy: 0.8548\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0102 - binary_accuracy: 0.9964 - val_loss: 0.5560 - val_binary_accuracy: 0.8387\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 0.6097 - val_binary_accuracy: 0.8871\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.5670 - val_binary_accuracy: 0.8387\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0061 - binary_accuracy: 0.9964 - val_loss: 0.6152 - val_binary_accuracy: 0.8871\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0241 - binary_accuracy: 0.9946 - val_loss: 0.8124 - val_binary_accuracy: 0.8226\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0095 - binary_accuracy: 0.9964 - val_loss: 0.9045 - val_binary_accuracy: 0.8387\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0152 - binary_accuracy: 0.9946 - val_loss: 1.2921 - val_binary_accuracy: 0.6774\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0126 - binary_accuracy: 0.9982 - val_loss: 0.5995 - val_binary_accuracy: 0.8226\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 0.7428 - val_binary_accuracy: 0.8065\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 0.6410 - val_binary_accuracy: 0.8387\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 1.3934 - val_binary_accuracy: 0.8065\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0352 - binary_accuracy: 0.9910 - val_loss: 1.6121 - val_binary_accuracy: 0.8226\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0179 - binary_accuracy: 0.9946 - val_loss: 0.6338 - val_binary_accuracy: 0.8065\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0095 - binary_accuracy: 0.9964 - val_loss: 0.5961 - val_binary_accuracy: 0.8226\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0057 - binary_accuracy: 1.0000 - val_loss: 0.5344 - val_binary_accuracy: 0.8387\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 0.5905 - val_binary_accuracy: 0.8387\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 0.6022 - val_binary_accuracy: 0.8548\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0081 - binary_accuracy: 0.9964 - val_loss: 0.5443 - val_binary_accuracy: 0.8387\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 0.6205 - val_binary_accuracy: 0.9032\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 0.5790 - val_binary_accuracy: 0.8871\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 0.5002 - val_binary_accuracy: 0.8387\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.5099 - val_binary_accuracy: 0.8387\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0052 - binary_accuracy: 0.9982 - val_loss: 0.5283 - val_binary_accuracy: 0.8387\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0038 - binary_accuracy: 0.9982 - val_loss: 0.6256 - val_binary_accuracy: 0.8387\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0065 - binary_accuracy: 0.9982 - val_loss: 0.8526 - val_binary_accuracy: 0.8387\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0088 - binary_accuracy: 0.9982 - val_loss: 0.6403 - val_binary_accuracy: 0.8548\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0083 - binary_accuracy: 0.9982 - val_loss: 0.6628 - val_binary_accuracy: 0.8710\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 0.8919 - val_binary_accuracy: 0.8387\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9964 - val_loss: 0.6809 - val_binary_accuracy: 0.8871\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0220 - binary_accuracy: 0.9928 - val_loss: 0.5199 - val_binary_accuracy: 0.8871\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0242 - binary_accuracy: 0.9910 - val_loss: 0.6927 - val_binary_accuracy: 0.8387\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0203 - binary_accuracy: 0.9910 - val_loss: 0.5745 - val_binary_accuracy: 0.8710\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0247 - binary_accuracy: 0.9892 - val_loss: 0.5245 - val_binary_accuracy: 0.8548\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0201 - binary_accuracy: 0.9910 - val_loss: 1.2175 - val_binary_accuracy: 0.7419\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0148 - binary_accuracy: 0.9946 - val_loss: 0.7451 - val_binary_accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0052 - binary_accuracy: 0.9982 - val_loss: 0.6801 - val_binary_accuracy: 0.9032\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0242 - binary_accuracy: 0.9946 - val_loss: 0.8021 - val_binary_accuracy: 0.8710\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0078 - binary_accuracy: 0.9982 - val_loss: 0.6501 - val_binary_accuracy: 0.8387\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0150 - binary_accuracy: 0.9928 - val_loss: 0.9472 - val_binary_accuracy: 0.8226\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 0.6806 - val_binary_accuracy: 0.8387\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 0.8176 - val_binary_accuracy: 0.8387\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0035 - binary_accuracy: 0.9982 - val_loss: 0.6880 - val_binary_accuracy: 0.8387\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0057 - binary_accuracy: 0.9982 - val_loss: 1.4669 - val_binary_accuracy: 0.8387\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0047 - binary_accuracy: 0.9982 - val_loss: 0.6815 - val_binary_accuracy: 0.8387\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0059 - binary_accuracy: 0.9964 - val_loss: 1.0583 - val_binary_accuracy: 0.8226\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0188 - binary_accuracy: 0.9964 - val_loss: 0.9845 - val_binary_accuracy: 0.7903\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 0.7808 - val_binary_accuracy: 0.8387\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 1.0948 - val_binary_accuracy: 0.8387\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.6305 - val_binary_accuracy: 0.8387\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0103 - binary_accuracy: 0.9964 - val_loss: 1.8036 - val_binary_accuracy: 0.8226\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0257 - binary_accuracy: 0.9928 - val_loss: 0.9218 - val_binary_accuracy: 0.8387\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0107 - binary_accuracy: 0.9946 - val_loss: 0.7154 - val_binary_accuracy: 0.8548\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0074 - binary_accuracy: 0.9964 - val_loss: 0.5569 - val_binary_accuracy: 0.8710\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0114 - binary_accuracy: 0.9964 - val_loss: 1.3908 - val_binary_accuracy: 0.8226\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0034 - binary_accuracy: 0.9982 - val_loss: 0.6337 - val_binary_accuracy: 0.8548\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 0.6140 - val_binary_accuracy: 0.8387\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0114 - binary_accuracy: 0.9946 - val_loss: 0.8730 - val_binary_accuracy: 0.8548\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 0.8706 - val_binary_accuracy: 0.8710\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 4.3492e-04 - binary_accuracy: 1.0000 - val_loss: 0.8129 - val_binary_accuracy: 0.8548\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0053 - binary_accuracy: 0.9982 - val_loss: 0.7461 - val_binary_accuracy: 0.8387\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0052 - binary_accuracy: 0.9982 - val_loss: 0.7676 - val_binary_accuracy: 0.8871\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0062 - binary_accuracy: 0.9982 - val_loss: 0.8615 - val_binary_accuracy: 0.8387\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 0.7253 - val_binary_accuracy: 0.8387- loss: 0.0020 - binary_accuracy\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 0.6198 - val_binary_accuracy: 0.8387\n",
      "accuracy for model 2 is 83.87096524238586\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 14s 26ms/sample - loss: 0.6063 - binary_accuracy: 0.7197 - val_loss: 1.4803 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.4577 - binary_accuracy: 0.8192 - val_loss: 1.2749 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.4085 - binary_accuracy: 0.8210 - val_loss: 0.6302 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.3461 - binary_accuracy: 0.8210 - val_loss: 0.8289 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2966 - binary_accuracy: 0.8608 - val_loss: 0.2430 - val_binary_accuracy: 0.8226\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2546 - binary_accuracy: 0.8915 - val_loss: 0.1464 - val_binary_accuracy: 0.9355\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2041 - binary_accuracy: 0.9204 - val_loss: 0.4848 - val_binary_accuracy: 0.8387\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1494 - binary_accuracy: 0.9476 - val_loss: 0.2089 - val_binary_accuracy: 0.8871\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1410 - binary_accuracy: 0.9512 - val_loss: 0.2079 - val_binary_accuracy: 0.9032\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0928 - binary_accuracy: 0.9675 - val_loss: 0.5488 - val_binary_accuracy: 0.8548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0828 - binary_accuracy: 0.9747 - val_loss: 0.4282 - val_binary_accuracy: 0.8871\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0828 - binary_accuracy: 0.9693 - val_loss: 0.2839 - val_binary_accuracy: 0.9032\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0515 - binary_accuracy: 0.9855 - val_loss: 0.4785 - val_binary_accuracy: 0.8871\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0533 - binary_accuracy: 0.9801 - val_loss: 0.4707 - val_binary_accuracy: 0.8548\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0575 - binary_accuracy: 0.9783 - val_loss: 0.3133 - val_binary_accuracy: 0.9032\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0471 - binary_accuracy: 0.9855 - val_loss: 0.2404 - val_binary_accuracy: 0.8871\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0417 - binary_accuracy: 0.9855 - val_loss: 0.2769 - val_binary_accuracy: 0.9032\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0374 - binary_accuracy: 0.9892 - val_loss: 0.2516 - val_binary_accuracy: 0.9194\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0245 - binary_accuracy: 0.9964 - val_loss: 0.7265 - val_binary_accuracy: 0.9032\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0312 - binary_accuracy: 0.9873 - val_loss: 0.4150 - val_binary_accuracy: 0.9032\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0393 - binary_accuracy: 0.9892 - val_loss: 0.3276 - val_binary_accuracy: 0.8871\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0171 - binary_accuracy: 0.9964 - val_loss: 0.5609 - val_binary_accuracy: 0.9032\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0189 - binary_accuracy: 0.9946 - val_loss: 0.6296 - val_binary_accuracy: 0.9032\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0283 - binary_accuracy: 0.9928 - val_loss: 0.3455 - val_binary_accuracy: 0.9032\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0147 - binary_accuracy: 0.9964 - val_loss: 0.2900 - val_binary_accuracy: 0.9516\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0277 - binary_accuracy: 0.9910 - val_loss: 0.3111 - val_binary_accuracy: 0.9355\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0157 - binary_accuracy: 0.9964 - val_loss: 0.5902 - val_binary_accuracy: 0.9032\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0099 - binary_accuracy: 0.9964 - val_loss: 0.8046 - val_binary_accuracy: 0.8871\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0083 - binary_accuracy: 0.9982 - val_loss: 0.6234 - val_binary_accuracy: 0.9032\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 0.5032 - val_binary_accuracy: 0.9032\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0283 - binary_accuracy: 0.9892 - val_loss: 0.7631 - val_binary_accuracy: 0.8548\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0415 - binary_accuracy: 0.9783 - val_loss: 0.4168 - val_binary_accuracy: 0.9032\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0228 - binary_accuracy: 0.9892 - val_loss: 0.5592 - val_binary_accuracy: 0.8871\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0424 - binary_accuracy: 0.9873 - val_loss: 0.7099 - val_binary_accuracy: 0.8871\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0288 - binary_accuracy: 0.9928 - val_loss: 0.3459 - val_binary_accuracy: 0.8871\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0302 - binary_accuracy: 0.9892 - val_loss: 0.3453 - val_binary_accuracy: 0.9194\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0353 - binary_accuracy: 0.9873 - val_loss: 0.3829 - val_binary_accuracy: 0.9194\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0313 - binary_accuracy: 0.9910 - val_loss: 0.4930 - val_binary_accuracy: 0.9032\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0109 - binary_accuracy: 0.9982 - val_loss: 1.1115 - val_binary_accuracy: 0.8387\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0092 - binary_accuracy: 0.9982 - val_loss: 0.9246 - val_binary_accuracy: 0.8871\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0057 - binary_accuracy: 0.9982 - val_loss: 0.6979 - val_binary_accuracy: 0.9032\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0083 - binary_accuracy: 0.9982 - val_loss: 0.4492 - val_binary_accuracy: 0.9194\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0120 - binary_accuracy: 0.9982 - val_loss: 0.5030 - val_binary_accuracy: 0.9032\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 0.5070 - val_binary_accuracy: 0.9032\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0198 - binary_accuracy: 0.9873 - val_loss: 0.3123 - val_binary_accuracy: 0.9194\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0073 - binary_accuracy: 1.0000 - val_loss: 0.2827 - val_binary_accuracy: 0.9032\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0185 - binary_accuracy: 0.9946 - val_loss: 0.6450 - val_binary_accuracy: 0.9032\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0167 - binary_accuracy: 0.9928 - val_loss: 0.7345 - val_binary_accuracy: 0.9032\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0137 - binary_accuracy: 0.9946 - val_loss: 0.4553 - val_binary_accuracy: 0.9032\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 0.8069 - val_binary_accuracy: 0.8871\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0105 - binary_accuracy: 0.9964 - val_loss: 0.6812 - val_binary_accuracy: 0.9032\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0093 - binary_accuracy: 0.9964 - val_loss: 0.5092 - val_binary_accuracy: 0.8871\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0026 - binary_accuracy: 0.9982 - val_loss: 0.6600 - val_binary_accuracy: 0.9032\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0243 - binary_accuracy: 0.9928 - val_loss: 0.4557 - val_binary_accuracy: 0.9032\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0047 - binary_accuracy: 0.9982 - val_loss: 0.4629 - val_binary_accuracy: 0.9032\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0045 - binary_accuracy: 0.9982 - val_loss: 0.6299 - val_binary_accuracy: 0.9032\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 6.3338e-04 - binary_accuracy: 1.0000 - val_loss: 0.5261 - val_binary_accuracy: 0.9032\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 0.9056 - val_binary_accuracy: 0.8871\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 0.7214 - val_binary_accuracy: 0.9032\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 0.6776 - val_binary_accuracy: 0.9032\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 8.2903e-04 - binary_accuracy: 1.0000 - val_loss: 0.5841 - val_binary_accuracy: 0.9032\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0038 - binary_accuracy: 0.9982 - val_loss: 0.6792 - val_binary_accuracy: 0.9032\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0173 - binary_accuracy: 0.9910 - val_loss: 0.5752 - val_binary_accuracy: 0.9032\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0280 - binary_accuracy: 0.9892 - val_loss: 0.3651 - val_binary_accuracy: 0.9194\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0140 - binary_accuracy: 0.9946 - val_loss: 0.5840 - val_binary_accuracy: 0.9194\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0254 - binary_accuracy: 0.9892 - val_loss: 0.3889 - val_binary_accuracy: 0.8871\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0103 - binary_accuracy: 0.9946 - val_loss: 1.0905 - val_binary_accuracy: 0.8226\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0171 - binary_accuracy: 0.9946 - val_loss: 0.5248 - val_binary_accuracy: 0.9194\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 0.9982 - val_loss: 0.6331 - val_binary_accuracy: 0.9032\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 0.5795 - val_binary_accuracy: 0.9032\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 0.7149 - val_binary_accuracy: 0.9032\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0123 - binary_accuracy: 0.9964 - val_loss: 1.6521 - val_binary_accuracy: 0.8226\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0511 - binary_accuracy: 0.9765 - val_loss: 0.9488 - val_binary_accuracy: 0.8065\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0202 - binary_accuracy: 0.9946 - val_loss: 0.3786 - val_binary_accuracy: 0.9194\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0179 - binary_accuracy: 0.9964 - val_loss: 0.9008 - val_binary_accuracy: 0.9032\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0071 - binary_accuracy: 0.9982 - val_loss: 0.6501 - val_binary_accuracy: 0.9032\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0127 - binary_accuracy: 0.9964 - val_loss: 0.6725 - val_binary_accuracy: 0.9032\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0140 - binary_accuracy: 0.9928 - val_loss: 0.8847 - val_binary_accuracy: 0.8871\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0060 - binary_accuracy: 0.9982 - val_loss: 0.8635 - val_binary_accuracy: 0.8871\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0094 - binary_accuracy: 0.9946 - val_loss: 0.8875 - val_binary_accuracy: 0.8871\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0065 - binary_accuracy: 0.9982 - val_loss: 1.0329 - val_binary_accuracy: 0.8871\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0147 - binary_accuracy: 0.9928 - val_loss: 0.6176 - val_binary_accuracy: 0.8871\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0087 - binary_accuracy: 0.9946 - val_loss: 0.4420 - val_binary_accuracy: 0.8871\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0066 - binary_accuracy: 0.9964 - val_loss: 0.6666 - val_binary_accuracy: 0.8871\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0049 - binary_accuracy: 0.9982 - val_loss: 0.8556 - val_binary_accuracy: 0.9032\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0127 - binary_accuracy: 0.9964 - val_loss: 0.4821 - val_binary_accuracy: 0.8871\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0025 - binary_accuracy: 0.9982 - val_loss: 0.6124 - val_binary_accuracy: 0.9032\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0090 - binary_accuracy: 0.9964 - val_loss: 0.4662 - val_binary_accuracy: 0.8871\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 0.5400 - val_binary_accuracy: 0.8710\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 0.8304 - val_binary_accuracy: 0.9032\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 0.6880 - val_binary_accuracy: 0.8871\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0116 - binary_accuracy: 0.9964 - val_loss: 0.7023 - val_binary_accuracy: 0.8871\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0330 - binary_accuracy: 0.9892 - val_loss: 0.8780 - val_binary_accuracy: 0.9032\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0114 - binary_accuracy: 0.9964 - val_loss: 1.0663 - val_binary_accuracy: 0.8226\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0066 - binary_accuracy: 0.9964 - val_loss: 1.0591 - val_binary_accuracy: 0.8226\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0082 - binary_accuracy: 0.9982 - val_loss: 0.5296 - val_binary_accuracy: 0.8871\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 0.9982 - val_loss: 0.4392 - val_binary_accuracy: 0.9355\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0048 - binary_accuracy: 0.9982 - val_loss: 0.7760 - val_binary_accuracy: 0.9032\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0057 - binary_accuracy: 0.9982 - val_loss: 0.4815 - val_binary_accuracy: 0.9194\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0076 - binary_accuracy: 0.9964 - val_loss: 0.9449 - val_binary_accuracy: 0.8871\n",
      "accuracy for model 3 is 88.70967626571655\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 11s 20ms/sample - loss: 0.5670 - binary_accuracy: 0.7450 - val_loss: 4.2030 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.4504 - binary_accuracy: 0.8228 - val_loss: 2.1450 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.3811 - binary_accuracy: 0.8354 - val_loss: 1.7305 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.3350 - binary_accuracy: 0.8481 - val_loss: 1.8051 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2884 - binary_accuracy: 0.8788 - val_loss: 0.7589 - val_binary_accuracy: 0.8226\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2189 - binary_accuracy: 0.9096 - val_loss: 0.4955 - val_binary_accuracy: 0.8226\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1831 - binary_accuracy: 0.9349 - val_loss: 0.4668 - val_binary_accuracy: 0.8226\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1140 - binary_accuracy: 0.9729 - val_loss: 0.4494 - val_binary_accuracy: 0.8548\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1031 - binary_accuracy: 0.9747 - val_loss: 0.3607 - val_binary_accuracy: 0.8548\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0611 - binary_accuracy: 0.9801 - val_loss: 0.4903 - val_binary_accuracy: 0.7419\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0647 - binary_accuracy: 0.9837 - val_loss: 0.3854 - val_binary_accuracy: 0.8387\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0619 - binary_accuracy: 0.9855 - val_loss: 0.3851 - val_binary_accuracy: 0.8710\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0436 - binary_accuracy: 0.9910 - val_loss: 0.4602 - val_binary_accuracy: 0.8065\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0358 - binary_accuracy: 0.9910 - val_loss: 0.6280 - val_binary_accuracy: 0.8387\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0431 - binary_accuracy: 0.9873 - val_loss: 0.5944 - val_binary_accuracy: 0.7742\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0359 - binary_accuracy: 0.9928 - val_loss: 0.4037 - val_binary_accuracy: 0.8871\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0238 - binary_accuracy: 0.9964 - val_loss: 0.6690 - val_binary_accuracy: 0.8387\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0558 - binary_accuracy: 0.9765 - val_loss: 0.8432 - val_binary_accuracy: 0.8226\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0323 - binary_accuracy: 0.9928 - val_loss: 0.5769 - val_binary_accuracy: 0.8710\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0331 - binary_accuracy: 0.9928 - val_loss: 0.4647 - val_binary_accuracy: 0.8710\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0442 - binary_accuracy: 0.9837 - val_loss: 0.8546 - val_binary_accuracy: 0.8387\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0291 - binary_accuracy: 0.9910 - val_loss: 0.6804 - val_binary_accuracy: 0.8548\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0133 - binary_accuracy: 0.9964 - val_loss: 0.5831 - val_binary_accuracy: 0.8548\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0172 - binary_accuracy: 0.9946 - val_loss: 0.5456 - val_binary_accuracy: 0.8710\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0309 - binary_accuracy: 0.9910 - val_loss: 0.5314 - val_binary_accuracy: 0.8387\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0339 - binary_accuracy: 0.9910 - val_loss: 0.9887 - val_binary_accuracy: 0.8226\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0109 - binary_accuracy: 0.9982 - val_loss: 0.6255 - val_binary_accuracy: 0.8710\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0203 - binary_accuracy: 0.9928 - val_loss: 0.6897 - val_binary_accuracy: 0.8226\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0164 - binary_accuracy: 0.9946 - val_loss: 1.0837 - val_binary_accuracy: 0.8226\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0161 - binary_accuracy: 0.9946 - val_loss: 0.7696 - val_binary_accuracy: 0.8387\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0233 - binary_accuracy: 0.9946 - val_loss: 1.2130 - val_binary_accuracy: 0.8226\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0132 - binary_accuracy: 0.9964 - val_loss: 0.7754 - val_binary_accuracy: 0.8548\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0169 - binary_accuracy: 0.9946 - val_loss: 0.6939 - val_binary_accuracy: 0.8065\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0266 - binary_accuracy: 0.9873 - val_loss: 1.0822 - val_binary_accuracy: 0.8226\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0240 - binary_accuracy: 0.9946 - val_loss: 1.1994 - val_binary_accuracy: 0.8226\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0131 - binary_accuracy: 0.9964 - val_loss: 0.5892 - val_binary_accuracy: 0.8548\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0186 - binary_accuracy: 0.9946 - val_loss: 0.6212 - val_binary_accuracy: 0.8548\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0339 - binary_accuracy: 0.9873 - val_loss: 1.4634 - val_binary_accuracy: 0.8226\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0239 - binary_accuracy: 0.9910 - val_loss: 0.7680 - val_binary_accuracy: 0.8548\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0187 - binary_accuracy: 0.9964 - val_loss: 0.6190 - val_binary_accuracy: 0.8548\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0132 - binary_accuracy: 0.9964 - val_loss: 0.7841 - val_binary_accuracy: 0.7258\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0104 - binary_accuracy: 0.9982 - val_loss: 0.6297 - val_binary_accuracy: 0.8226\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0086 - binary_accuracy: 0.9982 - val_loss: 0.6018 - val_binary_accuracy: 0.8387\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0262 - binary_accuracy: 0.9910 - val_loss: 0.7131 - val_binary_accuracy: 0.8387\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0077 - binary_accuracy: 0.9982 - val_loss: 0.9619 - val_binary_accuracy: 0.8387\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 0.8379 - val_binary_accuracy: 0.8548\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0127 - binary_accuracy: 0.9946 - val_loss: 0.6436 - val_binary_accuracy: 0.8548\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0175 - binary_accuracy: 0.9946 - val_loss: 0.7575 - val_binary_accuracy: 0.8548\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.6601 - val_binary_accuracy: 0.8548\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0096 - binary_accuracy: 0.9982 - val_loss: 0.9726 - val_binary_accuracy: 0.8387\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0137 - binary_accuracy: 0.9928 - val_loss: 0.8739 - val_binary_accuracy: 0.8710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0202 - binary_accuracy: 0.9928 - val_loss: 0.7807 - val_binary_accuracy: 0.8548\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0191 - binary_accuracy: 0.9946 - val_loss: 0.8928 - val_binary_accuracy: 0.8226\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0183 - binary_accuracy: 0.9946 - val_loss: 1.4420 - val_binary_accuracy: 0.8226\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0137 - binary_accuracy: 0.9928 - val_loss: 0.6157 - val_binary_accuracy: 0.8871\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0069 - binary_accuracy: 0.9982 - val_loss: 0.8059 - val_binary_accuracy: 0.8548\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 0.9310 - val_binary_accuracy: 0.8387\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0176 - binary_accuracy: 0.9946 - val_loss: 1.3753 - val_binary_accuracy: 0.8226\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0100 - binary_accuracy: 0.9964 - val_loss: 1.5697 - val_binary_accuracy: 0.6129\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0138 - binary_accuracy: 0.9964 - val_loss: 0.6518 - val_binary_accuracy: 0.8548\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.6595 - val_binary_accuracy: 0.8387\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0095 - binary_accuracy: 0.9964 - val_loss: 1.7832 - val_binary_accuracy: 0.8226\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0224 - binary_accuracy: 0.9892 - val_loss: 0.9531 - val_binary_accuracy: 0.8226\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0197 - binary_accuracy: 0.9910 - val_loss: 0.7098 - val_binary_accuracy: 0.7742\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0105 - binary_accuracy: 0.9946 - val_loss: 0.9972 - val_binary_accuracy: 0.8548\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0127 - binary_accuracy: 0.9964 - val_loss: 0.8820 - val_binary_accuracy: 0.6774\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0112 - binary_accuracy: 0.9982 - val_loss: 1.6068 - val_binary_accuracy: 0.8226\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0071 - binary_accuracy: 1.0000 - val_loss: 0.9142 - val_binary_accuracy: 0.8548\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 1.1379 - val_binary_accuracy: 0.8548\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0064 - binary_accuracy: 0.9964 - val_loss: 1.7432 - val_binary_accuracy: 0.8226\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0208 - binary_accuracy: 0.9910 - val_loss: 0.8187 - val_binary_accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0120 - binary_accuracy: 0.9964 - val_loss: 1.3739 - val_binary_accuracy: 0.8065\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0169 - binary_accuracy: 0.9946 - val_loss: 1.2827 - val_binary_accuracy: 0.8226\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0077 - binary_accuracy: 0.9964 - val_loss: 0.6154 - val_binary_accuracy: 0.8710\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 1.0875 - val_binary_accuracy: 0.8710\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0049 - binary_accuracy: 0.9964 - val_loss: 0.9917 - val_binary_accuracy: 0.8710\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0169 - binary_accuracy: 0.9964 - val_loss: 0.8006 - val_binary_accuracy: 0.8548\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0181 - binary_accuracy: 0.9964 - val_loss: 0.5342 - val_binary_accuracy: 0.8710\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 0.6153 - val_binary_accuracy: 0.8710\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0108 - binary_accuracy: 0.9964 - val_loss: 1.2103 - val_binary_accuracy: 0.8548\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0066 - binary_accuracy: 0.9982 - val_loss: 0.8878 - val_binary_accuracy: 0.7581\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0071 - binary_accuracy: 0.9946 - val_loss: 0.9280 - val_binary_accuracy: 0.8548\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0194 - binary_accuracy: 0.9928 - val_loss: 0.9768 - val_binary_accuracy: 0.7097\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0070 - binary_accuracy: 0.9964 - val_loss: 1.0577 - val_binary_accuracy: 0.8710\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0237 - binary_accuracy: 0.9910 - val_loss: 1.0387 - val_binary_accuracy: 0.8548\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0082 - binary_accuracy: 0.9982 - val_loss: 0.7978 - val_binary_accuracy: 0.8548\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0127 - binary_accuracy: 0.9946 - val_loss: 0.8038 - val_binary_accuracy: 0.8548\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0034 - binary_accuracy: 0.9982 - val_loss: 0.8599 - val_binary_accuracy: 0.8548\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0126 - binary_accuracy: 0.9964 - val_loss: 0.6812 - val_binary_accuracy: 0.8548\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0084 - binary_accuracy: 0.9964 - val_loss: 0.6892 - val_binary_accuracy: 0.8387\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0093 - binary_accuracy: 0.9982 - val_loss: 0.6923 - val_binary_accuracy: 0.8710\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0232 - binary_accuracy: 0.9946 - val_loss: 0.7266 - val_binary_accuracy: 0.8548\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0033 - binary_accuracy: 0.9982 - val_loss: 0.7307 - val_binary_accuracy: 0.8548\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 0.9982 - val_loss: 0.9693 - val_binary_accuracy: 0.8871\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 0.8473 - val_binary_accuracy: 0.8710\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 0.9522 - val_binary_accuracy: 0.8710\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0126 - binary_accuracy: 0.9928 - val_loss: 0.7013 - val_binary_accuracy: 0.8871\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 1.1343 - val_binary_accuracy: 0.8548\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 0.8876 - val_binary_accuracy: 0.8710\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0037 - binary_accuracy: 0.9982 - val_loss: 0.7162 - val_binary_accuracy: 0.8871\n",
      "accuracy for model 4 is 88.70967626571655\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 553 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 11s 20ms/sample - loss: 0.5363 - binary_accuracy: 0.7722 - val_loss: 2.0834 - val_binary_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.4539 - binary_accuracy: 0.8156 - val_loss: 1.0053 - val_binary_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.3873 - binary_accuracy: 0.8246 - val_loss: 0.6888 - val_binary_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.3363 - binary_accuracy: 0.8553 - val_loss: 1.3139 - val_binary_accuracy: 0.8226\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2831 - binary_accuracy: 0.8897 - val_loss: 0.6586 - val_binary_accuracy: 0.8226\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.2196 - binary_accuracy: 0.9259 - val_loss: 0.6753 - val_binary_accuracy: 0.7742\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1715 - binary_accuracy: 0.9476 - val_loss: 0.9113 - val_binary_accuracy: 0.5161\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.1224 - binary_accuracy: 0.9729 - val_loss: 1.0541 - val_binary_accuracy: 0.3548\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0947 - binary_accuracy: 0.9693 - val_loss: 0.7870 - val_binary_accuracy: 0.7903\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0605 - binary_accuracy: 0.9873 - val_loss: 1.0582 - val_binary_accuracy: 0.8226\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0516 - binary_accuracy: 0.9892 - val_loss: 0.9066 - val_binary_accuracy: 0.6935\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0415 - binary_accuracy: 0.9892 - val_loss: 0.9083 - val_binary_accuracy: 0.7742\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0350 - binary_accuracy: 0.9928 - val_loss: 1.1393 - val_binary_accuracy: 0.8226\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0299 - binary_accuracy: 0.9910 - val_loss: 0.9439 - val_binary_accuracy: 0.7581\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0221 - binary_accuracy: 0.9928 - val_loss: 1.0175 - val_binary_accuracy: 0.7903\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0334 - binary_accuracy: 0.9837 - val_loss: 0.8012 - val_binary_accuracy: 0.7258\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0359 - binary_accuracy: 0.9892 - val_loss: 1.0380 - val_binary_accuracy: 0.6452\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0325 - binary_accuracy: 0.9892 - val_loss: 1.5718 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0358 - binary_accuracy: 0.9837 - val_loss: 0.8613 - val_binary_accuracy: 0.7581\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0179 - binary_accuracy: 0.9964 - val_loss: 0.9192 - val_binary_accuracy: 0.7581\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0163 - binary_accuracy: 0.9964 - val_loss: 1.0234 - val_binary_accuracy: 0.7581\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0155 - binary_accuracy: 0.9964 - val_loss: 1.1125 - val_binary_accuracy: 0.7903\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0125 - binary_accuracy: 0.9982 - val_loss: 1.2295 - val_binary_accuracy: 0.7742\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 1.3297 - val_binary_accuracy: 0.7581\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0081 - binary_accuracy: 0.9982 - val_loss: 1.2654 - val_binary_accuracy: 0.7742\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0271 - binary_accuracy: 0.9928 - val_loss: 1.3153 - val_binary_accuracy: 0.6129\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0086 - binary_accuracy: 0.9982 - val_loss: 1.1103 - val_binary_accuracy: 0.7742\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0092 - binary_accuracy: 0.9982 - val_loss: 1.3855 - val_binary_accuracy: 0.7742\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0086 - binary_accuracy: 0.9982 - val_loss: 1.3611 - val_binary_accuracy: 0.7581\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0209 - binary_accuracy: 0.9964 - val_loss: 1.2977 - val_binary_accuracy: 0.7903\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 1.3312 - val_binary_accuracy: 0.7419\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0116 - binary_accuracy: 0.9982 - val_loss: 1.2700 - val_binary_accuracy: 0.7419\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 1.1851 - val_binary_accuracy: 0.7581\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0220 - binary_accuracy: 0.9910 - val_loss: 1.8862 - val_binary_accuracy: 0.5645\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0236 - binary_accuracy: 0.9928 - val_loss: 1.0794 - val_binary_accuracy: 0.7097\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0107 - binary_accuracy: 0.9946 - val_loss: 1.3613 - val_binary_accuracy: 0.7903\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 1.3529 - val_binary_accuracy: 0.7903\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0088 - binary_accuracy: 0.9964 - val_loss: 1.2440 - val_binary_accuracy: 0.7903\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0287 - binary_accuracy: 0.9873 - val_loss: 1.1393 - val_binary_accuracy: 0.6129\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0101 - binary_accuracy: 0.9964 - val_loss: 1.4432 - val_binary_accuracy: 0.8226\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0111 - binary_accuracy: 0.9928 - val_loss: 1.5659 - val_binary_accuracy: 0.8387\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0314 - binary_accuracy: 0.9855 - val_loss: 1.6949 - val_binary_accuracy: 0.8387\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0268 - binary_accuracy: 0.9892 - val_loss: 1.9193 - val_binary_accuracy: 0.5161\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0091 - binary_accuracy: 0.9982 - val_loss: 1.2800 - val_binary_accuracy: 0.7903\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0115 - binary_accuracy: 0.9964 - val_loss: 1.3789 - val_binary_accuracy: 0.7903\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 1.3057 - val_binary_accuracy: 0.7742\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0103 - binary_accuracy: 0.9964 - val_loss: 1.3723 - val_binary_accuracy: 0.7903\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 1.7859 - val_binary_accuracy: 0.8226\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0103 - binary_accuracy: 0.9964 - val_loss: 1.8258 - val_binary_accuracy: 0.8065\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0142 - binary_accuracy: 0.9946 - val_loss: 1.4142 - val_binary_accuracy: 0.6290\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0084 - binary_accuracy: 0.9982 - val_loss: 1.9622 - val_binary_accuracy: 0.6129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0083 - binary_accuracy: 0.9982 - val_loss: 1.6209 - val_binary_accuracy: 0.5968\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0221 - binary_accuracy: 0.9910 - val_loss: 1.3657 - val_binary_accuracy: 0.7581\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0133 - binary_accuracy: 0.9946 - val_loss: 1.7108 - val_binary_accuracy: 0.8226\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0052 - binary_accuracy: 0.9982 - val_loss: 1.4121 - val_binary_accuracy: 0.7581\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0054 - binary_accuracy: 0.9982 - val_loss: 1.3602 - val_binary_accuracy: 0.7581\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0076 - binary_accuracy: 0.9964 - val_loss: 1.5583 - val_binary_accuracy: 0.8226\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9964 - val_loss: 1.5769 - val_binary_accuracy: 0.7581\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0050 - binary_accuracy: 0.9982 - val_loss: 1.5819 - val_binary_accuracy: 0.7258\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0101 - binary_accuracy: 0.9982 - val_loss: 1.7112 - val_binary_accuracy: 0.8226\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 1.6032 - val_binary_accuracy: 0.8065\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 1.5732 - val_binary_accuracy: 0.7581\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0167 - binary_accuracy: 0.9946 - val_loss: 1.5021 - val_binary_accuracy: 0.7742\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0056 - binary_accuracy: 0.9982 - val_loss: 1.4967 - val_binary_accuracy: 0.7903\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 1.4554 - val_binary_accuracy: 0.8065\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0137 - binary_accuracy: 0.9928 - val_loss: 1.3772 - val_binary_accuracy: 0.7903\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0056 - binary_accuracy: 0.9982 - val_loss: 1.4274 - val_binary_accuracy: 0.7258\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0089 - binary_accuracy: 0.9982 - val_loss: 1.6784 - val_binary_accuracy: 0.6774\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0136 - binary_accuracy: 0.9946 - val_loss: 1.3831 - val_binary_accuracy: 0.7581\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 1.4180 - val_binary_accuracy: 0.6935\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0100 - binary_accuracy: 0.9964 - val_loss: 1.4730 - val_binary_accuracy: 0.7419\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 7.3499e-04 - binary_accuracy: 1.0000 - val_loss: 1.4951 - val_binary_accuracy: 0.7581\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 1.5493 - val_binary_accuracy: 0.7581\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0029 - binary_accuracy: 0.9982 - val_loss: 1.5091 - val_binary_accuracy: 0.7742\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0104 - binary_accuracy: 0.9946 - val_loss: 1.3736 - val_binary_accuracy: 0.7903\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0128 - binary_accuracy: 0.9928 - val_loss: 1.8147 - val_binary_accuracy: 0.4677\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0066 - binary_accuracy: 0.9982 - val_loss: 1.0510 - val_binary_accuracy: 0.7903\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0095 - binary_accuracy: 0.9946 - val_loss: 2.4047 - val_binary_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 0.9982 - val_loss: 1.3362 - val_binary_accuracy: 0.7903\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0047 - binary_accuracy: 0.9982 - val_loss: 1.4258 - val_binary_accuracy: 0.7903\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 1.4736 - val_binary_accuracy: 0.7903\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0134 - binary_accuracy: 0.9946 - val_loss: 1.4475 - val_binary_accuracy: 0.7903\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0025 - binary_accuracy: 0.9982 - val_loss: 2.0767 - val_binary_accuracy: 0.5645\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 1.7082 - val_binary_accuracy: 0.8226\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0092 - binary_accuracy: 0.9964 - val_loss: 1.4678 - val_binary_accuracy: 0.7903\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 1.6826 - val_binary_accuracy: 0.7903\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 3.9808e-04 - binary_accuracy: 1.0000 - val_loss: 1.6182 - val_binary_accuracy: 0.7903\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0030 - binary_accuracy: 0.9982 - val_loss: 1.5369 - val_binary_accuracy: 0.7903\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 1.4681 - val_binary_accuracy: 0.7742\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 1.5497 - val_binary_accuracy: 0.7581\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0026 - binary_accuracy: 0.9982 - val_loss: 1.6454 - val_binary_accuracy: 0.7742\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 1.7038 - val_binary_accuracy: 0.7903\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 7.6100e-04 - binary_accuracy: 1.0000 - val_loss: 1.6241 - val_binary_accuracy: 0.7903\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 5.7630e-04 - binary_accuracy: 1.0000 - val_loss: 1.5968 - val_binary_accuracy: 0.7742\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 5.2332e-04 - binary_accuracy: 1.0000 - val_loss: 1.6000 - val_binary_accuracy: 0.7581\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 4.7697e-04 - binary_accuracy: 1.0000 - val_loss: 1.6254 - val_binary_accuracy: 0.7581\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0096 - binary_accuracy: 0.9982 - val_loss: 1.5304 - val_binary_accuracy: 0.6613\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 5.1763e-04 - binary_accuracy: 1.0000 - val_loss: 1.2930 - val_binary_accuracy: 0.7581\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0069 - binary_accuracy: 0.9982 - val_loss: 1.4193 - val_binary_accuracy: 0.7581\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 2s 4ms/sample - loss: 0.0091 - binary_accuracy: 0.9964 - val_loss: 1.5331 - val_binary_accuracy: 0.7742\n",
      "accuracy for model 5 is 77.4193525314331\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 164s 296ms/sample - loss: 0.6260 - binary_accuracy: 0.6588 - val_loss: 1.4527 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.4653 - binary_accuracy: 0.8177 - val_loss: 1.0309 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.4254 - binary_accuracy: 0.8177 - val_loss: 0.6777 - val_binary_accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3842 - binary_accuracy: 0.8267 - val_loss: 0.5984 - val_binary_accuracy: 0.6557\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3466 - binary_accuracy: 0.8466 - val_loss: 0.4666 - val_binary_accuracy: 0.8033\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2989 - binary_accuracy: 0.8791 - val_loss: 0.5136 - val_binary_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2773 - binary_accuracy: 0.8863 - val_loss: 0.4782 - val_binary_accuracy: 0.8197\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1977 - binary_accuracy: 0.9350 - val_loss: 0.6881 - val_binary_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1612 - binary_accuracy: 0.9422 - val_loss: 0.5596 - val_binary_accuracy: 0.7213\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1217 - binary_accuracy: 0.9639 - val_loss: 0.7534 - val_binary_accuracy: 0.8197\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1014 - binary_accuracy: 0.9639 - val_loss: 2.2153 - val_binary_accuracy: 0.3770\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1108 - binary_accuracy: 0.9567 - val_loss: 0.7478 - val_binary_accuracy: 0.8361\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0580 - binary_accuracy: 0.9874 - val_loss: 0.6333 - val_binary_accuracy: 0.8033\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0703 - binary_accuracy: 0.9856 - val_loss: 0.6529 - val_binary_accuracy: 0.8361\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0780 - binary_accuracy: 0.9747 - val_loss: 0.6664 - val_binary_accuracy: 0.8361\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0721 - binary_accuracy: 0.9747 - val_loss: 0.8080 - val_binary_accuracy: 0.8361\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0444 - binary_accuracy: 0.9856 - val_loss: 0.7373 - val_binary_accuracy: 0.8197\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0435 - binary_accuracy: 0.9874 - val_loss: 0.7696 - val_binary_accuracy: 0.8197\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0325 - binary_accuracy: 0.9910 - val_loss: 0.9164 - val_binary_accuracy: 0.8361\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0294 - binary_accuracy: 0.9892 - val_loss: 0.8359 - val_binary_accuracy: 0.8033\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0281 - binary_accuracy: 0.9910 - val_loss: 0.9030 - val_binary_accuracy: 0.8361\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0294 - binary_accuracy: 0.9892 - val_loss: 0.8192 - val_binary_accuracy: 0.7869\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0205 - binary_accuracy: 0.9946 - val_loss: 0.8458 - val_binary_accuracy: 0.7869\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0130 - binary_accuracy: 0.9982 - val_loss: 0.9156 - val_binary_accuracy: 0.7869\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0229 - binary_accuracy: 0.9910 - val_loss: 0.8958 - val_binary_accuracy: 0.7705\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0149 - binary_accuracy: 0.9964 - val_loss: 0.9219 - val_binary_accuracy: 0.7705\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0104 - binary_accuracy: 0.9982 - val_loss: 0.9195 - val_binary_accuracy: 0.8361\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0114 - binary_accuracy: 0.9964 - val_loss: 1.0625 - val_binary_accuracy: 0.7705\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0207 - binary_accuracy: 0.9946 - val_loss: 1.0638 - val_binary_accuracy: 0.7377\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0165 - binary_accuracy: 0.9964 - val_loss: 1.2509 - val_binary_accuracy: 0.8361\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0160 - binary_accuracy: 0.9946 - val_loss: 0.8723 - val_binary_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0168 - binary_accuracy: 0.9928 - val_loss: 1.0478 - val_binary_accuracy: 0.7213\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0277 - binary_accuracy: 0.9946 - val_loss: 0.9022 - val_binary_accuracy: 0.8033\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0138 - binary_accuracy: 0.9946 - val_loss: 0.9031 - val_binary_accuracy: 0.8361\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0064 - binary_accuracy: 0.9982 - val_loss: 0.9358 - val_binary_accuracy: 0.8361\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0083 - binary_accuracy: 1.0000 - val_loss: 1.0318 - val_binary_accuracy: 0.7705\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0121 - binary_accuracy: 0.9964 - val_loss: 1.0433 - val_binary_accuracy: 0.8197\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 1.0128 - val_binary_accuracy: 0.8033\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0048 - binary_accuracy: 0.9982 - val_loss: 1.0511 - val_binary_accuracy: 0.8361\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0161 - binary_accuracy: 0.9928 - val_loss: 1.1862 - val_binary_accuracy: 0.8361\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0099 - binary_accuracy: 0.9964 - val_loss: 1.5913 - val_binary_accuracy: 0.6557\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0175 - binary_accuracy: 0.9892 - val_loss: 1.1462 - val_binary_accuracy: 0.7541\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0099 - binary_accuracy: 0.9964 - val_loss: 1.1538 - val_binary_accuracy: 0.7705\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 1.2135 - val_binary_accuracy: 0.8361\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0177 - binary_accuracy: 0.9946 - val_loss: 1.5580 - val_binary_accuracy: 0.6885\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0264 - binary_accuracy: 0.9892 - val_loss: 1.1547 - val_binary_accuracy: 0.8033\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0408 - binary_accuracy: 0.9856 - val_loss: 1.6854 - val_binary_accuracy: 0.8197\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0278 - binary_accuracy: 0.9910 - val_loss: 0.9156 - val_binary_accuracy: 0.8033\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0180 - binary_accuracy: 0.9946 - val_loss: 1.1209 - val_binary_accuracy: 0.8361\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0066 - binary_accuracy: 0.9982 - val_loss: 1.2693 - val_binary_accuracy: 0.8361\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 1.2152 - val_binary_accuracy: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0095 - binary_accuracy: 0.9946 - val_loss: 1.0902 - val_binary_accuracy: 0.8197\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0085 - binary_accuracy: 0.9982 - val_loss: 1.0977 - val_binary_accuracy: 0.7705\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 1.1958 - val_binary_accuracy: 0.8197\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0032 - binary_accuracy: 0.9982 - val_loss: 1.2210 - val_binary_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 1.1606 - val_binary_accuracy: 0.8197\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0161 - binary_accuracy: 0.9928 - val_loss: 1.5538 - val_binary_accuracy: 0.8361\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0098 - binary_accuracy: 0.9928 - val_loss: 1.0776 - val_binary_accuracy: 0.8197\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0050 - binary_accuracy: 0.9982 - val_loss: 1.2025 - val_binary_accuracy: 0.8033\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 1.2102 - val_binary_accuracy: 0.8197\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 1.1746 - val_binary_accuracy: 0.8033\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 1.2219 - val_binary_accuracy: 0.8197\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0146 - binary_accuracy: 0.9964 - val_loss: 1.6356 - val_binary_accuracy: 0.6885\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0151 - binary_accuracy: 0.9964 - val_loss: 1.1694 - val_binary_accuracy: 0.8197\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0131 - binary_accuracy: 0.9964 - val_loss: 1.2788 - val_binary_accuracy: 0.8525\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0161 - binary_accuracy: 0.9928 - val_loss: 0.8985 - val_binary_accuracy: 0.7869\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0098 - binary_accuracy: 0.9946 - val_loss: 0.8955 - val_binary_accuracy: 0.8033\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 0.9964 - val_loss: 1.1209 - val_binary_accuracy: 0.8361\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0032 - binary_accuracy: 1.0000 - val_loss: 0.8987 - val_binary_accuracy: 0.8197\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 2.4154 - val_binary_accuracy: 0.5246\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0159 - binary_accuracy: 0.9946 - val_loss: 1.3875 - val_binary_accuracy: 0.8361\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0175 - binary_accuracy: 0.9928 - val_loss: 1.9337 - val_binary_accuracy: 0.5574\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0031 - binary_accuracy: 0.9982 - val_loss: 1.3650 - val_binary_accuracy: 0.8361\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 1.3765 - val_binary_accuracy: 0.8361\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 1.2825 - val_binary_accuracy: 0.8033\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 1.3339 - val_binary_accuracy: 0.7869\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 1.4295 - val_binary_accuracy: 0.8197\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 6.8430e-04 - binary_accuracy: 1.0000 - val_loss: 1.3688 - val_binary_accuracy: 0.8361\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0049 - binary_accuracy: 0.9982 - val_loss: 1.3654 - val_binary_accuracy: 0.8525\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0036 - binary_accuracy: 0.9982 - val_loss: 1.4240 - val_binary_accuracy: 0.8525\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0160 - binary_accuracy: 0.9964 - val_loss: 1.1536 - val_binary_accuracy: 0.8525\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0139 - binary_accuracy: 0.9964 - val_loss: 1.3963 - val_binary_accuracy: 0.8197\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0107 - binary_accuracy: 0.9964 - val_loss: 1.5612 - val_binary_accuracy: 0.8361\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0535 - binary_accuracy: 0.9838 - val_loss: 2.7471 - val_binary_accuracy: 0.4098\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0222 - binary_accuracy: 0.9892 - val_loss: 1.7646 - val_binary_accuracy: 0.6885\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0151 - binary_accuracy: 0.9964 - val_loss: 0.9145 - val_binary_accuracy: 0.7705\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0097 - binary_accuracy: 0.9946 - val_loss: 1.0650 - val_binary_accuracy: 0.8361\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0061 - binary_accuracy: 0.9982 - val_loss: 1.2471 - val_binary_accuracy: 0.8525\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0048 - binary_accuracy: 0.9982 - val_loss: 1.3714 - val_binary_accuracy: 0.8525\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0038 - binary_accuracy: 0.9982 - val_loss: 1.0695 - val_binary_accuracy: 0.8033\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 1.1785 - val_binary_accuracy: 0.8361\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0036 - binary_accuracy: 0.9982 - val_loss: 1.1196 - val_binary_accuracy: 0.8033\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 0.9982 - val_loss: 1.6721 - val_binary_accuracy: 0.8361\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 1.2569 - val_binary_accuracy: 0.8197\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0058 - binary_accuracy: 0.9964 - val_loss: 1.1245 - val_binary_accuracy: 0.8033\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0020 - binary_accuracy: 0.9982 - val_loss: 1.1548 - val_binary_accuracy: 0.8525\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0096 - binary_accuracy: 0.9964 - val_loss: 1.0583 - val_binary_accuracy: 0.7869\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.2400 - val_binary_accuracy: 0.8361\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0070 - binary_accuracy: 0.9964 - val_loss: 1.9233 - val_binary_accuracy: 0.8525\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0098 - binary_accuracy: 0.9964 - val_loss: 1.5181 - val_binary_accuracy: 0.8033\n",
      "accuracy for model 6 is 80.32786846160889\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 11s 20ms/sample - loss: 0.5149 - binary_accuracy: 0.7798 - val_loss: 1.6274 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.4413 - binary_accuracy: 0.8213 - val_loss: 0.7029 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3914 - binary_accuracy: 0.8249 - val_loss: 0.9509 - val_binary_accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3603 - binary_accuracy: 0.8430 - val_loss: 1.5144 - val_binary_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3324 - binary_accuracy: 0.8556 - val_loss: 1.0266 - val_binary_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2390 - binary_accuracy: 0.9079 - val_loss: 0.5605 - val_binary_accuracy: 0.7377\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2094 - binary_accuracy: 0.9224 - val_loss: 0.5930 - val_binary_accuracy: 0.8197\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1679 - binary_accuracy: 0.9368 - val_loss: 0.7142 - val_binary_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1375 - binary_accuracy: 0.9549 - val_loss: 0.9698 - val_binary_accuracy: 0.8197\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1089 - binary_accuracy: 0.9603 - val_loss: 1.0252 - val_binary_accuracy: 0.8033\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0819 - binary_accuracy: 0.9783 - val_loss: 0.8332 - val_binary_accuracy: 0.8033\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0936 - binary_accuracy: 0.9657 - val_loss: 0.8023 - val_binary_accuracy: 0.8033\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0677 - binary_accuracy: 0.9856 - val_loss: 0.6874 - val_binary_accuracy: 0.6721\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0789 - binary_accuracy: 0.9657 - val_loss: 0.8152 - val_binary_accuracy: 0.8033\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0848 - binary_accuracy: 0.9747 - val_loss: 1.0503 - val_binary_accuracy: 0.6230\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0595 - binary_accuracy: 0.9801 - val_loss: 0.9987 - val_binary_accuracy: 0.7869\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0268 - binary_accuracy: 0.9964 - val_loss: 1.1935 - val_binary_accuracy: 0.7869\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0311 - binary_accuracy: 0.9946 - val_loss: 1.2804 - val_binary_accuracy: 0.8033\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0448 - binary_accuracy: 0.9819 - val_loss: 0.8614 - val_binary_accuracy: 0.6557\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0227 - binary_accuracy: 0.9964 - val_loss: 0.9480 - val_binary_accuracy: 0.7705\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0190 - binary_accuracy: 0.9946 - val_loss: 1.4407 - val_binary_accuracy: 0.8197\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0195 - binary_accuracy: 0.9946 - val_loss: 0.9511 - val_binary_accuracy: 0.7541\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0146 - binary_accuracy: 0.9964 - val_loss: 1.0617 - val_binary_accuracy: 0.7869\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0276 - binary_accuracy: 0.9892 - val_loss: 0.9400 - val_binary_accuracy: 0.7705\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0284 - binary_accuracy: 0.9856 - val_loss: 1.7005 - val_binary_accuracy: 0.8197\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1797 - binary_accuracy: 0.9296 - val_loss: 2.3759 - val_binary_accuracy: 0.8197\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0641 - binary_accuracy: 0.9801 - val_loss: 1.8315 - val_binary_accuracy: 0.8197\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0538 - binary_accuracy: 0.9856 - val_loss: 1.5999 - val_binary_accuracy: 0.8197\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0519 - binary_accuracy: 0.9874 - val_loss: 1.5206 - val_binary_accuracy: 0.8197\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0532 - binary_accuracy: 0.9856 - val_loss: 1.2939 - val_binary_accuracy: 0.8033\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0336 - binary_accuracy: 0.9874 - val_loss: 0.9760 - val_binary_accuracy: 0.7869\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0520 - binary_accuracy: 0.9856 - val_loss: 0.9466 - val_binary_accuracy: 0.7705\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0600 - binary_accuracy: 0.9819 - val_loss: 0.9723 - val_binary_accuracy: 0.7049\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0195 - binary_accuracy: 0.9946 - val_loss: 0.9982 - val_binary_accuracy: 0.7705\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0520 - binary_accuracy: 0.9801 - val_loss: 0.9962 - val_binary_accuracy: 0.7213\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0339 - binary_accuracy: 0.9910 - val_loss: 0.9984 - val_binary_accuracy: 0.7213\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0252 - binary_accuracy: 0.9910 - val_loss: 1.0931 - val_binary_accuracy: 0.7049\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0296 - binary_accuracy: 0.9946 - val_loss: 1.1019 - val_binary_accuracy: 0.7869\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0101 - binary_accuracy: 1.0000 - val_loss: 1.0819 - val_binary_accuracy: 0.7049\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0159 - binary_accuracy: 0.9964 - val_loss: 1.2242 - val_binary_accuracy: 0.7869\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0223 - binary_accuracy: 0.9910 - val_loss: 1.0843 - val_binary_accuracy: 0.7869\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0247 - binary_accuracy: 0.9910 - val_loss: 1.1432 - val_binary_accuracy: 0.6885\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0128 - binary_accuracy: 0.9964 - val_loss: 0.9972 - val_binary_accuracy: 0.7541\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0114 - binary_accuracy: 0.9982 - val_loss: 1.1667 - val_binary_accuracy: 0.6885\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0129 - binary_accuracy: 0.9964 - val_loss: 1.1004 - val_binary_accuracy: 0.7213\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0146 - binary_accuracy: 0.9982 - val_loss: 1.0692 - val_binary_accuracy: 0.7213\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0166 - binary_accuracy: 0.9928 - val_loss: 1.1755 - val_binary_accuracy: 0.7213\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0107 - binary_accuracy: 0.9982 - val_loss: 1.1917 - val_binary_accuracy: 0.7705\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0077 - binary_accuracy: 0.9982 - val_loss: 1.2090 - val_binary_accuracy: 0.7213\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 0.9982 - val_loss: 1.1895 - val_binary_accuracy: 0.7049\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 1.2161 - val_binary_accuracy: 0.7049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0083 - binary_accuracy: 1.0000 - val_loss: 1.2559 - val_binary_accuracy: 0.7541\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0076 - binary_accuracy: 0.9982 - val_loss: 1.2925 - val_binary_accuracy: 0.7705\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0067 - binary_accuracy: 1.0000 - val_loss: 1.3066 - val_binary_accuracy: 0.7541\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0141 - binary_accuracy: 0.9946 - val_loss: 1.5698 - val_binary_accuracy: 0.7869\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0124 - binary_accuracy: 0.9964 - val_loss: 1.5192 - val_binary_accuracy: 0.6721\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0144 - binary_accuracy: 0.9946 - val_loss: 1.4336 - val_binary_accuracy: 0.6721\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 0.9982 - val_loss: 1.5666 - val_binary_accuracy: 0.6721\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0127 - binary_accuracy: 0.9928 - val_loss: 1.4059 - val_binary_accuracy: 0.6721\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 1.4057 - val_binary_accuracy: 0.7049\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 1.4591 - val_binary_accuracy: 0.7705\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0052 - binary_accuracy: 0.9982 - val_loss: 1.4523 - val_binary_accuracy: 0.7869\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0032 - binary_accuracy: 1.0000 - val_loss: 1.4082 - val_binary_accuracy: 0.7541\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0074 - binary_accuracy: 0.9982 - val_loss: 1.4260 - val_binary_accuracy: 0.7049\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 1.3745 - val_binary_accuracy: 0.7213\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0093 - binary_accuracy: 0.9964 - val_loss: 1.6388 - val_binary_accuracy: 0.7705\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0065 - binary_accuracy: 0.9964 - val_loss: 1.5523 - val_binary_accuracy: 0.7869\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0057 - binary_accuracy: 0.9982 - val_loss: 1.7670 - val_binary_accuracy: 0.8033\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0095 - binary_accuracy: 0.9982 - val_loss: 1.3173 - val_binary_accuracy: 0.7705\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 1.3725 - val_binary_accuracy: 0.7377\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0066 - binary_accuracy: 0.9982 - val_loss: 1.3402 - val_binary_accuracy: 0.7213\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0052 - binary_accuracy: 0.9982 - val_loss: 1.4839 - val_binary_accuracy: 0.7049\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0029 - binary_accuracy: 0.9982 - val_loss: 1.5242 - val_binary_accuracy: 0.7049\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 1.4491 - val_binary_accuracy: 0.7213\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 1.5007 - val_binary_accuracy: 0.7213\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0147 - binary_accuracy: 0.9928 - val_loss: 1.5004 - val_binary_accuracy: 0.7213\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 1.5376 - val_binary_accuracy: 0.7869\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 1.6544 - val_binary_accuracy: 0.7869\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0085 - binary_accuracy: 0.9982 - val_loss: 1.5840 - val_binary_accuracy: 0.7869\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0037 - binary_accuracy: 0.9982 - val_loss: 1.5383 - val_binary_accuracy: 0.6885\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 0.9982 - val_loss: 1.6360 - val_binary_accuracy: 0.7541\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 1.7345 - val_binary_accuracy: 0.7705\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0093 - binary_accuracy: 0.9964 - val_loss: 1.3565 - val_binary_accuracy: 0.7869\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0097 - binary_accuracy: 0.9964 - val_loss: 1.3901 - val_binary_accuracy: 0.6885\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 1.4139 - val_binary_accuracy: 0.7213\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 0.9982 - val_loss: 1.5909 - val_binary_accuracy: 0.8033\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0074 - binary_accuracy: 0.9982 - val_loss: 1.5252 - val_binary_accuracy: 0.7869\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 1.6012 - val_binary_accuracy: 0.7705\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 1.4813 - val_binary_accuracy: 0.7213\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0038 - binary_accuracy: 0.9982 - val_loss: 1.5860 - val_binary_accuracy: 0.7869\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0124 - binary_accuracy: 0.9946 - val_loss: 1.6994 - val_binary_accuracy: 0.7049\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0037 - binary_accuracy: 0.9982 - val_loss: 1.7013 - val_binary_accuracy: 0.7705\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 1.6661 - val_binary_accuracy: 0.7869\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0053 - binary_accuracy: 0.9964 - val_loss: 1.4468 - val_binary_accuracy: 0.7869\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 1.3092 - val_binary_accuracy: 0.7377\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 1.5200 - val_binary_accuracy: 0.7377\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0040 - binary_accuracy: 0.9982 - val_loss: 1.6539 - val_binary_accuracy: 0.7377\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 1.5302 - val_binary_accuracy: 0.8033\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 8.3714e-04 - binary_accuracy: 1.0000 - val_loss: 1.5255 - val_binary_accuracy: 0.8197\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.5388 - val_binary_accuracy: 0.8033\n",
      "accuracy for model 7 is 80.32786846160889\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 9s 15ms/sample - loss: 0.4730 - binary_accuracy: 0.8141 - val_loss: 4.0968 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.4253 - binary_accuracy: 0.8213 - val_loss: 1.9069 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3907 - binary_accuracy: 0.8177 - val_loss: 1.2272 - val_binary_accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3312 - binary_accuracy: 0.8357 - val_loss: 0.6793 - val_binary_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2882 - binary_accuracy: 0.8700 - val_loss: 0.4970 - val_binary_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2652 - binary_accuracy: 0.8881 - val_loss: 0.9443 - val_binary_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2134 - binary_accuracy: 0.9224 - val_loss: 0.7641 - val_binary_accuracy: 0.8197\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1971 - binary_accuracy: 0.9224 - val_loss: 0.7798 - val_binary_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1527 - binary_accuracy: 0.9513 - val_loss: 0.6495 - val_binary_accuracy: 0.8361\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1492 - binary_accuracy: 0.9422 - val_loss: 0.9488 - val_binary_accuracy: 0.5902\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1176 - binary_accuracy: 0.9621 - val_loss: 0.8995 - val_binary_accuracy: 0.8525\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0888 - binary_accuracy: 0.9711 - val_loss: 0.6728 - val_binary_accuracy: 0.7869\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0626 - binary_accuracy: 0.9856 - val_loss: 1.1071 - val_binary_accuracy: 0.8197\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0580 - binary_accuracy: 0.9783 - val_loss: 0.6955 - val_binary_accuracy: 0.7213\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0499 - binary_accuracy: 0.9838 - val_loss: 1.0096 - val_binary_accuracy: 0.5246\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0478 - binary_accuracy: 0.9874 - val_loss: 1.0960 - val_binary_accuracy: 0.5246\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0448 - binary_accuracy: 0.9874 - val_loss: 0.7016 - val_binary_accuracy: 0.7541\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0373 - binary_accuracy: 0.9928 - val_loss: 0.8069 - val_binary_accuracy: 0.7541\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0271 - binary_accuracy: 0.9910 - val_loss: 0.8234 - val_binary_accuracy: 0.8033\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0225 - binary_accuracy: 0.9964 - val_loss: 1.2004 - val_binary_accuracy: 0.5902\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0215 - binary_accuracy: 0.9946 - val_loss: 1.0251 - val_binary_accuracy: 0.7869\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0261 - binary_accuracy: 0.9892 - val_loss: 0.8725 - val_binary_accuracy: 0.6885\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0247 - binary_accuracy: 0.9946 - val_loss: 0.8612 - val_binary_accuracy: 0.8197\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0208 - binary_accuracy: 0.9928 - val_loss: 0.9839 - val_binary_accuracy: 0.8197\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0267 - binary_accuracy: 0.9946 - val_loss: 0.9290 - val_binary_accuracy: 0.8033\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0143 - binary_accuracy: 0.9982 - val_loss: 0.9005 - val_binary_accuracy: 0.7049\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0118 - binary_accuracy: 1.0000 - val_loss: 1.1284 - val_binary_accuracy: 0.8361\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0168 - binary_accuracy: 0.9928 - val_loss: 0.9367 - val_binary_accuracy: 0.8033\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0167 - binary_accuracy: 0.9946 - val_loss: 1.0907 - val_binary_accuracy: 0.6393\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0110 - binary_accuracy: 0.9982 - val_loss: 1.0070 - val_binary_accuracy: 0.7541\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0143 - binary_accuracy: 0.9946 - val_loss: 0.9539 - val_binary_accuracy: 0.8033\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0103 - binary_accuracy: 0.9964 - val_loss: 0.9763 - val_binary_accuracy: 0.8033\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 0.9414 - val_binary_accuracy: 0.8361\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0056 - binary_accuracy: 0.9982 - val_loss: 0.9806 - val_binary_accuracy: 0.7869\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 1.0295 - val_binary_accuracy: 0.7869\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0203 - binary_accuracy: 0.9946 - val_loss: 1.3100 - val_binary_accuracy: 0.8361\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0068 - binary_accuracy: 0.9982 - val_loss: 1.0572 - val_binary_accuracy: 0.8033\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0107 - binary_accuracy: 0.9982 - val_loss: 1.0928 - val_binary_accuracy: 0.7705\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0140 - binary_accuracy: 0.9982 - val_loss: 1.2650 - val_binary_accuracy: 0.8197\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0112 - binary_accuracy: 0.9982 - val_loss: 1.2067 - val_binary_accuracy: 0.7869\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0078 - binary_accuracy: 0.9964 - val_loss: 1.4411 - val_binary_accuracy: 0.8197\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0072 - binary_accuracy: 0.9982 - val_loss: 1.6059 - val_binary_accuracy: 0.5902\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0064 - binary_accuracy: 0.9982 - val_loss: 1.2722 - val_binary_accuracy: 0.7049\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0167 - binary_accuracy: 0.9982 - val_loss: 1.2665 - val_binary_accuracy: 0.7377\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 1.3181 - val_binary_accuracy: 0.7705\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 1.3913 - val_binary_accuracy: 0.8197\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0083 - binary_accuracy: 0.9946 - val_loss: 1.2722 - val_binary_accuracy: 0.7049\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 1.1770 - val_binary_accuracy: 0.7705\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0085 - binary_accuracy: 0.9982 - val_loss: 1.2675 - val_binary_accuracy: 0.8033\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0070 - binary_accuracy: 0.9982 - val_loss: 1.4550 - val_binary_accuracy: 0.8361\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0076 - binary_accuracy: 0.9982 - val_loss: 1.4302 - val_binary_accuracy: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0072 - binary_accuracy: 0.9964 - val_loss: 1.6097 - val_binary_accuracy: 0.6230\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 1.2608 - val_binary_accuracy: 0.7705\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 1.2933 - val_binary_accuracy: 0.7541\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0086 - binary_accuracy: 0.9964 - val_loss: 1.2903 - val_binary_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0236 - binary_accuracy: 0.9928 - val_loss: 2.1920 - val_binary_accuracy: 0.5246\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0046 - binary_accuracy: 0.9982 - val_loss: 1.2308 - val_binary_accuracy: 0.7705\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 1.2606 - val_binary_accuracy: 0.7049\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0034 - binary_accuracy: 0.9982 - val_loss: 1.2757 - val_binary_accuracy: 0.6885\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0061 - binary_accuracy: 0.9982 - val_loss: 1.2815 - val_binary_accuracy: 0.7705\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0146 - binary_accuracy: 0.9964 - val_loss: 1.3247 - val_binary_accuracy: 0.7705\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0074 - binary_accuracy: 0.9982 - val_loss: 1.3693 - val_binary_accuracy: 0.7705\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 1.4803 - val_binary_accuracy: 0.8525\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0070 - binary_accuracy: 0.9982 - val_loss: 1.3719 - val_binary_accuracy: 0.7541\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 1.4540 - val_binary_accuracy: 0.7541\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.4673 - val_binary_accuracy: 0.7541\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0026 - binary_accuracy: 0.9982 - val_loss: 1.4482 - val_binary_accuracy: 0.7705\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 1.4329 - val_binary_accuracy: 0.7705\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0042 - binary_accuracy: 0.9982 - val_loss: 1.4142 - val_binary_accuracy: 0.7049\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 1.6137 - val_binary_accuracy: 0.8361\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 1.4294 - val_binary_accuracy: 0.7705\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.5001 - val_binary_accuracy: 0.7705\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 0.9982 - val_loss: 1.5336 - val_binary_accuracy: 0.7705\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0035 - binary_accuracy: 0.9982 - val_loss: 1.7033 - val_binary_accuracy: 0.8197\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0148 - binary_accuracy: 0.9982 - val_loss: 1.3864 - val_binary_accuracy: 0.7705\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0037 - binary_accuracy: 0.9982 - val_loss: 1.2556 - val_binary_accuracy: 0.7869\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0107 - binary_accuracy: 0.9964 - val_loss: 1.3997 - val_binary_accuracy: 0.7869\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0048 - binary_accuracy: 0.9982 - val_loss: 1.6998 - val_binary_accuracy: 0.8197\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 0.9982 - val_loss: 1.4301 - val_binary_accuracy: 0.7705\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.3514 - val_binary_accuracy: 0.7705\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.3561 - val_binary_accuracy: 0.7869\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.3743 - val_binary_accuracy: 0.8033\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 1.3983 - val_binary_accuracy: 0.7705\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 9.8622e-04 - binary_accuracy: 1.0000 - val_loss: 1.4170 - val_binary_accuracy: 0.7705\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 9.1443e-04 - binary_accuracy: 1.0000 - val_loss: 1.4370 - val_binary_accuracy: 0.8033\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 1.4688 - val_binary_accuracy: 0.7049\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 5.6731e-04 - binary_accuracy: 1.0000 - val_loss: 1.5049 - val_binary_accuracy: 0.7541\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 1.5739 - val_binary_accuracy: 0.6885\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 5.4452e-04 - binary_accuracy: 1.0000 - val_loss: 1.4983 - val_binary_accuracy: 0.8033\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 1.4324 - val_binary_accuracy: 0.7705\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 4.0372e-04 - binary_accuracy: 1.0000 - val_loss: 1.4012 - val_binary_accuracy: 0.8033\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 5.5298e-04 - binary_accuracy: 1.0000 - val_loss: 1.3782 - val_binary_accuracy: 0.7869\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.4050 - val_binary_accuracy: 0.7705\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.4031 - val_binary_accuracy: 0.8033\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0058 - binary_accuracy: 0.9964 - val_loss: 2.1156 - val_binary_accuracy: 0.8197\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0077 - binary_accuracy: 0.9964 - val_loss: 1.5899 - val_binary_accuracy: 0.6557\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0050 - binary_accuracy: 0.9982 - val_loss: 1.7181 - val_binary_accuracy: 0.8361\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0028 - binary_accuracy: 0.9982 - val_loss: 1.3705 - val_binary_accuracy: 0.7869\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0227 - binary_accuracy: 0.9946 - val_loss: 2.7410 - val_binary_accuracy: 0.8197\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0043 - binary_accuracy: 0.9982 - val_loss: 1.5197 - val_binary_accuracy: 0.6557\n",
      "accuracy for model 8 is 65.57376980781555\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 11s 21ms/sample - loss: 0.5648 - binary_accuracy: 0.7040 - val_loss: 1.0247 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.4250 - binary_accuracy: 0.8177 - val_loss: 0.4104 - val_binary_accuracy: 0.7705\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3716 - binary_accuracy: 0.8357 - val_loss: 0.3909 - val_binary_accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3368 - binary_accuracy: 0.8736 - val_loss: 0.5729 - val_binary_accuracy: 0.6885\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2743 - binary_accuracy: 0.8917 - val_loss: 0.4768 - val_binary_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2041 - binary_accuracy: 0.9314 - val_loss: 0.7254 - val_binary_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1425 - binary_accuracy: 0.9513 - val_loss: 0.7870 - val_binary_accuracy: 0.8197\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1317 - binary_accuracy: 0.9531 - val_loss: 1.1309 - val_binary_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1234 - binary_accuracy: 0.9585 - val_loss: 0.6855 - val_binary_accuracy: 0.8197\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0815 - binary_accuracy: 0.9729 - val_loss: 0.8871 - val_binary_accuracy: 0.8197\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0659 - binary_accuracy: 0.9747 - val_loss: 0.4353 - val_binary_accuracy: 0.8852\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0501 - binary_accuracy: 0.9874 - val_loss: 0.5150 - val_binary_accuracy: 0.8361\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0315 - binary_accuracy: 0.9910 - val_loss: 0.7108 - val_binary_accuracy: 0.8361\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0225 - binary_accuracy: 0.9964 - val_loss: 0.8699 - val_binary_accuracy: 0.8361\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0309 - binary_accuracy: 0.9910 - val_loss: 0.5971 - val_binary_accuracy: 0.8525\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0187 - binary_accuracy: 0.9964 - val_loss: 0.4399 - val_binary_accuracy: 0.8525\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0388 - binary_accuracy: 0.9910 - val_loss: 0.4703 - val_binary_accuracy: 0.8852\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0124 - binary_accuracy: 0.9982 - val_loss: 0.4720 - val_binary_accuracy: 0.8852\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0312 - binary_accuracy: 0.9856 - val_loss: 0.9038 - val_binary_accuracy: 0.8361\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0288 - binary_accuracy: 0.9928 - val_loss: 0.6103 - val_binary_accuracy: 0.8689\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0126 - binary_accuracy: 0.9982 - val_loss: 0.7467 - val_binary_accuracy: 0.8689\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0174 - binary_accuracy: 0.9946 - val_loss: 0.9002 - val_binary_accuracy: 0.8361\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0594 - binary_accuracy: 0.9765 - val_loss: 1.3503 - val_binary_accuracy: 0.8197\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0282 - binary_accuracy: 0.9928 - val_loss: 0.9758 - val_binary_accuracy: 0.8361\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0327 - binary_accuracy: 0.9874 - val_loss: 0.4224 - val_binary_accuracy: 0.8361\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0113 - binary_accuracy: 0.9964 - val_loss: 0.8417 - val_binary_accuracy: 0.8689\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 0.8705 - val_binary_accuracy: 0.8525\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0075 - binary_accuracy: 0.9982 - val_loss: 0.8556 - val_binary_accuracy: 0.8361\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0110 - binary_accuracy: 0.9946 - val_loss: 0.7411 - val_binary_accuracy: 0.8197\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0181 - binary_accuracy: 0.9928 - val_loss: 1.6300 - val_binary_accuracy: 0.8197\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0059 - binary_accuracy: 1.0000 - val_loss: 0.6542 - val_binary_accuracy: 0.8852\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0242 - binary_accuracy: 0.9910 - val_loss: 0.7145 - val_binary_accuracy: 0.8852\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0095 - binary_accuracy: 0.9982 - val_loss: 1.2125 - val_binary_accuracy: 0.8525\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0061 - binary_accuracy: 0.9982 - val_loss: 1.1529 - val_binary_accuracy: 0.8525\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 1.0392 - val_binary_accuracy: 0.8525\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0115 - binary_accuracy: 0.9946 - val_loss: 0.8552 - val_binary_accuracy: 0.8525\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 1.2562 - val_binary_accuracy: 0.8361\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0030 - binary_accuracy: 0.9982 - val_loss: 0.7600 - val_binary_accuracy: 0.8689\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0099 - binary_accuracy: 0.9964 - val_loss: 1.4035 - val_binary_accuracy: 0.8361\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0241 - binary_accuracy: 0.9928 - val_loss: 1.0995 - val_binary_accuracy: 0.6230\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0343 - binary_accuracy: 0.9874 - val_loss: 1.0170 - val_binary_accuracy: 0.8197\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 1.2652 - val_binary_accuracy: 0.8197\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0058 - binary_accuracy: 0.9982 - val_loss: 1.1486 - val_binary_accuracy: 0.8361\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 0.8487 - val_binary_accuracy: 0.8689\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 0.9675 - val_binary_accuracy: 0.8361\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 1.0237 - val_binary_accuracy: 0.8361\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 0.8823 - val_binary_accuracy: 0.8525\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0071 - binary_accuracy: 0.9982 - val_loss: 0.8812 - val_binary_accuracy: 0.8525\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 0.8600 - val_binary_accuracy: 0.8361\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0043 - binary_accuracy: 0.9982 - val_loss: 0.9543 - val_binary_accuracy: 0.8197\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.7000 - val_binary_accuracy: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 0.9180 - val_binary_accuracy: 0.8525\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 0.8293 - val_binary_accuracy: 0.8689\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0041 - binary_accuracy: 0.9982 - val_loss: 0.6640 - val_binary_accuracy: 0.8852\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 1.1182 - val_binary_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0131 - binary_accuracy: 0.9964 - val_loss: 0.6961 - val_binary_accuracy: 0.8689\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0037 - binary_accuracy: 1.0000 - val_loss: 0.8531 - val_binary_accuracy: 0.8033\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0098 - binary_accuracy: 0.9982 - val_loss: 0.8500 - val_binary_accuracy: 0.8689\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0133 - binary_accuracy: 0.9928 - val_loss: 0.5369 - val_binary_accuracy: 0.8197\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0082 - binary_accuracy: 0.9982 - val_loss: 0.8446 - val_binary_accuracy: 0.8852\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0181 - binary_accuracy: 0.9964 - val_loss: 0.9894 - val_binary_accuracy: 0.8689\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0083 - binary_accuracy: 0.9964 - val_loss: 0.9365 - val_binary_accuracy: 0.8852\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0198 - binary_accuracy: 0.9910 - val_loss: 0.7306 - val_binary_accuracy: 0.8689\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 0.8958 - val_binary_accuracy: 0.8525\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0110 - binary_accuracy: 0.9946 - val_loss: 1.0598 - val_binary_accuracy: 0.7705\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 0.8129 - val_binary_accuracy: 0.8689\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0100 - binary_accuracy: 0.9946 - val_loss: 1.8914 - val_binary_accuracy: 0.8197\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0128 - binary_accuracy: 0.9964 - val_loss: 0.7054 - val_binary_accuracy: 0.9016\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0215 - binary_accuracy: 0.9928 - val_loss: 1.0568 - val_binary_accuracy: 0.8197\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0161 - binary_accuracy: 0.9928 - val_loss: 1.6009 - val_binary_accuracy: 0.8197\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0306 - binary_accuracy: 0.9874 - val_loss: 0.4863 - val_binary_accuracy: 0.8033\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9964 - val_loss: 0.7846 - val_binary_accuracy: 0.8689\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 0.9982 - val_loss: 0.8851 - val_binary_accuracy: 0.8525\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0050 - binary_accuracy: 0.9982 - val_loss: 0.6452 - val_binary_accuracy: 0.8689\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 0.8301 - val_binary_accuracy: 0.8689\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0054 - binary_accuracy: 0.9964 - val_loss: 0.6383 - val_binary_accuracy: 0.8525\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0219 - binary_accuracy: 0.9964 - val_loss: 0.7398 - val_binary_accuracy: 0.9016\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 0.8173 - val_binary_accuracy: 0.8852\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0050 - binary_accuracy: 0.9982 - val_loss: 1.0186 - val_binary_accuracy: 0.8689\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 1.2553 - val_binary_accuracy: 0.8525\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0589 - binary_accuracy: 0.9819 - val_loss: 10.3862 - val_binary_accuracy: 0.1803\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0426 - binary_accuracy: 0.9801 - val_loss: 1.6988 - val_binary_accuracy: 0.3934\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0156 - binary_accuracy: 0.9928 - val_loss: 0.6331 - val_binary_accuracy: 0.7705\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0184 - binary_accuracy: 0.9928 - val_loss: 0.7870 - val_binary_accuracy: 0.8033\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0087 - binary_accuracy: 0.9982 - val_loss: 0.5504 - val_binary_accuracy: 0.8525\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0063 - binary_accuracy: 1.0000 - val_loss: 0.6810 - val_binary_accuracy: 0.9016\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0049 - binary_accuracy: 0.9982 - val_loss: 0.7921 - val_binary_accuracy: 0.8525\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0046 - binary_accuracy: 0.9982 - val_loss: 0.7704 - val_binary_accuracy: 0.7869\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0117 - binary_accuracy: 0.9964 - val_loss: 1.8584 - val_binary_accuracy: 0.8197\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0046 - binary_accuracy: 0.9982 - val_loss: 1.3797 - val_binary_accuracy: 0.8361\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 1.7378 - val_binary_accuracy: 0.8197\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0097 - binary_accuracy: 0.9982 - val_loss: 2.3905 - val_binary_accuracy: 0.8197\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0137 - binary_accuracy: 0.9964 - val_loss: 1.6304 - val_binary_accuracy: 0.8197\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.2985 - val_binary_accuracy: 0.8525\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 1.3960 - val_binary_accuracy: 0.8361\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0025 - binary_accuracy: 0.9982 - val_loss: 1.1919 - val_binary_accuracy: 0.8525\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 7.6565e-04 - binary_accuracy: 1.0000 - val_loss: 1.0565 - val_binary_accuracy: 0.8689\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 3.3251e-04 - binary_accuracy: 1.0000 - val_loss: 1.0721 - val_binary_accuracy: 0.8689\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 5.6685e-04 - binary_accuracy: 1.0000 - val_loss: 0.9120 - val_binary_accuracy: 0.9016\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 2.6047e-04 - binary_accuracy: 1.0000 - val_loss: 1.0105 - val_binary_accuracy: 0.8852\n",
      "accuracy for model 9 is 88.52459192276001\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 256)               159596032 \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 159,639,937\n",
      "Trainable params: 159,639,873\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 11s 21ms/sample - loss: 0.5001 - binary_accuracy: 0.8032 - val_loss: 2.1035 - val_binary_accuracy: 0.8197\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.4126 - binary_accuracy: 0.8177 - val_loss: 1.2826 - val_binary_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3971 - binary_accuracy: 0.8285 - val_loss: 1.4830 - val_binary_accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.3228 - binary_accuracy: 0.8502 - val_loss: 0.9062 - val_binary_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2674 - binary_accuracy: 0.8809 - val_loss: 0.5933 - val_binary_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.2185 - binary_accuracy: 0.9170 - val_loss: 0.9161 - val_binary_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1869 - binary_accuracy: 0.9386 - val_loss: 0.6296 - val_binary_accuracy: 0.8033\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1386 - binary_accuracy: 0.9386 - val_loss: 0.5666 - val_binary_accuracy: 0.7541\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1335 - binary_accuracy: 0.9477 - val_loss: 0.7134 - val_binary_accuracy: 0.8033\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.1100 - binary_accuracy: 0.9657 - val_loss: 0.9271 - val_binary_accuracy: 0.8197\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0838 - binary_accuracy: 0.9711 - val_loss: 0.5594 - val_binary_accuracy: 0.7049\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0660 - binary_accuracy: 0.9801 - val_loss: 0.5440 - val_binary_accuracy: 0.7705\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0668 - binary_accuracy: 0.9783 - val_loss: 0.6942 - val_binary_accuracy: 0.7541\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0467 - binary_accuracy: 0.9838 - val_loss: 0.7169 - val_binary_accuracy: 0.7705\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0676 - binary_accuracy: 0.9747 - val_loss: 0.7244 - val_binary_accuracy: 0.7541\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0377 - binary_accuracy: 0.9910 - val_loss: 0.6893 - val_binary_accuracy: 0.7541\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0409 - binary_accuracy: 0.9874 - val_loss: 0.7600 - val_binary_accuracy: 0.7541\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0230 - binary_accuracy: 0.9964 - val_loss: 0.7157 - val_binary_accuracy: 0.7541\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0224 - binary_accuracy: 0.9946 - val_loss: 1.1375 - val_binary_accuracy: 0.7705\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0287 - binary_accuracy: 0.9928 - val_loss: 0.7424 - val_binary_accuracy: 0.7705\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0269 - binary_accuracy: 0.9928 - val_loss: 0.7675 - val_binary_accuracy: 0.7049\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0301 - binary_accuracy: 0.9892 - val_loss: 0.9911 - val_binary_accuracy: 0.7541\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0245 - binary_accuracy: 0.9910 - val_loss: 0.9321 - val_binary_accuracy: 0.7541\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0196 - binary_accuracy: 0.9964 - val_loss: 0.9079 - val_binary_accuracy: 0.7541\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0237 - binary_accuracy: 0.9910 - val_loss: 0.9440 - val_binary_accuracy: 0.7541\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0224 - binary_accuracy: 0.9928 - val_loss: 0.9599 - val_binary_accuracy: 0.7705\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0422 - binary_accuracy: 0.9856 - val_loss: 1.4421 - val_binary_accuracy: 0.5738\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0108 - binary_accuracy: 0.9982 - val_loss: 0.9723 - val_binary_accuracy: 0.7541\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0205 - binary_accuracy: 0.9892 - val_loss: 0.9679 - val_binary_accuracy: 0.7541\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0147 - binary_accuracy: 0.9946 - val_loss: 1.0316 - val_binary_accuracy: 0.6557\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0163 - binary_accuracy: 0.9946 - val_loss: 1.0007 - val_binary_accuracy: 0.6721\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0205 - binary_accuracy: 0.9946 - val_loss: 0.8902 - val_binary_accuracy: 0.7705\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0203 - binary_accuracy: 0.9910 - val_loss: 1.0002 - val_binary_accuracy: 0.8033\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0184 - binary_accuracy: 0.9946 - val_loss: 1.0994 - val_binary_accuracy: 0.7869\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0129 - binary_accuracy: 0.9946 - val_loss: 1.0730 - val_binary_accuracy: 0.7705\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 1.1250 - val_binary_accuracy: 0.7869\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 1.0126 - val_binary_accuracy: 0.7541\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0461 - binary_accuracy: 0.9838 - val_loss: 0.9564 - val_binary_accuracy: 0.7869\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 1.1114 - val_binary_accuracy: 0.7541\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0089 - binary_accuracy: 0.9964 - val_loss: 0.9797 - val_binary_accuracy: 0.7541\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0420 - binary_accuracy: 0.9874 - val_loss: 1.2303 - val_binary_accuracy: 0.7541\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0251 - binary_accuracy: 0.9910 - val_loss: 1.2188 - val_binary_accuracy: 0.7541\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0321 - binary_accuracy: 0.9838 - val_loss: 1.2950 - val_binary_accuracy: 0.7705\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0098 - binary_accuracy: 0.9964 - val_loss: 1.4282 - val_binary_accuracy: 0.7705\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 1.3022 - val_binary_accuracy: 0.7705\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 1.1906 - val_binary_accuracy: 0.7705\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0072 - binary_accuracy: 0.9982 - val_loss: 1.1121 - val_binary_accuracy: 0.7377\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0029 - binary_accuracy: 0.9982 - val_loss: 1.1456 - val_binary_accuracy: 0.7541\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0056 - binary_accuracy: 1.0000 - val_loss: 1.1001 - val_binary_accuracy: 0.6721\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0095 - binary_accuracy: 0.9964 - val_loss: 1.1712 - val_binary_accuracy: 0.7541\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0059 - binary_accuracy: 0.9982 - val_loss: 1.0634 - val_binary_accuracy: 0.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 1.4687 - val_binary_accuracy: 0.7705\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0062 - binary_accuracy: 0.9982 - val_loss: 1.1663 - val_binary_accuracy: 0.7705\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0085 - binary_accuracy: 0.9982 - val_loss: 1.1725 - val_binary_accuracy: 0.7541\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0131 - binary_accuracy: 0.9964 - val_loss: 0.8449 - val_binary_accuracy: 0.7705\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0065 - binary_accuracy: 0.9982 - val_loss: 1.3046 - val_binary_accuracy: 0.7869\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0164 - binary_accuracy: 0.9946 - val_loss: 1.1004 - val_binary_accuracy: 0.7377\n",
      "Epoch 58/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0195 - binary_accuracy: 0.9928 - val_loss: 1.1547 - val_binary_accuracy: 0.6885\n",
      "Epoch 59/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0381 - binary_accuracy: 0.9874 - val_loss: 1.5616 - val_binary_accuracy: 0.8197\n",
      "Epoch 60/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0164 - binary_accuracy: 0.9946 - val_loss: 0.8991 - val_binary_accuracy: 0.6557\n",
      "Epoch 61/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0316 - binary_accuracy: 0.9874 - val_loss: 1.2931 - val_binary_accuracy: 0.7705\n",
      "Epoch 62/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0259 - binary_accuracy: 0.9892 - val_loss: 1.5356 - val_binary_accuracy: 0.7869\n",
      "Epoch 63/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0237 - binary_accuracy: 0.9910 - val_loss: 1.1989 - val_binary_accuracy: 0.7049\n",
      "Epoch 64/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0285 - binary_accuracy: 0.9892 - val_loss: 2.5165 - val_binary_accuracy: 0.8197\n",
      "Epoch 65/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0164 - binary_accuracy: 0.9982 - val_loss: 1.7839 - val_binary_accuracy: 0.8033\n",
      "Epoch 66/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 0.9835 - val_binary_accuracy: 0.6885\n",
      "Epoch 67/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0133 - binary_accuracy: 0.9946 - val_loss: 1.1207 - val_binary_accuracy: 0.6066\n",
      "Epoch 68/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 1.6664 - val_binary_accuracy: 0.8033\n",
      "Epoch 69/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0107 - binary_accuracy: 0.9964 - val_loss: 1.2676 - val_binary_accuracy: 0.7377\n",
      "Epoch 70/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0053 - binary_accuracy: 0.9982 - val_loss: 1.4398 - val_binary_accuracy: 0.7705\n",
      "Epoch 71/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0057 - binary_accuracy: 0.9982 - val_loss: 1.1106 - val_binary_accuracy: 0.7541\n",
      "Epoch 72/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0132 - binary_accuracy: 0.9946 - val_loss: 1.9795 - val_binary_accuracy: 0.8197\n",
      "Epoch 73/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0128 - binary_accuracy: 0.9964 - val_loss: 1.5086 - val_binary_accuracy: 0.6230\n",
      "Epoch 74/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0101 - binary_accuracy: 0.9964 - val_loss: 1.7758 - val_binary_accuracy: 0.8033\n",
      "Epoch 75/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0131 - binary_accuracy: 0.9928 - val_loss: 1.0800 - val_binary_accuracy: 0.7213\n",
      "Epoch 76/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0175 - binary_accuracy: 0.9946 - val_loss: 1.1100 - val_binary_accuracy: 0.6885\n",
      "Epoch 77/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 1.2557 - val_binary_accuracy: 0.7377\n",
      "Epoch 78/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0084 - binary_accuracy: 0.9982 - val_loss: 1.1748 - val_binary_accuracy: 0.7869\n",
      "Epoch 79/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0074 - binary_accuracy: 0.9982 - val_loss: 1.4261 - val_binary_accuracy: 0.8197\n",
      "Epoch 80/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0208 - binary_accuracy: 0.9892 - val_loss: 1.5469 - val_binary_accuracy: 0.8197\n",
      "Epoch 81/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0191 - binary_accuracy: 0.9910 - val_loss: 1.0250 - val_binary_accuracy: 0.7213\n",
      "Epoch 82/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 1.6130 - val_binary_accuracy: 0.7705\n",
      "Epoch 83/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0035 - binary_accuracy: 0.9982 - val_loss: 1.5832 - val_binary_accuracy: 0.7213\n",
      "Epoch 84/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0076 - binary_accuracy: 0.9964 - val_loss: 1.3461 - val_binary_accuracy: 0.7705\n",
      "Epoch 85/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0152 - binary_accuracy: 0.9964 - val_loss: 1.4424 - val_binary_accuracy: 0.7869\n",
      "Epoch 86/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0094 - binary_accuracy: 0.9964 - val_loss: 1.2871 - val_binary_accuracy: 0.7377\n",
      "Epoch 87/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0121 - binary_accuracy: 0.9982 - val_loss: 1.6569 - val_binary_accuracy: 0.7869\n",
      "Epoch 88/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.5584 - val_binary_accuracy: 0.7705\n",
      "Epoch 89/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 1.2715 - val_binary_accuracy: 0.7541\n",
      "Epoch 90/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0077 - binary_accuracy: 0.9982 - val_loss: 1.4283 - val_binary_accuracy: 0.7869\n",
      "Epoch 91/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 1.3121 - val_binary_accuracy: 0.7541\n",
      "Epoch 92/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 2.0034 - val_binary_accuracy: 0.5902\n",
      "Epoch 93/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 1.4375 - val_binary_accuracy: 0.7705\n",
      "Epoch 94/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 1.3188 - val_binary_accuracy: 0.6721\n",
      "Epoch 95/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 1.3344 - val_binary_accuracy: 0.7705\n",
      "Epoch 96/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 1.3662 - val_binary_accuracy: 0.7377\n",
      "Epoch 97/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 7.4554e-04 - binary_accuracy: 1.0000 - val_loss: 1.3048 - val_binary_accuracy: 0.7377\n",
      "Epoch 98/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 1.4385 - val_binary_accuracy: 0.7541\n",
      "Epoch 99/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 1.3940 - val_binary_accuracy: 0.7541\n",
      "Epoch 100/100\n",
      "554/554 [==============================] - 2s 4ms/sample - loss: 0.0046 - binary_accuracy: 0.9982 - val_loss: 2.0572 - val_binary_accuracy: 0.6230\n",
      "accuracy for model 10 is 62.29507923126221\n",
      "Training Testing Accuracy: 79.48% (8.75%)\n"
     ]
    }
   ],
   "source": [
    "best_DNN = eval_dnn(tt_vcf, tt_pheno, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout accuracy is 80.51947951316833\n"
     ]
    }
   ],
   "source": [
    "bs = ((ho_vcf.shape[0])/40)\n",
    "bs = round(bs)\n",
    "_, accuracy = best_DNN.evaluate(ho_vcf, ho_pheno, batch_size=bs, verbose=0)\n",
    "print(\"Holdout accuracy is \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = []\n",
    "results = []\n",
    "highest = 0\n",
    "i = 1\n",
    "while(i<6):\n",
    "    seed = randint(0,5000)\n",
    "    #divide up the training and testing data here\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tt_vcf, tt_pheno, test_size=0.2, random_state=seed)\n",
    "    #del my_list #to save memory\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "\n",
    "    #might need to reshape it??\n",
    "    #reshape into (examples, input snps, 1)\n",
    "    #A is x_train, B is x_test\n",
    "    # I think this is traditionally because CNNs are image data which use 3 dimensional input data?\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    model = build_DNN_model()\n",
    "    bs = ((X_train.shape[0])/20)\n",
    "    bs = round(bs)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=bs)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, batch_size=bs, verbose=0)\n",
    "    print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "    if(accuracy > highest):\n",
    "        highest = accuracy\n",
    "        best_model = model\n",
    "    results.append(accuracy)\n",
    "    i = i + 1\n",
    "print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results*100), np.std(results*100))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results)*100, np.std(results)*100)) \n",
    "bs = ((ho_vcf.shape[0])/20)\n",
    "bs = round(bs)\n",
    "_, accuracy = model.evaluate(ho_vcf, ho_pheno, batch_size=bs, verbose=0)\n",
    "print(\"Holdout accuracy is \" + str(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_DNN()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=my_DNN, epochs=50, batch_size=64, verbose=1)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, vcf, pheno, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
