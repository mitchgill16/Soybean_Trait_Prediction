{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT STATEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.3)\n",
      "Requirement already satisfied: sklearn in ./.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: xgboost in ./.local/lib/python3.6/site-packages (1.3.1)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.6/site-packages (3.3.3)\n",
      "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0+nv)\n",
      "Requirement already satisfied: keras==2.2.4 in ./.local/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: fastai in ./.local/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (2.8.1)\n",
      "Requirement already satisfied: scikit-optimize in ./.local/lib/python3.6/site-packages (0.8.1)\n",
      "Requirement already satisfied: scikit-learn==0.21 in ./.local/lib/python3.6/site-packages (0.21.0)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.6/site-packages (0.16)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./.local/lib/python3.6/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.local/lib/python3.6/site-packages (from matplotlib) (8.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.6/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./.local/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.11.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in ./.local/lib/python3.6/site-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
      "Requirement already satisfied: spacy in ./.local/lib/python3.6/site-packages (from fastai) (2.3.5)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastai) (20.0.2)\n",
      "Requirement already satisfied: torch<1.8,>=1.7.0 in ./.local/lib/python3.6/site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.6/site-packages (from fastai) (20.8)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.8 in ./.local/lib/python3.6/site-packages (from fastai) (1.3.18)\n",
      "Requirement already satisfied: torchvision<0.9,>=0.8 in ./.local/lib/python3.6/site-packages (from fastai) (0.8.2)\n",
      "Requirement already satisfied: pyaml>=16.9 in ./.local/lib/python3.6/site-packages (from scikit-optimize) (20.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.6/site-packages (from scikit-optimize) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.11.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (46.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (2.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (4.43.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (3.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (7.4.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.1.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in ./.local/lib/python3.6/site-packages (from torch<1.8,>=1.7.0->fastai) (0.8)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.6/site-packages (from torch<1.8,>=1.7.0->fastai) (3.7.4.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!TMPDIR=/home/mgill/ pip install --cache-dir=/home/mgill/ --build /home/mgill/ pandas numpy sklearn xgboost matplotlib tensorflow==2.1.0 keras==2.2.4 fastai python-dateutil scikit-optimize scikit-learn==0.21 graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mgill/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from random import randint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Activation\n",
    "from math import sqrt\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import interp\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_prep_data(tt_file, ho_file):\n",
    "    imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "    my_list = []\n",
    "    x = 0 \n",
    "    for chunk in pd.read_csv(tt_file, chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "        x=x+10000\n",
    "        chunk = chunk.T\n",
    "        if 'Value' in chunk.columns:\n",
    "            #does the selecting of pheno array for application ML\n",
    "            chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "            tt_pheno = chunk[\"Value\"].to_numpy()\n",
    "            #reshapes it so its not a 1D array\n",
    "            print(tt_pheno.shape)\n",
    "            tt_pheno = np.reshape(tt_pheno,(len(tt_pheno),1))\n",
    "            print(tt_pheno.shape)\n",
    "            chunk = chunk.drop(columns=['Value'])\n",
    "        headers = chunk.columns\n",
    "        row_idx = chunk.index\n",
    "        chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "        #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "        chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "        my_list.append(chunk)\n",
    "        print(x)\n",
    "    tt_vcf = pd.concat(my_list, axis = 1)\n",
    "    my_list = []\n",
    "    x=0\n",
    "    for chunk in pd.read_csv(ho_file, chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "        x=x+10000\n",
    "        chunk = chunk.T\n",
    "        if 'Value' in chunk.columns:\n",
    "            #does the selecting of pheno array for application ML\n",
    "            chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "            ho_pheno = chunk[\"Value\"].to_numpy()\n",
    "            #reshapes it so its not a 1D array\n",
    "            print(ho_pheno.shape)\n",
    "            ho_pheno = np.reshape(ho_pheno,(len(ho_pheno),1))\n",
    "            print(ho_pheno.shape)\n",
    "            chunk = chunk.drop(columns=['Value'])\n",
    "        headers = chunk.columns\n",
    "        row_idx = chunk.index\n",
    "        chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "        #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "        chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "        my_list.append(chunk)\n",
    "        print(x)\n",
    "    ho_vcf = pd.concat(my_list, axis = 1)\n",
    "    print(tt_vcf.shape)\n",
    "    print(ho_vcf.shape)\n",
    "    return tt_vcf, ho_vcf, tt_pheno, ho_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data(\"SCC_Merged_filtered.csv_train_test.csv_5pcnt.csv\", \"SCC_Merged_filtered.csv_holdout.csv_5pcnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if it hasn't been run and saved before\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "ohe = ohe.fit(tt_vcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ohe, open(\"SCC_ohe.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if need or have new holdout data etc.\n",
    "ohe = pickle.load(open(\"SCC_ohe.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_vcf.shape)\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_snp_from_header(ohe,snp_num):\n",
    "    count = 0\n",
    "    snp = \"Not found\"\n",
    "    found = False\n",
    "    i = 0\n",
    "    while i < len(ohe.categories_) and (found == False):\n",
    "        j = 0\n",
    "        while j < len(ohe.categories_[i]):\n",
    "            if(count == snp_num):\n",
    "                snp = ohe.categories_[i][j]\n",
    "                found = True\n",
    "                break\n",
    "            count = count + 1\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    return snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T/C\n"
     ]
    }
   ],
   "source": [
    "## TESTING IF IT WORKS\n",
    "my_snp = find_snp_from_header(ohe, 462793)\n",
    "print(my_snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_vcf.shape)\n",
    "print(tt_pheno.shape)\n",
    "seed = randint(0,5000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tt_vcf, tt_pheno, test_size=0.2, random_state=seed)\n",
    "print(X_test.shape)\n",
    "print(\"seed is \" + str(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'max_depth': Integer(0, 50),\n",
    "        'max_delta_step': Integer(0, 20),\n",
    "        'subsample': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': Real(0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': Real(1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 5),\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'scale_pos_weight': Real(1e-6, 500, 'log-uniform')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    \"\"\"\n",
    "    Callback meant to view scores after\n",
    "    each iteration while performing Bayesian\n",
    "    Optimization in Skopt\"\"\"\n",
    "    score = xgb_bayes_search.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "    if score >= 0.98:\n",
    "        print('Interrupting!')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbcl = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "xgb_bayes_search = BayesSearchCV(xgbcl, space, n_iter=32, # specify how many iterations\n",
    "                                    scoring=None, n_jobs=1, cv=5, verbose=3, random_state=42, n_points=12,\n",
    "                                 refit=True)\n",
    "xgb_bayes_search.fit(X_train, y_train.ravel(), callback = on_step)\n",
    "print(xgb_bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb_bayes_search.best_params_)\n",
    "model = xgb.XGBClassifier(**xgb_bayes_search.best_params_, objective='multi:softmax', num_class=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##if not in same run as optimisation\n",
    "best_params = OrderedDict([('colsample_bylevel', 0.25617325301227906), ('colsample_bytree', 0.7083937150495909), ('gamma', 2.41812432168581e-07), ('learning_rate', 0.13965555720269418), ('max_delta_step', 10), ('max_depth', 27), ('min_child_weight', 1), ('n_estimators', 76), ('reg_alpha', 3.178148842971562e-08), ('reg_lambda', 0.005381781269387993), ('scale_pos_weight', 0.23835043249575294), ('subsample', 0.9559763235078597)])\n",
    "model = xgb.XGBClassifier(**best_params, objective='multi:softmax', num_class=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO MORE STUFF HERE when OPTIMISED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_k_fold(m, x, y, k, hx, hy):\n",
    "    #model: xgboost model, should be with the best params available\n",
    "    #x: input data (eg. all samples and SNPS)\n",
    "    #y: labels\n",
    "    #k: number of folds for cross validation\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    fig1 = plt.figure(figsize=[12,12])\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    results = []\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    high = 0\n",
    "    best = m\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        prediction = m.fit(x[train],y[train].ravel()).predict_proba(x[test])\n",
    "        print(\"variables for auroc curve done. Processing fold accuracy + checking best model\")\n",
    "        y_pred = m.predict(x[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        print(\"The accuracy of this model is\" + str(pcent))\n",
    "        if(pcent > high):\n",
    "            high = pcent\n",
    "            best = m\n",
    "       # fpr, tpr, t = roc_curve(y[test], prediction[:, 1])\n",
    "       # tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "       # roc_auc = auc(fpr, tpr)\n",
    "       # aucs.append(roc_auc)\n",
    "        results.append(pcent)\n",
    "       # plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        i= i+1\n",
    "\n",
    "   # plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "   # mean_tpr = np.mean(tprs, axis=0)\n",
    "   # mean_auc = auc(mean_fpr, mean_tpr)\n",
    "   # plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "    #         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "    \n",
    "    holdout_pred = best.predict(hx)\n",
    "    predictions = [round(value) for value in holdout_pred]\n",
    "    #sees how accurate the model was when testing the test set\n",
    "    accuracy = accuracy_score(hy, predictions)\n",
    "    pcent = accuracy * 100.0\n",
    "    print(pcent)\n",
    "    xgb_predictions = best.predict(hx)\n",
    "    xgb_probs = best.predict_proba(hx)[:, 1]\n",
    "    #model_fpr, model_tpr, my_roccy = evaluate_model(xgb_predictions, xgb_probs, hy)\n",
    "    #plt.plot(model_fpr, model_tpr, 'r', label = 'Holdout Data'+my_roccy, lw=2)\n",
    "    \n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC Flower Colour Training Model & Holdout Data')\n",
    "    #plt.legend(loc=\"lower right\")\n",
    "    #plt.show()\n",
    "\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    print(\"Holdout Accuracy: %.2f%%\" % (pcent))\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_vcf.shape)\n",
    "print(tt_pheno.shape)\n",
    "print(ho_vcf.shape)\n",
    "print(ho_pheno.shape)\n",
    " #if optimised in same session, other enter manually below\n",
    "#this function should average out 10 folds and training, with inital params optimised\n",
    "#average accuracy and std should be calculated along with a nice AUROC graph of train/test models\n",
    "#best model should be extracted for use on holdout set\n",
    "best_model = eval_k_fold(model, tt_vcf, tt_pheno, 10, ho_vcf, ho_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_model, open(\"SCC_kfold_10_tt_from_all.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only load if not generated in same session\n",
    "best_model = pickle.load(open(\"SCC_kfold_10_tt_from_all.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO SNPS of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "#best_model = pickle.load(open(\"FC_kfold_10_tt_from_all.pickle.dat\", \"rb\"))\n",
    "plt.figure(figsize = (20, 20))\n",
    "plot_importance(best_model, max_num_features=15, importance_type='gain', height=0.3)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my X value is: 28494\n",
      "(620, 28494)\n",
      "my header list is: 28494\n",
      "my X value is: 57334\n",
      "(620, 28840)\n",
      "my header list is: 57334\n",
      "my X value is: 86364\n",
      "(620, 29030)\n",
      "my header list is: 86364\n",
      "my X value is: 115483\n",
      "(620, 29119)\n",
      "my header list is: 115483\n",
      "my X value is: 144269\n",
      "(620, 28786)\n",
      "my header list is: 144269\n",
      "my X value is: 173493\n",
      "(620, 29224)\n",
      "my header list is: 173493\n",
      "my X value is: 202638\n",
      "(620, 29145)\n",
      "my header list is: 202638\n",
      "my X value is: 231595\n",
      "(620, 28957)\n",
      "my header list is: 231595\n",
      "my X value is: 260443\n",
      "(620, 28848)\n",
      "my header list is: 260443\n",
      "my X value is: 289243\n",
      "(620, 28800)\n",
      "my header list is: 289243\n",
      "my X value is: 318230\n",
      "(620, 28987)\n",
      "my header list is: 318230\n",
      "my X value is: 347155\n",
      "(620, 28925)\n",
      "my header list is: 347155\n",
      "my X value is: 376380\n",
      "(620, 29225)\n",
      "my header list is: 376380\n",
      "my X value is: 405248\n",
      "(620, 28868)\n",
      "my header list is: 405248\n",
      "my X value is: 434615\n",
      "(620, 29367)\n",
      "my header list is: 434615\n",
      "my X value is: 463674\n",
      "(620, 29059)\n",
      "my header list is: 463674\n",
      "my X value is: 492799\n",
      "(620, 29125)\n",
      "my header list is: 492799\n",
      "my X value is: 522018\n",
      "(620, 29219)\n",
      "my header list is: 522018\n",
      "my X value is: 551111\n",
      "(620, 29093)\n",
      "my header list is: 551111\n",
      "my X value is: 580023\n",
      "(620, 28912)\n",
      "my header list is: 580023\n",
      "my X value is: 608962\n",
      "(620, 28939)\n",
      "my header list is: 608962\n",
      "dropping value so it doesn't include that in headers\n",
      "my X value is: 621607\n",
      "(620, 12645)\n",
      "my header list is: 621607\n",
      "621607\n"
     ]
    }
   ],
   "source": [
    "#This function essentially returns an array of dataframe headers the length of OHE'd input SNPs for training data\n",
    "#EG. It will be able to determine that feature 357310 is Gm13_17683957 but not what allele it is\n",
    "#eg. feature 357309 357310 and 357311 may all be one hot encoded versions of all possible values of Gm13_17683957\n",
    "#iterating through the saved OHE will by able to determine what specific allele the feature is but cannot determine\n",
    "#what SNP header it belongs to. Therefore combining these two methods you can determine both allele and SNP\n",
    "snp = []\n",
    "imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "fs_ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "x = 0\n",
    "n_headers = []\n",
    "le = LabelEncoder()\n",
    "#while (i < 10):\n",
    "for chunk in pd.read_csv(\"SCC_Merged_filtered.csv_train_test.csv_5pcnt.csv\", chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "    chunk = chunk.T\n",
    "    if 'Value' in chunk.columns:\n",
    "        print(\"dropping value so it doesn't include that in headers\")\n",
    "        chunk = chunk.drop(columns=['Value'])\n",
    "    headers = chunk.columns\n",
    "    row_idx = chunk.index\n",
    "    chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "    #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "    chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "    chunk = chunk.apply(lambda col: le.fit_transform(col))\n",
    "    c_headers = chunk.columns\n",
    "    y = 0\n",
    "    for column in chunk:\n",
    "        d = (chunk[column].nunique())\n",
    "        n_headers.extend([c_headers[y] for i in range(d)])\n",
    "        #print(n_headers)\n",
    "        #print(l)\n",
    "        #n_headers.append(c_headers[y] * d)\n",
    "        #print(n_headers)\n",
    "        y = y + 1\n",
    "    #to double check that it would indeed be one hot encoded with this amount of columns\n",
    "    chunk = fs_ohe.fit_transform(chunk)\n",
    "    x = x + chunk.shape[1]\n",
    "    print(\"my X value is: \" + str(x))\n",
    "    print(chunk.shape)\n",
    "    print(\"my header list is: \" + str(len(n_headers)))\n",
    "print(len(n_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "fs = [181106,56313,581117,214419,133458,214671,214582,214543,213998,214557,214545,214000,331158,30222,214531]\n",
    "scores = [125,92.7,57.8,34.9,27.5,22.4,20.3,20.2,19.9,16.9,16.8,16.1,15.51,15.5,13.1]\n",
    "snp_label = []\n",
    "for jj in fs:\n",
    "    jj_allele = find_snp_from_header(ohe, jj)\n",
    "    this_snp = (n_headers[jj] + ' ('+str(jj_allele)+')')\n",
    "    print(this_snp)\n",
    "    snp_label.append(this_snp)\n",
    "snp_label.reverse()\n",
    "scores.reverse()\n",
    "print(len(scores))\n",
    "print(len(snp_label))\n",
    "plt.barh(snp_label,scores)\n",
    "plt.title('SNP Importance XGBoost Seed Coat Colour')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = best_model.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_f_header(fn,n_headers,ohe):\n",
    "    fn = fn[1:]\n",
    "    fn = int(fn)\n",
    "    allele = find_snp_from_header(ohe, fn)\n",
    "    this_snp = (n_headers[fn] + ' ('+str(allele)+')')\n",
    "    return this_snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n"
     ]
    }
   ],
   "source": [
    "#convert feature to actual SNP name\n",
    "i = 0\n",
    "new_dict = {}\n",
    "for key in my_dict:\n",
    "    new_key = rename_f_header(key, n_headers, ohe)\n",
    "    new_dict[new_key] = my_dict[key]\n",
    "    i = i + 1\n",
    "    print(str(i))\n",
    "    if(my_dict):\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gm06_48831323 (G/G)    125.047882\n",
      "Gm01_20816751 (C/A)      3.407623\n",
      "Gm08_8792006 (T/T)      22.362222\n",
      "Gm09_40394306 (C/C)     10.705885\n",
      "Gm13_19050182 (C/C)      8.111638\n",
      "                          ...    \n",
      "Gm04_5428280 (T/T)       0.064938\n",
      "Gm08_11806621 (A/A)      0.052873\n",
      "Gm05_36162676 (T/T)      0.085195\n",
      "Gm16_1334966 (C/C)       0.067094\n",
      "Gm10_15082121 (A/A)      0.055978\n",
      "Length: 1815, dtype: float64\n",
      "                     F_Score(GAIN)\n",
      "Gm06_48831323 (G/G)     125.047882\n",
      "Gm01_20816751 (C/A)       3.407623\n",
      "Gm08_8792006 (T/T)       22.362222\n",
      "Gm09_40394306 (C/C)      10.705885\n",
      "Gm13_19050182 (C/C)       8.111638\n",
      "...                            ...\n",
      "Gm04_5428280 (T/T)        0.064938\n",
      "Gm08_11806621 (A/A)       0.052873\n",
      "Gm05_36162676 (T/T)       0.085195\n",
      "Gm16_1334966 (C/C)        0.067094\n",
      "Gm10_15082121 (A/A)       0.055978\n",
      "\n",
      "[1815 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "new_fi = pd.Series(new_dict)\n",
    "print(new_fi)\n",
    "df = new_fi.to_frame()\n",
    "df = df.rename(columns = {0:'F_Score(GAIN)'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "indexes = df.nlargest(20, \"F_Score(GAIN)\").index\n",
    "values = df.nlargest(20, \"F_Score(GAIN)\").values.ravel()\n",
    "indexes = indexes[::-1]\n",
    "values = values[::-1]\n",
    "plt.barh(indexes, values)\n",
    "plt.title('SNP Importance XGBoost Seed Coat Colour')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9gAAANICAYAAAA8TEcyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1yVdf8/8NcB4XCQ4QBRQFFERXGLAzXNQtDIUZoLc6+SwsxF4u3K3Hr3dWADUXPbVxI1FQeaA3NiuRAURwpUjsMUEd6/P/xy/bw8jIOdMuv1fDyux831+bw/47rOkbs3n2toRERARERERERERH+I2YueABEREREREdE/ARNsIiIiIiIiIhNggk1ERERERERkAkywiYiIiIiIiEyACTYRERERERGRCTDBJiIiIiIiIjIBJthEREREREREJsAEm4iIiIiIiMgEmGATERERERERmQATbCIiIiL6w1atWgWNRoPr16+/6Kn87fFcEf1zMcEmIqI/1c8//4yePXvCzc0NVlZWcHFxQceOHbFkyRJVXPXq1aHRaPDBBx8Y9HHw4EFoNBp8++23SlnBf6AWbFZWVqhduzaCgoKQmppa4rw0Gg2CgoL++AG+IMeOHcO0adPw4MGDFz2VP+zhw4fw8PCAp6cnHj16ZFDfuXNn2Nvb486dO6ryX3/9FZMmTUKDBg1gY2MDKysreHh4YPDgwThy5Igq9tnvi0ajQaVKldChQwfs2rXrTz0+Y2RlZWHatGk4ePCg0W2uX7+OwYMHo2bNmrCyskLlypXRrl07TJ069c+bqAnFxcWhf//+qFq1KrRaLSpUqABfX19EREQgLy/vTxt3+fLlWLVqVanaPHz4EIsXL0bLli1hb2+v+n1z5cqVP2eiRPRSKvOiJ0BERP9cx44dQ4cOHVCtWjUMHz4clStXxq1bt3D8+HF8/vnnhSbTX331FUJCQuDs7GzUGDNmzECNGjXw8OFDHDlyBGFhYfj+++9x/vx5WFtbm/qQ/jaOHTuG6dOnY9CgQShXrtyLns4fYmVlhbCwMPj5+WH27NmqBHHjxo3YvXs3lixZovpOnDhxAgEBAUhPT0efPn0watQoaLVaJCUl4bvvvsOqVatw6NAhtGvXTjVWwfdFRJCamopVq1bhjTfewPbt2/Hmm2/+Zcf8rKysLEyfPh0A8Oqrr5YYn5iYiObNm0On02HIkCGoXr06kpOTcebMGcydO1fp6+/q66+/xqhRo+Dk5IR3330XtWrVQnp6Ovbv34+hQ4ciOTkZn3zyyZ8y9vLly+Hg4IBBgwYZFf/777+jU6dOOH36NN58803069cPNjY2iI+Px8aNG/Hll18W+ochIvp3YoJNRER/mlmzZsHe3h4nT540SAJ//fVXg3gvLy/Ex8djzpw5+J//+R+jxujcuTO8vb0BAMOGDUPFihWxaNEibNu2DX379v3Dx/B3k5mZibJly77oaZhcx44d0a9fP8yePRt9+/ZF7dq18eDBA3z00Udo3rw53n//fSX2/v376N69O8qUKYO4uDh4enqq+vr000+xceNG6HQ6g3Ge/r4AwNChQ+Hk5IQNGza80AS7tBYvXoyMjAzExcXBzc1NVVfYv62/k+PHj2PUqFHw8fHB999/D1tbW6VuzJgxOHXqFM6fP/8CZ6g2aNAgnD17Ft9++y169Oihqps5cyYmT578gmZWeg8fPoSlpSXMzHgRK9Gfhf+6iIjoT3P16lV4eXkVusJaqVIlg7Lq1atjwIAB+OqrrwwuBzbWa6+9BgBISkoqVbuCy9A3b96M6dOnw8XFBba2tujZsyf0ej1ycnIwZswYVKpUCTY2Nhg8eDBycnJUfRRcdr5u3TrUqVMHVlZWaNasGX744QeD8c6ePYvOnTvDzs4ONjY2eP3113H8+HFVTMFlzYcOHcL777+PSpUqwdXVFdOmTcP48eMBADVq1FAueS64nzMiIgKvvfYaKlWqBK1Wi3r16iEsLMxgDtWrV8ebb76JI0eOoEWLFrCysoK7uzvWrFljEFuQ7FavXh1arRaurq4YMGAAfv/9dyUmJycHU6dOhYeHB7RaLapWrYoJEyYYnKeiLF68GNbW1hg1ahQAYNKkSfjtt9/wxRdfqBKCFStWIDk5Gf/9738NkmvgyefQt29fNG/evMQxy5UrB51OhzJl1GsOmZmZ+Pjjj5XLl+vUqYMFCxZARFRxjx8/xsyZM1GzZk1otVpUr14dn3zyicExnzp1Cv7+/nBwcIBOp0ONGjUwZMgQAE8u9XZ0dAQATJ8+Xfk8p02bVuS8r169CldXV4PkGij839auXbvwyiuvoGzZsrC1tUVAQAAuXLhgEHf58mX07NkTFSpUgJWVFby9vREVFWUQd+HCBbz22mvQ6XRwdXXFp59+ivz8/CLn+7SCY1y3bp0quS7g7e2tWl029rMw5ntfvXp1XLhwAYcOHVLOc3FXDPz444/YuXMnhg4dapBcA4BWq8WCBQtUZQcOHFDOdbly5dCtWzdcunTJiDPzZHXdy8sLWq0Wzs7OGD16tMFtINWrVy909f3VV19VHUvB77SNGzciNDQULi4usLa2RlpamlFzIaLnwxVsIiL607i5uSE2Nhbnz59H/fr1jWozefJkrFmzplSr2E+7evUqAKBixYqlbgsAs2fPhk6nw6RJk5CYmIglS5bAwsICZmZmuH//PqZNm4bjx49j1apVqFGjBv7zn/+o2h86dAibNm3Chx9+CK1Wi+XLl6NTp044ceKEcg4uXLiAV155BXZ2dpgwYQIsLCzwxRdf4NVXX8WhQ4fQsmVLVZ/vv/8+HB0d8Z///AeZmZno3Lkzrly5gg0bNmDx4sVwcHAAACVJCwsLg5eXF7p27YoyZcpg+/bteP/995Gfn4/Ro0er+k5MTETPnj0xdOhQDBw4ECtXrsSgQYPQrFkzeHl5AQAyMjLwyiuv4NKlSxgyZAiaNm2K33//HVFRUfjll1/g4OCA/Px8dO3aFUeOHMGIESNQt25d/Pzzz1i8eDGuXLmC7777rsRzX6lSJcyZMwcjR47EBx98gC+//BJjxoxBkyZNVHHbt2+HTqfD22+/bfwH+3/0ej1+//13iAh+/fVXLFmyBBkZGejfv78SIyLo2rUrYmJiMHToUDRu3Bh79uzB+PHjcfv2bSxevFiJHTZsGFavXo2ePXvi448/xo8//ojZs2fj0qVLiIyMBPBkRdnPzw+Ojo6YNGkSypUrh+vXr2Pr1q3K5xYWFob33nsPb731lnJcDRs2LPI43NzcsG/fPhw4cED5o1JRvvnmGwwcOBD+/v6YO3cusrKyEBYWhrZt2+Ls2bOoXr06gCffyzZt2sDFxQWTJk1C2bJlsXnzZnTv3h3/+7//i7feegsAkJKSgg4dOuDx48dK3JdfflnoFQPPysrKwv79+9GuXTtUq1atxPjSfBbGfO//+9//4oMPPoCNjY2y8uzk5FTk+AV/XHj33XdLnCsA7Nu3D507d4a7uzumTZuG7OxsLFmyBG3atMGZM2eUc12YadOmYfr06fD19cV7772H+Ph4hIWF4eTJkzh69CgsLCyMmsOzZs6cCUtLS4wbNw45OTmwtLR8rn6IyEhCRET0J4mOjhZzc3MxNzcXHx8fmTBhguzZs0cePXpkEOvm5iYBAQEiIjJ48GCxsrKSO3fuiIhITEyMAJAtW7Yo8REREQJA9u3bJ7/99pvcunVLNm7cKBUrVhSdTie//PJLsXMDIKNHj1b2C8aoX7++an59+/YVjUYjnTt3VrX38fERNzc3gz4ByKlTp5SyGzduiJWVlbz11ltKWffu3cXS0lKuXr2qlN25c0dsbW2lXbt2BsfYtm1befz4sWqs+fPnCwBJSkoyOLasrCyDMn9/f3F3d1eVubm5CQD54YcflLJff/1VtFqtfPzxx0rZf/7zHwEgW7duNeg3Pz9fRES++eYbMTMzk8OHD6vqV6xYIQDk6NGjBm0Lk5+fL23atBEAUrVqVUlPTzeIKV++vDRu3NigPC0tTX777Tdly8jIUOoKzuWzm1arlVWrVqn6+e677wSAfPrpp6rynj17ikajkcTERBERiYuLEwAybNgwVdy4ceMEgBw4cEBERCIjIwWAnDx5ssjj/u233wSATJ06tfgT9H/Onz8vOp1OAEjjxo0lODhYvvvuO8nMzFTFpaenS7ly5WT48OGq8pSUFLG3t1eVv/7669KgQQN5+PChUpafny+tW7eWWrVqKWVjxowRAPLjjz8qZb/++qvY29sX+Z0scO7cOQEgwcHBRh2nsZ+FiPHfey8vL2nfvr1R47/11lsCQO7fv29UfOPGjaVSpUpy9+5dpezcuXNiZmYmAwYMUMoKvo8F5+rXX38VS0tL8fPzk7y8PCVu6dKlAkBWrlyplLm5ucnAgQMNxm7fvr3quAp+p7m7uxd6bojoz8FLxImI6E/TsWNHxMbGomvXrjh37hzmzZsHf39/uLi4FHrZaYHQ0FA8fvwYc+bMKXEMX19fODo6omrVqujTpw9sbGwQGRkJFxeX55rzgAEDVCtFLVu2hIgol/M+XX7r1i08fvxYVe7j44NmzZop+9WqVUO3bt2wZ88e5OXlIS8vD9HR0ejevTvc3d2VuCpVqqBfv344cuSIwSWcw4cPh7m5udHH8PRKYsGKbfv27XHt2jXo9XpVbL169fDKK68o+46OjqhTpw6uXbumlP3v//4vGjVqpKxgPk2j0QAAtmzZgrp168LT0xO///67shWsrsbExBg1d41GgwoVKgB4ci5tbGwMYtLS0gotf/fdd+Ho6KhsEydONIhZtmwZ9u7di71792Lt2rXo0KEDhg0bpqwmA8D3338Pc3NzfPjhh6q2H3/8MUREeer4999/DwAYO3asQRwA7Ny5EwCUWyR27NiB3Nxco85DSby8vJSncF+/fh2ff/45unfvDicnJ3z11VdK3N69e/HgwQP07dtX9bmYm5ujZcuWyudy7949HDhwAL169UJ6eroSd/fuXfj7+yMhIQG3b99WjrtVq1Zo0aKFMo6joyMCAwNLnHfBd7uwS8MLY+xnAZTue2+s0sw3OTkZcXFxGDRokPIdBp5cidCxY0fl+1KYffv24dGjRxgzZozqdojhw4fDzs5O+S49j4EDBxp1dQERmQYTbCIi+lM1b94cW7duxf3793HixAmEhIQgPT0dPXv2xMWLFwtt4+7ujnfffRdffvklkpOTi+2/IGGKiYnBxYsXce3aNfj7+z/3fJ+9bNXe3h4AULVqVYPy/Px8g/9wr1WrlkGftWvXRlZWFn777Tf89ttvyMrKQp06dQzi6tati/z8fNy6dUtVXqNGjVIdw9GjR+Hr66vcA+ro6Kg8kfnZ+RZ2mW758uVx//59Zf/q1aslXuKfkJCACxcuqBJcR0dH1K5dG4DxD97aunUrtm/fjvr162PLli04fPiwQYytrS0yMjIMymfMmKEkz0Vp0aIFfH194evri8DAQOzcuRP16tVDUFCQ8iToGzduwNnZ2SCpqlu3rlJf8L9mZmbw8PBQxVWuXBnlypVT4tq3b48ePXpg+vTpcHBwQLdu3RAREWH0velFqV27Nr755hv8/vvv+Omnn/DZZ5+hTJkyGDFiBPbt2wfgyecCPHk2wbOfTXR0tPK5JCYmQkQwZcoUg7iCp7oXxN64caPQ73lh3+ln2dnZAQDS09ONOkZjPwugdN97Y5VmvgVzKerf9u+//47MzMxStbW0tIS7u7vqOEurtL8/iOiP4T3YRET0l7C0tETz5s3RvHlz1K5dG4MHD8aWLVuKfGfv5MmT8c0332Du3Lno3r17kf22aNFC9VToP6qoleKiyuWZBy39GUqz+nT16lW8/vrr8PT0xKJFi1C1alVYWlri+++/x+LFiw0eRGWq48rPz0eDBg2waNGiQuuf/QNFYdLT0/Hhhx+iWbNmiImJQcOGDfHee+/h7NmzqqsKPD09ce7cOeTm5qrKi7tnuShmZmbo0KEDPv/8cyQkJCj3nZdGwSp+cfXffvstjh8/ju3bt2PPnj0YMmQIFi5ciOPHjxe6Gl8a5ubmaNCgARo0aAAfHx906NAB69atg6+vr/J5f/PNN6hcubJB24KHuxXEjRs3rsg/UD37h4Tn4eHhgTJlyuDnn3/+w309rbTfe2MVPETv559/Vl3p8SIV9X3Ly8sr9N8zV6+J/lpMsImI6C9XkBAXtzpds2ZN9O/fH1988YXBQ7/+zgpWDJ925coVWFtbKw8hs7a2Rnx8vEHc5cuXYWZmZlQyWtR/ZG/fvh05OTmIiopSrU4be4l2YWrWrFnia5Nq1qyJc+fO4fXXXy8x4SxKaGgokpOTsW3bNtja2mLJkiXo0qULFi5ciEmTJilxb775Jo4fP47IyEj06tXrucZ6WsFl/gWr4gUPEEtPT1etnF6+fFmpL/jf/Px8JCQkKCuqAJCamooHDx4YPOG7VatWaNWqFWbNmoX169cjMDAQGzduxLBhw577nD3r2X9bNWvWBPDkAXK+vr5Ftiu4XcHCwqLYOODJcRf2PS/sO/0sa2trvPbaazhw4ABu3bpV4nfd2M+iNN/70pzrLl26YPbs2Vi7dm2JCXbBXIr6t+3g4FDkK/aebvv0rSOPHj1CUlKS6jMpX768wZPFgSer4E+3JaIXg5eIExHRnyYmJqbQldCCexFLuqQ0NDQUubm5mDdv3p8yvz9DbGwszpw5o+zfunUL27Ztg5+fH8zNzWFubg4/Pz9s27ZNea0W8CQpW79+Pdq2batcllqcgv9Qf/Y/tAtWsJ4+73q9HhEREc99TD169MC5c+eUp2I/rWCcXr164fbt26r7fwtkZ2cXeWlsgdOnT2PZsmUICgpS7mF/88038dZbb2HmzJmqS2Tfe+89ODk54aOPPsKVK1eKnJMxcnNzER0dDUtLSyVJfuONN5CXl4elS5eqYhcvXgyNRoPOnTsrccCTJ1M/rWAVPyAgAMCT93Y/O6fGjRsDgHKZuLW1NQDDz7Mohw8fLvR+7mf/bfn7+8POzg6fffZZofG//fYbgCcJ+Kuvvoovvvii0D98FcQBT477+PHjOHHihKp+3bp1Rs196tSpEBG8++67hV7qf/r0aaxevVoZy5jPojTf+7Jlyxp9nn18fNCpUyd8/fXXhT4J/9GjRxg3bhyAJ89RaNy4MVavXq3q//z584iOjla+L4Xx9fWFpaUl/ud//kd1DOHh4dDr9cp3CXjyR5Pjx48rtzQAT+7vf/bWEiJ6MbiCTUREf5oPPvgAWVlZeOutt+Dp6YlHjx7h2LFj2LRpE6pXr47BgwcX275gFbvgP7ZfBvXr14e/v7/qNV3Ak3f/Fvj000+xd+9etG3bFu+//z7KlCmDL774Ajk5OUb/MaEgCZ08eTL69OkDCwsLdOnSBX5+frC0tESXLl0wcuRIZGRk4KuvvkKlSpVKvJ+9KOPHj8e3336Ld955B0OGDEGzZs1w7949REVFYcWKFWjUqBHeffddbN68GaNGjUJMTAzatGmDvLw8XL58GZs3b8aePXuKvJQ/Ly8PI0aMQOXKlfHpp5+q6j7//HPUq1cPH3zwgfJgvAoVKiAyMhJdunRBo0aN0KdPHzRv3hwWFha4desWtmzZAqDw+8t37dqlrH7++uuvWL9+PRISEjBp0iTlDxtdunRBhw4dMHnyZFy/fh2NGjVCdHQ0tm3bhjFjxiirwo0aNcLAgQPx5Zdf4sGDB2jfvj1OnDiB1atXo3v37ujQoQMAYPXq1Vi+fDneeust1KxZE+np6fjqq69gZ2enJF06nQ716tXDpk2bULt2bVSoUAH169cv8t73uXPn4vTp03j77beVS+PPnDmDNWvWoEKFChgzZgyAJ/cQh4WF4d1330XTpk3Rp08fODo64ubNm9i5cyfatGmjJK/Lli1D27Zt0aBBAwwfPhzu7u5ITU1FbGwsfvnlF5w7dw4AMGHCBHzzzTfo1KkTgoODldd0ubm54aeffirp64TWrVtj2bJleP/99+Hp6Yl3330XtWrVQnp6Og4ePIioqCjle2DsZ1Ga732zZs0QFhaGTz/9FB4eHqhUqVKxrzpbs2YN/Pz88Pbbb6NLly54/fXXUbZsWSQkJGDjxo1ITk5W3oU9f/58dO7cGT4+Phg6dKjymi57e/ti32vu6OiIkJAQTJ8+HZ06dULXrl0RHx+P5cuXo3nz5qrXyA0bNgzffvstOnXqhF69euHq1atYu3atci6I6AV7EY8uJyKif4ddu3bJkCFDxNPTU2xsbMTS0lI8PDzkgw8+kNTUVFXs06/pelpCQoKYm5sX+Zqu4l59VBwU8Zqup8cobpypU6cKAPntt98M+ly7dq3UqlVLtFqtNGnSRGJiYgzGP3PmjPj7+4uNjY1YW1tLhw4d5NixY0aNXWDmzJni4uIiZmZmqlf+REVFScOGDcXKykqqV68uc+fOlZUrVxq8Qqmoc/7s635ERO7evStBQUHi4uIilpaW4urqKgMHDpTff/9diXn06JHMnTtXvLy8RKvVSvny5aVZs2Yyffp00ev1hR6DiMjixYsFgHz77beF1i9YsKDQ14QlJyfL+PHjpV69eqLT6USr1Yq7u7sMGDBA9eoxkcJf02VlZSWNGzeWsLAw5XVjBdLT0+Wjjz4SZ2dnsbCwkFq1asn8+fMN4nJzc2X69OlSo0YNsbCwkKpVq0pISIjqVVdnzpyRvn37SrVq1USr1UqlSpXkzTffVL3OTUTk2LFj0qxZM7G0tCzxlV1Hjx6V0aNHS/369cXe3l4sLCykWrVqMmjQINXr3wrExMSIv7+/2Nvbi5WVldSsWVMGDRpkMIerV6/KgAEDpHLlymJhYSEuLi7y5ptvGnw2P/30k7Rv316srKzExcVFZs6cKeHh4SW+putpp0+fln79+innuHz58vL666/L6tWrVa+qMvazMPZ7n5KSIgEBAWJraysAjHplV1ZWlixYsECaN2+u/C6rVauWfPDBB6pXhYmI7Nu3T9q0aSM6nU7s7OykS5cucvHiRVXMs6/pKrB06VLx9PQUCwsLcXJykvfee6/QV4QtXLhQXFxcRKvVSps2beTUqVNFvqbr2d9pRPTn0oj8BU9nISIi+hfQaDQYPXq0weWsRERE9O/Ae7CJiIiIiIiITIAJNhEREREREZEJMMEmIiIiIiIiMgE+RZyIiMhE+FgTIiKifzeuYBMRERERERGZABNsIiIiIiIiIhPgJeJERcjPz8edO3dga2sLjUbzoqdDREREREQviIggPT0dzs7OMDMrep2aCTZREe7cuYOqVau+6GkQEREREdHfxK1bt+Dq6lpkPRNsoiLY2toCePKPyM7O7gXPhoiIiIiIXpS0tDRUrVpVyRGKwgSbqAgFl4Xb2dkxwSYiIiIiohJvHeVDzoiIiIiIiIhMgAk2ERERERERkQkwwSYiIiIiIiIyASbYRERERERERCbABJuIiIiIiIjIBJhgExEREREREZkAE2wiIiIiIiIiE2CCTURERERERGQCTLCJiIiIiIiITIAJNhEREREREZEJMMEmIiIiIiIiMgEm2EREREREREQmwASbiIiIiIiIyASYYBMRERERERGZABNsIiIiIiIiIhNggk1ERERERERkAkywiYiIiIiIiEyACTYRERERERGRCTDBJiIiIiIiIjIBJthEREREREREJsAEm4iIiIiIiMgEmGATERERERERmQATbCIiIiIiIiITYIJNREREREREZAJMsImIiIiIiIhMgAk2ERERERERkQkwwSYiIiIiIiIyASbYRERERERERCbABJuIiIiIiIjIBJhgExEREREREZkAE2wiIiIiIiIiEyjzoidA9Hdnb/+iZ0D0chF50TMgIiIiejG4gk1ERERERERkAkywiYiIiIiIiEyACTYRERERERGRCTDBJiIiIiIiIjIBJthEREREREREJsAEm4iIiIiIiMgEmGATERERERERmQATbCIiIiIiIiITYIJNf5n4+HhUrlwZ6enpf+m4Fy9ehKurKzIzM//ScYmIiIiI6N/lb59gp6SkIDg4GB4eHrCysoKTkxPatGmDsLAwZGVl/eH+Dx48iKZNm0Kr1cLDwwOrVq1S1efl5WHKlCmoUaMGdDodatasiZkzZ0JEjOo/IyMDQUFBcHV1hU6nQ7169bBixQpVzMiRI1GzZk3odDo4OjqiW7duuHz5sirmww8/RLNmzaDVatG4cWODca5fvw6NRmOwHT9+XIlZtWqVQb2VlZVSn5ubi4kTJ6JBgwYoW7YsnJ2dMWDAANy5c0c11pUrV9CtWzc4ODjAzs4Obdu2RUxMTInnIiQkBB988AFsbW2VMhHBV199BR8fH9jZ2cHGxgZeXl4IDg5GYmKiQR/Tp09H//79lf2zZ8+id+/eqFKlCrRaLdzc3PDmm29i+/btymdUr149tGrVCosWLSpxjkRERERERM/rb51gX7t2DU2aNEF0dDQ+++wznD17FrGxsZgwYQJ27NiBffv2/aH+k5KSEBAQgA4dOiAuLg5jxozBsGHDsGfPHiVm7ty5CAsLw9KlS3Hp0iXMnTsX8+bNw5IlS4waY+zYsdi9ezfWrl2LS5cuYcyYMQgKCkJUVJQS06xZM0RERODSpUvYs2cPRAR+fn7Iy8tT9TVkyBD07t272PH27duH5ORkZWvWrJmq3s7OTlV/48YNpS4rKwtnzpzBlClTcObMGWzduhXx8fHo2rWrqo8333wTjx8/xoEDB3D69Gk0atQIb775JlJSUoqc182bN7Fjxw4MGjRIKRMR9OvXDx9++CHeeOMNREdH4+LFiwgPD4eVlRU+/fRTg362bdumzGfbtm1o1aoVMjIysHr1aly6dAm7d+/GW2+9hdDQUOj1eqXd4MGDERYWhsePHxd7/oiIiIiIiJ6b/I35+/uLq6urZGRkFFqfn5+v/AxAVqxYIQEBAaLT6cTT01OOHTsmCQkJ0r59e7G2thYfHx9JTExU2kyYMEG8vLxUffbu3Vv8/f2V/YCAABkyZIgq5u2335bAwECjjsHLy0tmzJihKmvatKlMnjy5yDbnzp0TAKq5Fpg6dao0atTIoDwpKUkAyNmzZ4vsNyIiQuzt7Y2ad4ETJ04IALlx44aIiPz2228CQH744QclJi0tTQDI3r17i+xn/vz54u3trSrbsGGDAJBt27YV2ubpz1dE5ObNm2JpaSl6vV4yMjKkYsWK8tZbbxU55tPtc3JyRKvVyr59+4o+2Gfo9XoBIIBeAOHGjZuRGxEREdE/TUFuoNfri437265g3717F9HR0Rg9ejTKli1baIxGo1Htz5w5EwMGDEBcXBw8PT3Rr18/jBw5EiEhITh16hREBEFBQUp8bGwsfH19VX34+/sjNjZW2W/dujX279+PK1euAADOnTuHI0eOoHPnzkYdR+vWrREVFYXbt29DRBATE4MrV67Az8+v0PjMzExERESgRo0aqFq1qlFjPK1r166oVKkS2rZtq1olL5CRkQE3NzdUrVoV3bp1w4ULF4rtT6/XQ6PRoFy5cgCAihUrok6dOlizZg0yMzPx+PFjfPHFF6hUqZLBavnTDh8+DG9vb1XZhg0bUKdOHYMV8gLPfr5RUVF49dVXYWdnh+joaNy9excTJkwocsyn21taWqJx48Y4fPhwkfE5OTlIS0tTbURERERERMb62ybYiYmJEBHUqVNHVe7g4AAbGxvY2Nhg4sSJqrrBgwejV69eqF27NiZOnIjr168jMDAQ/v7+qFu3LoKDg3Hw4EElPiUlBU5OTqo+nJyckJaWhuzsbADApEmT0KdPH3h6esLCwgJNmjTBmDFjEBgYaNRxLFmyBPXq1YOrqyssLS3RqVMnLFu2DO3atVPFLV++XDmuXbt2Ye/evbC0tDT2dMHGxgYLFy7Eli1bsHPnTrRt2xbdu3dXJdl16tTBypUrsW3bNqxduxb5+flo3bo1fvnll0L7fPjwISZOnIi+ffvCzs4OwJOkdd++fTh79ixsbW1hZWWFRYsWYffu3ShfvnyR87tx4wacnZ1VZVeuXDH4fMeMGaOcB1dXV1Xd05eHF/zB4+n2J0+eVNra2Nhgx44dqvbOzs6qS+KfNXv2bNjb2yvb8/yBg4iIiIiI/r3+tgl2UU6cOIG4uDh4eXkhJydHVdewYUPl54LEuUGDBqqyhw8flmplcvPmzVi3bh3Wr1+PM2fOYPXq1ViwYAFWr15tVPslS5bg+PHjiIqKwunTp7Fw4UKMHj3a4P7xwMBAnD17FocOHULt2rXRq1cvPHz40Oh5Ojg4YOzYsWjZsiWaN2+OOXPmoH///pg/f74S4+PjgwEDBqBx48Zo3749tm7dCkdHR3zxxRcG/eXm5qJXr14QEYSFhSnlIoLRo0ejUqVKOHz4ME6cOIHu3bujS5cuSE5OLnJ+2dnZqgeqFWXy5MmIi4vDf/7zH2RkZCjlaWlpOHToUJGr3cCTzz8uLg5xcXHK6vrTdDpdsQ/GCwkJgV6vV7Zbt26VOF8iIiIiIqICZV70BIri4eEBjUaD+Ph4Vbm7uzuAJ8nSsywsLJSfCy4PLqwsPz8fAFC5cmWkpqaq+khNTYWdnZ3S//jx45VVbOBJwn7jxg3Mnj0bAwcOLPYYsrOz8cknnyAyMhIBAQEA/n8SuGDBAtXl6QWrprVq1UKrVq1Qvnx5REZGom/fvsWOUZyWLVti7969RdYXrMg/+7TuguT6xo0bOHDggLJ6DQAHDhzAjh07cP/+faV8+fLl2Lt3L1avXo1JkyYVOpaDgwPu37+vKqtVq5bB5+vo6AhHR0dUqlRJVb5r1y7Uq1dPWVWuVasWgCev/mrVqhUAKE+CL8q9e/dQs2bNIuu1Wi20Wm2R9URERERERMX5265gV6xYER07dsTSpUv/tPcX+/j4YP/+/aqyvXv3wsfHR9nPysqCmZn6NJmbmytJenFyc3ORm5tb6vYiAhExWKEvrbi4OFSpUqXI+ry8PPz888+qmILkOiEhAfv27UPFihVVbQpWgJ89JjMzs2KPqUmTJrh48aKqrG/fvoiPj8e2bdtKPJZt27ahW7duyr6fnx8qVKiAuXPnlti2wPnz59GkSROj44mIiIiIiErjb7uCDTxZGW3Tpg28vb0xbdo0NGzYEGZmZjh58iQuX75c7EO1jDFq1CgsXboUEyZMwJAhQ3DgwAFs3rwZO3fuVGK6dOmCWbNmoVq1avDy8sLZs2exaNEiDBkypMT+7ezs0L59e4wfPx46nQ5ubm44dOgQ1qxZo7yT+dq1a9i0aRP8/Pzg6OiIX375BXPmzIFOp8Mbb7yh9JWYmIiMjAykpKQgOzsbcXFxAJ6849nS0hKrV6+GpaWlkkBu3boVK1euxNdff630MWPGDLRq1QoeHh548OAB5s+fjxs3bmDYsGEAniTXPXv2xJkzZ7Bjxw7k5eUpr96qUKECLC0t4ePjg/Lly2PgwIH4z3/+A51Oh6+++kp55VlR/P39MWzYMOTl5cHc3BwA0KdPH2zduhV9+vRBSEgI/P394eTkhBs3bmDTpk1K3OPHj7Fr1y6MGzdO6c/GxgZff/01evfujYCAAHz44YeoVasWMjIysHv3bgBQ2gNP3hN++/Ztg4faERERERERmcyf/TjzP+rOnTsSFBQkNWrUEAsLC7GxsZEWLVrI/PnzJTMzU4kDIJGRkcp+Ya+tiomJEQBy//59VVnjxo3F0tJS3N3dJSIiQjV+WlqaBAcHS7Vq1cTKykrc3d1l8uTJkpOTY9T8k5OTZdCgQeLs7CxWVlZSp04dWbhwofIKqdu3b0vnzp2lUqVKYmFhIa6urtKvXz+5fPmyqp/27dsLAIMtKSlJRERWrVoldevWFWtra7Gzs5MWLVrIli1bVH2MGTNGqlWrJpaWluLk5CRvvPGGnDlzxuCcFbbFxMQocSdPnhQ/Pz+pUKGC2NraSqtWreT7778v9jzk5uaKs7Oz7N69W1Wel5cnK1askJYtW0rZsmWVz2H48OFy8eJFERHZt2+fuLq6FtrvyZMnpWfPnlKpUiUpU6aMVKxYUfz9/WXjxo2q13R99tlnqtevGYOv6eLG7fk2IiIion8aY1/TpRER+evTevo3WrZsGaKiorBnz55Stfvwww/x+PFjLF++/LnGffToEWrVqoX169ejTZs2RrdLS0uDvb09AD0Au5LCiej/8P9ViIiI6J+mIDfQ6/WqZ1Q96299iTj9s4wcORIPHjxAeno6bG1tjW5Xv3591X3xpXXz5k188sknpUquiYiIiIiISosr2H/A4cOH0blz5yLrn37NFL18uIJN9Hz4/ypERET0T8MV7L+At7e38rAxIiIiIiIi+ndjgv0H6HS6Yt+7TERERERERP8ef9v3YBMRERERERG9TJhgExEREREREZkAE2wiIiIiIiIiE+A92EQl0OuBYh4USEREREREBIAr2EREREREREQmwQSbiIiIiIiIyASYYBMRERERERGZABNsIiIiIiIiIhNggk1ERERERERkAkywiYiIiIiIiEyAr+kiKoG9/YueAf1diLzoGRARERHR3xlXsImIiIiIiIhMgAk2ERERERERkQkwwSYiIiIiIiIyASbYRERERERERCbABJuIiIiIiIjIBJhgExEREREREZkAE2wiIiIiIiIiE2CCTURERERERGQCTLDphYqPj0flypWRnp7+p47Tp08fLFy48E8dg4iIiIiI/t1eygQ7JSUFwcHB8PDwgJWVFZycnNCmTRuEhYUhKyvrD/d/8OBBNG3aFFqtFh4eHli1apWqPi8vD1OmTEGNGjWg0+lQs2ZNzJw5EyJiVP8ZGRkICgqCq6srdDod6tWrhxUrVij1169fh0ajKXTbsmWLErd//360bt0atra2qFy5MiZOnIjHjx+rjqNbt26oUqUKypYti8aNG2PdunUG89myZQs8PT1hZWWFBg0a4Pvvv1fViwj+85//oEqVKtDpdPD19UVCQoJBPzt37kTLli2h0+lQvnx5dO/evcRzERISgg8++AC2trYYNGhQkcet0WhQvXp1VdsOHTrA1dW12DYajQYAEBoailmzZkGv15c4JyIiIiIiouciL5mrV69K5cqVxdPTUzZt2iQXL16Uq1evynfffSdvvPGGbNu27Q/1f+3aNbG2tpaxY8fKxYsXZcmSJWJubi67d+9WYmbNmiUVK1aUHTt2SFJSkmzZskVsbGzk888/N2qM4cOHS82aNSUmJkaSkpLkiy++EHNzc2Xujx8/luTkZNU2ffp0sbGxkfT0dBERiYuLE0tLS5k+fbokJCTIwYMHxdPTUz7++GPVPENDQ+Xo0aOSmJgo//3vf8XMzEy2b9+uxBw9elTMzc1l3rx5cvHiRQkNDRULCwv5+eeflZg5c+aIvb29fPfdd3Lu3Dnp2rWr1KhRQ7Kzs5WYb7/9VsqXLy9hYWESHx8vFy5ckE2bNhV7Hm7cuCEWFhbyyy+/iIjIgwcPVMcMQCIiIpT9X3/9VWl79+5dsbCwkOvXr6vauLq6yowZM1RlBby9vWXp0qVGfUYiInq9XgAIoBdAuHEjIiIion+pgtxAr9cXG/fS/Sejv7+/uLq6SkZGRqH1+fn5ys8AZMWKFRIQECA6nU48PT3l2LFjkpCQIO3btxdra2vx8fGRxMREpc2ECRPEy8tL1Wfv3r3F399f2Q8ICJAhQ4aoYt5++20JDAw06hi8vLxkxowZqrKmTZvK5MmTi2zTuHFj1ZghISHi7e2tiomKihIrKytJS0srsp833nhDBg8erOz36tVLAgICVDEtW7aUkSNHisiT81m5cmWZP3++Uv/gwQPRarWyYcMGERHJzc0VFxcX+frrr4sctzDz5883OIanAZDIyMhC69asWSMtW7Y0KHdzc5PFixcX2mb69OnStm3bIsd7+PCh6PV6Zbt165Ywweb29EZERERE/07GJtgv1SXid+/eRXR0NEaPHo2yZcsWGlNwSXCBmTNnYsCAAYiLi4Onpyf69euHkSNHIiQkBKdOnYKIICgoSImPjY2Fr6+vqg9/f3/ExsYq+61bt8b+/ftx5coVAMC5c+dw5MgRdO7c2ajjaN26NaKionD79m2ICGJiYnDlyhX4+fkVGn/69GnExcVh6NChSllOTg6srKxUcTqdDg8fPsTp06eLHFuv16NChQpGH29SUhJSUlJUMfb29mjZsqUSc+bMGdy+fRtmZmZo0qQJqlSpgs6dO+P8+fPFnofDhw/D29u72JiiREVFoVu3bqVq06JFC5w4cQI5OTmF1s+ePRv29vbKVrVq1eeaGxERERER/Tu9VAl2YmIiRAR16tRRlTs4OMDGxgY2NjaYOHGiqm7w4MHo1asXateujYkTJ+L69esIDAyEv78/6tati+DgYBw8eFCJT0lJgZOTk6oPJycnpKWlITs7GwAwadIk9OnTB56enrCwsECTJk0wZswYBAYGGnUcS5YsQb169eDq6gpLS0t06tQJy5YtQ7t27QqNDw8PR926ddG6dWulzN/fH8eOHcOGDRuQl5eH27dvY8aMGQCA5OTkQvvZvHkzTp48icGDB5d4vCkpKUp9QVlRMdeuXQMATJs2DaGhodixYwfKly+PV199Fffu3SvyPNy4cQPOzs5F1hclJycHu3fvRteuXUvVztnZGY8ePVLm/ayQkBDo9Xplu3XrVqnnRkRERERE/14vVYJdlBMnTiAuLg5eXl4Gq5MNGzZUfi5IEhs0aKAqe/jwIdLS0oweb/PmzVi3bh3Wr1+PM2fOYPXq1ViwYAFWr15tVPslS5bg+PHjiIqKwunTp7Fw4UKMHj0a+/btM4jNzs7G+vXrVavXAODn54f58+dj1KhR0Gq1qF27Nt544w0AgJmZ4ccaExODwYMH46uvvoKXl5fRx2qM/Px8AMDkyZPRo0cPNGvWDBEREQYPZXtWdna2wSq8MQ4cOIBKlSqV+jh0Oh0AFPkgPK1WCzs7O9VGRERERERkrDIvegKl4eHhAY1Gg/j4eFW5u7s7gP+fQD3NwsJC+bng8vHCygqSxMqVKyM1NVXVR2pqKuzs7JT+x48fr6xiA08S9hs3bmD27NkYOHBgsceQnZ2NTz75BJGRkQgICADw5I8AcXFxWLBggcHl2t9++y2ysrIwYMAAg77Gjh2Ljz76CMnJyShfvjyuX7+OkJAQ5XwUOHToELp06YLFixcb9FPU8VauXFmpLyirUqWKKqZx48YAoJTXq1dPqddqtXB3d8fNmzeLPBcODg64f/9+kfVFiYqKKvXqNQBlNd3R0bHUbYmIiIiIiEryUq1gV6xYER07dsTSpUuRmZn5p4zh4+OD/fv3q8r27t0LHx8fZT8rK8tgldjc3FxJ0ouTm5uL3Nxco9uHh4eja9euRSaFGo0Gzs7O0Ol02LBhA6pWrYqmTZsq9QcPHkRAQADmzp2LESNGlPp4a9SogcqVK6ti0tLS8OOPPyoxzZo1g1arVf3hIzc3F9evX4ebm1uR56JJkya4ePFikfWFERFs37691PdfA8D58+fh6uoKBweHUrclIiIiIiIqyUu1gg0Ay5cvR5s2beDt7Y1p06ahYcOGMDMzw8mTJ3H58mU0a9bsD/U/atQoLF26FBMmTMCQIUNw4MABbN68GTt37lRiunTpglmzZqFatWrw8vLC2bNnsWjRIgwZMqTE/u3s7NC+fXuMHz8eOp0Obm5uOHToENasWYNFixapYhMTE/HDDz8YvJe6wPz589GpUyeYmZlh69atmDNnDjZv3gxzc3MATy4Lf/PNNxEcHIwePXoo9x5bWloqDzoLDg5G+/btsXDhQgQEBGDjxo04deoUvvzySwBPEvgxY8bg008/Ra1atVCjRg1MmTIFzs7Oynuu7ezsMGrUKEydOhVVq1aFm5sb5s+fDwB45513ijwX/v7+GDZsGPLy8pQ5l+T06dPIyspC27ZtjYp/2uHDh4t8kBwREREREdEf9hc80dzk7ty5I0FBQVKjRg2xsLAQGxsbadGihcyfP18yMzOVOED9mqekpCQBIGfPnlXKYmJiBIDcv39fVda4cWOxtLQUd3d3iYiIUI2flpYmwcHBUq1aNbGyshJ3d3eZPHmy5OTkGDX/5ORkGTRokDg7O4uVlZXUqVNHFi5cqHrFmMiTV3FVrVpV8vLyCu2nQ4cOYm9vL1ZWVtKyZUv5/vvvVfUDBw4UAAZb+/btVXGbN2+W2rVri6WlpXh5ecnOnTtV9fn5+TJlyhRxcnISrVYrr7/+usTHx6tiHj16JB9//LFUqlRJbG1txdfXV86fP1/secjNzRVnZ2fVO8af9uznJyISGhpa7OvQinpNV3Z2ttjb20tsbGyxc3oa34PN7dmNiIiIiP6djH1Nl0ZE5AXl9kRYtmwZoqKisGfPHqPiGzZsiNDQUPTq1atU44SFhSEyMhLR0dFGt0lLS4O9vT0APQA+8IyepNlERERE9O9TkBvo9fpiH4b80l0iTv8sI0eOxIMHD5Ceng5bW9tiYx89eoQePXoY/b7xp1lYWGDJkiXPO00iIiIiIqIScQXbxA4fPlxsApiRkfEXzob+CK5g07P425KIiIjo34kr2C+It7c34uLiXvQ0iIiIiIiI6C/GBNvEdDodPDw8XvQ0iIiIiIiI6C/2Ur0Hm4iIiIiIiOjvigk2ERERERERkQnwEnGiEuj1QDHPMSAiIiIiIgLAFWwiIiIiIiIik2CCTURERERERGQCTLCJiIiIiIiITIAJNhEREREREZEJMMEmIiIiIiIiMgEm2EREREREREQmwNd0EZXA3v5Fz4D+LCIvegZERERE9E/CFWwiIiIiIiIiE2CCTURERERERGQCTLCJiIiIiIiITIAJNhEREREREZEJMMEmIiIiIiIiMgEm2EREREREREQmwASbiIiIiIiIyASYYBMRERERERGZABNseiEePXoEDw8PHDt27C8Zb8WKFejSpctfMhYREREREf07vVQJdkpKCoKDg+Hh4QErKys4OTmhTZs2CAsLQ1ZW1h/u/+DBg2jatCm0Wi08PDywatUqVX1eXh6mTJmCGjVqQKfToWbNmpg5cyZExKj+MzIyEBQUBFdXV+h0OtSrVw8rVqwwiIuNjcVrr72GsmXLws7ODu3atUN2drZS37VrV1SrVg1WVlaoUqUK3n33Xdy5c0fVx549e9CqVSvY2trC0dERPXr0wPXr11UxOTk5mDx5Mtzc3KDValG9enWsXLlSFbNlyxZ4enrCysoKDRo0wPfff28w30uXLqFr166wt7dH2bJl0bx5c9y8ebPYc7FixQrUqFEDrVu3NqgbOXIkzM3NsWXLliLbT58+Hf3791eVzZ49G+bm5pg/f75B/JAhQ3DmzBkcPny42HkRERERERE9N3lJXL16VSpXriyenp6yadMmuXjxoly9elW+++47eeONN2Tbtm1/qP9r166JtbW1jB07Vi5evChLliwRc3Nz2b17txIza9YsqVixouzYsUOSkpJky5YtYmNjI59//rlRYwwfPlxq1qwpMTExkpSUJF988YWYm5ur5n7s2DGxs7OT2bNny/nz5+Xy5cuyadMmefjwoRKzaNEiiY2NlevXr8vRo0fFx8dHfHx8VMei1WolJCREEhMT5fTp09KuXTtp0qSJaj5du3aVli1byt69eyUpKUmOHTsmR44cUeqPHj0q5ubmMm/ePLl48aKEhoaKhYWF/Pzzz0pMYmKiVKhQQcaPHy9nzpyRxMRE2bZtm6SmphZ5HvLz86VWrVqyYcMGg7rMzEyxs7OTSZMmSadOnYrso0mTJrJp0yZVmYeHh0yaNEk8PT0LbTNu3Djp2bNnkX0+S6/XCwAB9AIIt3/gRkRERERkjILcQK/XFxv30vwnpr+/v7i6ukpGRkah9fn5+crPAGTFihUSEBAgOp1OPD095dixY5KQkCDt27cXa2tr8fHxkcTERKXNhAkTxMvLS9Vn7969xd/fX9kPCAiQIUOGqGLefvttCQwMNOoYvLy8ZMaMGaqypk2byuTJk5X9li1bSmhoqFH9Fdi2bZtoNBp59OiRiIhs2bJFypQpI3l5eUpMVFSUKmbXrl1ib28vd+/eLbLfXr16SUBAgKqsZcuWMnLkSGW/d+/e0r9//1LN9+TJk2JmZiZpaWkGdatWrZJWrVrJgwcPxNraWm7evGkQc/PmTbG0tFR9uQ8ePCguLi7y6NEjcXZ2lqNHjxq0O3TokFhaWkpWVpZR82SC/c/fiIiIiIiMYWyC/VJcIn737l1ER0dj9OjRKFu2bKExGo1GtT9z5kwMGDAAcXFx8PT0RL9+/TBy5EiEhITg1KlTEBEEBQUp8bGxsfD19VX14e/vj9jYWGW/devW2L9/P65cuQIAOHfuHI4cOYLOnTsbdRytW7dGVFQUbt++DRFBTEwMrly5Aj8/PwDAr7/+ih9//BGVKlVC69at4eTkhPbt2+PIkSNF9nnv3j2sW7cOrVu3hoWFBQCgWbNmMDMzQ0REBPLy8qDX6/HNN9/A19dXiYmKioK3tzfmzZsHFxcX1K5dG+PGjVNdil7SOcnPz8fOnTtRu3Zt+Pv7o1KlSmjZsiW+++67Ys/D4cOHUbt2bdja2hrUhYeHo3///rC3t0fnzp0NLtMvmPurr74KOzs7Vbu+ffvCwsICffv2RXh4uEE7b29vPH78GD/++GOh88rJyUFaWppqIyIiIiIiMtpfku7/QcePHxcAsnXrVlV5xYoVpWzZslK2bFmZMGGCUg5AtQocGxsrACQ8PFwp27Bhg1hZWSn7tWrVks8++0zV/86dOwWAsuKZl5cnEydOFI1GI2XKlBGNRmPQpjgPHz6UAQMGCAApU6aMWFpayurVqw3mWaFCBVm5cqWcOXNGxowZI5aWlnLlyhVVXxMmTBBra2sBIK1atZLff/9dVX/w4EGpVKmSmJubCwDx8fGR+/fvK/X+/v6i1WolICBAfvzxR9m5c6e4ubnJoEGDlBgLCwtZv369qt9ly5ZJpUqVREQkOTlZAIi1tbUsWrRIzp49K7NnzxaNRiMHDx4s8jwEBwfLa6+9ZlB+5coVsbCwkN9++01ERCIjI6VGjRqqqxNERDp27ChLly5V9vV6veh0OomLixMRkbNnz4qNjY2kp6cbjFG+fHlZtWpVofOaOnWqAChk4wr2P3UjIiIiIjLGP2oFuygnTpxAXFwcvLy8kJOTo6pr2LCh8rOTkxMAoEGDBqqyhw8flmqVcvPmzVi3bh3Wr1+PM2fOYPXq1ViwYAFWr15tVPslS5bg+PHjiIqKwunTp7Fw4UKMHj0a+/btA/BkRRh48pCvwYMHo0mTJli8eDHq1Klj8PCx8ePH4+zZs4iOjoa5uTkGDBgAEQHw5GFww4cPx8CBA3Hy5EkcOnQIlpaW6NmzpxKTn58PjUaDdevWoUWLFnjjjTewaNEirF69WrWKXZyC+Xbr1g0fffQRGjdujEmTJuHNN98s9OFtBbKzs2FlZWVQvnLlSvj7+8PBwQEA8MYbb0Cv1+PAgQNKTFpaGg4dOoSuXbsqZRs2bEDNmjXRqFEjAEDjxo3h5uaGTZs2GYyh0+mKfCBeSEgI9Hq9st26dcuIs0BERERERPREmRc9AWN4eHhAo9EgPj5eVe7u7g7gSdL0rIJLoYH/f/l4YWUFSWLlypWRmpqq6iM1NRV2dnZK/+PHj8ekSZPQp08fAE8S9hs3bmD27NkYOHBgsceQnZ2NTz75BJGRkQgICADw5I8AcXFxWLBgAXx9fVGlShUAQL169VRt69ata/BUbgcHBzg4OKB27dqoW7cuqlatiuPHj8PHxwfLli2Dvb095s2bp8SvXbsWVatWxY8//ohWrVqhSpUqcHFxgb29vWocEcEvv/yCWrVqFXlOKleurMyhTJkyhc63uMvaHRwc8PPPP6vK8vLysHr1aqSkpKBMmTKq8pUrV+L1118HAOzatQv16tVD1apVlZjw8HBcuHBB1S4/Px8rV67E0KFDVePcu3cPjo6Ohc5Lq9VCq9UWOW8iIiIiIqLivBQr2BUrVkTHjh2xdOlSZGZm/ilj+Pj4YP/+/aqyvXv3wsfHR9nPysqCmZn6lJmbmytJenFyc3ORm5tbbPvq1avD2dnZ4A8JV65cgZubW5F9F7QvWMUvap5Px7Zp0wZ37txBRkaGahwzMzO4uroCKPmcWFpaonnz5qWeb5MmTXD58mVlNR0Avv/+e6Snp+Ps2bOIi4tTtg0bNmDr1q148OABAGDbtm3o1q2b0u7nn3/GqVOncPDgQVW7gwcPIjY2FpcvX1Zir169iocPH6JJkyZFzo2IiIiIiOi5/QWXq5tEYmKiODk5iaenp2zcuFEuXrwoly9flm+++UacnJxk7NixSiwAiYyMVPaTkpIEgJw9e1Ypi4mJEQDKfckFr+kaP368XLp0SZYtW2bwmq6BAweKi4uL8pqurVu3ioODg+r+7+K0b99evLy8JCYmRq5duyYRERFiZWUly5cvV2IWL14sdnZ2smXLFklISJDQ0FCxsrJSnnh+/PhxWbJkiZw9e1auX78u+/fvl9atW0vNmjWVV3nt379fNBqNTJ8+Xa5cuSKnT58Wf39/cXNzU+4nT09PF1dXV+nZs6dcuHBBDh06JLVq1ZJhw4Ypczl69KiUKVNGFixYIJcuXZKpU6cavKZr69atYmFhIV9++aUkJCQorzc7fPhwkefh999/N+inW7du0rt3b4PYvLw8qVy5sixdulRyc3OlXLlycvr0aaU+ODhYWrZsWeg4LVq0kHHjxin7ERER4u7uXuS8nsWniP/zNyIiIiIiY/zjXtMlInLnzh0JCgqSGjVqiIWFhdjY2EiLFi1k/vz5kpmZqcQ9T4JdUNa4cWOxtLQUd3d3iYiIUI2flpYmwcHBUq1aNbGyshJ3d3eZPHmy5OTkGDX/5ORkGTRokDg7O4uVlZXUqVNHFi5caPAQr9mzZ4urq6vyOrGnk9WffvpJOnToIBUqVBCtVivVq1eXUaNGyS+//KLqY8OGDdKkSRMpW7asODo6SteuXeXSpUuqmEuXLomvr6/odDpxdXWVsWPHGrzCavPmzVK7dm2xtLQULy8v2blzp8FxhYeHi4eHh1hZWUmjRo3ku+++K/Fc9OrVSyZNmiQiIikpKVKmTBnZvHlzobHvvfeeNGnSRPbt2yeurq5KeU5OjlSsWFHmzZtXaLu5c+dKpUqVlFeT+fn5yezZs0ucWwEm2P/8jYiIiIjIGMYm2BoRkRe1ek7/Xj/99BM6duyIq1evwsbGxqg2H374IR4/fozly5eXerwLFy7gtddew5UrV1T3nRcnLS3t/2L1AOxKCqeXEH/7EREREZExCnIDvV6vel3ws16Kh5zRP0/Dhg0xd+5cJCUlqZ7uXpz69eur7okvjeTkZKxZs8bo5JqIiIiIiKi0uIJtIocPH0bnzp2LrH/6YWL0cuAK9j8ff/sRERERkTG4gv0X8/b2Rlxc3IueBhEREREREb0gTLBNRKfTwcPD40VPg4iIiIiIiF6Ql+I92ERERERERER/d0ywiYiIiIiIiEyACTYRERERERGRCfAebKIS6PVAMQ8KJCIiIiIiAsAVbCIiIiIiIiKTYIJNREREREREZAJMsImIiIiIiIhMgAk2ERERERERkQkwwSYiIiIiIiIyASbYRERERERERCbA13QRlcDe/kXPgP4MIi96BkRERET0T8MVbCIiIiIiIiITYIJNREREREREZAJMsImIiIiIiIhMgAk2ERERERERkQkwwSYiIiIiIiIyASbYRERERERERCbABJuIiIiIiIjIBJhgExEREREREZkAE2x6IeLj41G5cmWkp6f/JeP16dMHCxcu/EvGIiIiIiKif6eXKsFOSUlBcHAwPDw8YGVlBScnJ7Rp0wZhYWHIysr6w/0fPHgQTZs2hVarhYeHB1atWqWqz8vLw5QpU1CjRg3odDrUrFkTM2fOhIgY1X9GRgaCgoLg6uoKnU6HevXqYcWKFaqYV199FRqNRrWNGjVKFfNsvUajwcaNG1UxOTk5mDx5Mtzc3KDValG9enWsXLmy2HE0Gg0CAgKUmNTUVAwaNAjOzs6wtrZGp06dkJCQUOr5FiYkJAQffPABbG1tDeo8PT2h1WqRkpJSZPsOHTrg66+/VpX5+/vD3NwcJ0+eNIgPDQ3FrFmzoNfrS5wbERERERHR8yjzoidgrGvXrqFNmzYoV64cPvvsMzRo0ABarRY///wzvvzyS7i4uKBr167P3X9SUhICAgIwatQorFu3Dvv378ewYcNQpUoV+Pv7AwDmzp2LsLAwrF69Gl5eXjh16hQGDx4Me3t7fPjhhyWOMXbsWBw4cABr165F9erVER0djffffx/Ozs6quQ8fPhwzZsxQ9q2trQ36ioiIQKdOnZT9cuXKqep79eqF1NRUhIeHw8PDA8nJycjPz1fqt27dikePHin7d+/eRaNGjfDOO+8AAEQE3bt3h4WFBbZt2wY7OzssWrQIvr6+uHjxIsqWLVuq+T7t5s2b2LFjB5YsWWJQd+TIEWRnZ6Nnz55YvXo1Jk6caBBz7949HD16VPVHhZs3b+LYsWMICgrCypUr0bx5c1Wb+vXro2bNmli7di1Gjx5d7PyIiIiIiIiei7wk/P39xdXVVTIyMgqtz8/PV34GICtWrJCAgADR6XTi6ekpx44dk4SEBGnfvr1YW1uLj4+PJCYmKm0mTJggXl5eqj579+4t/v7+yn5AQIAMGTJEFfP2229LYGCgUcfg5eUlM2bMUJU1bdpUJk+erOy3b99egoODi+0HgERGRhZZv2vXLrG3t5e7d+8aNS8RkcWLF4utra1yfuPj4wWAnD9/XonJy8sTR0dH+eqrr0o132fNnz9fvL29C60bNGiQTJo0SXbt2iW1a9cuNGbNmjXSsmVLVdm0adOkT58+cunSJbG3t5esrCyDdtOnT5e2bdsaPU+9Xi8ABNALINz+YRsRERERkbEKcgO9Xl9s3Etxifjdu3cRHR2N0aNHq1ZOn6bRaFT7M2fOxIABAxAXFwdPT0/069cPI0eOREhICE6dOgURQVBQkBIfGxsLX19fVR/+/v6IjY1V9lu3bo39+/fjypUrAIBz587hyJEj6Ny5s1HH0bp1a0RFReH27dsQEcTExODKlSvw8/NTxa1btw4ODg6oX78+QkJCCr38ffTo0XBwcECLFi2wcuVK1WXqUVFR8Pb2xrx58+Di4oLatWtj3LhxyM7OLnJu4eHh6NOnj3J+c3JyAABWVlZKjJmZGbRaLY4cOVLq+T7t8OHD8Pb2NihPT0/Hli1b0L9/f3Ts2BF6vR6HDx82iIuKikK3bt2UfRFBREQE+vfvD09PT3h4eODbb781aNeiRQucOHFCObZn5eTkIC0tTbUREREREREZ7S9I9v+w48ePCwDZunWrqrxixYpStmxZKVu2rEyYMEEpByChoaHKfmxsrACQ8PBwpWzDhg1iZWWl7NeqVUs+++wzVf87d+4UAMpqaF5enkycOFE0Go2UKVNGNBqNQZviPHz4UAYMGCAApEyZMmJpaSmrV69WxXzxxReye/du+emnn2Tt2rXi4uIib731lipmxowZcuTIETlz5ozMmTNHtFqtfP7550q9v7+/aLVaCQgIkB9//FF27twpbm5uMmjQoELn9eOPPwoA+fHHH5WyR48eSbVq1eSdd96Re/fuSU5OjsyZM0cAiJ+fX6nm+6xGjRoZrOSLiHz55ZfSuHFjZT84OFgGDhxocA5tbGxUK+vR0dHi6Ogoubm5IvJkNb59+/YG/Z87d04AyPXr1wud19SpUwVAIRtXsP+JGxERERGRsYxdwX5p7sEuzIkTJ5Cfn4/AwECDVcmGDRsqPzs5OQEAGjRooCp7+PAh0tLSYGdnZ9R4mzdvxrp167B+/Xp4eXkhLi4OY8aMgbOzMwYOHFhi+yVLluD48eOIioqCm5sbfvjhB4wePRrOzs7K6vmIESOU+AYNGqBKlSp4/fXXcfXqVdSsWRMAMGXKFCWmSZMmyMzMxPz585X7wPPz86HRaLBu3TrY29sDABYtWoSePXti+fLl0Ol0qnmFh4ejQYMGaNGihVJmYWGBrVu3YujQoahQoQLMzc3h6+uLzp07q1bLjZnvs7Kzs1Ur4wVWrlyJ/v37K/v9+/dH+/btsWTJEuVhaAcOHEClSpXg5eWlate7d2+UKfPk69y3b1+MHz/eYA4Fx13UCntISAjGjh2r7KelpaFq1aqFxhIRERERET3rpbhE3MPDAxqNBvHx8apyd3d3eHh4GCSMwJMEsUDB5eOFlRU8+Kty5cpITU1V9ZGamgo7Ozul//Hjx2PSpEno06cPGjRogHfffRcfffQRZs+eXeIxZGdn45NPPsGiRYvQpUsXNGzYEEFBQejduzcWLFhQZLuWLVsCABITE4uN+eWXX5Q/MlSpUgUuLi5Kcg0AdevWhYjgl19+UbXNzMzExo0bMXToUIN+mzVrhri4ODx48ADJycnYvXs37t69C3d39z80XwcHB9y/f19VdvHiRRw/fhwTJkxAmTJlUKZMGbRq1QpZWVmqh5lFRUWpHgh37949REZGYvny5Uo7FxcXPH78WPXU9IJYAHB0dCx0XlqtFnZ2dqqNiIiIiIjIWC9Fgl2xYkV07NgRS5cuRWZm5p8yho+PD/bv368q27t3L3x8fJT9rKwsmJmpT5m5ubnq6dxFyc3NRW5ubqnbx8XFAXiSNBcXU758eWi1WgBAmzZtcOfOHWRkZCgxV65cgZmZGVxdXVVtt2zZgpycHNXK8bPs7e3h6OiIhIQEnDp1SnX/8/PMt0mTJrh48aKqLDw8HO3atcO5c+cQFxenbGPHjkV4eDgAQESwfft21fjr1q2Dq6urQbuFCxdi1apVyMvLU2LPnz8PV1dXODg4FDk3IiIiIiKi5/ZXXK9uComJieLk5CSenp6yceNGuXjxoly+fFm++eYbcXJykrFjxyqxgPop20lJSQJAzp49q5TFxMQIALl//76IiFy7dk2sra1l/PjxcunSJVm2bJmYm5vL7t27lTYDBw4UFxcX2bFjhyQlJcnWrVvFwcFBdf93cdq3by9eXl4SExMj165dk4iICLGyspLly5crxzhjxgw5deqUJCUlybZt28Td3V3atWun9BEVFSVfffWV/Pzzz5KQkCDLly8Xa2tr+c9//qPEpKeni6urq/Ts2VMuXLgghw4dklq1asmwYcMM5tS2bVvp3bt3ofPdvHmzxMTEyNWrV+W7774TNzc3efvtt1WfSUnzLUxUVJRUqlRJHj9+LCJP7vd2dHSUsLAwg9iLFy8K8ORp5idPnpTy5csr91qLPLmfe+LEiQbtHjx4IJaWlrJjxw6lbODAgQZPgS8OnyL+z96IiIiIiIxl7D3YL9V/Zt65c0eCgoKkRo0aYmFhITY2NtKiRQuZP3++ZGZmKnHPk2AXlDVu3FgsLS3F3d1dIiIiVOOnpaVJcHCwVKtWTaysrMTd3V0mT54sOTk5Rs0/OTlZBg0aJM7OzmJlZSV16tSRhQsXKq8Yu3nzprRr104qVKggWq1WPDw8ZPz48aoPcdeuXdK4cWOxsbGRsmXLSqNGjWTFihWSl5enGuvSpUvi6+srOp1OXF1dZezYsQavrrp8+bIAkOjo6ELn+/nnn4urq6tYWFhItWrVJDQ0VHWsxsy3MLm5ueLs7Kz88eLbb78VMzMzSUlJKTS+bt268tFHH0loaKjqlWinTp0SAHLixIlC23Xu3Fl54Fp2drbY29tLbGxssXN7GhPsf/ZGRERERGQsYxNsjYjIC1k6p3+1ZcuWISoqCnv27DG6TcOGDREaGopevXqVerywsDBERkYiOjra6DZpaWn/dx+7HgDvx/6n4W8+IiIiIjJWQW6g1+uLfVbTS/0UcXp5jRw5Eg8ePEB6erryhPDiPHr0CD169DD6nePPsrCwwJIlS56rLRERERERkTG4gm0ihw8fLjb5e/qBY/Ry4Ar2Pxt/8xERERGRsbiC/Rfz9vZWnqBNRERERERE/z5MsE1Ep9PBw8PjRU+DiIiIiIiIXpCX4j3YRERERERERH93TLCJiIiIiIiITIAJNhEREREREZEJ8B5sohLo9UAxDwokIiIiIiICwBVsIiIiIiIiIpNggk1ERERERERkAkywiYiIiIiIiEyACTYRERERERGRCTDBJiIiIiIiIjIBJthEREREREREJsDXdBGVwN7+Rc+ATEnkRc+AiIiIiP6puIJNREREREREZAJMsImIiIiIiIhMgAk2ERERERERkQkwwSYiIiIiIiIyASbYRERERERERCbABJuIiIiIiIjIBJhgExEREREREZkAE2wiIiIiIiIiE2CCTS9EeHg4/Pz8/rLxVqxYgS5duvxl4xERERER0b/PS5Vgp6SkIDg4GB4eHrCysoKTkxPatGmDsLAwZGVl/eH+Dx48iKZNm0Kr1cLDwwOrVq1S1efl5WHKlCmoUaMGdDodatasiZkzZ0JEjOpfo9EUus2fP18Zv6iYkydPGvSXmJgIW1tblCtXTlX+1Vdf4ZVXXkH58uVRvnx5+Pr64sSJE6qYrVu3ws/PDxUrVoRGo0FcXJyq/t69e/jggw9Qp04d6HQ6VKtWDR9++CH0er0Sc+7cOfTt2xdVq1aFTqdD3bp18fnnn5d4Hh4+fIgpU6Zg6tSpqvK0tDRMnjwZnp6esLKyQuXKleHr64utW7canOMOHTrg66+/Vvb/93//F6+++irs7e1hY2ODhg0bYsaMGbh37x4AYMiQIThz5gwOHz5c4vyIiIiIiIiex0uTYF+7dg1NmjRBdHQ0PvvsM5w9exaxsbGYMGECduzYgX379v2h/pOSkhAQEIAOHTogLi4OY8aMwbBhw7Bnzx4lZu7cuQgLC8PSpUtx6dIlzJ07F/PmzcOSJUuMGiM5OVm1rVy5EhqNBj169AAAtG7d2iBm2LBhqFGjBry9vVV95ebmom/fvnjllVcMxjl48CD69u2LmJgYxMbGomrVqvDz88Pt27eVmMzMTLRt2xZz584tdK537tzBnTt3sGDBApw/fx6rVq3C7t27MXToUCXm9OnTqFSpEtauXYsLFy5g8uTJCAkJwdKlS4s9D99++y3s7OzQpk0bpezBgwdo3bo11qxZg5CQEJw5cwY//PADevfujQkTJqgS+3v37uHo0aPKivTkyZPRu3dvNG/eHLt27cL58+excOFCnDt3Dt988w0AwNLSEv369cP//M//FDs3IiIiIiKi5yYvCX9/f3F1dZWMjIxC6/Pz85WfAciKFSskICBAdDqdeHp6yrFjxyQhIUHat28v1tbW4uPjI4mJiUqbCRMmiJeXl6rP3r17i7+/v7IfEBAgQ4YMUcW8/fbbEhgY+FzH1K1bN3nttdeKrH/06JE4OjrKjBkzDOomTJgg/fv3l4iICLG3ty92nMePH4utra2sXr3aoC4pKUkAyNmzZ0uc7+bNm8XS0lJyc3OLjHn//felQ4cOxfYTEBAg48aNU5W99957UrZsWbl9+7ZBfHp6umrMNWvWSMuWLUVE5McffxQA8t///rfQse7fv6/8fOjQIbG0tJSsrKxCYx8+fCh6vV7Zbt26JQAE0Asg3P4hGxERERFRaen1egEger2+2LiXYgX77t27iI6OxujRo1G2bNlCYzQajWp/5syZGDBgAOLi4uDp6Yl+/fph5MiRCAkJwalTpyAiCAoKUuJjY2Ph6+ur6sPf3x+xsbHKfuvWrbF//35cuXIFwJNLpI8cOYLOnTuX+phSU1Oxc+dO1Yrws6KionD37l0MHjxYVX7gwAFs2bIFy5YtM2qsrKws5ObmokKFCqWe59P0ej3s7OxQpkyZYmNKGufIkSOqFfn8/Hxs3LgRgYGBcHZ2Noi3sbFRjRkVFYVu3boBANatWwcbGxu8//77hY719OXz3t7eePz4MX788cdCY2fPng17e3tlq1q1arHHQURERERE9LSXIsFOTEyEiKBOnTqqcgcHB9jY2MDGxgYTJ05U1Q0ePBi9evVC7dq1MXHiRFy/fh2BgYHw9/dH3bp1ERwcjIMHDyrxKSkpcHJyUvXh5OSEtLQ0ZGdnAwAmTZqEPn36wNPTExYWFmjSpAnGjBmDwMDAUh/T6tWrYWtri7fffrvImPDwcPj7+8PV1VUpu3v3LgYNGoRVq1bBzs7OqLEmTpwIZ2dngz8glMbvv/+OmTNnYsSIEUXGHDt2DJs2bSo25sGDB9Dr9apE+vfff8f9+/fh6elZ4jxycnKwe/dudO3aFQCQkJAAd3d3WFhYlNjW2toa9vb2uHHjRqH1ISEh0Ov1ynbr1q0S+yQiIiIiIipQ9FLkS+DEiRPIz89HYGAgcnJyVHUNGzZUfi5InBs0aKAqe/jwIdLS0oxOVDdv3ox169Zh/fr18PLyUu7VdnZ2xsCBA0s195UrVyIwMBBWVlaF1v/yyy/Ys2cPNm/erCofPnw4+vXrh3bt2hk1zpw5c7Bx40YcPHiwyLFKkpaWhoCAANSrVw/Tpk0rNOb8+fPo1q0bpk6dWuzTwQv+WPH0XMTIh8QBT1bvK1WqBC8vr1K3BQCdTlfkA/G0Wi20Wm2p+iMiIiIiIirwUiTYHh4e0Gg0iI+PV5W7u7sDeJI0PevpFc2Cy8cLK8vPzwcAVK5cGampqao+UlNTYWdnp/Q/fvx4ZRUbeJKw37hxA7Nnzy5Vgn348GHEx8dj06ZNRcZERESgYsWKykptgQMHDiAqKgoLFiwA8CTBzM/PR5kyZfDll19iyJAhSuyCBQswZ84c7Nu3T/UHh9JIT09Hp06dYGtri8jIyEJXii9evIjXX38dI0aMQGhoaLH9FTy1/P79+0qZo6MjypUrh8uXL5c4n6ioKNU5qV27No4cOYLc3FyjVrHv3bsHR0fHEuOIiIiIiIhK66W4RLxixYro2LEjli5diszMzD9lDB8fH+zfv19VtnfvXvj4+Cj7WVlZMDNTnzJzc3MlSTdWeHg4mjVrhkaNGhVaLyKIiIjAgAEDDJLG2NhYxMXFKduMGTNga2uLuLg4vPXWW0rcvHnzMHPmTOzevdvgCeTGSktLg5+fHywtLREVFVXoCviFCxfQoUMHDBw4ELNmzSqxT0tLS9SrVw8XL15UyszMzNCnTx+sW7cOd+7cMWiTkZGBx48fQ0Swfft25f5rAOjXrx8yMjKwfPnyQsd78OCB8vPVq1fx8OFDNGnSpMR5EhERERERldZLkWADwPLly/H48WN4e3tj06ZNuHTpEuLj47F27VpcvnwZ5ubmf6j/UaNG4dq1a5gwYQIuX76M5cuXY/Pmzfjoo4+UmC5dumDWrFnYuXMnrl+/jsjISCxatEiV2JYkLS0NW7ZswbBhw4qMOXDgAJKSkgqNqVu3LurXr69sLi4uMDMzQ/369VG+fHkAT14nNmXKFKxcuRLVq1dHSkoKUlJSkJGRofRz7949xMXFKYlufHw84uLikJKSoszTz88PmZmZCA8PR1pamtJPXl4egCeXhXfo0AF+fn4YO3asUv/bb78Vew78/f1x5MgRVdmsWbNQtWpVtGzZEmvWrMHFixeRkJCAlStXokmTJsjIyMDp06eRlZWFtm3bKu1atmyJCRMm4OOPP8aECRMQGxuLGzduYP/+/XjnnXewevVqJfbw4cNwd3dHzZo1i50fERERERHRc/mzH2duSnfu3JGgoCCpUaOGWFhYiI2NjbRo0ULmz58vmZmZShwAiYyMVPYLexVVTEyMAFC9xikmJkYaN24slpaW4u7uLhEREarx09LSJDg4WKpVqyZWVlbi7u4ukydPlpycHKOP4YsvvhCdTicPHjwoMqZv377SunVro/or7DVdbm5uAsBgmzp1qqpdcTEF56ewLSkpSUREpk6dWmi9m5tbsXO+cOFCoefgwYMHMmnSJKlVq5ZYWlqKk5OT+Pr6SmRkpOTn50toaGiRr0TbtGmTtGvXTmxtbaVs2bLSsGFDmTFjhurz9fPzk9mzZxtzWkXk/z+Kn6/p+mdtRERERESlZexrujQipXxKFJEJvPPOO2jatClCQkKMbtOwYUOEhoaiV69epR7vwoULeO2113DlyhXY29sb1SYtLe3/YvUAjHsQHv398TceEREREZVWQW5Q8Oriorw0l4jTP8v8+fNhY2NjdPyjR4/Qo0eP53rnOAAkJydjzZo1RifXREREREREpcUVbBM5fPhwscnf0/c/08uBK9j/TPyNR0RERESlZewK9kvxmq6Xgbe3N+Li4l70NIiIiIiIiOgFYYJtIjqdDh4eHi96GkRERERERPSC8B5sIiIiIiIiIhNggk1ERERERERkArxEnKgEej1QzHMMiIiIiIiIAHAFm4iIiIiIiMgkmGATERERERERmQATbCIiIiIiIiITYIJNREREREREZAJMsImIiIiIiIhMgAk2ERERERERkQnwNV1EJbC3f9EzoAIiL3oGRERERERF4wo2ERERERERkQkwwSYiIiIiIiIyASbYRERERERERCbABJuIiIiIiIjIBJhgExEREREREZkAE2wiIiIiIiIiE2CCTURERERERGQCTLCJiIiIiIiITIAJNr1Q8fHxqFy5MtLT0//Ucfr06YOFCxf+qWMQEREREdG/20uZYKekpCA4OBgeHh6wsrKCk5MT2rRpg7CwMGRlZf3h/g8ePIimTZtCq9XCw8MDq1atUtXn5eVhypQpqFGjBnQ6HWrWrImZM2dCRIzqPyMjA0FBQXB1dYVOp0O9evWwYsUKVcyrr74KjUaj2kaNGqWKOXnyJF5//XWUK1cO5cuXh7+/P86dO6fUT5s2zaAPjUaDsmXLFjuORqNBQECAElNYvUajwfz585WYWbNmoXXr1rC2tka5cuWMOg8AEBISgg8++AC2trYYNGhQkWNpNBpUr15d1bZDhw5wdXUtto1GowEAhIaGYtasWdDr9UbPjYiIiIiIqDReugT72rVraNKkCaKjo/HZZ5/h7NmziI2NxYQJE7Bjxw7s27fvD/WflJSEgIAAdOjQAXFxcRgzZgyGDRuGPXv2KDFz585FWFgYli5dikuXLmHu3LmYN28elixZYtQYY8eOxe7du7F27VpcunQJY8aMQVBQEKKiolRxw4cPR3JysrLNmzdPqcvIyECnTp1QrVo1/Pjjjzhy5AhsbW3h7++P3NxcAMC4ceNU7ZOTk1GvXj288847Sj9bt25V1Z8/fx7m5uaqmGf7WLlyJTQaDXr06KHEPHr0CO+88w7ee+89o8/1zZs3sWPHDgwaNAgA8Pnnn6vGAYCIiAhl/+TJk0rbe/fu4ejRozh69KiqjaurK2bMmGHQT/369VGzZk2sXbvW6PkRERERERGVirxk/P39xdXVVTIyMgqtz8/PV34GICtWrJCAgADR6XTi6ekpx44dk4SEBGnfvr1YW1uLj4+PJCYmKm0mTJggXl5eqj579+4t/v7+yn5AQIAMGTJEFfP2229LYGCgUcfg5eUlM2bMUJU1bdpUJk+erOy3b99egoODi+zj5MmTAkBu3ryplP30008CQBISEgptExcXJwDkhx9+KLLfxYsXi62tbZHnV0SkW7du8tprrxVaFxERIfb29kW2fdr8+fPF29u7yHoAEhkZWWjdmjVrpGXLlgblbm5usnjx4kLbTJ8+Xdq2bWvU3ERE9Hq9ABBAL4Bw+xtsREREREQvQkFuoNfri417qVaw7969i+joaIwePVp1mfPTCi4JLjBz5kwMGDAAcXFx8PT0RL9+/TBy5EiEhITg1KlTEBEEBQUp8bGxsfD19VX14e/vj9jYWGW/devW2L9/P65cuQIAOHfuHI4cOYLOnTsbdRytW7dGVFQUbt++DRFBTEwMrly5Aj8/P1XcunXr4ODggPr16yMkJER1+XudOnVQsWJFhIeH49GjR8jOzkZ4eDjq1q1rcCl1ga+//hq1a9fGK6+8UuTcwsPD0adPnyLPb2pqKnbu3ImhQ4cadazFOXz4MLy9vZ+rbVRUFLp161aqNi1atMCJEyeQk5NTaH1OTg7S0tJUGxERERERkbFeqgQ7MTERIoI6deqoyh0cHGBjYwMbGxtMnDhRVTd48GD06tULtWvXxsSJE3H9+nUEBgbC398fdevWRXBwMA4ePKjEp6SkwMnJSdWHk5MT0tLSkJ2dDQCYNGkS+vTpA09PT1hYWKBJkyYYM2YMAgMDjTqOJUuWoF69enB1dYWlpSU6deqEZcuWoV27dkpMv379sHbtWsTExCAkJATffPMN+vfvr9Tb2tri4MGDWLt2LXQ6HWxsbLB7927s2rULZcqUMRjz4cOHWLduXbGJ8YkTJ3D+/HkMGzasyJjVq1fD1tYWb7/9tlHHWpwbN27A2dm51O1ycnKwe/dudO3atVTtnJ2d8ejRI6SkpBRaP3v2bNjb2ytb1apVSz03IiIiIiL69zLMxF5CJ06cQH5+PgIDAw1WJxs2bKj8XJA4N2jQQFX28OFDpKWlwc7OzqjxNm/ejHXr1mH9+vXw8vJS7tV2dnbGwIEDS2y/ZMkSHD9+HFFRUXBzc8MPP/yA0aNHw9nZWVk9HzFihBLfoEEDVKlSBa+//jquXr2KmjVrIjs7G0OHDkWbNm2wYcMG5OXlYcGCBQgICMDJkyeh0+lUY0ZGRiI9Pb3Y+YWHh6NBgwZo0aJFkTErV65EYGAgrKysSjzOkmRnZz9XPwcOHEClSpXg5eVVqnYF56SoB+GFhIRg7Nixyn5aWhqTbCIiIiIiMtpLlWB7eHhAo9EgPj5eVe7u7g4ABkklAFhYWCg/F1w+XlhZfn4+AKBy5cpITU1V9ZGamgo7Ozul//Hjxyur2MCTBPjGjRuYPXt2iQl2dnY2PvnkE0RGRipP6m7YsCHi4uKwYMECg8vTC7Rs2RLAk1X8mjVrYv369bh+/TpiY2NhZvbkQoT169ejfPny2LZtmzK3Al9//TXefPNNg9X5ApmZmdi4cSNmzJhR5NwPHz6M+Ph4bNq0qdhjNJaDgwPu379f6nZRUVGlXr0GnjwYDQAcHR0LrddqtdBqtaXul4iIiIiICHjJLhGvWLEiOnbsiKVLlyIzM/NPGcPHxwf79+9Xle3duxc+Pj7KflZWlpLUFjA3N1eS9OLk5uYiNze31O3j4uIAAFWqVFHN4el7zgv2n+0nKSkJMTExxV4evmXLFuTk5KguQ39WeHg4mjVrhkaNGhUZUxpNmjTBxYsXS9VGRLB9+/ZS338NAOfPn4erqyscHBxK3ZaIiIiIiKgkL1WCDQDLly/H48eP4e3tjU2bNuHSpUuIj4/H2rVrcfnyZZibm/+h/keNGoVr165hwoQJuHz5MpYvX47Nmzfjo48+UmK6dOmCWbNmYefOnbh+/ToiIyOxaNEivPXWWyX2b2dnh/bt22P8+PE4ePAgkpKSsGrVKqxZs0Zpf/XqVcycOROnT5/G9evXERUVhQEDBqBdu3bKJe8dO3bE/fv3MXr0aFy6dAkXLlzA4MGDUaZMGXTo0EE15sqVK1GlSpViH8IWHh6O7t27o2LFioXWp6WlYcuWLUXen33z5k3ExcXh5s2byMvLQ1xcHOLi4pCRkVHkmAUPj8vLyyv2nD3t9OnTyMrKQtu2bY1uU+Dw4cMGD5IjIiIiIiIymb/gieYmd+fOHQkKCpIaNWqIhYWF2NjYSIsWLWT+/PmSmZmpxOGZ1zwlJSUJADl79qxSFhMTIwDk/v37qrLGjRuLpaWluLu7S0REhGr8tLQ0CQ4OlmrVqomVlZW4u7vL5MmTJScnx6j5Jycny6BBg8TZ2VmsrKykTp06snDhQuUVYzdv3pR27dpJhQoVRKvVioeHh4wfP97gkfDR0dHSpk0bsbe3l/Lly8trr70msbGxqpi8vDxxdXWVTz75pMj5XL58WQBIdHR0kTFffPGF6HQ6efDgQaH1AwcO/L9XWqm3mJiYIvvMzc0VZ2dn2b17d6H1z35+IiKhoaHFvg6tqNd0ZWdni729vcH5KQ5f0/X324iIiIiIXgRjX9OlERF5Mak9EbBs2TJERUVhz549RsU3bNgQoaGh6NWrV6nGCQsLQ2RkJKKjo41uk5aWBnt7ewB6AMY9AI/+XPxtRUREREQvQkFuoNfri3049kv1kDP65xk5ciQePHiA9PR02NraFhv76NEj9OjRw+j3jT/NwsICS5Ysed5pEhERERERlYgr2CZ2+PDhYhPA4u5Jpr8XrmD//fC3FRERERG9CFzBfkG8vb2VJ34TERERERHRvwcTbBPT6XTw8PB40dMgIiIiIiKiv9hL95ouIiIiIiIior8jJthEREREREREJsAEm4iIiIiIiMgEeA82UQn0eqCYBwUSEREREREB4Ao2ERERERERkUkwwSYiIiIiIiIyASbYRERERERERCbABJuIiIiIiIjIBJhgExEREREREZkAE2wiIiIiIiIiE+BruohKYG//omdAACDyomdARERERFQ8rmATERERERERmQATbCIiIiIiIiITYIJNREREREREZAJMsImIiIiIiIhMgAk2ERERERERkQkwwSYiIiIiIiIyASbYRERERERERCbABJuIiIiIiIjIBJhg0wsVHx+PypUrIz09/U8dp0+fPli4cOGfOgYREREREf27vZQJdkpKCoKDg+Hh4QErKys4OTmhTZs2CAsLQ1ZW1h/u/+DBg2jatCm0Wi08PDywatUqVX1eXh6mTJmCGjVqQKfToWbNmpg5cyZExKj+MzIyEBQUBFdXV+h0OtSrVw8rVqxQxbz66qvQaDSqbdSoUaqYZ+s1Gg02btyoisnJycHkyZPh5uYGrVaL6tWrY+XKlcWOo9FoEBAQoMSkpqZi0KBBcHZ2hrW1NTp16oSEhIRSz7cwISEh+OCDD2Bra4tBgwYVOpeCrXr16qq2HTp0gKura7FtNBoNACA0NBSzZs2CXq8vcU5ERERERETPo8yLnkBpXbt2DW3atEG5cuXw2WefoUGDBtBqtfj555/x5ZdfwsXFBV27dn3u/pOSkhAQEIBRo0Zh3bp12L9/P4YNG4YqVarA398fADB37lyEhYVh9erV8PLywqlTpzB48GDY29vjww8/LHGMsWPH4sCBA1i7di2qV6+O6OhovP/++3B2dlbNffjw4ZgxY4ayb21tbdBXREQEOnXqpOyXK1dOVd+rVy+kpqYiPDwcHh4eSE5ORn5+vlK/detWPHr0SNm/e/cuGjVqhHfeeQcAICLo3r07LCwssG3bNtjZ2WHRokXw9fXFxYsXUbZs2VLN92k3b97Ejh07sGTJEgDA559/jjlz5ij1VapUUR2fubm5Unfv3j0cPXoUCQkJ0Gq1Snnz5s0xYsQIDB8+XDVW/fr1UbNmTaxduxajR48udl5ERERERETP46VLsN9//32UKVMGp06dUiV37u7u6Natm2oVWaPRYMWKFdi+fTsOHDgANzc3rFy5Eo6Ojhg2bBhOnjyJRo0a4ZtvvkHNmjUBACtWrECNGjWUy4nr1q2LI0eOYPHixUqCfezYMXTr1k1Z5a1evTo2bNiAEydOGHUMx44dw8CBA/Hqq68CAEaMGIEvvvgCJ06cUCXY1tbWqFy5crF9lStXrsiY3bt349ChQ7h27RoqVKigzPVpBeUFNm7cCGtrayXBTkhIwPHjx3H+/Hl4eXkBAMLCwlC5cmVs2LABw4YNK9V8n7Z582Y0atQILi4uAAB7e3vY29sbdXw7d+5E06ZN4ebmpio3NzeHra1toW26dOmCjRs3MsEmIiIiIqI/xUt1ifjdu3cRHR2N0aNHq5LrpxVcElxg5syZGDBgAOLi4uDp6Yl+/fph5MiRCAkJwalTpyAiCAoKUuJjY2Ph6+ur6sPf3x+xsbHKfuvWrbF//35cuXIFAHDu3DkcOXIEnTt3Nuo4WrdujaioKNy+fRsigpiYGFy5cgV+fn6quHXr1sHBwQH169dHSEhIoZe/jx49Gg4ODmjRogVWrlyp+gNDVFQUvL29MW/ePLi4uKB27doYN24csrOzi5xbeHg4+vTpo5zfnJwcAICVlZUSY2ZmBq1WiyNHjpR6vk87fPgwvL29i40pSlRUFLp161aqNi1atMCJEyeUY3pWTk4O0tLSVBsREREREZGxXqoV7MTERIgI6tSpoyp3cHDAw4cPATxJOOfOnavUDR48GL169QIATJw4ET4+PpgyZYqyGh0cHIzBgwcr8SkpKXByclL17+TkhLS0NGRnZ0On02HSpElIS0uDp6cnzM3NkZeXh1mzZiEwMNCo41iyZAlGjBgBV1dXlClTBmZmZvjqq6/Qrl07JaZfv35wc3ODs7MzfvrpJ0ycOBHx8fHYunWrEjNjxgy89tprsLa2Vi4zz8jIUC5Tv3btGo4cOQIrKytERkbi999/x/vvv4+7d+8iIiLCYF4nTpzA+fPnER4erpR5enqiWrVqCAkJwRdffIGyZcti8eLF+OWXX5CcnFyq+T7rxo0bz5Vg5+TkYPfu3Zg2bVqp2jk7O+PRo0dISUkxWPkGgNmzZ2P69Omlng8RERERERHwkiXYRTlx4gTy8/MRGBhosDrZsGFD5eeCxLlBgwaqsocPHyItLQ12dnZGjbd582asW7cO69evh5eXF+Li4jBmzBg4Oztj4MCBJbZfsmQJjh8/jqioKLi5ueGHH37A6NGj4ezsrKyejxgxQolv0KABqlSpgtdffx1Xr15VLmefMmWKEtOkSRNkZmZi/vz5SoKdn58PjUaDdevWKZdeL1q0CD179sTy5cuh0+lU8woPD0eDBg3QokULpczCwgJbt27F0KFDUaFCBZibm8PX1xedO3dWrZYbM99nZWdnq1bGjXXgwAFUqlRJuWTdWAXHW9TKekhICMaOHavsp6WloWrVqqWeHxERERER/Tu9VAm2h4cHNBoN4uPjVeXu7u4AYJAwAk8SxAIFl48XVlbw4K/KlSsjNTVV1Udqairs7OyU/sePH49JkyahT58+AJ4klDdu3MDs2bNLTLCzs7PxySefIDIyUrmHu2HDhoiLi8OCBQsMLk8v0LJlSwBPVvGLSlhbtmyJmTNnIicnB1qtFlWqVIGLi4vqvua6detCRPDLL7+gVq1aSnlmZiY2btyoekhZgWbNmiEuLg56vR6PHj2Co6MjWrZsWezqszHzdXBwwP3794vsoyhRUVHP9SC7e/fuAQAcHR0LrddqtaoHphEREREREZXGS3UPdsWKFdGxY0csXboUmZmZf8oYPj4+2L9/v6ps79698PHxUfazsrJgZqY+debm5qqncxclNzcXubm5pW4fFxcH4MmTtYuLKV++vJIktmnTBnfu3EFGRoYSc+XKFZiZmcHV1VXVdsuWLcjJyUH//v2L7N/e3h6Ojo5ISEjAqVOnir0H2pj5NmnSBBcvXiyyvjAigu3bt5f6/msAOH/+PFxdXeHg4FDqtkRERERERCV5qVawAWD58uVo06YNvL29MW3aNDRs2BBmZmY4efIkLl++jGbNmv2h/keNGoWlS5diwoQJGDJkCA4cOIDNmzdj586dSkyXLl0wa9YsVKtWDV5eXjh79iwWLVqEIUOGlNi/nZ0d2rdvj/Hjx0On08HNzQ2HDh3CmjVrsGjRIgDA1atXsX79erzxxhuoWLEifvrpJ3z00Udo166dcsn79u3bkZqailatWsHKygp79+7FZ599hnHjxilj9evXDzNnzsTgwYMxffp0/P777xg/fjyGDBlS6OXh3bt3R8WKFQ3mvGXLFjg6OqJatWr4+eefERwcjO7duysPZTNmvoXx9/fHsGHDkJeXp3oFV3FOnz6NrKwstG3b1qj4px0+fNjgQXJEREREREQmIy+hO3fuSFBQkNSoUUMsLCzExsZGWrRoIfPnz5fMzEwlDoBERkYq+0lJSQJAzp49q5TFxMQIALl//76qrHHjxmJpaSnu7u4SERGhGj8tLU2Cg4OlWrVqYmVlJe7u7jJ58mTJyckxav7JyckyaNAgcXZ2FisrK6lTp44sXLhQ8vPzRUTk5s2b0q5dO6lQoYJotVrx8PCQ8ePHi16vV/rYtWuXNG7cWGxsbKRs2bLSqFEjWbFiheTl5anGunTpkvj6+opOpxNXV1cZO3asZGVlqWIuX74sACQ6OrrQ+X7++efi6uoqFhYWUq1aNQkNDVUdqzHzLUxubq44OzvL7t27C61/9vMTEQkNDZXAwMAi+3Rzc5PFixcblGdnZ4u9vb3ExsYWO6en6fV6ASCAXgDh9oI3IiIiIqIXpSA3KCnH0Yg89aQqor/YsmXLEBUVhT179hgV37BhQ4SGhipPhjdWWFgYIiMjER0dbXSbtLS0/7t/XQ/AuAfg0Z+Hv6mIiIiI6EUpyA30en2xD8d+6S4Rp3+WkSNH4sGDB0hPT4etrW2xsY8ePUKPHj2Mft/40ywsLLBkyZLnnSYREREREVGJuIJtYocPHy42AXz6gWP098YV7L8X/qYiIiIioheFK9gviLe3t/IEbSIiIiIiIvr3YIJtYjqdDh4eHi96GkRERERERPQXe6neg01ERERERET0d8UEm4iIiIiIiMgEmGATERERERERmQDvwSYqgV4PFPOgQCIiIiIiIgBcwSYiIiIiIiIyCSbYRERERERERCbABJuIiIiIiIjIBJhgExEREREREZkAE2wiIiIiIiIiE2CCTURERERERGQCfE0XUQns7V/0DP6dRF70DIiIiIiISocr2EREREREREQmwASbiIiIiIiIyASYYBMRERERERGZABNsIiIiIiIiIhNggk1ERERERERkAkywiYiIiIiIiEyACTYRERERERGRCTDBJiIiIiIiIjIBJtj0QoWHh8PPz+9PHePRo0eoXr06Tp069aeOQ0RERERE/24vZYKdkpKC4OBgeHh4wMrKCk5OTmjTpg3CwsKQlZX1h/s/ePAgmjZtCq1WCw8PD6xatUpVn5eXhylTpqBGjRrQ6XSoWbMmZs6cCRExqn+NRlPoNn/+fGX8omJOnjxp0F9iYiJsbW1Rrlw5VflXX32FV155BeXLl0f58uXh6+uLEydOqGK2bt0KPz8/VKxYERqNBnFxcar6e/fu4YMPPkCdOnWg0+lQrVo1fPjhh9Dr9UrMuXPn0LdvX1StWhU6nQ5169bF559/XuJ5ePjwIaZMmYKpU6cCAKpXr17kcWs0GgwaNEhpm52djbJly8LV1bXYNq+++iosLS0xbtw4TJw4scQ5ERERERERPa8yL3oCpXXt2jW0adMG5cqVw2effYYGDRpAq9Xi559/xpdffgkXFxd07dr1uftPSkpCQEAARo0ahXXr1mH//v0YNmwYqlSpAn9/fwDA3LlzERYWhtWrV8PLywunTp3C4MGDYW9vjw8//LDEMZKTk1X7u3btwtChQ9GjRw8AQOvWrQ1ipkyZgv3798Pb21tVnpubi759++KVV17BsWPHVHUHDx5E37590bp1a1hZWWHu3Lnw8/PDhQsX4OLiAgDIzMxE27Zt0atXLwwfPtxgrnfu3MGdO3ewYMEC1KtXDzdu3MCoUaNw584dfPvttwCA06dPo1KlSli7di2qVq2KY8eOYcSIETA3N0dQUFCR5+Hbb7+FnZ0d2rRpAwA4efIk8vLyAADHjh1Djx49EB8fDzs7OwCATqdT2u7duxdubm44cuQIHj16BAC4desWWrRogX379sHLywsAYGlpCQAIDAzExx9/jAsXLih1REREREREJiUvGX9/f3F1dZWMjIxC6/Pz85WfAciKFSskICBAdDqdeHp6yrFjxyQhIUHat28v1tbW4uPjI4mJiUqbCRMmiJeXl6rP3r17i7+/v7IfEBAgQ4YMUcW8/fbbEhgY+FzH1K1bN3nttdeKrH/06JE4OjrKjBkzDOomTJgg/fv3l4iICLG3ty92nMePH4utra2sXr3aoC4pKUkAyNmzZ0uc7+bNm8XS0lJyc3OLjHn//felQ4cOxfYTEBAg48aNK7QuJiZGAMj9+/cLrR8yZIhMnDhRVVbSMXTo0EFCQ0OLnM/Dhw9Fr9cr261btwSAAHoBhNtfvBERERER/V3o9XoBIHq9vti4l+oS8bt37yI6OhqjR49G2bJlC43RaDSq/ZkzZ2LAgAGIi4uDp6cn+vXrh5EjRyIkJASnTp2CiKhWWWNjY+Hr66vqw9/fH7Gxscp+69atsX//fly5cgXAk0ukjxw5gs6dO5f6mFJTU7Fz504MHTq0yJioqCjcvXsXgwcPVpUfOHAAW7ZswbJly4waKysrC7m5uahQoUKp5/k0vV4POzs7lClT9AUQer2+xHGOHDlisCJvjPz8fOzYsQPdunUrVbsWLVrg8OHDRdbPnj0b9vb2yla1atVSz42IiIiIiP69XqoEOzExESKCOnXqqModHBxgY2MDGxsbg/tsBw8ejF69eqF27dqYOHEirl+/jsDAQPj7+6Nu3boIDg7GwYMHlfiUlBQ4OTmp+nByckJaWhqys7MBAJMmTUKfPn3g6ekJCwsLNGnSBGPGjEFgYGCpj2n16tWwtbXF22+/XWRMeHg4/P394erqqpTdvXsXgwYNwqpVq5RLqEsyceJEODs7G/wBoTR+//13zJw5EyNGjCgy5tixY9i0aVOxMQ8ePIBer4ezs3Op53D8+HEAQMuWLUvVztnZGTdu3CiyPiQkBHq9Xtlu3bpV6rkREREREdG/10t3D3ZhTpw4gfz8fAQGBiInJ0dV17BhQ+XngsS5QYMGqrKHDx8iLS3N6ER18+bNWLduHdavXw8vLy/ExcVhzJgxcHZ2xsCBA0s195UrVyIwMBBWVlaF1v/yyy/Ys2cPNm/erCofPnw4+vXrh3bt2hk1zpw5c7Bx40YcPHiwyLFKkpaWhoCAANSrVw/Tpk0rNOb8+fPo1q0bpk6dWuzTwQv+WPE8c9m2bRvefPNNmJmV7u9DOp2u2IfgabVaaLXaUs+HiIiIiIgIeMkSbA8PD2g0GsTHx6vK3d3dAagfglXAwsJC+bng8vHCyvLz8wEAlStXRmpqqqqP1NRU2NnZKf2PHz9eWcUGniTsN27cwOzZs0uVYB8+fBjx8fHYtGlTkTERERGoWLGiwYPbDhw4gKioKCxYsAAAICLIz89HmTJl8OWXX2LIkCFK7IIFCzBnzhzs27dP9QeH0khPT0enTp1ga2uLyMhI1TkscPHiRbz++usYMWIEQkNDi+2v4Knl9+/fL/VcoqKiMGfOnFK3u3fvHhwdHUvdjoiIiIiIyBgv1SXiFStWRMeOHbF06VJkZmb+KWP4+Phg//79qrK9e/fCx8dH2c/KyjJYPTU3N1eSdGOFh4ejWbNmaNSoUaH1IoKIiAgMGDDAIKGNjY1FXFycss2YMQO2traIi4vDW2+9pcTNmzcPM2fOxO7du5/rfmfgycq1n58fLC0tERUVVeiq84ULF9ChQwcMHDgQs2bNKrFPS0tL1KtXDxcvXizVXBISEnDjxg107NixVO2AJ6vrTZo0KXU7IiIiIiIiY7xUCTYALF++HI8fP4a3tzc2bdqES5cuIT4+HmvXrsXly5dhbm7+h/ofNWoUrl27hgkTJuDy5ctYvnw5Nm/ejI8++kiJ6dKlC2bNmoWdO3fi+vXriIyMxKJFi1SJbUnS0tKwZcsWDBs2rMiYAwcOICkpqdCYunXron79+srm4uICMzMz1K9fH+XLlwfw5HViU6ZMwcqVK1G9enWkpKQgJSUFGRkZSj/37t1DXFyckujGx8cjLi4OKSkpyjz9/PyQmZmJ8PBwpKWlKf0UvFLr/Pnz6NChA/z8/DB27Fil/rfffiv2HPj7++PIkSNGnzPgyeXhvr6+sLa2LlU74MkVA8Vdtk5ERERERPSH/AVPNDe5O3fuSFBQkNSoUUMsLCzExsZGWrRoIfPnz5fMzEwlDoBERkYq+4W9xqmw10HFxPw/9u49Luf7/x/44+p0XRcd0FEOUVFJEcaSMXOoNLMjpuZ82jSNjTQZ4+M0h82HCVvOmjk1YRKqLUShnJpD5CzbRzqnUq/fH369v96uyhXXHLbH/XZ7325dr+Pz/a657Xm93u/XO060bt1aGBkZCXt7e7Fq1SrZ/Lm5uSIoKEg0btxYqFQqYW9vLyZPniyKi4u1Pofly5cLtVotsrOzq2zz4Ycfio4dO2o1XmWv6bKzs/v/r5mSH1OnTpX1q65NxfWp7MjIyBBCCDF16tRK6+3s7KqN+cyZM1Veg6pe09WpUyfxww8/VDpeda/pOnTokKhTp44oLCysNqaHVWzFz9d08TVdRERERPTvpu1ruhRCCPFsUnkiTR988AHatGmDkJCQx7b93//+h/r16+P69esaO70/Tr9+/dCqVSt8+eWXWvfJzc2FmZkZgBwA2m2AR7rDf5mIiIiI6EVRkRtUvLK4Ki/dLeL0zzJv3jwYGxtr1TYrKwsLFy6scXJdUlICNzc32W3+REREREREusYVbB1LSEiAr69vlfUPP/9MLzauYD9f/JeJiIiIiF4U2q5gv1Sv6XoZtGvXDqmpqc87DCIiIiIiInrGmGDrmFqthqOj4/MOg4iIiIiIiJ4xPoNNREREREREpANMsImIiIiIiIh0gLeIEz1GTg5QzT4GREREREREALiCTURERERERKQTTLCJiIiIiIiIdIAJNhEREREREZEOMMEmIiIiIiIi0gEm2EREREREREQ6wASbiIiIiIiISAf4mi6ixzAze94RvFyEeN4REBERERE9H1zBJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiIdYIJNREREREREpANMsImIiIiIiIh0gAk2ERERERERkQ4wwabn4ty5c7CxsUFeXt4zma9///5YsGDBM5mLiIiIiIj+nV6qBDszMxNBQUFwdHSESqWCtbU1vLy8EBYWhsLCwqcePz4+Hm3atIFSqYSjoyNWr14tqy8rK8OUKVPQtGlTqNVqODg4YMaMGRBCaDV+fn4+AgMD0bBhQ6jVarRo0QLLli2TtXn99dehUChkx+jRo6X6O3fuwMfHB7a2tlAqlWjUqBECAwORm5srG2fDhg1o1aoVatWqhfr162Po0KG4c+eOrM3mzZvh7OwMlUoFNzc3/Prrrxox//HHH3jrrbdgZmaG2rVr45VXXsHVq1e1jrcqISEh+PTTT2FiYqJR5+zsDKVSiczMzCr7d+3aFT/++KOszNvbG/r6+khOTtZoHxoaipkzZyInJ+exsRERERERET0R8ZK4ePGisLGxEc7OzuLnn38WaWlp4uLFi+KXX34RvXr1Etu3b3+q8S9duiRq1aolxo8fL9LS0sTixYuFvr6+iI6OltrMnDlTmJubi507d4qMjAyxefNmYWxsLBYtWqTVHCNGjBAODg4iLi5OZGRkiOXLlwt9fX1Z7F26dBEjRowQt27dko6cnBypPisrSyxdulQkJyeLy5cvi3379gknJyfx4YcfSm0OHDgg9PT0xKJFi8SlS5dEQkKCcHV1Fe+8847U5uDBg0JfX1988803Ii0tTYSGhgpDQ0Nx6tQpqU16erqoV6+emDBhgjh+/LhIT08X27dvF7dv39Y63spcuXJFGBoaiuvXr2vUJSQkiMaNG4sBAwaIOXPmVNr/zp07wtDQUGRmZsrGNDY2FmPHjhWjR4+utF+7du3EkiVLqo3tYTk5OQKAAHIEIHhoeRARERER/dNU5AaPy3Vemv8d9vb2Fg0bNhT5+fmV1peXl0s/AxDLli0Tfn5+Qq1WC2dnZ3Ho0CFx4cIF0aVLF1GrVi3h6ekp0tPTpT4TJ04Urq6usjH79esnvL29pc9+fn5i6NChsjbvvvuu8Pf31+ocXF1dxfTp02Vlbdq0EZMnT5Y+d+nSRQQFBWk1XoVFixaJhg0bSp/nzZsn7O3tZW3++9//igYNGkif+/btK/z8/GRtOnToIEaNGiV97tevnwgICKh27ieJd968eaJdu3aV1g0ePFhMmjRJ7N69WzRv3rzSNmvXrhUdOnSQlU2bNk30799f/PHHH8LMzEwUFhZq9Pv6669Fp06dtI6TCTYTbCIiIiIiIbRPsF+KW8Tv3LmDmJgYjBkzBrVr1660jUKhkH2eMWMGBg4ciNTUVDg7O2PAgAEYNWoUQkJCcPToUQghEBgYKLVPTExE9+7dZWN4e3sjMTFR+tyxY0fs378f58+fBwCcOHECBw4cgK+vr1bn0bFjR0RFReHGjRsQQiAuLg7nz59Hz549Ze02bNgACwsLtGzZEiEhIdXe/n7z5k1s27YNXbp0kco8PT1x7do1/PrrrxBC4Pbt29iyZQt69eql9fmWl5dj165daN68Oby9vWFlZYUOHTrgl19+0YihJvECQEJCAtq1a6dRnpeXh82bNyMgIAA9evRATk4OEhISNNpFRUWhT58+0mchBFatWoWAgAA4OzvD0dERW7Zs0ejXvn17JCUlobi4uNK4iouLkZubKzuIiIiIiIi09gyS/ad2+PBhAUBs27ZNVm5ubi5q164tateuLSZOnCiVAxChoaHS58TERAFAhIeHS2U//fSTUKlU0udmzZqJWbNmycbftWuXACCthpaVlYng4GChUCiEgYGBUCgUGn2qc+/ePTFw4EABQBgYGAgjIyOxZs0aWZvly5eL6OhocfLkSbF+/XrRoEED2a3dFfr37y/UarUAIHr37i2Kiopk9Zs2bRLGxsbCwMBAalNSUiLVGxoaioiICFmf77//XlhZWQkhhLh165YAIGrVqiUWLlwoUlJSxOzZs4VCoRDx8fE1jvdhrVq10ljJF0KIFStWiNatW0ufg4KCxKBBgzSuobGxsTh9+rRUFhMTIywtLUVpaakQQohvv/1WdOnSRWP8EydOCADi8uXLlcY1derU/79i/ejBFWyuYBMRERHRv9k/agW7KklJSUhNTYWrq6vGqqS7u7v0s7W1NQDAzc1NVnbv3r0arVJu2rQJGzZsQEREBI4fP441a9Zg/vz5WLNmjVb9Fy9ejMOHDyMqKgrHjh3DggULMGbMGOzbt09qM3LkSHh7e8PNzQ3+/v5Yu3YtIiMjcfHiRdlY3377LY4fP47t27fj4sWLGD9+vFSXlpaGoKAgfPXVVzh27Biio6Nx+fJlrTYfq1BeXg4A6NOnD8aNG4fWrVtj0qRJePPNN2Ubs2kb78OKioqgUqk0yleuXImAgADpc0BAADZv3izbaTw2NhZWVlZwdXWV9evXrx8MDAwAAB9++CEOHjyoEYNarQaAKlfYQ0JCkJOTIx3Xrl2r8hyIiIiIiIgeZfC8A9CGo6MjFAoFzp07Jyu3t7cH8H+J08MMDQ2lnytuH6+srCKRtLGxwe3bt2Vj3L59G6amptL4EyZMwKRJk9C/f38ADxL2K1euYPbs2Rg0aFC151BUVIQvv/wSkZGR8PPzA/DgS4DU1FTMnz9f43btCh06dAAApKenw8HBQSq3sbGBjY0NnJ2dUa9ePbz22muYMmUK6tevj9mzZ8PLywsTJkyQ5qlduzZee+01/Oc//0H9+vWrPF8bGxsAgIWFBQwMDNCiRQtZGxcXFxw4cKDK86wq3odZWFjg7t27srK0tDQcPnwYSUlJCA4OlsrLysqwceNGjBgxAsCD28PfeustqT4rKwuRkZEoLS1FWFiYrN/KlSsxc+ZMWVsAsLS0rDQupVIJpVJZ5bkRERERERFV56VYwTY3N0ePHj2wZMkSFBQU/C1zeHp6Yv/+/bKyvXv3wtPTU/pcWFgIPT35JdPX15eS9OqUlpaitLS0xv1TU1MBAPXr16+yTUX/ilX8quIEHjyvDDz+fI2MjPDKK69ofKlx/vx52NnZPVW8Hh4eSEtLk5WFh4ejc+fOOHHiBFJTU6Vj/PjxCA8Pl2LfsWOH7PnrDRs2oGHDhhr9FixYgNWrV6OsrExqe/r0aTRs2BAWFhZVxkZERERERPTEnskN6zqQnp4urK2thbOzs9i4caNIS0sTZ8+eFevWrRPW1tZi/PjxUlsAIjIyUvqckZEhAIiUlBSpLC4uTgAQd+/eFUL832u6JkyYIP744w/x/fffa7yma9CgQaJBgwbSa7q2bdsmLCwsZM9/V6dLly7C1dVVxMXFiUuXLolVq1YJlUolli5dKp3j9OnTxdGjR0VGRobYvn27sLe3F507d5bG2LVrl1i5cqU4deqUyMjIEDt37hQuLi7Cy8tLarNq1SphYGAgli5dKi5evCgOHDgg2rVrJ9q3by+1OXjwoDAwMBDz588Xf/zxh5g6darGa7q2bdsmDA0NxYoVK8SFCxekV5clJCRoHW9loqKihJWVlbh//74QQoiSkhJhaWkpwsLCNNqmpaUJAOL06dMiOTlZ1K1bV3rWWogHz3MHBwdr9MvOzhZGRkZi586dUtmgQYM0doGvDncR5zPYRERERERC/ANf0yWEEDdv3hSBgYGiadOmwtDQUBgbG4v27duLefPmiYKCAqndkyTYFWWtW7cWRkZGwt7eXqxatUo2f25urggKChKNGzcWKpVK2Nvbi8mTJ4vi4mKt4r9165YYPHiwsLW1FSqVSjg5OYkFCxZIrxi7evWq6Ny5s6hXr55QKpXC0dFRTJgwQfZLjI2NFZ6ensLMzEyoVCrRrFkzERwcLDsPIR68lqtFixZCrVaL+vXrC39/f433Tm/atEk0b95cGBkZCVdXV7Fr1y6NmMPDw4Wjo6NQqVSiVatW4pdffpHqtIm3MqWlpcLW1lb68mLLli1CT09P9l7rh7m4uIhx48aJ0NBQ2SvRjh49KgCIpKSkSvv5+vpKG64VFRUJMzMzkZiYWG1sD2OCzQSbiIiIiEgI7RNshRBCPJ+1c/o3+/777xEVFYU9e/Zo3cfd3R2hoaHo27dvjecLCwtDZGQkYmJitO6Tm5sLMzMzADkATGs8578V/0UhIiIion+aitwgJycHpqZV5wYvxSZn9M8zatQoZGdnIy8vDyYmJo9tX1JSgvfee0/rd44/ytDQEIsXL36ivkRERERERNrgCraOJCQkVJv85efnP8NoSBe4gv1k+C8KEREREf3TcAX7GWvXrp20gzYRERERERH9+zDB1hG1Wg1HR8fnHQYRERERERE9Jy/Fe7CJiIiIiIiIXnRMsImIiIiIiIh0gAk2ERERERERkQ7wGWyix8jJAarZKJCIiIiIiAgAV7CJiIiIiIiIdIIJNhEREREREZEOMMEmIiIiIiIi0gEm2EREREREREQ6wASbiIiIiIiISAe02kX85MmTWg/o7u7+xMEQERERERERvay0SrBbt24NhUIBIUSl9RV1CoUCZWVlOg2Q6HkzM3veEbw8qvgngoiIiIjoX0GrBDsjI+PvjoOIiIiIiIjopaZVgm1nZ/d3x0FERERERET0UnuiTc7WrVsHLy8v2Nra4sqVKwCA7777Dtu3b9dpcEREREREREQvixon2GFhYRg/fjx69eqF7Oxs6ZnrOnXq4LvvvtN1fEREREREREQvhRon2IsXL8YPP/yAyZMnQ19fXypv164dTp06pdPgiIiIiIiIiF4WNU6wMzIy4OHhoVGuVCpRUFCgk6CIiIiIiIiIXjY1TrCbNm2K1NRUjfLo6Gi4uLjoIiYiIiIiIiKil45Wu4g/bPz48RgzZgzu3bsHIQSSkpLw008/Yfbs2fjxxx//jhiJiIiIiIiIXng1XsEePnw45s6di9DQUBQWFmLAgAEICwvDokWL0L9//78jRvqHKCkpgaOjIw4dOvTM523SpAmOHj36TOclIiIiIqJ/lyd6TZe/vz8uXLiA/Px8ZGZm4vr16xg2bJiuYwMAZGZmIigoCI6OjlCpVLC2toaXlxfCwsJQWFj41OPHx8ejTZs2UCqVcHR0xOrVq2X1ZWVlmDJlCpo2bQq1Wg0HBwfMmDEDQgitxr99+zYGDx4MW1tb1KpVCz4+Prhw4YKszYoVK/D666/D1NQUCoUC2dnZGjEqFIpKj+TkZADAvXv3MHjwYLi5ucHAwABvv/12tXEdPHgQBgYGaN26dY3PNz8/H4GBgWjYsCHUajVatGiBZcuWPfZaLFu2DE2bNkXHjh1l5XFxcXjzzTdhaWkJlUoFBwcH9OvXD7///rvGGL/99hsaNWokfdbm78PIyAhffPEFgoODHxsjERERERHRk6rxLeIV/vzzT5w7dw4AoFAoYGlpqbOgKly6dAleXl6oU6cOZs2aBTc3NyiVSpw6dQorVqxAgwYN8NZbbz3x+BkZGfDz88Po0aOxYcMG7N+/H8OHD0f9+vXh7e0NAJg7dy7CwsKwZs0auLq64ujRoxgyZAjMzMwwduzYascXQuDtt9+GoaEhtm/fDlNTUyxcuBDdu3dHWloaateuDQAoLCyEj48PfHx8EBISojFOx44dcevWLVnZlClTsH//frRr1w7Ag8RYrVZj7Nix2Lp1a7VxZWdnY+DAgejWrRtu374tq9PmfMePH4/Y2FisX78eTZo0QUxMDD755BPY2tpW+fsQQmDJkiWYPn26rHzp0qUIDAzERx99hJ9//hkODg7IyclBXFwcxo0bh2PHjsnab9++Hb179wZQs78Pf39/fP755zhz5gxcXV2rvT5ERERERERPRNRQbm6uCAgIEPr6+kKhUAiFQiEMDAyEv7+/yM7Orulw1fL29hYNGzYU+fn5ldaXl5dLPwMQy5YtE35+fkKtVgtnZ2dx6NAhceHCBdGlSxdRq1Yt4enpKdLT06U+EydOFK6urrIx+/XrJ7y9vaXPfn5+YujQobI27777rvD3939s/OfOnRMAxOnTp6WysrIyYWlpKX744QeN9nFxcQKAuHv3brXjlpSUCEtLSzF9+vRK6wcNGiT69OlTZf9+/fqJ0NBQMXXqVNGqVStZnTbn6+rqqjF3mzZtxOTJk6ucMzk5Wejp6Ync3Fyp7MqVK8LQ0FCMGzeu0j4P/34rODg4iN27dwshavb3IYQQXbt2FaGhoVXG+KicnBwBQAA5AhA8tDiIiIiIiP6JKnKDnJycats90TPYR44cwa5du5CdnY3s7Gzs3LkTR48exahRo3SW+N+5cwcxMTEYM2aMtNL7KIVCIfs8Y8YMDBw4EKmpqXB2dsaAAQMwatQohISE4OjRoxBCIDAwUGqfmJiI7t27y8bw9vZGYmKi9Lljx47Yv38/zp8/DwA4ceIEDhw4AF9f38eeQ3FxMQBApVJJZXp6elAqlThw4MBj+1clKioKd+7cwZAhQ2rcd9WqVbh06RKmTp1aab0259uxY0dERUXhxo0bEEIgLi4O58+fR8+ePaucNyEhAc2bN4eJiYlUtnXrVpSWlmLixImV9nn093vmzBn8+eefeOONN57o76N9+/ZISEioMsbi4mLk5ubKDiIiIiIiIm3VOMHeuXMnVq5cCW9vb5iamsLU1BTe3t744YcfsGPHDp0Flp6eDiEEnJycZOUWFhYwNjaGsbGxxjO1Q4YMQd++fdG8eXMEBwfj8uXL8Pf3h7e3N1xcXBAUFIT4+HipfWZmJqytrWVjWFtbIzc3F0VFRQCASZMmoX///nB2doahoSE8PDzw2Wefwd/f/7Hn4OzsjMaNGyMkJAR3795FSUkJ5s6di+vXr2vc8l0T4eHh8Pb2RsOGDWvU78KFC5g0aRLWr18PA4PKnw7Q5nwXL16MFi1aoGHDhjAyMoKPjw++//57dO7cucq5r1y5AltbW1nZ+fPnYWpqChsbG6ls69at0u/X2NgYp06dkuq2b98Ob29vGBkZPdHfh62tLa5cuVJljLNnz4aZmZl0PPysNxERERER0ePUOME2NzeHmZmZRrmZmRnq1q2rk6Cqk5SUhNTUVLi6ukorxBXc3d2lnysSZzc3N1nZvXv3arQyuWnTJmzYsAERERE4fvw41qxZg/nz52PNmjWP7WtoaIht27bh/PnzqFevHmrVqoW4uDj4+vpCT++J9pfD9evXsWfPnhpvKldWVoYBAwbg66+/RvPmzatsp835Ll68GIcPH0ZUVBSOHTuGBQsWYMyYMdi3b1+V4xYVFclW8is8usrs7e2N1NRU7Nq1CwUFBSgrK5Pqtm/f/thn7qv7+1Cr1dVujBcSEoKcnBzpuHbtWrVzERERERERPazGm5yFhoZi/PjxWLdunbTymJmZiQkTJmDKlCk6C8zR0REKhULaSK2Cvb09gAfJ0qMMDQ2lnysSt8rKysvLAQA2NjYam3zdvn0bpqam0vgTJkyQVnWBBwn7lStXMHv2bAwaNOix59G2bVukpqYiJycHJSUlsLS0RIcOHaTNyWpq1apVMDc3r/Hmbnl5eTh69ChSUlKk2+TLy8shhICBgQFiYmLwxhtvPPZ8i4qK8OWXXyIyMhJ+fn4AHnyxkZqaivnz52vccl/BwsJCthoNAM2aNUNOTg4yMzOlvyVjY2M4OjpqrLDfunULKSkp0pxP8veRlZVV7WZ8SqUSSqWyynoiIiIiIqLqaLWM6uHhgTZt2qBNmzZYtmwZDh8+jMaNG8PR0RGOjo5o3LgxDh06hOXLl+ssMHNzc/To0QNLlixBQUGBzsZ9mKenJ/bv3y8r27t3Lzw9PaXPhYWFGqvN+vr6UpKuLTMzM1haWuLChQs4evQo+vTpU+N4hRBYtWoVBg4cKPviQBumpqY4deoUUlNTpWP06NFwcnJCamoqOnToAODx51taWorS0tIaXxMPDw+cPXtW9rqv999/H4aGhpg7d+5j49+xYwc6duyIevXqAXiyv4/Tp0/Dw8NDq7ZEREREREQ1pdUK9uPeqfx3Wbp0Kby8vNCuXTtMmzYN7u7u0NPTQ3JyMs6ePYu2bds+1fijR4/GkiVLMHHiRAwdOhSxsbHYtGkTdu3aJbXp3bs3Zs6cicaNG8PV1RUpKSlYuHAhhg4dqtUcmzdvhqWlJRo3boxTp04hKCgIb7/9tmxDsMzMTGRmZiI9PR0AcOrUKZiYmKBx48ZSQgkAsbGxyMjIwPDhwyudKy0tDSUlJcjKykJeXh5SU1MBAK1bt4aenh5atmwpa29lZQWVSiUrf9z5mpqaokuXLpgwYQLUajXs7Ozw22+/Ye3atVi4cGGV16Fr167Iz8/HmTNnpPkaN26MBQsWICgoCFlZWRg8eDCaNm2KrKwsrF+/HsCDxB14sLHbo6v2Nf37SEhIwIwZM6qMkYiIiIiI6Kn83duZP62bN2+KwMBA0bRpU2FoaCiMjY1F+/btxbx580RBQYHUDoCIjIyUPmdkZAgAIiUlRSqr7DVYcXFxonXr1sLIyEjY29uLVatWyebPzc0VQUFBonHjxkKlUgl7e3sxefJkUVxcrFX8ixYtEg0bNhSGhoaicePGIjQ0VKPv1KlT///roOTHo7F8+OGHomPHjlXOZWdnV+k4VansNV3anO+tW7fE4MGDha2trVCpVMLJyUksWLCg0tdqPaxv375i0qRJGuV79+4Vvr6+ol69esLAwEBYW1uLt99+W0RHRwshhMjPzxcqlUpcuHBBo6+2fx+HDh0SderUEYWFhdXG+DC+pouv6SIiIiIiEkL713QphHjonl2iv9HJkyfRo0cPXLx4EcbGxlr327ZtG0JDQ5GWlvbEc/fr1w+tWrXCl19+qXWf3Nzc/7+hXw4A0yee+9+E/5oQERER0T9RRW6Qk5MDU9Oqc4Mab2VdVlaG+fPno3379rCxsUG9evVkB1FV3N3dMXfuXGRkZNSon7GxsVbPaVelpKQEbm5uGDdu3BOPQURERERE9Dg1XsH+6quv8OOPP+Lzzz9HaGgoJk+ejMuXL+OXX37BV199hbFjx/5dsb5wEhIS4OvrW2V9fn7+M4yGdI0r2DXHFWwiIiIi+ifSdgW7xgm2g4MD/vvf/8LPzw8mJiZITU2Vyg4fPoyIiIinDv5lUVRUhBs3blRZ7+jo+AyjIV1jgl1zTLCJiIiI6J9I2wS7xu/BzszMhJubG4AHt+7m5OQAAN58802dvgf7ZaBWq5lEExEREREREYAneAa7YcOGuHXrFoAHq9kxMTEAgOTkZCiVSt1GR0RERERERPSSqHGC/c4772D//v0AgE8//RRTpkxBs2bNMHDgQK3fDU1ERERERET0T/PUr+k6fPgwDh06hGbNmqF37966iovoueMz2DXHZ7CJiIiI6J/ob9vkrCp//vknfvzxxxq9Z5joRabtf0RERERERPTP9re9B7sqt27d+tdtckZERERERERUQWcJNhEREREREdG/GRNsIiIiIiIiIh1ggk1ERERERESkAwbaNhw/fny19X/99ddTB0NERERERET0stI6wU5JSXlsm86dOz9VMEREREREREQvK60T7Li4uL8zDqIXl5nZ847g34Ev0SYiIiKilxyfwSYiIiIiIiLSASbYRERERERERDrABJuIiIiIiIhIB5hgExEREREREekAE2wiIiIiIiIiHdA6wS4oKMDHH3+MBg0awNLSEv379+e7r4mIiIiIiIj+P60T7ClTpmDdunV488034e/vj9jYWIwcOfLvjI2IiIiIiIjopaH1e7AjIyOxatUqfPDBBwCAjz76CK+++iru378PAwOthyEiIiIiIiL6R9J6Bfv69evw8vKSPrdt2xaGhoa4efPm3xIY/TucO3cONjY2yMvL+1vn6d+/PxYsWPC3zkFERERERP9uWifY5eXlMDQ0lJUZGBigrKxMpwFlZmYiKCgIjo6OUKlUsLa2hpeXF8LCwlBYWPhUY9+6dQsDBgxA8+bNoaenh88++0yjzQ8//IDXXnsNdevWRd26ddG9e3ckJSVpPce2bdvQs2dPmJubQ6FQIDU1VVaflZWFTz/9FE5OTlCr1WjcuDHGjh2LnJwcWbuxY8eibdu2UCqVaN26tcY89+7dw+DBg+Hm5gYDAwO8/fbb1cZ18OBBGBgYaIyVl5eHzz77DHZ2dlCr1ejYsSOSk5NlbfLz8xEYGIiGDRtCrVajRYsWWLZsmazN66+/DoVCITtGjx5dbUwAEBISgk8//RQmJiYYPHiwxhgPH02aNJH17dq1Kxo2bFhtH4VCAQAIDQ3FzJkzNa4zERERERGRrmh9b7cQAt26dZPdDl5YWIjevXvDyMhIKjt+/PgTB3Pp0iV4eXmhTp06mDVrFtzc3KBUKnHq1CmsWLECDRo0wFtvvfXE4xcXF8PS0hKhoaH49ttvK20THx+PDz/8EB07doRKpcLcuXPRs2dPnDlzBg0aNHjsHAUFBejUqRP69u2LESNGaNTfvHkTN2/exPz589GiRQtcuXIFo0ePxs2bN7FlyxZZ26FDh+LIkSM4efKkxjhlZWVQq9UYO3Ystm7dWm1M2dnZGDhwILp164bbt2/L6oYPH47Tp09j3bp1sLW1xfr169G9e3ekpaVJ5zt+/HjExsZi/fr1aNKkCWJiYvDJJ5/A1tZW9vsYMWIEpk+fLn2uVatWtXFdvXoVO3fuxOLFiwEAixYtwpw5c6T6+vXrY9WqVfDx8QEA6OvrS3VZWVk4ePAgLly4AKVSKZW/8sorGDlypMa1b9myJRwcHLB+/XqMGTOm2riIiIiIiIiehNYJ9tSpUzXK+vTpo9NgPvnkExgYGODo0aOoXbu2VG5vb48+ffpACCGVKRQKLFu2DDt27EBsbCzs7OywcuVKWFpaYvjw4UhOTkarVq2wbt06ODg4AACaNGmCRYsWAQBWrlxZaQwbNmyQff7xxx+xdetW7N+/HwMHDnzsOXz00UcAgMuXL1da37JlS1lC7ODggJkzZyIgIED2PPt///tfAMBff/1VaYJdu3ZthIWFAXiwOp2dnV1lTKNHj8aAAQOgr6+PX375RSovKirC1q1bsX37dnTu3BkAMG3aNOzYsQNhYWH4z3/+AwA4dOgQBg0ahNdffx0AMHLkSCxfvhxJSUmyBLtWrVqwsbGp5urIbdq0Ca1atZISeTMzM5iZmcna1KlTp9Ixd+3ahTZt2sDOzk5Wrq+vDxMTk0r79O7dGxs3bqwywS4uLkZxcbH0OTc3V+tzISIiIiIieqoEW5fu3LmDmJgYzJo1S5ZcP6zidt8KM2bMwMKFC7Fw4UIEBwdjwIABsLe3R0hICBo3boyhQ4ciMDAQu3fvfuK4CgsLUVpainr16j3xGI+Tk5MDU1PTv2WzuFWrVuHSpUtYv369lDBXuH//PsrKyqBSqWTlarUaBw4ckD537NgRUVFRGDp0KGxtbREfH4/z589r3AWwYcMGrF+/HjY2NujduzemTJlS7Sp2QkIC2rVr90TnFRUVVeMveNq3b4+ZM2eiuLhYtupdYfbs2fj666+fKB4iIiIiIiKtn8H+u6Wnp0MIAScnJ1m5hYUFjI2NYWxsjODgYFndkCFD0LdvXzRv3hzBwcG4fPky/P394e3tDRcXFwQFBSE+Pv6p4goODoatrS26d+/+VONU5X//+x9mzJjxt7zy7MKFC5g0aRLWr19fafJuYmICT09PzJgxAzdv3kRZWRnWr1+PxMRE3Lp1S2q3ePFitGjRAg0bNoSRkRF8fHzw/fffS6veADBgwACsX78ecXFxCAkJwbp16xAQEFBtfFeuXIGtrW2Nz6u4uBjR0dE1flzA1tYWJSUlyMzMrLQ+JCQEOTk50nHt2rUax0ZERERERP9eWi+Zdu3aVWMF+VEKhQL79+9/6qAelpSUhPLycvj7+8tu3wUAd3d36Wdra2sAgJubm6zs3r17yM3NhampaY3nnjNnDjZu3Ij4+HiNVV5dyM3NhZ+fH1q0aIFp06bpdOyysjIMGDAAX3/9NZo3b15lu3Xr1mHo0KFo0KAB9PX10aZNG3z44Yc4duyY1Gbx4sU4fPgwoqKiYGdnh99//x1jxoyRffHw8BcEbm5uqF+/Prp164aLFy9Kt+g/qqio6Imua2xsLKysrODq6lqjfmq1GgCq3CxPqVRWurJNRERERESkDa0T7Mp2sq6Ql5eHiIgIjQS4JhwdHaFQKHDu3DlZub29PYD/S44e9vCu5hXJf2Vl5eXlNY5n/vz5mDNnDvbt2ydL5HUlLy8PPj4+MDExQWRkpMYO7boY/+jRo0hJSUFgYCCAB9dBCAEDAwPExMTgjTfegIODA3777TcUFBQgNzcX9evXR79+/aTrXlRUhC+//BKRkZHw8/MD8OCLjdTUVMyfP7/Klf0OHToAeHBnQlUJtoWFBe7evVvjc4uKinqize6ysrIAAJaWljXuS0RERERE9DhaJ9iV7bp9//59fP/995g5cyYaNGiAGTNmPHEg5ubm6NGjB5YsWYJPP/20yuewn4VvvvkGM2fOxJ49e574GeHq5ObmwtvbG0qlElFRUX/L6ripqSlOnTolK1u6dCliY2OxZcsWNG3aVFZXu3Zt1K5dG3fv3sWePXvwzTffAABKS0tRWloKPT350wT6+vrVfnFR8Xqy+vXrV9nGw8MDaWlpNTktCCGwY8cOrF+/vkb9AOD06dNo2LAhLCwsatyXiIiIiIjocZ54V60NGzbgq6++QlFREaZNm4aRI0c+9SZdS5cuhZeXF9q1a4dp06bB3d0denp6SE5OxtmzZ9G2bdunGh/4v8QvPz8ff/31F1JTU2FkZIQWLVoAAObOnYuvvvoKERERaNKkifS8bsVz4I+TlZWFq1ev4ubNmwAgrcjb2NjAxsYGubm56NmzJwoLC7F+/Xrk5uZKu1VbWlpKr6JKT09Hfn4+MjMzUVRUJMXdokUL6bVoaWlpKCkpQVZWFvLy8qQ2rVu3hp6eHlq2bCmLzcrKCiqVSla+Z88e6dn39PR0TJgwAc7OzhgyZAiAB4l6ly5dMGHCBKjVatjZ2eG3337D2rVrsXDhQgDAxYsXERERgV69esHc3BwnT57EuHHj0Llz52pX/729vTF8+HCUlZXJXsFVnWPHjqGwsBCdOnXSqv3DEhIS0LNnzxr3IyIiIiIi0oqood27d4tWrVoJU1NTMX36dJGfn1/TIap18+ZNERgYKJo2bSoMDQ2FsbGxaN++vZg3b54oKCiQ2gEQkZGR0ueMjAwBQKSkpEhlcXFxAoC4e/eurN+jh52dnVRvZ2dXaZupU6dqFf+qVauq7V8RU2VHRkaGNE6XLl0e26aqWKsydepU0apVK1nZzz//LOzt7YWRkZGwsbERY8aMEdnZ2bI2t27dEoMHDxa2trZCpVIJJycnsWDBAlFeXi6EEOLq1auic+fOol69ekKpVApHR0cxYcIEkZOTU+21Ki0tFba2tiI6OrrS+kd/x0IIERoaKvz9/asc087OTnz77bca5UVFRcLMzEwkJiZWG9PDcnJyBACRAwjB4+8/iIiIiIheUFJu8JgcRyHEQy+XrkZSUhKCg4Nx+PBhjB49GpMnT+attvTUvv/+e0RFRWHPnj1atXd3d0doaCj69u1bo3nCwsIQGRmJmJgYrfvk5ubCzMwMOQBqvkUe1Zh2/xQRERERET1zUm7w/1+xXBWt7+l+9dVXoVarMXr0aDRt2hQRERGVths7dmzNo6V/rVGjRiE7Oxt5eXkwMTGptm1JSQnee+89+Pr61ngeQ0NDLF68+EnDJCIiIiIieiytV7CbNGmi1Wu6Ll26pJPAXkQJCQnVJnf5+fnPMBr6u3EF+xnjCjYRERERvaB0voJ9+fJlXcT1UmvXrp20kRgRERERERHRw55u2+9/GbVaDUdHx+cdBhEREREREb2A9B7f5IHExETs3LlTVrZ27Vo0bdoUVlZWGDlyJIqLi3UeIBEREREREdHLQOsEe/r06Thz5oz0+dSpUxg2bBi6d++OSZMmYceOHZg9e/bfEiQRERERERHRi07rW8RTU1MxY8YM6fPGjRvRoUMH/PDDDwCARo0aYerUqZg2bZrOgyR6rnJygGo2MiAiIiIiIgJqsIJ99+5dWFtbS59/++032Y7ar7zyCq5du6bb6IiIiIiIiIheElon2NbW1sjIyADw4H3Ex48fx6uvvirV5+XlwdDQUPcREhEREREREb0EtE6we/XqhUmTJiEhIQEhISGoVasWXnvtNan+5MmTcHBw+FuCJCIiIiIiInrRaf0M9owZM/Duu++iS5cuMDY2xpo1a2BkZCTVr1y5Ej179vxbgiQiIiIiIiJ60SmEEKImHXJycmBsbAx9fX1ZeVZWFoyNjWVJN9HLLDc3F2ZmZsjJyYEpNzkjIiIiIvrX0jY30HoFu4KZmVml5fXq1avpUERERERERET/GDVOsIn+dar4Uukfr2Y3txARERER/etpvckZEREREREREVWNCTYRERERERGRDjDBJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiIdYIJNREREREREpANMsOm52L9/P1xcXFBWVvZM5nv11VexdevWZzIXERERERH9O70wCXZmZiaCgoLg6OgIlUoFa2treHl5ISwsDIWFhU819q1btzBgwAA0b94cenp6+OyzzzTa/PDDD3jttddQt25d1K1bF927d0dSUpLWc2zbtg09e/aEubk5FAoFUlNTK22XmJiIN954A7Vr14apqSk6d+6MoqIiAMDly5cxbNgwNG3aFGq1Gg4ODpg6dSpKSkqk/ufOnUPXrl1hbW0NlUoFe3t7hIaGorS0VDbPd999BycnJ6jVajRq1Ajjxo3DvXv3pPqysjJMmTJFNteMGTMghJDaKBSKSo958+ZJbbKysuDv7w9TU1PUqVMHw4YNQ35+/mOv18SJExEaGgp9fX1ZeVFREerVqwcLCwsUFxdX2b9p06bYt2+frMzZ2RlKpRKZmZka7UNDQzFp0iSUl5c/NjYiIiIiIqIn8UIk2JcuXYKHhwdiYmIwa9YspKSkIDExERMnTsTOnTs1EqmaKi4uhqWlJUJDQ9GqVatK28THx+PDDz9EXFwcEhMT0ahRI/Ts2RM3btzQao6CggJ06tQJc+fOrbJNYmIifHx80LNnTyQlJSE5ORmBgYHQ03vwazh79izKy8uxfPlynDlzBt9++y2WLVuGL7/8UhrD0NAQAwcORExMDM6dO4fvvvsOP/zwA6ZOnSq1iYiIwKRJkzB16lT88ccfCA8Px88//ywbZ+7cuQgLC8OSJUvwxx9/YO7cufjmm2+wePFiqc2tW7dkx8qVK6FQKPDee+9Jbfz9/XHmzBns3bsXO3fuxO+//46RI0dWe60OHDiAixcvysapsHXrVri6usLZ2Rm//PJLpf1PnjyJu3fvokuXLrIxi4qK8P7772PNmjUafXx9fZGXl4fdu3dXGxsREREREdGTUoiHlyyfEx8fH5w5cwZnz55F7dq1NeqFEFAoFAAerKouW7YMO3bsQGxsLOzs7LBy5UpYWlpi+PDhSE5ORqtWrbBu3To4ODhojPX666+jdevW+O6776qNqaysDHXr1sWSJUswcOBArc/l8uXLaNq0KVJSUtC6dWtZ3auvvooePXpgxowZWo83b948hIWF4dKlS1W2GT9+PJKTk5GQkAAACAwMxB9//IH9+/dLbT7//HMcOXIEBw4cAAC8+eabsLa2Rnh4uNTmvffeg1qtxvr16yud5+2330ZeXp407h9//IEWLVogOTkZ7dq1AwBER0ejV69euH79OmxtbSsdJzAwELdv38bmzZs16rp27Yr+/ftDCIFt27YhJiZGo82MGTNw5swZbNy4USobMmQIbGxs0KVLFwQFBeHcuXMa/YYOHYrS0lKsW7eu0rgelZubCzMzM+QAMNWqxz/M8/+ngYiIiIjohSDlBjk5MDWtOjt47ivYd+7cQUxMDMaMGVNpcg1ASq4rzJgxAwMHDkRqaiqcnZ0xYMAAjBo1CiEhITh69CiEEAgMDHyquAoLC1FaWop69eo91TgV/vzzTxw5cgRWVlbo2LEjrK2t0aVLFynhrUpOTk61MaSnpyM6Olq2mtuxY0ccO3ZMusX90qVL+PXXX9GrVy9Zm/379+P8+fMAgBMnTuDAgQPw9fWtdJ7bt29j165dGDZsmFSWmJiIOnXqSMk1AHTv3h16eno4cuRIlTEnJCTI+lS4ePEiEhMT0bdvX/Tt2xcJCQm4cuWKRruoqCj06dNH+pyXl4fNmzcjICAAPXr0QE5OjvRlw8Pat29faXmF4uJi5Obmyg4iIiIiIiJtPfcEOz09HUIIODk5ycotLCxgbGwMY2NjBAcHy+qGDBmCvn37onnz5ggODsbly5fh7+8Pb29vuLi4ICgoCPHx8U8VV3BwMGxtbdG9e/enGqdCxQr0tGnTMGLECERHR6NNmzbo1q0bLly4UGmf9PR0LF68GKNGjdKo69ixI1QqFZo1a4bXXnsN06dPl+oGDBiA6dOno1OnTjA0NISDgwNef/112S3ikyZNQv/+/eHs7AxDQ0N4eHjgs88+g7+/f6WxrFmzBiYmJnj33XelsszMTFhZWcnaGRgYoF69epU+B13hypUrla5ur1y5Er6+vqhbty7q1asHb29vrFq1Stbmxo0bOHnypOyLgI0bN6JZs2ZwdXWFvr4++vfvL1uZr2Bra4tr165V+Rz27NmzYWZmJh2NGjWq8hyIiIiIiIge9dwT7KokJSUhNTUVrq6uGptdubu7Sz9bW1sDANzc3GRl9+7de+IVyDlz5mDjxo2IjIyESqV6ojEeVZHUjRo1CkOGDIGHhwe+/fZbODk5YeXKlRrtb9y4AR8fH3zwwQcYMWKERv3PP/+M48ePIyIiArt27cL8+fOluvj4eMyaNQtLly7F8ePHsW3bNuzatUt2a/qmTZuwYcMGRERE4Pjx41izZg3mz59f6fPLwIPk19/fXyfXo6ioSGOcsrIyrFmzBgEBAVJZQEAAVq9eLUuIo6Ki0KlTJ9SpU0cW26P9Nm/ejLy8PNkcarUa5eXlVW6eFhISgpycHOm4du3a05wmERERERH9yxg87wAcHR2hUCg0npm1t7cH8CApepShoaH0c8Xt45WVPcmO0fPnz8ecOXOwb98+WSL/tOrXrw8AaNGihazcxcUFV69elZXdvHkTXbt2RceOHbFixYpKx6tYXW3RogXKysowcuRIfP7559DX18eUKVPw0UcfYfjw4QAefPlQUFCAkSNHYvLkydDT08OECROkVeyKNleuXMHs2bMxaNAg2VwJCQk4d+4cfv75Z1m5jY0N/vzzT1nZ/fv3kZWVBRsbmyqvhYWFBe7evSsr27NnD27cuIF+/frJysvKyrB//3706NEDwIME+6233pLq09LScPjwYSQlJcnudCgrK8PGjRtlX05kZWWhdu3alf5NAYBSqYRSqawybiIiIiIiouo89xVsc3Nz9OjRA0uWLEFBQcFzjeWbb77BjBkzEB0dXekzwk+jSZMmsLW11fgi4fz587Czs5M+37hxA6+//jratm2LVatWSTuMV6e8vBylpaXSFwqFhYUa/Speh1Wxp11VbSr7UiI8PBxt27bV2IHd09MT2dnZOHbsmFQWGxuL8vJydOjQocp4PTw8kJaWpjFH//79kZqaKjsevt07Pz8fcXFxsuevw8PD0blzZ5w4cULWb/z48Rq3iZ8+fRoeHh5VxkVERERERPQ0nvsKNgAsXboUXl5eaNeuHaZNmwZ3d3fo6ekhOTkZZ8+eRdu2bZ96jor3Uufn5+Ovv/5CamoqjIyMpBXluXPn4quvvkJERASaNGkiPUNc8Rz442RlZeHq1au4efMmAEiJtI2NDWxsbKBQKDBhwgRMnToVrVq1QuvWrbFmzRqcPXsWW7ZsAfB/ybWdnR3mz5+Pv/76Sxq/YkV4w4YNMDQ0hJubG5RKJY4ePYqQkBD069dPWsXv3bs3Fi5cCA8PD3To0AHp6emYMmUKevfuLSXavXv3xsyZM9G4cWO4uroiJSUFCxcuxNChQ2XnlZubi82bN2PBggUa5+zi4gIfHx+MGDECy5YtQ2lpKQIDA9G/f/8qdxAHAG9vb9mt6H/99Rd27NiBqKgotGzZUtZ24MCBeOedd5CVlYXY2Fg0b94cTZo0AQBpR/Dp06dr9Bs+fDgWLlyIM2fOwNXVFcCDlfiePXtWGRcREREREdFTES+ImzdvisDAQNG0aVNhaGgojI2NRfv27cW8efNEQUGB1A6AiIyMlD5nZGQIACIlJUUqi4uLEwDE3bt3Zf0ePezs7KR6Ozu7SttMnTpVq/hXrVqlVf/Zs2eLhg0bilq1aglPT0+RkJDw2DEe/jVt3LhRtGnTRhgbG4vatWuLFi1aiFmzZomioiKpTWlpqZg2bZpwcHAQKpVKNGrUSHzyySey65GbmyuCgoJE48aNhUqlEvb29mLy5MmiuLhYFu/y5cuFWq0W2dnZlZ73nTt3xIcffiiMjY2FqampGDJkiMjLy6v2Wt25c0eoVCpx9uxZIYQQ8+fPF3Xq1BElJSUabYuLi0WdOnXEokWLREBAgJg8ebJUt2XLFqGnpycyMzMrncfFxUWMGzdOCCHE9evXhaGhobh27Vq1sT0sJydHABA5D15Y9e87iIiIiIhICPFQbpCTU227F+I92PTvM2HCBOTm5mL58uVatb9//z6sra2xe/dutG/fvsbzBQcH4+7du1U+014Zvgeb/zQQEREREQEv0Xuw6d9p8uTJsLOz03ojuqysLIwbNw6vvPLKE81nZWUl20WdiIiIiIhI17iCrYWEhATZe5cflZ+f/wyjoWeFK9j8p4GIiIiICNB+BfuF2OTsRdeuXTtpkzQiIiIiIiKiyjDB1oJarYajo+PzDoOIiIiIiIheYHwGm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiId4DPYRI+TkwNUs1MgERERERERwBVsIiIiIiIiIp1ggk1ERERERESkA0ywiYiIiIiIiHSACTYRERERERGRDjDBJiIiIiIiItIBJthEREREREREOsDXdBE9htlsM0D1vKMgIiIiIvr3EFPF8w7hiXAFm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiIdYIJNREREREREpANMsImIiIiIiIh0gAk2ERERERERkQ4wwSYiIiIiIiLSASbYRERERERERDrABJueqfDwcPTs2fOZz7ts2TL07t37mc9LRERERET/Hs89wc7MzERQUBAcHR2hUqlgbW0NLy8vhIWFobCw8KnHj4+PR5s2baBUKuHo6IjVq1drtLlx4wYCAgJgbm4OtVoNNzc3HD16tMZzjR49GgqFAt99952s/Pz58+jTpw8sLCxgamqKTp06IS4uTtYmOTkZ3bp1Q506dVC3bl14e3vjxIkTUv25c+fQtWtXWFtbQ6VSwd7eHqGhoSgtLZXanDlzBu+99x6aNGlSaRwAEBYWBnd3d5iamsLU1BSenp7YvXu3VJ+VlYVPP/0UTk5OUKvVaNy4McaOHYucnBypzZ07d+Dj4wNbW1solUo0atQIgYGByM3Nrfb63Lt3D1OmTMHUqVNl5bm5uZgyZQpcXV2hVqthbm6OV155Bd988w3u3r2rMU7Xrl3x448/Sp+3bt2KN954A3Xr1oVarYaTkxOGDh2KlJQUqc3QoUNx/PhxJCQkVBsjERERERHRk3quCfalS5fg4eGBmJgYzJo1CykpKUhMTMTEiROxc+dO7Nu376nGz8jIgJ+fH7p27YrU1FR89tlnGD58OPbs2SO1uXv3Lry8vGBoaIjdu3cjLS0NCxYsQN26dWs0V2RkJA4fPgxbW1uNujfffBP3799HbGwsjh07hlatWuHNN99EZmYmACA/Px8+Pj5o3Lgxjhw5ggMHDsDExATe3t5SAm1oaIiBAwciJiYG586dw3fffYcffvhBlqwWFhbC3t4ec+bMgY2NTaVxNmzYEHPmzMGxY8dw9OhRvPHGG+jTpw/OnDkDALh58yZu3ryJ+fPn4/Tp01i9ejWio6MxbNgwaQw9PT306dMHUVFROH/+PFavXo19+/Zh9OjR1V6jLVu2wNTUFF5eXlJZVlYWXn31VaxatQpffPEFjhw5guPHj2PmzJlISUlBRESEbIysrCwcPHhQWo0ODg5Gv3790Lp1a0RFReHcuXOIiIiAvb09QkJCpH5GRkYYMGAA/vvf/1YbIxERERER0ZNSCCHE85rcx8cHZ86cwdmzZ1G7dm2NeiEEFAoFAEChUGDZsmXYsWMHYmNjYWdnh5UrV8LS0hLDhw9HcnIyWrVqhXXr1sHBwQHAg+Rr165dOH36tDRm//79kZ2djejoaADApEmTcPDgwada2bxx4wY6dOiAPXv2wM/PD5999hk+++wzAMD//vc/WFpa4vfff8drr70GAMjLy4OpqSn27t2L7t274+jRo3jllVdw9epVNGrUCABw6tQpuLu748KFC3B0dKx03vHjxyM5ObnS2Js0aSKLozr16tXDvHnzZEn0wzZv3oyAgAAUFBTAwMCg0jb//e9/MW/ePFy7dq3Ked588024uLhg3rx5Utno0aOxfv16nD9/vtIvJx7+GwCAdevW4fvvv8fhw4dx+PBheHp6YtGiRRg7duxj+/7+++/o0aMHsrOzoVarq4yzQm5uLszMzIBJAFSPbU5ERERERDoipj63NLVSFblBTk4OTE1Nq2z33Faw79y5g5iYGIwZM6bS5BqALDkCgBkzZmDgwIFITU2Fs7MzBgwYgFGjRiEkJARHjx6FEAKBgYFS+8TERHTv3l02hre3NxITE6XPUVFRaNeuHT744ANYWVnBw8MDP/zwg9bnUV5ejo8++ggTJkyAq6urRr25uTmcnJywdu1aFBQU4P79+1i+fDmsrKzQtm1bAICTkxPMzc0RHh6OkpISFBUVITw8HC4uLmjSpEml86anpyM6OhpdunTROtZHlZWVYePGjSgoKICnp2eV7Sr+iKpKrm/evIlt27Y9NpYDBw6gXbt20ufy8nL8/PPPCAgIqDS5BjT/BqKiotCnTx8AwE8//QRjY2N88sknWvVt164d7t+/jyNHjlTavri4GLm5ubKDiIiIiIhIW88twU5PT4cQAk5OTrJyCwsLGBsbw9jYGMHBwbK6IUOGoG/fvmjevDmCg4Nx+fJl+Pv7w9vbGy4uLggKCkJ8fLzUPjMzE9bW1rIxrK2tkZubi6KiIgAPblMPCwtDs2bNsGfPHnz88ccYO3Ys1qxZo9V5zJ07FwYGBpWuoAIPkrx9+/YhJSUFJiYmUKlUWLhwIaKjo6Xb0E1MTBAfH4/169dDrVbD2NgY0dHR2L17t0ZS27FjR6hUKjRr1gyvvfYapk+frlWcDzt16hSMjY2hVCoxevRoREZGokWLFpW2/d///ocZM2Zg5MiRGnUffvghatWqhQYNGsDU1FT2XPSjsrOzkZOTI0uk//rrL2RnZ2v8DbRt21b6G/jwww+l8uLiYkRHR+Ott94C8ODZdnt7e9k1WrhwodTX2NhY9ux4rVq1YGZmhitXrlQa4+zZs2FmZiYdFXcTEBERERERaeO5b3L2qKSkJKSmpsLV1RXFxcWyOnd3d+nnisTZzc1NVnbv3r0arTyWl5ejTZs2mDVrFjw8PDBy5EiMGDECy5Yte2zfY8eOYdGiRVi9erXGamkFIQTGjBkDKysrJCQkICkpCW+//TZ69+6NW7duAQCKioowbNgweHl54fDhwzh48CBatmwJPz8/6YuACj///DOOHz+OiIgI7Nq1C/Pnz9f6XCs4OTkhNTUVR44cwccff4xBgwYhLS1No11ubi78/PzQokULTJs2TaP+22+/xfHjx7F9+3ZcvHgR48ePr3LOivNQqR5/r3VkZCRSU1Ph7e0tO//Y2FhYWVlVeqdAhaFDhyI1NRXLly9HQUEBHn0CQq1WV7l5XkhICHJycqSjutvdiYiIiIiIHlX5Pb/PgKOjIxQKBc6dOycrt7e3B4BKn5E1NDSUfq5IaCsrKy8vBwDY2Njg9u3bsjFu374NU1NTafz69etrrN66uLhg69atjz2HhIQE/Pnnn2jcuLFUVlZWhs8//xzfffcdLl++jNjYWOzcuRN3796V7tVfunQp9u7dizVr1mDSpEmIiIjA5cuXkZiYCD29B995REREoG7duti+fTv69+8vjV+xqtqiRQuUlZVh5MiR+Pzzz6Gvr//YeCsYGRlJz3W3bdsWycnJWLRoEZYvXy61ycvLg4+PD0xMTBAZGSm7zhVsbGxgY2MDZ2dn1KtXD6+99hqmTJmC+vXra7Q1NzeHQqGQ7QpuaWmJOnXqaPwNVFxPExMTZGdnS+VRUVHS6jUANGvWDAcOHEBpaakUX506dVCnTh1cv3690nPPysqCpaVlpXVKpRJKpbLSOiIiIiIiosd5bivY5ubm6NGjB5YsWYKCgoK/ZQ5PT0/s379fVrZ3717Z88ZeXl4aCd758+dhZ2f32PE/+ugjnDx5EqmpqdJha2uLCRMmSDuVV6yWViTOFfT09KQvAgoLC6GnpydbBa/4XNGmMuXl5SgtLa22jTbKy8tldwvk5uaiZ8+eMDIyQlRUlFarzhUxPHrXQQUjIyO0aNFCtlKup6eHvn37Yv369bh582a14wshsGPHDun5a+DBLer5+flYunTpY+MDgIsXL+LevXvw8PDQqj0REREREVFNPLcVbODBSq6XlxfatWuHadOmwd3dHXp6ekhOTsbZs2elTcCe1OjRo7FkyRJMnDgRQ4cORWxsLDZt2oRdu3ZJbcaNG4eOHTti1qxZ6Nu3L5KSkrBixQqsWLHiseObm5vD3NxcVmZoaAgbGxvpuWJPT0/UrVsXgwYNwldffQW1Wo0ffvhBeoUYAPTo0QMTJkzAmDFj8Omnn6K8vBxz5syBgYEBunbtCgDYsGEDDA0N4ebmBqVSiaNHjyIkJAT9+vWTVm9LSkqkBLakpAQ3btxAamoqjI2NpRXrkJAQ+Pr6onHjxsjLy0NERATi4+OlLwQqkuvCwkKsX79ettmXpaUl9PX18euvv+L27dt45ZVXYGxsjDNnzmDChAnw8vKqclM24MEGcwcOHJDtbD5r1izEx8ejffv2mD59Otq1a4fatWvj5MmTSExMRMuWLQE8uB2/sLAQnTp1kvp6enri888/x+eff44rV67g3XffRaNGjXDr1i2Eh4dDoVDIvthISEiAvb29tMs8ERERERGRLj3XBNvBwQEpKSmYNWsWQkJCcP36dSiVSrRo0QJffPFFlbtDa6tp06bYtWsXxo0bh0WLFqFhw4b48ccf4e3tLbV55ZVXEBkZiZCQEEyfPh1NmzbFd999B39//6c9PQAPNm2Ljo7G5MmT8cYbb6C0tBSurq7Yvn07WrVqBQBwdnbGjh078PXXX8PT0xN6enrw8PBAdHS0dLu1gYEB5s6di/Pnz0MIATs7OwQGBmLcuHHSXDdv3pStzs6fPx/z589Hly5dpM3f/vzzTwwcOBC3bt2CmZkZ3N3dsWfPHvTo0QMAcPz4cWmX7UdfD5aRkYEmTZpIXxKMGzcOxcXFaNSoEd59911MmjSp2msxbNgwtGvXDjk5OQ9ef4UHX1IkJSVh7ty5mDdvHjIyMqCnp4dmzZqhX79+UjK+fft29OrVS2PTt/nz56N9+/YICwvDypUrUVhYCGtra3Tu3BmJiYmyLfR/+uknjBgxQqvfGxERERERUU091/dg07/PBx98gDZt2iAkJKRG/dzd3REaGoq+ffs+0bxnzpzBG2+8gfPnz0vJ/ePwPdhERERERM8H34NNpIV58+bB2Ni4Rn1KSkrw3nvvwdfX94nnvXXrFtauXat1ck1ERERERFRTXMGuRkJCQrVJXX5+/jOMhp41rmATERERET0fL+sK9nN9BvtF165dO6Smpj7vMIiIiIiIiOglwAS7Gmq1WmOjLyIiIiIiIqLK8BlsIiIiIiIiIh1ggk1ERERERESkA0ywiYiIiIiIiHSAz2ATPUZOSPU7BRIREREREQFcwSYiIiIiIiLSCSbYRERERERERDrABJuIiIiIiIhIB5hgExEREREREekAE2wiIiIiIiIiHWCCTURERERERKQDfE0X0WOZPe8AiIiI6F9LPO8AiKgGuIJNREREREREpANMsImIiIiIiIh0gAk2ERERERERkQ4wwSYiIiIiIiLSASbYRERERERERDrABJuIiIiIiIhIB5hgExEREREREekAE2wiIiIiIiIiHWCCTc/FRx99hFmzZj2TudLS0tCwYUMUFBQ8k/mIiIiIiOjf6YVJsDMzMxEUFARHR0eoVCpYW1vDy8sLYWFhKCwsfOrx4+Pj0aZNGyiVSjg6OmL16tWy+tmzZ+OVV16BiYkJrKys8Pbbb+PcuXM1nkcIAV9fXygUCvzyyy+Vtrlz5w4aNmwIhUKB7OzsStscPHgQBgYGaN26tay8rKwMU6ZMQdOmTaFWq+Hg4IAZM2ZACCFr98cff+Ctt96CmZkZateujVdeeQVXr16V6l9//XUoFArZMXr0aKn+xIkT+PDDD9GoUSOo1Wq4uLhg0aJFsjkGDx6sMYZCoYCrq2u11+jEiRP49ddfMXbsWI26n376Cfr6+hgzZkyV/X/77Tc0atRIVpaYmAh9fX34+flptG/RogVeffVVLFy4sNq4iIiIiIiInsYLkWBfunQJHh4eiImJwaxZs5CSkoLExERMnDgRO3fuxL59+55q/IyMDPj5+aFr165ITU3FZ599huHDh2PPnj1Sm99++w1jxozB4cOHsXfvXpSWlqJnz541XvX87rvvoFAoqm0zbNgwuLu7V1mfnZ2NgQMHolu3bhp1c+fORVhYGJYsWYI//vgDc+fOxTfffIPFixdLbS5evIhOnTrB2dkZ8fHxOHnyJKZMmQKVSiUba8SIEbh165Z0fPPNN1LdsWPHYGVlhfXr1+PMmTOYPHkyQkJCsGTJEqnNokWLZP2vXbuGevXq4YMPPqj2/BcvXowPPvgAxsbGGnXh4eGYOHEifvrpJ9y7d6/S/tu3b0fv3r01+n366af4/fffcfPmTY0+Q4YMQVhYGO7fv19tbERERERERE9MvAC8vb1Fw4YNRX5+fqX15eXl0s8AxLJly4Sfn59Qq9XC2dlZHDp0SFy4cEF06dJF1KpVS3h6eor09HSpz8SJE4Wrq6tszH79+glvb+8qY/rzzz8FAPHbb79pfR4pKSmiQYMG4tatWwKAiIyM1GizdOlS0aVLF7F//34BQNy9e1ejTb9+/URoaKiYOnWqaNWqlazOz89PDB06VFb27rvvCn9/f1n/gICAamPt0qWLCAoK0vbUhBBCfPLJJ6Jr165V1kdGRgqFQiEuX75cZZv79+8LMzMzsXPnTo26S5cuCbVaLbKzs0WHDh3Ehg0bKh3DwcFB7N69W/qcl5cnjI2NxdmzZ0W/fv3EzJkzNfoUFxcLpVIp9u3bV2Vs9+7dEzk5OdJx7do1AUDk5EAIwYMHDx48ePDg8TwOInoR5OTk/P/cIKfads99BfvOnTuIiYnBmDFjULt27UrbPLoiPGPGDAwcOBCpqalwdnbGgAEDMGrUKISEhODo0aMQQiAwMFBqn5iYiO7du8vG8Pb2RmJiYpVx5eTkAADq1aun1XkUFhZiwIAB+P7772FjY1Npm7S0NEyfPh1r166Fnl7ll37VqlW4dOkSpk6dWml9x44dsX//fpw/fx7Ag9utDxw4AF9fXwBAeXk5du3ahebNm8Pb2xtWVlbo0KFDpberb9iwARYWFmjZsiVCQkIeeyt+Tk5OtdcjPDwc3bt3h52dXZVtTp48iZycHLRr106jbtWqVfDz84OZmRkCAgIQHh6u0ebMmTP4888/8cYbb0hlmzZtgrOzM5ycnBAQEICVK1dCCPkt80ZGRmjdujUSEhKqjG327NkwMzOTjkdvQyciIiIiIqrWM0n3q3H48GEBQGzbtk1Wbm5uLmrXri1q164tJk6cKJUDEKGhodLnxMREAUCEh4dLZT/99JNQqVTS52bNmolZs2bJxt+1a5cAIAoLCzViKisrE35+fsLLy0vr8xg5cqQYNmyYLM6HV7Dv3bsn3N3dxbp164QQQsTFxWmsYJ8/f15YWVmJc+fOCSFEpSvYZWVlIjg4WCgUCmFgYCAUCoXs3CpWz2vVqiUWLlwoUlJSxOzZs4VCoRDx8fFSu+XLl4vo6Ghx8uRJsX79etGgQQPxzjvvVHl+Bw8eFAYGBmLPnj2V1t+4cUPo6+uLn3/+udrrFBkZKfT19WV3JVScV6NGjcQvv/wihBDir7/+EkZGRuLSpUuydjNnzhTvv/++rKxjx47iu+++E0IIUVpaKiwsLERcXJzG3O+8844YPHhwlbFxBZsHDx48ePDg8eIdRPQi0HYF2+C5ZfaPkZSUhPLycvj7+6O4uFhW9/Dzy9bW1gAANzc3Wdm9e/eQm5sLU1PTGs89ZswYnD59GgcOHNCqfVRUFGJjY5GSklJlm5CQELi4uCAgIKDS+rKyMgwYMABff/01mjdvXuU4mzZtwoYNGxAREQFXV1fpmXJbW1sMGjQI5eXlAIA+ffpg3LhxAIDWrVvj0KFDWLZsGbp06QIAGDlypDSmm5sb6tevj27duuHixYtwcHCQzXn69Gn06dMHU6dORc+ePSuNa82aNahTpw7efvvtKmMHgKKiIiiVSo27Evbu3YuCggL06tULAGBhYYEePXpg5cqVmDFjhtRu+/btsrsTzp07h6SkJERGRgIADAwM0K9fP4SHh+P111+XzaFWq6tdpVcqlVAqldXGT0REREREVJXnnmA7OjpCoVBo7Nhtb28P4EFS9ChDQ0Pp54pErbKyimTTxsYGt2/flo1x+/ZtmJqaaowfGBiInTt34vfff0fDhg21OofY2FhcvHgRderUkZW/9957eO211xAfH4/Y2FicOnUKW7ZsAfBgt3HgQSI5efJkjBs3DkePHkVKSoqUQJaXl0MIAQMDA8TExOCNN97AhAkTMGnSJPTv3x/Ag+T4ypUrmD17NgYNGgQLCwsYGBigRYsWslhcXFyq/cKgQ4cOAID09HRZgp2WloZu3bph5MiRCA0NrbSvEAIrV67ERx99BCMjo2qvlYWFBQoLC1FSUiJrGx4ejqysLNnvo7y8HCdPnsTXX38NPT093Lp1CykpKbKdwsPDw3H//n3Y2trK4lEqlViyZAnMzMyk8qysLI0vD4iIiIiIiHTluSfY5ubm6NGjB5YsWYJPP/20yuewn4anpyd+/fVXWdnevXvh6ekpfRZC4NNPP0VkZCTi4+PRtGlTrcefNGkShg8fLitzc3PDt99+K+12vXXrVhQVFUn1ycnJGDp0KBISEuDg4ABTU1OcOnVKNsbSpUsRGxuLLVu2SPEUFhZqPL+tr68vfZlgZGSEV155ReMLi/Pnz1f7bHRqaioAoH79+lLZmTNn8MYbb2DQoEGYOXNmlX1/++03pKenY9iwYVW2qVDx2rG0tDTp5zt37mD79u3YuHGj7BVfZWVl6NSpE2JiYuDj44MdO3agY8eO0nPg9+/fx9q1a7FgwQKNlfW3334bP/30k+zVY6dPn8b777//2BiJiIiIiIiexHNPsIEHiaSXlxfatWuHadOmwd3dHXp6ekhOTsbZs2fRtm3bpxp/9OjRWLJkCSZOnIihQ4ciNjYWmzZtwq5du6Q2Y8aMQUREBLZv3w4TExNkZmYCAMzMzCpdRX+YjY1NpRubNW7cWEqMH105/d///gfgwcpyxcp3y5YtZW2srKygUqlk5b1798bMmTPRuHFjuLq6IiUlBQsXLsTQoUOlNhMmTEC/fv3QuXNndO3aFdHR0dixYwfi4+MBPHiNV0REBHr16gVzc3OcPHkS48aNQ+fOnaXb70+fPo033ngD3t7eGD9+vHQ99PX1YWlpKYszPDwcHTp00Ii/MpaWlmjTpg0OHDggJdjr1q2Dubk5+vbtq3HreK9evRAeHg4fHx9ERUXhrbfekup27tyJu3fvYtiwYbKVauDB3QPh4eFSgn358mXcuHFDY7M7IiIiIiIinfn7HwfXzs2bN0VgYKBo2rSpMDQ0FMbGxqJ9+/Zi3rx5oqCgQGqHRzYPy8jIEABESkqKVFbZBmJxcXGidevWwsjISNjb24tVq1bJ5gdQ6fFoO209GuejKovxUZVtcpabmyuCgoJE48aNhUqlEvb29mLy5MmiuLhY1i48PFw4OjoKlUolWrVqJW0eJoQQV69eFZ07dxb16tUTSqVSODo6igkTJsge2J86dWql18POzk42T3Z2tlCr1WLFihWPvSYVli5dKl599VXps5ubm/jkk08qbfvzzz8LIyMjcfnyZaFSqcSFCxekujfffFP06tWr0n5HjhwRAMSJEyeEEELMmjWr2teyVeb/NjJ43pub8ODBgwcPHjz+vQcRvQi03eRMIYQQIHqGioqK4OTkhJ9//ll2m351tm3bhtDQUKSlpdV4vpKSEjRr1gwRERHw8vLSul9ubi7MzMyQkwM8wV55RERERDrA/1UnehH8X26QU+1G2s/9Pdj076NWq7F27VrpNnltGBsbY+7cuU8039WrV/Hll1/WKLkmIiIiIiKqKa5ga2HDhg0YNWpUpXV2dnY4c+bMM46IngWuYBMREdHzx/9VJ3oRaLuC/UJscvaie+utt6TXWD3q4deDERERERER0b8XE2wtmJiYwMTE5HmHQURERERERC8wPoNNREREREREpANMsImIiIiIiIh0gLeIEz1WDgDuckZERERERNXjCjYRERERERGRDjDBJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiId4Gu6iB5nkxlQ63kHQUT0DzBAPO8IiIiI/lZcwSYiIiIiIiLSASbYRERERERERDrABJuIiIiIiIhIB5hgExEREREREekAE2wiIiIiIiIiHWCCTURERERERKQDTLCJiIiIiIiIdIAJNhEREREREZEOMMGm52L//v1wcXFBWVnZM5nv1VdfxdatW5/JXERERERE9O/0wiTYmZmZCAoKgqOjI1QqFaytreHl5YWwsDAUFhY+1di3bt3CgAED0Lx5c+jp6eGzzz7TaFNaWorp06fDwcEBKpUKrVq1QnR0tNZzhIWFwd3dHaampjA1NYWnpyd2794ta3Px4kW88847sLS0hKmpKfr27Yvbt29rjLVr1y506NABarUadevWxdtvvy2rv3r1Kvz8/FCrVi1YWVlhwoQJuH//vlS/bds29OjRQ5rH09MTe/bskY0xbdo0KBQK2eHs7Cxrc+/ePYwZMwbm5uYwNjbGe++9pxFvcnIyunXrhjp16qBu3brw9vbGiRMnHnu9Jk6ciNDQUOjr68vKi4qKUK9ePVhYWKC4uLjK/k2bNsW+fftkZc7OzlAqlcjMzNRoHxoaikmTJqG8vPyxsRERERERET2JFyLBvnTpEjw8PBATE4NZs2YhJSUFiYmJmDhxInbu3KmRSNVUcXExLC0tERoailatWlXaJjQ0FMuXL8fixYuRlpaG0aNH45133kFKSopWczRs2BBz5szBsWPHcPToUbzxxhvo06cPzpw5AwAoKChAz549oVAoEBsbi4MHD6KkpAS9e/eWJX1bt27FRx99hCFDhuDEiRM4ePAgBgwYINWXlZXBz88PJSUlOHToENasWYPVq1fjq6++ktr8/vvv6NGjB3799VccO3YMXbt2Re/evTXOxdXVFbdu3ZKOAwcOyOrHjRuHHTt2YPPmzfjtt99w8+ZNvPvuu1J9fn4+fHx80LhxYxw5cgQHDhyAiYkJvL29UVpaWuW1OnDgAC5evIj33ntPo27r1q1wdXWFs7Mzfvnll0r7nzx5Enfv3kWXLl1kYxYVFeH999/HmjVrNPr4+voiLy9P40sPIiIiIiIiXVEIIcTzDsLHxwdnzpzB2bNnUbt2bY16IQQUCgUAQKFQYNmyZdixYwdiY2NhZ2eHlStXwtLSEsOHD0dycjJatWqFdevWwcHBQWOs119/Ha1bt8Z3330nK7e1tcXkyZMxZswYqey9996DWq3G+vXrn+i86tWrh3nz5mHYsGGIiYmBr68v7t69C1NTUwBATk4O6tati5iYGHTv3h33799HkyZN8PXXX2PYsGGVjrl79268+eabuHnzJqytrQEAy5YtQ3BwMP766y8YGRlV2s/V1RX9+vWTEvFp06bhl19+QWpqaqXtc3JyYGlpiYiICLz//vsAgLNnz8LFxQWJiYl49dVXcfToUbzyyiu4evUqGjVqBAA4deoU3N3dceHCBTg6OlY6dmBgIG7fvo3Nmzdr1HXt2hX9+/eHEALbtm1DTEyMRpsZM2bgzJkz2Lhxo1Q2ZMgQ2NjYoEuXLggKCsK5c+c0+g0dOhSlpaVYt25dpXE9Kjc3F2ZmZsj5ATCtpVUXIiKqzoDn/r8cRERET0TKDXJypHyuMs99BfvOnTuIiYnBmDFjKk2uAUjJdYUZM2Zg4MCBSE1NhbOzMwYMGIBRo0YhJCQER48ehRACgYGBNYqjuLgYKpVKVqZWqzVWdbVRVlaGjRs3oqCgAJ6entL4CoUCSqVSaqdSqaCnpyfNcfz4cdy4cQN6enrw8PBA/fr14evri9OnT0t9EhMT4ebmJiXXAODt7Y3c3FxptfxR5eXlyMvLQ7169WTlFy5cgK2tLezt7eHv74+rV69KdceOHUNpaSm6d+8ulTk7O6Nx48ZITEwEADg5OcHc3Bzh4eEoKSlBUVERwsPD4eLigiZNmlR5fRISEtCuXTuN8osXLyIxMRF9+/ZF3759kZCQgCtXrmi0i4qKQp8+faTPeXl52Lx5MwICAtCjRw/k5OQgISFBo1/79u0rLa9QXFyM3Nxc2UFERERERKSt555gp6enQwgBJycnWbmFhQWMjY1hbGyM4OBgWd2QIUPQt29fNG/eHMHBwbh8+TL8/f3h7e0NFxcXBAUFIT4+vkZxeHt7Y+HChbhw4QLKy8uxd+9ebNu2Dbdu3dJ6jFOnTsHY2BhKpRKjR49GZGQkWrRoAeDBJlu1a9dGcHAwCgsLUVBQgC+++AJlZWXSHJcuXQLwYHU5NDQUO3fuRN26dfH6668jKysLwINn1R9OrgFInyt79hgA5s+fj/z8fPTt21cq69ChA1avXo3o6GiEhYUhIyMDr732GvLy8qSxjIyMUKdOHY25KuYxMTFBfHw81q9fD7VaDWNjY0RHR2P37t0wMDCo8jpduXIFtra2GuUrV66Er68v6tati3r16sHb2xurVq2Stblx4wZOnjwJX19fqWzjxo1o1qwZXF1doa+vj/79+yM8PFxjfFtbW1y7dq3K57Bnz54NMzMz6ahYlSciIiIiItLGc0+wq5KUlITU1FS4urpqbHbl7u4u/VyRXLq5ucnK7t27V6MVyEWLFqFZs2ZwdnaGkZERAgMDMWTIEOjpaX+JnJyckJqaiiNHjuDjjz/GoEGDkJaWBgCwtLTE5s2bsWPHDhgbG8PMzAzZ2dlo06aNNEdF4jd58mS89957aNu2LVatWgWFQlHp7dTaiIiIwNdff41NmzbByspKKvf19cUHH3wAd3d3eHt749dff0V2djY2bdqk9dhFRUUYNmwYvLy8cPjwYRw8eBAtW7aEn58fioqKqu336N0CZWVlWLNmDQICAqSygIAArF69WpYQR0VFoVOnTrLEf+XKlRr9Nm/eLH1ZUEGtVqO8vLzKzdNCQkKQk5MjHdeuXdPqOhAREREREQFA1cuMz4ijoyMUCoXGM7P29vYAHiRFjzI0NJR+rrh9vLKymuwYbWlpiV9++QX37t3DnTt3YGtri0mTJklxaMPIyEh67rht27ZITk7GokWLsHz5cgBAz549cfHiRfzvf/+DgYEB6tSpAxsbG2mO+vXrA4C06g0ASqUS9vb20u3bNjY2SEpKks1bsbO3jY2NrHzjxo0YPnw4Nm/eLLvVuzJ16tRB8+bNkZ6eLo1VUlKC7OxsWTJ7+/ZtaZ6IiAhcvnwZiYmJ0pcEERERqFu3LrZv347+/ftXOpeFhQXu3r0rK9uzZw9u3LiBfv36ycrLysqwf/9+9OjRA8CDBPutt96S6tPS0nD48GEkJSXJ7nSouE1/xIgRUllWVhZq165d6d8U8OBaP3wLPxERERERUU089xVsc3Nz9OjRA0uWLEFBQcHzDgcqlQoNGjTA/fv3sXXrVtmzvjVV1WqphYUF6tSpg9jYWPz5559Swti2bVsolUrZlw2lpaW4fPky7OzsAACenp44deoU/vzzT6nN3r17YWpqKkvMf/rpJwwZMgQ//fQT/Pz8Hhtrfn4+Ll68KCX5bdu2haGhIfbv3y+1OXfuHK5evSo9V15YWAg9PT3ZM/IVn6v7csPDw0Na2a8QHh6O/v37IzU1VXY8fLt3fn4+4uLiZL+T8PBwdO7cGSdOnJD1Gz9+vMZt4qdPn4aHh8djrwUREREREdGTeO4r2ACwdOlSeHl5oV27dpg2bRrc3d2hp6eH5ORknD17Fm3btn3qOSp2y87Pz8dff/2F1NRUGBkZSUnpkSNHcOPGDbRu3Ro3btzAtGnTUF5ejokTJ2o1fkhICHx9fdG4cWPk5eUhIiIC8fHxsvdPr1q1Ci4uLrC0tERiYiKCgoIwbtw46flzU1NTjB49GlOnTkWjRo1gZ2eHefPmAQA++OADAA9WwVu0aIGPPvoI33zzDTIzMxEaGooxY8ZIq68REREYNGgQFi1ahA4dOkjPTKvVapiZmQEAvvjiC/Tu3Rt2dna4efMmpk6dCn19fXz44YcAADMzMwwbNgzjx49HvXr1YGpqik8//RSenp549dVXAQA9evTAhAkTMGbMGHz66acoLy/HnDlzYGBggK5du1Z5rby9vWWv0vrrr7+wY8cOREVFoWXLlrK2AwcOxDvvvIOsrCzExsaiefPm0gZqFTuCT58+XaPf8OHDsXDhQpw5cwaurq4AHmyu1rNnT61+n0RERERERDX1QiTYDg4OSElJwaxZsxASEoLr169DqVSiRYsW+OKLL/DJJ5889RwPr1weO3YMERERsLOzw+XLlwEA9+7dQ2hoKC5dugRjY2P06tUL69at09jkqyp//vknBg4ciFu3bsHMzAzu7u7Ys2ePdGsz8GAFOCQkBFlZWWjSpAkmT56McePGycaZN28eDAwM8NFHH6GoqAgdOnRAbGws6tatCwDQ19fHzp078fHHH8PT0xO1a9fGoEGDMH36dGmMFStW4P79+xgzZozstWODBg3C6tWrAQDXr1/Hhx9+iDt37sDS0hKdOnXC4cOHYWlpKbX/9ttvoaenh/feew/FxcXw9vbG0qVLpXpnZ2fs2LEDX3/9NTw9PaXdz6Ojo6WV8Mr4+/tj4sSJOHfuHJycnLB27VrUrl0b3bp102jbrVs36VVpycnJstvDo6KicOfOHbzzzjsa/VxcXODi4oLw8HAsXLgQN27cwKFDh574lWtERERERESP80K8B5v+fSZMmIDc3Fzp+fTHuX//PqytrbF79260b9++xvMFBwfj7t27WLFihdZ9+B5sIiId43uwiYjoJfXSvAeb/p0mT54MOzs7rTeiy8rKwrhx4/DKK6880XxWVlaYMWPGE/UlIiIiIiLSBlewtXD16lXZBmKPSktLQ+PGjZ9hRPQscAWbiEjHuIJNREQvKW1XsF+IZ7BfdLa2ttImaVXVExERERER0b8bE2wtGBgYSO+3JiIiIiIiIqoMn8EmIiIiIiIi0gEm2EREREREREQ6wASbiIiIiIiISAf4DDbR4/TNAarZKZCIiIiIiAjgCjYRERERERGRTjDBJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiId4Gu6iB7DzMzseYdA/3JCiOcdAhERERFpgSvYRERERERERDrABJuIiIiIiIhIB5hgExEREREREekAE2wiIiIiIiIiHWCCTURERERERKQDTLCJiIiIiIiIdIAJNhEREREREZEOMMEmIiIiIiIi0gEm2PRcnDt3DjY2NsjLy3sm8/Xv3x8LFix4JnMREREREdG/00uVYGdmZiIoKAiOjo5QqVSwtraGl5cXwsLCUFhY+NTjx8fHo02bNlAqlXB0dMTq1atl9dOmTYNCoZAdzs7ONZojMTERb7zxBmrXrg1TU1N07twZRUVFUv3MmTPRsWNH1KpVC3Xq1Kl0jP3796Njx44wMTGBjY0NgoODcf/+fVmbkydP4rXXXoNKpUKjRo3wzTffyOpff/11jXNRKBTw8/OT2gwePFij3sfHRzbO+fPn0adPH1hYWMDU1BSdOnVCXFzcY69DSEgIPv30U5iYmGjUOTs7Q6lUIjMzs8r+Xbt2xY8//igr8/b2hr6+PpKTkzXah4aGYubMmcjJyXlsbERERERERE/ipUmwL126BA8PD8TExGDWrFlISUlBYmIiJk6ciJ07d2Lfvn1PNX5GRgb8/PzQtWtXpKam4rPPPsPw4cOxZ88eWTtXV1fcunVLOg4cOKD1HImJifDx8UHPnj2RlJSE5ORkBAYGQk/v/34NJSUl+OCDD/Dxxx9XOsaJEyfQq1cv+Pj4ICUlBT///DOioqIwadIkqU1ubi569uwJOzs7HDt2DPPmzcO0adOwYsUKqc22bdtk53H69Gno6+vjgw8+kM3n4+Mja/fTTz/J6t98803cv38fsbGxOHbsGFq1aoU333yz2uT46tWr2LlzJwYPHqxRd+DAARQVFeH999/HmjVrKu2flZWFgwcPonfv3rIxDx06hMDAQKxcuVKjT8uWLeHg4ID169dXGRcREREREdFTES8Jb29v0bBhQ5Gfn19pfXl5ufQzALFs2TLh5+cn1Gq1cHZ2FocOHRIXLlwQXbp0EbVq1RKenp4iPT1d6jNx4kTh6uoqG7Nfv37C29tb+jx16lTRqlWrJz6HDh06iNDQUK3arlq1SpiZmWmUh4SEiHbt2snKoqKihEqlErm5uUIIIZYuXSrq1q0riouLpTbBwcHCycmpyvm+/fZbYWJiIru+gwYNEn369Kmyz19//SUAiN9//10qy83NFQDE3r17q+w3b948jXOoMHjwYDFp0iSxe/du0bx580rbrF27VnTo0EFWNm3aNNG/f3/xxx9/CDMzM1FYWKjR7+uvvxadOnWqMq5H5eTkCAA8eDz3g4iIiIier4rcICcnp9p2L8UK9p07dxATE4MxY8agdu3albZRKBSyzzNmzMDAgQORmpoKZ2dnDBgwAKNGjUJISAiOHj0KIQQCAwOl9omJiejevbtsDG9vbyQmJsrKLly4AFtbW9jb28Pf3x9Xr17V6hz+/PNPHDlyBFZWVujYsSOsra3RpUuXGq2AA0BxcTFUKpWsTK1W4969ezh27Jh0Lp07d4aRkZHsXM6dO4e7d+9WOm54eDj69++vcX3j4+NhZWUFJycnfPzxx7hz545UZ25uDicnJ6xduxYFBQW4f/8+li9fDisrK7Rt27bKc0hISEC7du00yvPy8rB582YEBASgR48eyMnJQUJCgka7qKgo9OnTR/oshMCqVasQEBAAZ2dnODo6YsuWLRr92rdvj6SkJBQXF1caV3FxMXJzc2UHERERERGRtl6KBDs9PR1CCDg5OcnKLSwsYGxsDGNjYwQHB8vqhgwZgr59+6J58+YIDg7G5cuX4e/vD29vb7i4uCAoKAjx8fFS+8zMTFhbW8vGsLa2Rm5urvSMdIcOHbB69WpER0cjLCwMGRkZeO2117TaqOvSpUsAHjzHPWLECERHR6NNmzbo1q0bLly4oPW18Pb2xqFDh/DTTz+hrKwMN27cwPTp0wEAt27dqvZcKuoelZSUhNOnT2P48OGych8fH6xduxb79+/H3Llz8dtvv8HX1xdlZWUAHnypsW/fPqSkpMDExAQqlQoLFy5EdHQ06tatW+U5XLlyBba2thrlGzduRLNmzeDq6gp9fX30798f4eHhsjbFxcWIjo7GW2+9JZXt27cPhYWF8Pb2BgAEBARo9AMAW1tblJSUVHn7+uzZs2FmZiYdjRo1qvIciIiIiIiIHvVSJNhVSUpKQmpqKlxdXTVWJd3d3aWfK5JLNzc3Wdm9e/dqtErp6+uLDz74AO7u7vD29savv/6K7OxsbNq06bF9y8vLAQCjRo3CkCFD4OHhgW+//RZOTk6VPjNclZ49e2LevHkYPXo0lEolmjdvjl69egGA7FnumggPD4ebmxvat28vK+/fvz/eeustuLm54e2338bOnTuRnJwsfTEhhMCYMWNgZWWFhIQEJCUl4e2330bv3r2lZL8yRUVFGqvwALBy5UoEBARInwMCArB582bZFxixsbGwsrKCq6urrF+/fv1gYGAAAPjwww9x8OBBXLx4UTa+Wq0GgCo3xAsJCUFOTo50XLt2rcpzICIiIiIietRLkWA7OjpCoVDg3LlzsnJ7e3s4OjpKidPDDA0NpZ8rbh+vrKwi8bWxscHt27dlY9y+fRumpqaVjg8AderUQfPmzZGenv7Yc6hfvz4AoEWLFrJyFxcXrW8zrzB+/HhkZ2fj6tWr+N///ifdLm1vb1/tuVTUPaygoAAbN27EsGHDHjuvvb09LCwspPONjY3Fzp07sXHjRnh5eaFNmzZYunQp1Gp1lRuUAQ/uPHj0VvW0tDQcPnwYEydOhIGBAQwMDPDqq6+isLAQGzdulNpFRUXJVq+zsrIQGRmJpUuXSv0aNGiA+/fva3xxkZWVBQCwtLSsNC6lUglTU1PZQUREREREpK2XIsE2NzdHjx49sGTJEhQUFPwtc3h6emL//v2ysr1798LT07PKPvn5+bh48aKUPFenSZMmsLW11fiS4Pz587Czs6txvAqFAra2tlCr1fjpp5/QqFEjtGnTRjqX33//HaWlpbJzcXJy0rh1e/PmzSguLpatHFfl+vXruHPnjnS+FSvBj66c6+npSV9cVMbDwwNpaWmysvDwcHTu3BknTpxAamqqdIwfP1663VsIgR07dsiev96wYQMaNmyo0W/BggVYvXq1dDs7AJw+fRoNGzaEhYXFY8+ViIiIiIioxv7+/dZ0Iz09XVhbWwtnZ2exceNGkZaWJs6ePSvWrVsnrK2txfjx46W2AERkZKT0OSMjQwAQKSkpUllcXJwAIO7evSuEEOLSpUuiVq1aYsKECeKPP/4Q33//vdDX1xfR0dFSn88//1zEx8eLjIwMcfDgQdG9e3dhYWEh/vzzT63O4dtvvxWmpqZi8+bN4sKFCyI0NFSoVCrZbuZXrlwRKSkp4uuvvxbGxsYiJSVFpKSkiLy8PKnNN998I06ePClOnz4tpk+fLgwNDWXnm52dLaytrcVHH30kTp8+LTZu3Chq1aolli9frhFTp06dRL9+/TTK8/LyxBdffCESExNFRkaG2Ldvn2jTpo1o1qyZuHfvnhDiwS7i5ubm4t133xWpqani3Llz4osvvhCGhoYiNTW1yusQFRUlrKysxP3794UQQpSUlAhLS0sRFham0TYtLU0AEKdPnxbJycmibt26orS0VKpv1aqVCA4O1uiXnZ0tjIyMxM6dO6WyQYMGiaFDh1YZ16O4iziPF+UgIiIioudL213EX6r/c7t586YIDAwUTZs2FYaGhsLY2Fi0b99ezJs3TxQUFEjtgJon2BVlrVu3FkZGRsLe3l6sWrVKNn+/fv1E/fr1hZGRkWjQoIHo16+fLDnWxuzZs0XDhg2lV4UlJCTI6gcNGlTp/2DHxcVJbbp27SrMzMyESqUSHTp0EL/++qvGPCdOnBCdOnUSSqVSNGjQQMyZM0ejzdmzZwUAERMTo1FXWFgoevbsKSwtLYWhoaGws7MTI0aMEJmZmbJ2ycnJomfPnqJevXrCxMREvPrqq5XG87DS0lJha2srfXmxZcsWoaenpzF2BRcXFzFu3DgRGhoq/P39pfKjR48KACIpKanSfr6+vuKdd94RQghRVFQkzMzMRGJiYrWxPYwJNo8X5SAiIiKi50vbBFshhBAgesa+//57REVFYc+ePVr3cXd3R2hoKPr27Vvj+cLCwhAZGYmYmBit++Tm5sLMzKzGcxHpGv+ZJiIiInq+KnKDnJycavdqMniGMRFJRo0ahezsbOTl5cHExOSx7UtKSvDee+/B19f3ieYzNDTE4sWLn6gvERERERGRNriCrSMbNmzAqFGjKq2zs7PDmTNnnnFE9LS4gk0vCv4zTURERPR8cQX7GXvrrbfQoUOHSusefj0YERERERER/TMxwdYRExMTrW51JiIiIiIion+ml+I92EREREREREQvOibYRERERERERDrABJuIiIiIiIhIB/gMNtFjPG6nQCIiIiIiIoAr2EREREREREQ6wQSbiIiIiIiISAeYYBMRERERERHpABNsIiIiIiIiIh1ggk1ERERERESkA0ywiYiIiIiIiHSAr+kiegwzM7PnHcK/ghDieYdARERERPRUuIJNREREREREpANMsImIiIiIiIh0gAk2ERERERERkQ4wwSYiIiIiIiLSASbYRERERERERDrABJuIiIiIiIhIB5hgExEREREREekAE2wiIiIiIiIiHWCCTc/F/v374eLigrKysmcy36uvvoqtW7c+k7mIiIiIiOjf6YVJsDMzMxEUFARHR0eoVCpYW1vDy8sLYWFhKCwsfOrx4+Pj0aZNGyiVSjg6OmL16tWy+t9//x29e/eGra0tFAoFfvnllxqNP3jwYCgUCtnh4+Mja9OkSRONNnPmzJG1OXnyJF577TWoVCo0atQI33zzjcZc2dnZGDNmDOrXrw+lUonmzZvj119/lerLysowZcoUNG3aFGq1Gg4ODpgxYwaEEFKb/Px8BAYGomHDhlCr1WjRogWWLVsmm+f111/XiHf06NGyNmPHjkXbtm2hVCrRunVrra/XxIkTERoaCn19fVl5UVER6tWrBwsLCxQXF1fZv2nTpti3b5+szNnZGUqlEpmZmRrtQ0NDMWnSJJSXl2sdIxERERERUU0YPO8AAODSpUvw8vJCnTp1MGvWLLi5uUGpVOLUqVNYsWIFGjRogLfeeuuJx8/IyICfnx9Gjx6NDRs2YP/+/Rg+fDjq168Pb29vAEBBQQFatWqFoUOH4t13332ieXx8fLBq1Srps1Kp1Ggzffp0jBgxQvpsYmIi/Zybm4uePXuie/fuWLZsGU6dOoWhQ4eiTp06GDlyJACgpKQEPXr0gJWVFbZs2YIGDRrgypUrqFOnjjTO3LlzERYWhjVr1sDV1RVHjx7FkCFDYGZmhrFjxwIAxo8fj9jYWKxfvx5NmjRBTEwMPvnkE9ja2squ9YgRIzB9+nTpc61atTTOaejQoThy5AhOnjyp1XU6cOAALl68iPfee0+jbuvWrXB1dYUQAr/88gv69eun0ebkyZO4e/cuunTpIhuzqKgI77//PtasWYPg4GBZH19fXwwfPhy7d++Gn5+fVnESERERERHVxAuRYH/yyScwMDDA0aNHUbt2banc3t4effr0ka28KhQKLFu2DDt27EBsbCzs7OywcuVKWFpaYvjw4UhOTkarVq2wbt06ODg4AACWLVuGpk2bYsGCBQAAFxcXHDhwAN9++62UYPv6+sLX1/epzkOpVMLGxqbaNiYmJlW22bBhA0pKSrBy5UoYGRnB1dUVqampWLhwoZRgr1y5EllZWTh06BAMDQ0BPFgZf9ihQ4fQp08fKZFs0qQJfvrpJyQlJcnaDBo0CK+//joAYOTIkVi+fDmSkpJkCXatWrWqPaf//ve/AIC//vpL6wR748aN6NGjB1QqlUZdeHg4AgICIIRAeHh4pQn29u3b4ePjI51/Rb8BAwagS5cuCAoK0kiw9fX10atXL2zcuLHKBLu4uFi2ap6bm6vV+RAREREREQEvwC3id+7cQUxMDMaMGSNLrh+mUChkn2fMmIGBAwciNTUVzs7OGDBgAEaNGoWQkBAcPXoUQggEBgZK7RMTE9G9e3fZGN7e3khMTNTpucTHx8PKygpOTk74+OOPcefOHY02c+bMgbm5OTw8PDBv3jzcv39fFmfnzp1hZGQki/PcuXO4e/cuACAqKgqenp4YM2YMrK2t0bJlS8yaNUv2LHPHjh2xf/9+nD9/HgBw4sQJHDhwQPYFQseOHREVFYUbN25ACIG4uDicP38ePXv2lMW7YcMGWFhYoGXLlggJCdHJ7foJCQlo166dRvnFixeRmJiIvn37om/fvkhISMCVK1c02kVFRaFPnz7S57y8PGzevBkBAQHo0aMHcnJykJCQoNGvffv2lZZXmD17NszMzKSjUaNGT3iGRERERET0b/TcE+z09HQIIeDk5CQrt7CwgLGxMYyNjTVWI4cMGYK+ffuiefPmCA4OxuXLl+Hv7w9vb2+4uLggKCgI8fHxUvvMzExYW1vLxrC2tkZubi6Kiop0ch4+Pj5Yu3Yt9u/fj7lz5+K3336Dr6+vLPEdO3YsNm7ciLi4OIwaNQqzZs3CxIkTHxtnRR3w4Hb6LVu2oKysDL/++iumTJmCBQsW4D//+Y/UZ9KkSejfvz+cnZ1haGgIDw8PfPbZZ/D395faLF68GC1atEDDhg1hZGQEHx8ffP/99+jcubPUZsCAAVi/fj3i4uIQEhKCdevWISAg4Kmv1ZUrV2Bra6tRvnLlSvj6+qJu3bqoV68evL29ZbfcA8CNGzdw8uRJ2ZcFGzduRLNmzeDq6gp9fX30798f4eHhGuPb2tri2rVrVT6HHRISgpycHOm4du3aU54pERERERH9m7wQt4hXJikpCeXl5fD399fY7Mrd3V36uSIBdXNzk5Xdu3cPubm5MDU1fSbx9u/fX/rZzc0N7u7ucHBwQHx8PLp16wbgwXPPFdzd3WFkZIRRo0Zh9uzZlT6vXZny8nJYWVlhxYoV0NfXR9u2bXHjxg3MmzcPU6dOBQBs2rQJGzZsQEREhHSb+WeffQZbW1sMGjQIwIME+/Dhw4iKioKdnR1+//13jBkzBra2ttJqf8Vt6RXnVL9+fXTr1g0XL16Ubr9/EkVFRRq3h5eVlWHNmjVYtGiRVBYQEIAvvvgCX331FfT0HnwXFBUVhU6dOsmeOV+5cqUs8Q8ICECXLl2wePFi2TPuarUa5eXlKC4uhlqt1ohLqVRq/XsgIiIiIiJ61HNPsB0dHaFQKHDu3DlZub29PQBUmgg9/Oxtxe3jlZVVrFTa2Njg9u3bsjFu374NU1PTSsfXBXt7e1hYWCA9PV1KsB/VoUMH3L9/H5cvX4aTk1OVcVacAwDUr18fhoaGst23XVxckJmZiZKSEhgZGWHChAnSKjbwIDm+cuUKZs+ejUGDBqGoqAhffvklIiMjpeeR3d3dkZqaivnz52vcTv9wvMCDuw6eJsG2sLCQbnmvsGfPHty4cUPjmeuysjLs378fPXr0APAgwX74GfG0tDQcPnwYSUlJsjsdysrKsHHjRtmGcllZWahdu/bf9jsnIiIiIqJ/t+d+i7i5uTl69OiBJUuWoKCg4G+Zw9PTE/v375eV7d27F56enn/LfABw/fp13LlzB/Xr16+yTWpqKvT09GBlZSXF+fvvv6O0tFQWp5OTE+rWrQsA8PLyQnp6uuw25/Pnz6N+/frSs9uFhYXSim8FfX19qU9paSlKS0urbVNVvACqPSdteHh4IC0tTVYWHh6O/v37IzU1VXY8fLt3fn4+4uLiZM9fh4eHo3Pnzjhx4oSs3/jx4zVuEz99+jQ8PDyeKnYiIiIiIqIqiRdAenq6sLa2Fs7OzmLjxo0iLS1NnD17Vqxbt05YW1uL8ePHS20BiMjISOlzRkaGACBSUlKksri4OAFA3L17VwghxKVLl0StWrXEhAkTxB9//CG+//57oa+vL6Kjo6U+eXl5IiUlRaSkpAgAYuHChSIlJUVcuXLlsfHn5eWJL774QiQmJoqMjAyxb98+0aZNG9GsWTNx7949IYQQhw4dEt9++61ITU0VFy9eFOvXrxeWlpZi4MCB0jjZ2dnC2tpafPTRR+L06dNi48aNolatWmL58uVSm6tXrwoTExMRGBgozp07J3bu3CmsrKzEf/7zH6nNoEGDRIMGDcTOnTtFRkaG2LZtm7CwsBATJ06U2nTp0kW4urqKuLg4cenSJbFq1SqhUqnE0qVLpd/J9OnTxdGjR0VGRobYvn27sLe3F507d5ad+4ULF0RKSooYNWqUaN68uXQNi4uLq7xe//3vf0Xbtm2lz3/++acwNDQUu3fv1mj766+/CqVSKe7cuSM2b94s3NzcpLqSkhJhaWkpwsLCNPqlpaUJAOL06dOyc54+fXqVcT0qJydHAODxjA4iIiIiohdVRW6Qk5NTbbsX5v9qb968KQIDA0XTpk2FoaGhMDY2Fu3btxfz5s0TBQUFUrsnSbArylq3bi2MjIyEvb29WLVqlWz+ij6PHoMGDXps7IWFhaJnz57C0tJSGBoaCjs7OzFixAiRmZkptTl27Jjo0KGDMDMzEyqVSri4uIhZs2ZJCXiFEydOiE6dOgmlUikaNGgg5syZozHfoUOHRIcOHYRSqRT29vZi5syZ4v79+1J9bm6uCAoKEo0bNxYqlUrY29uLyZMny5LeW7duicGDBwtbW1uhUqmEk5OTWLBggSgvLxdCPEjkO3fuLOrVqyeUSqVwdHQUEyZM0PiD6tKlS6XXLSMjo8rrdefOHaFSQiTWeQAAQm5JREFUqcTZs2eFEELMnz9f1KlTR5SUlGi0LS4uFnXq1BGLFi0SAQEBYvLkyVLdli1bhJ6enuw6P8zFxUWMGzdOCCHE9evXhaGhobh27VqVcT2KCTYTbCIiIiIiIbRPsBVCPPSSaaJnZMKECcjNzcXy5cu1an///n1YW1tj9+7daN++fY3nCw4Oxt27d7FixQqt++Tm5sLMzKzGc9GT4T9FRP+vvTuPqqrq/wf+vsyXWUFAQBFEBklNRQiHx3xEr8qTWD1JiGI4P180JefUry1doWblkKZZhvaIUyVKFigqTkmiIuKAiDE5oStBEBAE7v794Y/z9cgFr3YTtfdrrbMWZ+999v6cs2/kh33uOURERPS8qssNSkpKGn2QdpN/B5v+nubMmQMXF5dGv/P9sKKiIkRFRaFbt25PNZ6dnR0WLlz4VMcSERERERFpgyvYWjhy5IjsvcuPKisre4bR0LPCFexni7+KiIiIiOh5pe0KdpO/putF4OvrKz1Bm4iIiIiIiEgTJthaUCqVcHd3b+owiIiIiIiI6DnG72ATERERERER6QATbCIiIiIiIiId4C3iRI/xuAcZEBERERERAVzBJiIiIiIiItIJJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiIdYIJNREREREREpAN8TRfRY1hZWTV1CC8UIURTh0BERERE1CS4gk1ERERERESkA0ywiYiIiIiIiHSACTYRERERERGRDjDBJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiIdYIJNTWLevHkYN27cMxtv1qxZmDRp0jMbj4iIiIiI/n6emwS7sLAQkydPhru7O0xMTGBvb48ePXpgzZo1qKio+NP9Hzx4EF26dIGxsTHc3d2xYcMGWX2bNm2gUCjqbZGRkVr1v27dOrz++uuwtLSEQqHAnTt36rXRNMbixYul+o8++khjDGZmZlKbDRs21Ks3MTGRjfPRRx/By8sLZmZmaNasGQIDA3H8+HFZm7S0NPTr1w/W1tawsbHBuHHjUFZWVi/mDRs2oGPHjjAxMYGdnZ3semRlZaFPnz6wt7eHiYkJ3NzcMHfuXFRXVzd6rQoLC7FixQrMmTOnXvmkSZPg5uYGY2NjtGrVCm+88Qb2799frw9XV1fs27cPACCEwLp16+Dv7w9zc3NYW1vD19cXy5cvlz4706ZNw8aNG5GTk9NobERERERERE/LoKkDAICcnBz06NED1tbWiI6ORocOHWBsbIyzZ89i3bp1cHJywuDBg5+6/9zcXAQFBWHChAmIjY3F/v37MWbMGLRs2RIqlQoAcOLECdTW1krHnDt3Dv369cM777yj1RgVFRUYMGAABgwYgNmzZzfYbsGCBRg7dqy0b2FhIf08bdo0TJgwQda+b9++6Natm6zM0tISWVlZ0r5CoZDVe3h4YNWqVXBzc8O9e/ewbNky9O/fH5cvX0aLFi1w/fp1BAYGIiQkBKtWrUJpaSmmTJmC9957Dz/88IPUz+eff47PPvsMS5cuhb+/P8rLy5GXlyfVGxoaIjw8HF26dIG1tTXOnDmDsWPHQq1WIzo6usFr8M0336B79+5wcXGRyvLy8qTPwNKlS9GhQwdUV1djz549iIyMxMWLF6W2GRkZKC4uRu/evQEAI0aMwI4dOzB37lysWrUKLVq0wJkzZ7B8+XK0adMGQ4YMga2tLVQqFdasWYOlS5c2GBsREREREdFTE88BlUolnJ2dRVlZmcZ6tVot/QxArF27VgQFBQmlUim8vLzEsWPHRHZ2tujdu7cwNTUVAQEB4vLly9IxM2bMED4+PrI+Q0JChEqlajCmyZMni7Zt28rG1kZycrIAIIqLi+vVubi4iGXLlmndV3p6ugAgDh8+LJXFxMQIKyurJ4qppKREABD79u0TQgjx1VdfCTs7O1FbWyu1ycjIEABEdna2EEKIoqIioVQqpWO0FRUVJXr27NloGx8fH7Fq1SpZ2cCBA4WTk5PGz8Cj13LBggUiJCRECCHEtm3bBACxc+fOesep1Wpx584daX/jxo3C2dlZ21ORrhu3J9uIiIiIiF42dblBSUlJo+2a/Bbx27dvY+/evYiMjJTdCv2wR1doFy5ciPDwcKSnp8PLywvDhg3D+PHjMXv2bJw8eRJCCEycOFFqn5KSgsDAQFkfKpUKKSkpGse7f/8+Nm3ahFGjRtUb+89avHgxbGxs0LlzZyxduhQ1NTUNtv3mm2/g4eGBXr16ycrLysrg4uKCVq1aITg4GOfPn2+wj/v372PdunWwsrJCp06dAABVVVUwMjKCnt7/Tb9SqQQAHD16FACQlJQEtVqNa9euwdvbG87Ozhg6dCiuXLnS4FiXL19GYmKitLKsSVFRES5cuABfX19ZWWJiYoOfAWtra9l+fHw8goODAQCxsbHw9PSU9h+mUChgZWUl7fv5+eHq1auyVfiHVVVVobS0VLYRERERERFpq8kT7MuXL0MIAU9PT1m5ra0tzM3NYW5ujpkzZ8rqIiIiMHToUHh4eGDmzJnIy8tDWFgYVCoVvL29MXnyZBw8eFBqX1hYCHt7e1kf9vb2KC0txb179+rFtHPnTty5cwfvvfeezs4TAN5//31s3boVycnJGD9+PKKjozFjxgyNbSsrKxEbG4vRo0fLyj09PfHtt99i165d2LRpE9RqNbp3746rV6/K2u3evRvm5uYwMTHBsmXLkJSUBFtbWwDAP//5TxQWFmLp0qW4f/8+iouLMWvWLADAjRs3ADy4bb/uVu/ly5fjhx9+QFFREfr164f79+/LxurevTtMTEzQrl079OrVCwsWLGjwGhQUFEAIAUdHR6ms7jPg5eX12Gt47do1ZGRkYODAgQCA7Ozsep+dhtSNmZ+fr7F+0aJFsLKykrZWrVpp1S8RERERERHwHCTYDUlNTUV6ejp8fHxQVVUlq+vYsaP0c13i3KFDB1lZZWXlU69Arl+/HgMHDpQlgbrwwQcf4PXXX0fHjh0xYcIEfPbZZ/jiiy/qnR8AxMXF4e7duxg5cqSsPCAgAOHh4Xj11VfRu3dv7NixAy1atMBXX30la9enTx+kp6fj2LFjGDBgAIYOHYpbt24BAHx8fLBx40Z89tlnMDU1hYODA1xdXWFvby+taqvValRXV2PlypVQqVR47bXXsGXLFmRnZyM5OVk21rZt25CWlobNmzfj559/xqefftrgNaj7g8bDD2YTQmh9DePj49GzZ09pVftJjq1bpW/ooXmzZ89GSUmJtDW2Wk9ERERERPSoJn/Imbu7OxQKheyhXQDg5uYG4P+SoocZGhpKP9fdwq2pTK1WAwAcHBxw8+ZNWR83b96EpaVlvf7z8/Oxb98+7Nix42lPSWv+/v6oqalBXl5evVXYb775Bv/617/qrbw/ytDQEJ07d8bly5dl5WZmZnB3d4e7uztee+01tGvXDuvXr5cewDZs2DAMGzYMN2/ehJmZGRQKBT7//HPpurds2RIA0L59e6nPFi1awNbWFgUFBbKx6lZ627dvj9raWowbNw5Tp06Fvr5+vXjrVtGLi4vRokULAEC7du2gUChkDzJrSHx8vOyBdx4eHlodBzy4Fb3uPDQxNjaGsbGxVn0RERERERE9qslXsG1sbNCvXz+sWrUK5eXlf8kYAQEB9V71lJSUhICAgHptY2JiYGdnh6CgoL8kloelp6dDT08PdnZ2svLc3FwkJyfXuz1ck9raWpw9e1ZKiBuiVqs1rpTb29vD3Nwc27Ztg4mJCfr16wcA6NGjBwDI/vBRVFSEP/74Q/b0b03jVFdXS3/ceFTbtm1haWmJCxcuSGXNmzeHSqXC6tWrNX4G6l55VlZWhuTkZNn3rYcNG4ZLly5h165d9Y4TQqCkpETaP3fuHAwNDeHj49Ng/ERERERERE+ryRNsAPjyyy9RU1MDX19fbNu2DZmZmcjKysKmTZtw8eJFjSuhT2LChAnIycnBjBkzcPHiRXz55ZfYvn07oqKiZO3UajViYmIwcuRIGBg82eJ+YWEh0tPTpZXks2fPIj09XVo1TUlJwfLly3HmzBnk5OQgNjYWUVFRGD58OJo1aybr69tvv0XLli2l7xk/bMGCBdi7dy9ycnKQlpaG4cOHIz8/H2PGjAEAlJeX48MPP8Rvv/2G/Px8nDp1CqNGjcK1a9dkrxxbtWoV0tLScOnSJaxevRoTJ07EokWLpFuvPTw8EBwcjMmTJ+PYsWM4d+4cRo4cCS8vL/Tp0wfAgweMbd++HZmZmcjJycH27dsxe/ZshISEyO4oeJienh4CAwOlh6nVWb16NWpra+Hn54cff/wR2dnZyMzMxMqVK6U/hCQmJsLDwwNt2rSRjhs6dChCQkIQGhqK6OhonDx5Evn5+di9ezcCAwNlt7MfOXIEvXr10nhXBBERERER0Z/2Vz/OXFvXr18XEydOFK6ursLQ0FCYm5sLPz8/sXTpUlFeXi61AyDi4uKk/dzcXAFAnD59WirT9Kqs5ORk8eqrrwojIyPh5uYmYmJi6sWwZ88eAUBkZWU9cfzz58/X+MqiunFOnTol/P39hZWVlTAxMRHe3t4iOjpaVFZWyvqpra0Vzs7O4sMPP9Q4zpQpU0Tr1q2FkZGRsLe3F4MGDRJpaWlS/b1798Sbb74pHB0dhZGRkWjZsqUYPHiwSE1NlfUzYsQI0bx5c2FkZCQ6duwovvvuu3pjlZSUiFGjRglra2vRvHlz8eabb4qCggKpfuvWraJLly7C3NxcmJmZifbt24vo6Ghx7969Rq/VL7/8IpycnGSvCRPiwWcgMjJSuLi4CCMjI+Hk5CQGDx4skpOThRBCDB8+XMyZM6def7W1tWLNmjWiW7duwtTUVFhaWoquXbuKFStWiIqKCqmdp6en2LJlS6OxPXr+muaUG1/TRURERER/L9q+pkshxBM8JYpIB4QQ8Pf3R1RUFEJDQ7U6pqamBvb29khISICfn98Tj5mQkICpU6ciIyND67sTSktLZa/5Iu3wVwoRERERvWzqcoOSkhJYWlo22O65uEWc/l4UCgXWrVvX6DvAH1VUVISoqCh069btqcYsLy9HTEzME9/6T0REREREpC2uYGshNjYW48eP11jn4uKC8+fPP+OI6FngCvbT4a8UIiIiInrZaLuCzeU8LQwePBj+/v4a6xp6mBcRERERERH9vTDB1oKFhQUsLCyaOgwiIiIiIiJ6jvE72EREREREREQ6wASbiIiIiIiISAeYYBMRERERERHpAL+DTfQYj3tSIBEREREREcAVbCIiIiIiIiKdYIJNREREREREpANMsImIiIiIiIh0gAk2ERERERERkQ4wwSYiIiIiIiLSASbYRERERERERDrA13QRPYaVlVVTh/DcE0I0dQhERERERE2OK9hEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiIdYIJNREREREREpANMsImIiIiIiIh0gAk2ERERERERkQ4wwSYiIiIiIiLSASbY1CTmzZuHcePGPbPxZs2ahUmTJj2z8YiIiIiI6O/nuUmwCwsLMXnyZLi7u8PExAT29vbo0aMH1qxZg4qKij/d/8GDB9GlSxcYGxvD3d0dGzZskNUfPnwYb7zxBhwdHaFQKLBz506t+66ursbMmTPRoUMHmJmZwdHREeHh4bh+/bpsfIVCoXE7ceJEvT4vX74MCwsLWFtby8q//vpr9OrVC82aNUOzZs0QGBiI1NRUWZsdO3agf//+sLGxgUKhQHp6er3+x48fj7Zt20KpVKJFixYIDg7GxYsXZW1OnDiBvn37wtraGs2aNYNKpcKZM2dk5xQcHIyWLVvCzMwMr776KmJjYx97vQoLC7FixQrMmTOnXvmkSZPg5uYGY2NjtGrVCm+88Qb2799frw9XV1fs27cPACCEwLp16+Dv7w9zc3NYW1vD19cXy5cvlz4706ZNw8aNG5GTk/PY+IiIiIiIiJ7Gc5Fg5+TkoHPnzti7dy+io6Nx+vRppKSkYMaMGdi9e7eUSD2t3NxcBAUFoU+fPkhPT8eUKVMwZswY7NmzR2pTXl6OTp06YfXq1U/cf0VFBdLS0jBv3jykpaVhx44dyMrKwuDBg6U23bt3x40bN2TbmDFj4OrqCl9fX1l/1dXVCA0NRa9eveqNdfDgQYSGhiI5ORkpKSlo1aoV+vfvj2vXrsnOpWfPnliyZEmDMXft2hUxMTHIzMzEnj17IIRA//79UVtbCwAoKyvDgAED0Lp1axw/fhxHjx6FhYUFVCoVqqurAQDHjh1Dx44d8eOPPyIjIwMREREIDw/H7t27G71e33zzDbp37w4XFxepLC8vD127dsWBAwewdOlSnD17FomJiejTpw8iIyNlx2dkZKC4uBi9e/cGAIwYMQJTpkxBcHAwkpOTkZ6ejnnz5mHXrl3Yu3cvAMDW1hYqlQpr1qxpNDYiIiIiIqKnJp4DKpVKODs7i7KyMo31arVa+hmAWLt2rQgKChJKpVJ4eXmJY8eOiezsbNG7d29hamoqAgICxOXLl6VjZsyYIXx8fGR9hoSECJVKpXE8ACIuLu5PnVNqaqoAIPLz8zXW379/X7Ro0UIsWLCgXt2MGTPE8OHDRUxMjLCysmp0nJqaGmFhYSE2btxYry43N1cAEKdPn35svGfOnBEApOt24sQJAUAUFBRIbTIyMgQAkZ2d3WA/gwYNEhEREY2O5ePjI1atWiUrGzhwoHByctL4GSguLpbtL1iwQISEhAghhNi2bZsAIHbu3FnvOLVaLe7cuSPtb9y4UTg7Ozca28NKSkoEAG5abEREREREL7O63KCkpKTRdk2+gn379m3s3bsXkZGRMDMz09hGoVDI9hcuXIjw8HCkp6fDy8sLw4YNw/jx4zF79mycPHkSQghMnDhRap+SkoLAwEBZHyqVCikpKbo/of+vpKQECoWi3i3edeLj43H79m1ERETIyg8cOIDvv/9e65X0iooKVFdXo3nz5k8da3l5OWJiYuDq6opWrVoBADw9PWFjY4P169fj/v37uHfvHtavXw9vb2+0adOmwb5KSkoajaWoqAgXLlyQrdoXFRUhMTGxwc/Ao9cwPj4ewcHBAIDY2Fh4enpK+w9TKBSwsrKS9v38/HD16lXk5eVpjK2qqgqlpaWyjYiIiIiISFtNnmBfvnwZQgh4enrKym1tbWFubg5zc3PMnDlTVhcREYGhQ4fCw8MDM2fORF5eHsLCwqBSqeDt7Y3Jkyfj4MGDUvvCwkLY29vL+rC3t0dpaSnu3bun83OqrKzEzJkzERoaCktLS41t1q9fD5VKBWdnZ6ns9u3beO+997Bhw4YGj3vUzJkz4ejoWO8PCNr48ssvpWuckJCApKQkGBkZAQAsLCxw8OBBbNq0CUqlEubm5khMTERCQgIMDAw09rd9+3acOHGi3h8NHlZQUAAhBBwdHaWyus+Al5fXY2O+du0aMjIyMHDgQABAdnZ2vc9OQ+rGzM/P11i/aNEiWFlZSVvdHxuIiIiIiIi00eQJdkNSU1ORnp4OHx8fVFVVyeo6duwo/VyXOHfo0EFWVllZ2SQrkNXV1Rg6dCiEEA1+3/fq1avYs2cPRo8eLSsfO3Yshg0bhn/84x9ajbV48WJs3boVcXFxMDExeeJYw8LCcPr0aRw6dAgeHh4YOnQoKisrAQD37t3D6NGj0aNHD/z222/49ddf8corryAoKEjjHyWSk5MRERGBr7/+Gj4+Pg2OWXfsw/EKIbSOOT4+Hj179pRWtZ/kWKVSCQANPjRv9uzZKCkpkbYrV65o3TcREREREZHmpchnyN3dHQqFAllZWbJyNzc3AP+XFD3M0NBQ+rnu9nFNZWq1GgDg4OCAmzdvyvq4efMmLC0tNfb/tOqS6/z8fBw4cKDBVeiYmBjY2NjIHoIGPLg9PD4+Hp9++imAB8mjWq2GgYEB1q1bh1GjRkltP/30UyxevBj79u2T/cHhSdSt1LZr1w6vvfYamjVrhri4OISGhmLz5s3Iy8tDSkoK9PQe/B1m8+bNaNasGXbt2oV3331X6ufQoUN44403sGzZMoSHhzc6pq2tLQCguLgYLVq0AAC0a9cOCoWi3lPMNYmPj5ddNw8PD62OAx7cig5AGvdRxsbGMDY21qovIiIiIiKiRzX5CraNjQ369euHVatWoby8/C8ZIyAgoN6rnpKSkhAQEKCzMeqS6+zsbOzbtw82NjYa2wkhEBMTg/DwcNkfBYAH3xVPT0+XtgULFsDCwgLp6el48803pXaffPIJFi5ciMTExHpPIH9aQggIIaS7BSoqKqCnpyf7/nvdft0fLoAHTzUPCgrCkiVLtHqvddu2bWFpaYkLFy5IZc2bN4dKpcLq1as1fgbu3LkD4MGTzZOTk2Xftx42bBguXbqEXbt2aTynkpISaf/cuXMwNDRsdIWdiIiIiIjoaTV5gg08+C5wTU0NfH19sW3bNmRmZiIrKwubNm3CxYsXoa+v/6f6nzBhAnJycjBjxgxcvHgRX375JbZv346oqCipTVlZmZTYAg9e7ZWeno6CgoLH9l9dXY1///vfOHnyJGJjY1FbW4vCwkIUFhbi/v37srYHDhxAbm4uxowZU68fb29vvPLKK9Lm5OQEPT09vPLKK2jWrBkAYMmSJZg3bx6+/fZbtGnTRhqnrKxM6qeoqAjp6elSEpuVlYX09HQUFhYCePBatEWLFuHUqVMoKCjAsWPH8M4770CpVGLQoEEAgH79+qG4uBiRkZHIzMzE+fPnERERAQMDA/Tp0wfAg9vCg4KC8P777+Ptt9+WYqlbKdZET08PgYGBOHr0qKx89erVqK2thZ+fH3788UdkZ2cjMzMTK1eulP4QkpiYCA8PD9lD1oYOHYqQkBCEhoYiOjoaJ0+eRH5+Pnbv3o3AwEAkJydLbY8cOYJevXrp9K4FIiIiIiIiyV/4JPMncv36dTFx4kTh6uoqDA0Nhbm5ufDz8xNLly4V5eXlUjs88gotTa+iSk5OFgBkr3dKTk4Wr776qjAyMhJubm4iJiZGNn7dMY9uI0eOfGzsdTFo2pKTk2VtQ0NDRffu3bW6Jppe0+Xi4qJxnPnz58uOa6zNtWvXxMCBA4WdnZ0wNDQUzs7OYtiwYeLixYuysfbu3St69OghrKysRLNmzcQ///lPkZKSItWPHDlS4zi9e/du9Lx++eUX4eTkJGpra2Xl169fF5GRkcLFxUUYGRkJJycnMXjwYOkaDh8+XMyZM6def7W1tWLNmjWiW7duwtTUVFhaWoquXbuKFStWiIqKCqmdp6en2LJlS6OxPYyv6eJruoiIiIiIhND+NV0KIZ7gKVFEOiCEgL+/P6KiohAaGqrVMTU1NbC3t0dCQgL8/PyeeMyEhARMnToVGRkZDT4F/VGlpaWy13xRw/hrhIiIiIheZnW5QUlJSaNvfHoubhGnvxeFQoF169ahpqZG62OKiooQFRWFbt26PdWYde/61ja5JiIiIiIielJcwdbCkSNHpPcua/Lw95/p5cEVbO3x1wgRERERvcy0XcHmcp4WfH19pYefEREREREREWnCBFsLSqUS7u7uTR0GERERERERPcf4HWwiIiIiIiIiHWCCTURERERERKQDTLCJiIiIiIiIdIDfwSZ6jMc9KZCIiIiIiAjgCjYRERERERGRTjDBJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiId4Gu6iB7DysqqqUNoEkKIpg6BiIiIiOiFwhVsIiIiIiIiIh1ggk1ERERERESkA0ywiYiIiIiIiHSACTYRERERERGRDjDBJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbGoS8+bNw7hx457ZeLNmzcKkSZOe2XhERERERPT389wk2IWFhZg8eTLc3d1hYmICe3t79OjRA2vWrEFFRcWf7v/gwYPo0qULjI2N4e7ujg0bNsjq7969iylTpsDFxQVKpRLdu3fHiRMnnmqsCRMmQKFQYPny5bLyoqIihIWFwdLSEtbW1hg9ejTKysqk+qysLPTp0wf29vYwMTGBm5sb5s6di+rqaqlNdXU1FixYgLZt28LExASdOnVCYmJig7EsXrwYCoUCU6ZMkZWPHz8ebdu2hVKpRIsWLRAcHIyLFy/K2hQUFCAoKAimpqaws7PD9OnTUVNTI2tTVVWFOXPmwMXFBcbGxmjTpg2+/fbbRq9PYWEhVqxYgTlz5tQrnzRpEtzc3GBsbIxWrVrhjTfewP79++v14erqin379gEAhBBYt24d/P39YW5uDmtra/j6+mL58uXSZ2fatGnYuHEjcnJyGo2NiIiIiIjoaRk0dQAAkJOTgx49esDa2hrR0dHo0KEDjI2NcfbsWaxbtw5OTk4YPHjwU/efm5uLoKAgTJgwAbGxsdi/fz/GjBmDli1bQqVSAQDGjBmDc+fO4b///S8cHR2xadMmBAYG4sKFC3ByctJ6rLi4OPz2229wdHSsVxcWFoYbN24gKSkJ1dXViIiIwLhx47B582YAgKGhIcLDw9GlSxdYW1vjzJkzGDt2LNRqNaKjowEAc+fOxaZNm/D111/Dy8sLe/bswZtvvoljx46hc+fOsvFOnDiBr776Ch07dqwXS9euXREWFobWrVujqKgIH330Efr374/c3Fzo6+ujtrYWQUFBcHBwwLFjx3Djxg2Eh4fD0NBQigUAhg4dips3b2L9+vVwd3fHjRs3oFarG71G33zzDbp37w4XFxepLC8vT/oMLF26FB06dEB1dTX27NmDyMhIWfKfkZGB4uJi9O7dGwAwYsQI7NixA3PnzsWqVavQokULnDlzBsuXL0ebNm0wZMgQ2NraQqVSYc2aNVi6dOnjppGIiIiIiOjJieeASqUSzs7OoqysTGO9Wq2WfgYg1q5dK4KCgoRSqRReXl7i2LFjIjs7W/Tu3VuYmpqKgIAAcfnyZemYGTNmCB8fH1mfISEhQqVSCSGEqKioEPr6+mL37t2yNl26dBFz5szR+jyuXr0qnJycxLlz54SLi4tYtmyZVHfhwgUBQJw4cUIqS0hIEAqFQly7dq3BPqOiokTPnj2l/ZYtW4pVq1bJ2rz11lsiLCxMVnb37l3Rrl07kZSUJHr37i0mT57caOxnzpwRAKTr9ssvvwg9PT1RWFgotVmzZo2wtLQUVVVVUvxWVlbi9u3bjfb9KB8fn3rnMHDgQOHk5KTxM1BcXCzbX7BggQgJCRFCCLFt2zYBQOzcubPecWq1Wty5c0fa37hxo3B2dm4wrsrKSlFSUiJtV65cEQD+thsRERERET1QUlIiAIiSkpJG2zX5LeK3b9/G3r17ERkZCTMzM41tFAqFbH/hwoUIDw9Heno6vLy8MGzYMIwfPx6zZ8/GyZMnIYTAxIkTpfYpKSkIDAyU9aFSqZCSkgIAqKmpQW1tLUxMTGRtlEoljh49qtV5qNVqjBgxAtOnT4ePj0+9+pSUFOnW5TqBgYHQ09PD8ePHNfZ5+fJlJCYmSiu1wINbsrWJMzIyEkFBQfXOW5Py8nLExMTA1dUVrVq1kuLt0KED7O3tpXYqlQqlpaU4f/48ACA+Ph6+vr745JNP4OTkBA8PD0ybNg337t1rcKyioiJcuHBBdh2KioqQmJjY4GfA2tpath8fH4/g4GAAQGxsLDw9PaX9hykUClhZWUn7fn5+uHr1KvLy8jTGtmjRIlhZWUlb3bUgIiIiIiLSRpMn2JcvX4YQAp6enrJyW1tbmJubw9zcHDNnzpTVRUREYOjQofDw8MDMmTORl5eHsLAwqFQqeHt7Y/LkyTh48KDUvrCwUJYoAoC9vT1KS0tx7949WFhYICAgAAsXLsT169dRW1uLTZs2ISUlBTdu3NDqPJYsWQIDAwO8//77GusLCwthZ2cnKzMwMEDz5s1RWFgoK+/evTtMTEzQrl079OrVCwsWLJDqVCoVPv/8c2RnZ0OtViMpKQk7duyQxbl161akpaVh0aJFjcb85ZdfStc4ISEBSUlJMDIykuLVdM3q6oAHt/YfPXoU586dQ1xcHJYvX44ffvgB//M//9PgmAUFBRBCyG6hr/sMeHl5NRovAFy7dg0ZGRkYOHAgACA7O7veZ6chdWPm5+drrJ89ezZKSkqk7cqVK1r1S0REREREBDwHCXZDUlNTkZ6eDh8fH1RVVcnqHv5OcV3S16FDB1lZZWUlSktLtR7vv//9L4QQcHJygrGxMVauXInQ0FDo6T3+Ep06dQorVqzAhg0b6q22P41t27YhLS0Nmzdvxs8//4xPP/1UqluxYgXatWsHLy8vGBkZYeLEiYiIiJDivHLlCiZPnozY2Nh6K92PCgsLw+nTp3Ho0CF4eHhg6NChqKys1DpOtVoNhUKB2NhY+Pn5YdCgQfj888+xcePGBlex68ofjk0IofWY8fHx6Nmzp7Sq/STHKpVKAGjwoXnGxsawtLSUbURERERERNpq8gTb3d0dCoUCWVlZsnI3Nze4u7tLSdHDDA0NpZ/rElpNZXUP23JwcMDNmzdlfdy8eROWlpZS/23btsWhQ4dQVlaGK1euIDU1FdXV1XBzc3vsORw5cgS3bt1C69atYWBgAAMDA+Tn52Pq1Klo06aNFMOtW7dkx9XU1KCoqAgODg6y8latWqF9+/YIDQ3F4sWL8dFHH6G2thYA0KJFC+zcuRPl5eXIz8/HxYsXYW5uLsV56tQp3Lp1C126dJFiOXToEFauXAkDAwOpHwCwsrJCu3bt8I9//AM//PADLl68iLi4uEavWV0dALRs2RJOTk6y27C9vb0hhMDVq1c1XitbW1sAQHFxsVTWrl07KBSKek8x1yQ+Pl72wDsPDw+tjgMe3IoOPLiGREREREREutbkCbaNjQ369euHVatWoby8/C8ZIyAgoN6rnpKSkhAQEFCvrZmZGVq2bIni4mLs2bNH43d7HzVixAhkZGQgPT1d2hwdHTF9+nTs2bNHiuHOnTs4deqUdNyBAwegVqvh7+/fYN9qtRrV1dX1nsxtYmICJycn1NTU4Mcff5Ti7Nu3L86ePSuLxdfXF2FhYUhPT4e+vr7GcYQQEEJIdwsEBATg7Nmzsj8KJCUlwdLSEu3btwcA9OjRA9evX5e9auzSpUvQ09ODs7OzxnHatm0LS0tLXLhwQSpr3rw5VCoVVq9erfEzcOfOHQBAWVkZkpOTZXMybNgwXLp0Cbt27dJ4TiUlJdL+uXPnYGhoqPE78kRERERERH9WkyfYwIPvAtfU1MDX1xfbtm1DZmYmsrKysGnTJly8eLHBpFBbEyZMQE5ODmbMmIGLFy/iyy+/xPbt2xEVFSW12bNnDxITE5Gbm4ukpCT06dMHXl5eiIiIeGz/NjY2eOWVV2SboaEhHBwcpO8He3t7Y8CAARg7dixSU1Px66+/YuLEiXj33Xel7wbHxsZi+/btyMzMRE5ODrZv347Zs2cjJCREWqE/fvw4duzYgZycHBw5cgQDBgyAWq3GjBkzAAAWFhb1YjEzM5NiBB58d3rRokU4deoUCgoKcOzYMbzzzjtQKpUYNGgQAKB///5o3749RowYgTNnzmDPnj2YO3cuIiMjYWxsDOBBcmtjY4OIiAhcuHABhw8fxvTp0zFq1CiNdx4AgJ6eHgIDA+s9lG316tWora2Fn58ffvzxR2RnZyMzMxMrV66U/hCSmJgIDw8P6a4A4MFrwkJCQhAaGoro6GicPHkS+fn52L17NwIDA5GcnCy1PXLkCHr16tVgbERERERERH/KX/ko8ydx/fp1MXHiROHq6ioMDQ2Fubm58PPzE0uXLhXl5eVSOwAiLi5O2s/NzRUAxOnTp6Wy5ORkAUD2eqfk5GTx6quvCiMjI+Hm5iZiYmJk42/btk24ubkJIyMj4eDgICIjI2WveHpSj76mSwghbt++LUJDQ4W5ubmwtLQUERER4u7du1L91q1bRZcuXYS5ubkwMzMT7du3F9HR0eLevXtSm4MHDwpvb29hbGwsbGxsxIgRIxp9zZcQot5ruq5duyYGDhwo7OzshKGhoXB2dhbDhg0TFy9elB2Xl5cnBg4cKJRKpbC1tRVTp04V1dXVsjaZmZkiMDBQKJVK4ezsLD744ANRUVHRaDy//PKLcHJyErW1tbLy69evi8jISOHi4iKMjIyEk5OTGDx4sEhOThZCCDF8+HCNr02rra0Va9asEd26dROmpqbC0tJSdO3aVaxYsUIWi6enp9iyZUujsT2s7lH8f9eNiIiIiIge0PY1XQohnuApUUQ6IISAv78/oqKiEBoaqtUxNTU1sLe3R0JCAvz8/J54zISEBEydOhUZGRkwMDDQ6pjS0lLZ98v/bvirgYiIiIjogbrcoKSkpNGHIT8Xt4jT34tCocC6detQU1Oj9TFFRUWIiopCt27dnmrMund9a5tcExERERERPSmuYGvhyJEj0nuXNXn4IV/08uAKNn81EBEREREB2q9gczlPC76+vkhPT2/qMIiIiIiIiOg5xgRbC0qlEu7u7k0dBhERERERET3H+B1sIiIiIiIiIh1ggk1ERERERESkA7xFnOgxHvcgAyIiIiIiIoAr2EREREREREQ6wQSbiIiIiIiISAeYYBMRERERERHpABNsIiIiIiIiIh1ggk1ERERERESkA0ywiYiIiIiIiHSACTYRERERERGRDjDBJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiIdYIJNREREREREpANMsImIiIiIiIh0gAk2ERERERERkQ4wwSYiIiIiIiLSASbYRERERERERDrABJuIiIiIiIhIB5hgExEREREREekAE2wiIiIiIiIiHWCCTURERERERKQDTLCJiIiIiIiIdIAJNhEREREREZEOMMEmIiIiIiIi0gEm2EREREREREQ6wASbiIiIiIiISAeYYBMRERERERHpABNsIiIiIiIiIh1ggk1ERERERESkA0ywiYiIiIiIiHSACTYRERERERGRDjDBJiIiIiIiItIBJthEREREREREOmDQ1AEQPa+EEACA0tLSJo6EiIiIiIiaUl1OUJcjNIQJNlEDbt++DQBo1apVE0dCRERERETPg7t378LKyqrBeibYRA1o3rw5AKCgoKDR/4joxVJaWopWrVrhypUrsLS0bOpwSEc4ry8nzuvLifP6cuK8vpw4r/9HCIG7d+/C0dGx0XZMsIkaoKf34BEFVlZWf/tfKC8jS0tLzutLiPP6cuK8vpw4ry8nzuvLifP6gDaLbnzIGREREREREZEOMMEmIiIiIiIi0gEm2EQNMDY2xvz582FsbNzUoZAOcV5fTpzXlxPn9eXEeX05cV5fTpzXJ6cQj3vOOBERERERERE9FlewiYiIiIiIiHSACTYRERERERGRDjDBJiIiIiIiItIBJthEREREREREOsAEm0iD1atXo02bNjAxMYG/vz9SU1ObOiR6AosWLUK3bt1gYWEBOzs7DBkyBFlZWbI2lZWViIyMhI2NDczNzfH222/j5s2bTRQxPY3FixdDoVBgypQpUhnn9cV07do1DB8+HDY2NlAqlejQoQNOnjwp1Qsh8L//+79o2bIllEolAgMDkZ2d3YQR0+PU1tZi3rx5cHV1hVKpRNu2bbFw4UI8/GxdzuuL4fDhw3jjjTfg6OgIhUKBnTt3yuq1mceioiKEhYXB0tIS1tbWGD16NMrKyp7hWdCjGpvX6upqzJw5Ex06dICZmRkcHR0RHh6O69evy/rgvGrGBJvoEdu2bcMHH3yA+fPnIy0tDZ06dYJKpcKtW7eaOjTS0qFDhxAZGYnffvsNSUlJqK6uRv/+/VFeXi61iYqKwk8//YTvv/8ehw4dwvXr1/HWW281YdT0JE6cOIGvvvoKHTt2lJVzXl88xcXF6NGjBwwNDZGQkIALFy7gs88+Q7NmzaQ2n3zyCVauXIm1a9fi+PHjMDMzg0qlQmVlZRNGTo1ZsmQJ1qxZg1WrViEzMxNLlizBJ598gi+++EJqw3l9MZSXl6NTp05YvXq1xnpt5jEsLAznz59HUlISdu/ejcOHD2PcuHHP6hRIg8bmtaKiAmlpaZg3bx7S0tKwY8cOZGVlYfDgwbJ2nNcGCCKS8fPzE5GRkdJ+bW2tcHR0FIsWLWrCqOjPuHXrlgAgDh06JIQQ4s6dO8LQ0FB8//33UpvMzEwBQKSkpDRVmKSlu3fvinbt2omkpCTRu3dvMXnyZCEE5/VFNXPmTNGzZ88G69VqtXBwcBBLly6Vyu7cuSOMjY3Fli1bnkWI9BSCgoLEqFGjZGVvvfWWCAsLE0JwXl9UAERcXJy0r808XrhwQQAQJ06ckNokJCQIhUIhrl279sxip4Y9Oq+apKamCgAiPz9fCMF5bQxXsIkecv/+fZw6dQqBgYFSmZ6eHgIDA5GSktKEkdGfUVJSAgBo3rw5AODUqVOorq6WzbOXlxdat27NeX4BREZGIigoSDZ/AOf1RRUfHw9fX1+88847sLOzQ+fOnfH1119L9bm5uSgsLJTNq5WVFfz9/Tmvz7Hu3btj//79uHTpEgDgzJkzOHr0KAYOHAiA8/qy0GYeU1JSYG1tDV9fX6lNYGAg9PT0cPz48WceMz2dkpISKBQKWFtbA+C8NsagqQMgep788ccfqK2thb29vazc3t4eFy9ebKKo6M9Qq9WYMmUKevTogVdeeQUAUFhYCCMjI+l/EnXs7e1RWFjYBFGStrZu3Yq0tDScOHGiXh3n9cWUk5ODNWvW4IMPPsCHH36IEydO4P3334eRkRFGjhwpzZ2m38uc1+fXrFmzUFpaCi8vL+jr66O2thYff/wxwsLCAIDz+pLQZh4LCwthZ2cnqzcwMEDz5s051y+IyspKzJw5E6GhobC0tATAeW0ME2wieqlFRkbi3LlzOHr0aFOHQn/SlStXMHnyZCQlJcHExKSpwyEdUavV8PX1RXR0NACgc+fOOHfuHNauXYuRI0c2cXT0tLZv347Y2Fhs3rwZPj4+SE9Px5QpU+Do6Mh5JXqBVFdXY+jQoRBCYM2aNU0dzguBt4gTPcTW1hb6+vr1njp88+ZNODg4NFFU9LQmTpyI3bt3Izk5Gc7OzlK5g4MD7t+/jzt37sjac56fb6dOncKtW7fQpUsXGBgYwMDAAIcOHcLKlSthYGAAe3t7zusLqGXLlmjfvr2szNvbGwUFBQAgzR1/L79Ypk+fjlmzZuHdd99Fhw4dMGLECERFRWHRokUAOK8vC23m0cHBod6DYmtqalBUVMS5fs7VJdf5+flISkqSVq8BzmtjmGATPcTIyAhdu3bF/v37pTK1Wo39+/cjICCgCSOjJyGEwMSJExEXF4cDBw7A1dVVVt+1a1cYGhrK5jkrKwsFBQWc5+dY3759cfbsWaSnp0ubr68vwsLCpJ85ry+eHj161HuN3qVLl+Di4gIAcHV1hYODg2xeS0tLcfz4cc7rc6yiogJ6evJ/Zurr60OtVgPgvL4stJnHgIAA3LlzB6dOnZLaHDhwAGq1Gv7+/s88ZtJOXXKdnZ2Nffv2wcbGRlbPeW1EUz9ljeh5s3XrVmFsbCw2bNggLly4IMaNGyesra1FYWFhU4dGWvrPf/4jrKysxMGDB8WNGzekraKiQmozYcIE0bp1a3HgwAFx8uRJERAQIAICApowanoaDz9FXAjO64soNTVVGBgYiI8//lhkZ2eL2NhYYWpqKjZt2iS1Wbx4sbC2tha7du0SGRkZIjg4WLi6uop79+41YeTUmJEjRwonJyexe/dukZubK3bs2CFsbW3FjBkzpDac1xfD3bt3xenTp8Xp06cFAPH555+L06dPS0+T1mYeBwwYIDp37iyOHz8ujh49Ktq1aydCQ0Ob6pRIND6v9+/fF4MHDxbOzs4iPT1d9m+pqqoqqQ/Oq2ZMsIk0+OKLL0Tr1q2FkZGR8PPzE7/99ltTh0RPAIDGLSYmRmpz79498T//8z+iWbNmwtTUVLz55pvixo0bTRc0PZVHE2zO64vpp59+Eq+88oowNjYWXl5eYt26dbJ6tVot5s2bJ+zt7YWxsbHo27evyMrKaqJoSRulpaVi8uTJonXr1sLExES4ubmJOXPmyP5xznl9MSQnJ2v8f+rIkSOFENrN4+3bt0VoaKgwNzcXlpaWIiIiQty9e7cJzobqNDavubm5Df5bKjk5WeqD86qZQgghnt16OREREREREdHLid/BJiIiIiIiItIBJthEREREREREOsAEm4iIiIiIiEgHmGATERERERER6QATbCIiIiIiIiIdYIJNREREREREpANMsImIiIiIiIh0gAk2ERERERERkQ4wwSYiIqJGHTx4EAqFAnfu3Hku+qH/s3//fnh7e6O2trapQ6nntddew48//tjUYRARPVNMsImIiF5i7733HhQKBRQKBQwNDeHq6ooZM2agsrLyLx339ddfx5QpU2Rl3bt3x40bN2BlZfWXjZuXlyed78Pb8OHDtTo+Li4Or732GqysrGBhYQEfH5965/E8mTFjBubOnQt9fX2p7P79+1i6dCm6dOkCMzMzWFlZoVOnTpg7dy6uX79er4+UlBTo6+sjKCioXl3d9UxPT5ft29nZ4e7du7K2r776Kj766CNpf+7cuZg1axbUarVuTpaI6AXABJuIiOglN2DAANy4cQM5OTlYtmwZvvrqK8yfP/+Zx2FkZAQHBwcoFIq/fKx9+/bhxo0b0rZ69erHHrN//36EhITg7bffRmpqKk6dOoWPP/4Y1dXVf1mctbW1T52AHj16FL///jvefvttqayqqgr9+vVDdHQ03nvvPRw+fBhnz57FypUr8ccff+CLL76o18/69esxadIkHD58WGMCrsndu3fx6aefNtpm4MCBuHv3LhISEp7sxIiIXmBMsImIiF5yxsbGcHBwQKtWrTBkyBAEBgYiKSlJqler1Vi0aBFcXV2hVCrRqVMn/PDDDw32d/v2bYSGhsLJyQmmpqbo0KEDtmzZItW/9957OHToEFasWCGtIOfl5cluES8tLYVSqayXfMXFxcHCwgIVFRUAgCtXrmDo0KGwtrZG8+bNERwcjLy8vMees42NDRwcHKRNm1Xzn376CT169MD06dPh6ekJDw8PDBkypF5y/tNPP6Fbt24wMTGBra0t3nzzTamuuLgY4eHhaNasGUxNTTFw4EBkZ2dL9Rs2bIC1tTXi4+PRvn17GBsbo6CgAFVVVZg2bRqcnJxgZmYGf39/HDx4sNF4t27din79+sHExEQqW7ZsGY4ePYoDBw7g/fffR9euXdG6dWv07t0ba9euRXR0tKyPsrIybNu2Df/5z38QFBSEDRs2PPY6AcCkSZPw+eef49atWw220dfXx6BBg7B161at+iQiehkwwSYiIvobOXfuHI4dOwYjIyOpbNGiRfjuu++wdu1anD9/HlFRURg+fDgOHTqksY/Kykp07doVP//8M86dO4dx48ZhxIgRSE1NBQCsWLECAQEBGDt2rLSC3KpVK1kflpaW+Ne//oXNmzfLymNjYzFkyBCYmpqiuroaKpUKFhYWOHLkCH799VeYm5tjwIABuH//vo6vDODg4IDz58/j3LlzDbb5+eef8eabb2LQoEE4ffo09u/fDz8/P6n+vffew8mTJxEfH4+UlBQIITBo0CDZKnhFRQWWLFmCb775BufPn4ednR0mTpyIlJQUbN26FRkZGXjnnXcwYMAAWXL+qCNHjsDX11dWtmXLFvTr1w+dO3fWeMyjdw9s374dXl5e8PT0xPDhw/Htt99CCNHodQKA0NBQuLu7Y8GCBY228/Pzw5EjRx7bHxHRS0MQERHRS2vkyJFCX19fmJmZCWNjYwFA6OnpiR9++EEIIURlZaUwNTUVx44dkx03evRoERoaKoQQIjk5WQAQxcXFDY4TFBQkpk6dKu337t1bTJ48Wdbm0X7i4uKEubm5KC8vF0IIUVJSIkxMTERCQoIQQoj//ve/wtPTU6jVaqmPqqoqoVQqxZ49ezTGkZubKwAIpVIpzMzMpC0tLe2x16qsrEwMGjRIABAuLi4iJCRErF+/XlRWVkptAgICRFhYmMbjL126JACIX3/9VSr7448/hFKpFNu3bxdCCBETEyMAiPT0dKlNfn6+0NfXF9euXZP117dvXzF79uwG47WyshLfffedrMzExES8//77srIhQ4ZI1yEgIEBW1717d7F8+XIhhBDV1dXC1tZWJCcnS/V11/P06dP19hMTE4WhoaG4fPmyEEKITp06ifnz58v637Vrl9DT0xO1tbUNngcR0cvEoMkyeyIiInom+vTpgzVr1qC8vBzLli2DgYGB9L3dy5cvo6KiAv369ZMdc//+/QZXQWtraxEdHY3t27fj2rVruH//PqqqqmBqavpEcQ0aNAiGhoaIj4/Hu+++ix9//BGWlpYIDAwEAJw5cwaXL1+GhYWF7LjKykr8/vvvjfa9bds2eHt7S/uPrqBrYmZmhp9//hm///47kpOT8dtvv2Hq1KlYsWIFUlJSYGpqivT0dIwdO1bj8ZmZmTAwMIC/v79UZmNjA09PT2RmZkplRkZG6Nixo7R/9uxZ1NbWwsPDQ9ZfVVUVbGxsGoz33r17stvDG/Lll1+ivLwcK1euxOHDh6XyrKwspKamIi4uDgBgYGCAkJAQrF+/Hq+//vpj+1WpVOjZsyfmzZtX706EOkqlEmq1GlVVVVAqlY/tk4joRccEm4iI6CVnZmYGd3d3AMC3336LTp06Yf369Rg9ejTKysoAPLj12cnJSXacsbGxxv6WLl2KFStWYPny5ejQoQPMzMwwZcqUJ75t28jICP/+97+xefNmvPvuu9i8eTNCQkJgYPDgnydlZWXo2rUrYmNj6x3bokWLRvtu1aqVdM5Pqm3btmjbti3GjBmDOXPmwMPDA9u2bUNERIROkkSlUim7VbusrAz6+vo4deqU7GngAGBubt5gP7a2tiguLpaVtWvXDllZWbKyli1bAgCaN28uK1+/fj1qamrg6OgolQkhYGxsjFWrVmn1vfXFixcjICAA06dP11hfVFQEMzMzJtdE9LfB72ATERH9jejp6eHDDz/E3Llzce/ePdmDttzd3WVbQ6u+v/76K4KDgzF8+HB06tQJbm5uuHTpkqyNkZGRVu9mDgsLQ2JiIs6fP48DBw4gLCxMquvSpQuys7NhZ2dXL7a/8lVfD2vTpg1MTU1RXl4OAOjYsSP279+vsa23tzdqampw/Phxqez27dvIyspC+/btGxyjc+fOqK2txa1bt+qdp4ODQ6PHXbhwQVYWGhqKpKQknD59utHzqqmpwXfffYfPPvsM6enp0nbmzBk4OjrKHlrXGD8/P7z11luYNWuWxvpz5841eCcEEdHLiAk2ERHR38w777wDfX19rF69GhYWFpg2bRqioqKwceNG/P7770hLS8MXX3yBjRs3ajy+Xbt2SEpKwrFjx5CZmYnx48fj5s2bsjZt2rTB8ePHkZeXhz/++KPBV1H94x//gIODA8LCwuDq6iq7vTosLAy2trYIDg7GkSNHkJubi4MHD+L999/H1atXdXdB/r+PPvoIM2bMwMGDB5Gbm4vTp09j1KhRqK6ulm6hnz9/PrZs2YL58+cjMzMTZ8+exZIlS6TrEhwcjLFjx+Lo0aM4c+YMhg8fDicnJwQHBzc4roeHB8LCwhAeHo4dO3YgNzcXqampWLRoEX7++ecGj1OpVDh69KisLCoqCgEBAejbty9WrFiBtLQ05ObmYs+ePUhISJBWyHfv3o3i4mKMHj0ar7zyimx7++23sX79eq2v28cff4wDBw7UWzkHHjyIrX///lr3RUT0omOCTURE9DdjYGCAiRMn4pNPPkF5eTkWLlyIefPmYdGiRfD29saAAQPw888/w9XVVePxc+fORZcuXaBSqfD666/DwcEBQ4YMkbWZNm0a9PX10b59e7Ro0QIFBQUa+1IoFAgNDcWZM2dkq9cAYGpqisOHD6N169Z466234O3tjdGjR6OyshKWlpY6uRYP6927N3JychAeHg4vLy8MHDgQhYWF2Lt3Lzw9PQEAr7/+Or7//nvEx8fj1VdfxT//+U/p6ekAEBMTg65du+Jf//oXAgICIITAL7/8AkNDw0bHjomJQXh4OKZOnQpPT08MGTIEJ06cQOvWrRs8JiwsDOfPn5cltiYmJti/fz9mzpyJmJgY9OzZE97e3pgyZQp69OiBnTt3Anhwe3hgYKDGOwHefvttnDx5EhkZGVpdNw8PD4waNQqVlZWy8mvXruHYsWOIiIjQqh8iopeBQggt3sVARERERM+d6dOno7S0FF999VVTh1LPzJkzUVxcjHXr1jV1KEREzwxXsImIiIheUHPmzIGLi0uDt+A3JTs7OyxcuLCpwyAieqa4gk1ERER/CxMmTMCmTZs01g0fPhxr1659xhEREdHLhgk2ERER/S3cunULpaWlGussLS1hZ2f3jCMiIqKXDRNsIiIiIiIiIh3gd7CJiIiIiIiIdIAJNhEREREREZEOMMEmIiIiIiIi0gEm2EREREREREQ6wASbiIiIiIiISAeYYBMRERERERHpABNsIiIiIiIiIh34f053diN7m5kxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#generate figure object\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "#load in the 20 lardest values and their SNP label\n",
    "indexes = df.nlargest(20, \"F_Score(GAIN)\").index\n",
    "values = df.nlargest(20, \"F_Score(GAIN)\").values.ravel()\n",
    "#reverse to make the largest be at the front\n",
    "indexes = indexes[::-1]\n",
    "values = values[::-1]\n",
    "#for each different chromosome you want to colour add a index(*_i) and value (*_v) array\n",
    "#black would be colour for singular/notinteresting chromosomes\n",
    "r_i = []\n",
    "r_v = []\n",
    "b_i = []\n",
    "b_v = []\n",
    "g_i = []\n",
    "g_v = []\n",
    "y_i = []\n",
    "y_v = []\n",
    "bl_i = []\n",
    "bl_v = []\n",
    "p_i = []\n",
    "p_v = []\n",
    "br_i = []\n",
    "br_v = []\n",
    "pu_i = []\n",
    "pu_v = []\n",
    "#for each value in the top n (default 20) check which chromosome it belongs to and add it to the colour array\n",
    "i = 0\n",
    "while i < len(indexes):\n",
    "    if('Gm12' in indexes[i]):\n",
    "        r_i.append(indexes[i])\n",
    "        r_v.append(values[i])\n",
    "    elif('Gm08' in indexes[i]):\n",
    "        b_i.append(indexes[i])\n",
    "        b_v.append(values[i])\n",
    "    elif('Gm06' in indexes[i]):\n",
    "        g_i.append(indexes[i])\n",
    "        g_v.append(values[i])\n",
    "    elif('Gm02' in indexes[i]):\n",
    "        y_i.append(indexes[i])\n",
    "        y_v.append(values[i])\n",
    "    elif('Gm19' in indexes[i]):\n",
    "        p_i.append(indexes[i])\n",
    "        p_v.append(values[i])\n",
    "   # elif('Gm04' in indexes[i]):\n",
    "   #     br_i.append(indexes[i])\n",
    "   #     br_v.append(values[i])\n",
    "   # elif('Gm13' in indexes[i]):\n",
    "   #     pu_i.append(indexes[i])\n",
    "   #     pu_v.append(values[i])\n",
    "    else:\n",
    "        bl_i.append(indexes[i])\n",
    "        bl_v.append(values[i])\n",
    "    i = i + 1\n",
    "#plot each of the arrays with appropriate colour and label graph\n",
    "plt.barh(bl_i, bl_v, color=\"black\")\n",
    "plt.barh(br_i, br_v, color=\"brown\")\n",
    "plt.barh(pu_i, pu_v, color=\"purple\")\n",
    "plt.barh(p_i, p_v, color=\"orange\")\n",
    "plt.barh(y_i, y_v, color=\"yellow\")\n",
    "plt.barh(g_i, g_v, color=\"green\")\n",
    "plt.barh(r_i, r_v, color=\"red\")\n",
    "plt.barh(b_i, b_v, color=\"blue\")\n",
    "plt.title('SNP Importance XGBoost Seed Coat Colour')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data(\"SCC_Merged_filtered.csv_train_test.csv_5pcnt.csv\", \"SCC_Merged_filtered.csv_holdout.csv_5pcnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if need or have new holdout data etc.\n",
    "ohe = pickle.load(open(\"SCC_ohe.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_vcf.shape)\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_vcf.shape)\n",
    "print(tt_pheno.shape)\n",
    "print(ho_vcf.shape)\n",
    "print(ho_pheno.shape)\n",
    "seed = randint(0,5000)\n",
    " #if optimised in same session, other enter manually below\n",
    "#this function should average out 10 folds and training, with inital params optimised\n",
    "#average accuracy and std should be calculated along with a nice AUROC graph of train/test models\n",
    "#best model should be extracted for use on holdout set\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=seed, max_features = 'sqrt',n_jobs=1, verbose = 1)\n",
    "best_model = eval_k_fold(model, tt_vcf, tt_pheno, 10, ho_vcf, ho_pheno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (based off primer paper and Philipp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "(620,)\n",
      "(620, 1)\n",
      "220000\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "(155,)\n",
      "(155, 1)\n",
      "220000\n",
      "(620, 214310)\n",
      "(155, 214310)\n"
     ]
    }
   ],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data(\"SCC_Merged_filtered.csv_train_test.csv_5pcnt.csv\", \"SCC_Merged_filtered.csv_holdout.csv_5pcnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 621607)\n",
      "(155, 214310)\n",
      "(155, 621607)\n"
     ]
    }
   ],
   "source": [
    "ohe = pickle.load(open(\"SCC_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##how to mlb both tt and ho for same scheme? do i even need to?\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb = mlb.fit(tt_pheno)\n",
    "##print(tt_pheno.shape)\n",
    "#print(ho_pheno.shape)\n",
    "#tt_pheno = mlb.transform(tt_pheno)\n",
    "#print(tt_pheno.shape)\n",
    "#ho_pheno = mlb.transform(ho_pheno)\n",
    "#print(ho_pheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN_model(x_len):    \n",
    "    #del model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=10, kernel_size=10, \n",
    "                     input_shape=(x_len, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=8, kernel_size=8, \n",
    "                     input_shape=(10, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=6, kernel_size=6, \n",
    "                     input_shape=(8, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(24, activation='linear'))\n",
    "    model.add(Dense(16, activation='linear'))\n",
    "    model.add(Dense(8, activation='linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cnn(x,y,k,mlb):\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    best_model = []\n",
    "    results = []\n",
    "    highest = 0\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        print(y.shape)\n",
    "        print(y[train])\n",
    "        if(i==1):\n",
    "            y = mlb.transform(y)\n",
    "            print(y.shape)\n",
    "            print(y[train])\n",
    "        x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "        model = build_CNN_model(x[train].shape[1])\n",
    "        bs = ((x[train].shape[0])/20)\n",
    "        bs = round(bs)\n",
    "        history = model.fit(x[train], y[train], validation_data=(x[test], y[test]), epochs=100, batch_size=bs)\n",
    "        _, accuracy = model.evaluate(x[test], y[test], batch_size=bs, verbose=0)\n",
    "        accuracy = accuracy *100\n",
    "        print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "        if(accuracy > highest):\n",
    "            highest = accuracy\n",
    "            best_model = model\n",
    "        results.append(accuracy)\n",
    "        del model\n",
    "        i = i + 1\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results))) \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]]\n",
      "(620, 4)\n",
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 556 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "556/556 [==============================] - 23s 42ms/sample - loss: 1.0473 - accuracy: 0.6349 - val_loss: 0.9156 - val_accuracy: 0.7969\n",
      "Epoch 2/100\n",
      "556/556 [==============================] - 5s 10ms/sample - loss: 0.8851 - accuracy: 0.7464 - val_loss: 1.2021 - val_accuracy: 0.4844\n",
      "Epoch 3/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.8058 - accuracy: 0.7896 - val_loss: 1.4717 - val_accuracy: 0.2188\n",
      "Epoch 4/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.7506 - accuracy: 0.8058 - val_loss: 1.7444 - val_accuracy: 0.2188\n",
      "Epoch 5/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.6906 - accuracy: 0.8147 - val_loss: 1.9124 - val_accuracy: 0.2188\n",
      "Epoch 6/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.6489 - accuracy: 0.8219 - val_loss: 2.2701 - val_accuracy: 0.2188\n",
      "Epoch 7/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.5703 - accuracy: 0.8273 - val_loss: 2.6513 - val_accuracy: 0.2188\n",
      "Epoch 8/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.5214 - accuracy: 0.8363 - val_loss: 3.3659 - val_accuracy: 0.2188\n",
      "Epoch 9/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.3928 - accuracy: 0.8885 - val_loss: 3.8835 - val_accuracy: 0.2188\n",
      "Epoch 10/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.2838 - accuracy: 0.9568 - val_loss: 3.8270 - val_accuracy: 0.2188\n",
      "Epoch 11/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.1604 - accuracy: 0.9910 - val_loss: 3.3598 - val_accuracy: 0.2188\n",
      "Epoch 12/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.1207 - accuracy: 0.9928 - val_loss: 3.2586 - val_accuracy: 0.2188\n",
      "Epoch 13/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0844 - accuracy: 0.9982 - val_loss: 3.0481 - val_accuracy: 0.2188\n",
      "Epoch 14/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0676 - accuracy: 0.9982 - val_loss: 2.6643 - val_accuracy: 0.2188\n",
      "Epoch 15/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0587 - accuracy: 1.0000 - val_loss: 2.4181 - val_accuracy: 0.2188\n",
      "Epoch 16/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0558 - accuracy: 0.9946 - val_loss: 1.6277 - val_accuracy: 0.2188\n",
      "Epoch 17/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0554 - accuracy: 0.9982 - val_loss: 2.0451 - val_accuracy: 0.2188\n",
      "Epoch 18/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0380 - accuracy: 1.0000 - val_loss: 1.5041 - val_accuracy: 0.2188\n",
      "Epoch 19/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.3698 - val_accuracy: 0.2656\n",
      "Epoch 20/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.4219\n",
      "Epoch 21/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.9971 - val_accuracy: 0.6562\n",
      "Epoch 22/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.0567 - val_accuracy: 0.5781\n",
      "Epoch 23/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.7344\n",
      "Epoch 24/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.0484 - val_accuracy: 0.6406\n",
      "Epoch 25/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.9187 - val_accuracy: 0.7188\n",
      "Epoch 26/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.7969\n",
      "Epoch 27/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0304 - accuracy: 0.9982 - val_loss: 0.5729 - val_accuracy: 0.8125\n",
      "Epoch 28/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0476 - accuracy: 0.9982 - val_loss: 0.5887 - val_accuracy: 0.8125\n",
      "Epoch 29/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0229 - accuracy: 0.9982 - val_loss: 0.5916 - val_accuracy: 0.8281\n",
      "Epoch 30/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.5887 - val_accuracy: 0.8281\n",
      "Epoch 31/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.5863 - val_accuracy: 0.8281\n",
      "Epoch 32/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.8125\n",
      "Epoch 33/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.8125\n",
      "Epoch 34/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.8438\n",
      "Epoch 35/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.8125\n",
      "Epoch 36/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6168 - val_accuracy: 0.7969\n",
      "Epoch 37/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.8059 - val_accuracy: 0.7969\n",
      "Epoch 38/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0274 - accuracy: 0.9964 - val_loss: 0.7372 - val_accuracy: 0.8281\n",
      "Epoch 39/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.8438\n",
      "Epoch 40/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0206 - accuracy: 0.9982 - val_loss: 0.7483 - val_accuracy: 0.7812\n",
      "Epoch 41/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6307 - val_accuracy: 0.8125\n",
      "Epoch 42/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7777 - val_accuracy: 0.7812\n",
      "Epoch 43/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.8125\n",
      "Epoch 44/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6105 - val_accuracy: 0.8125\n",
      "Epoch 45/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.8125\n",
      "Epoch 46/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.8125\n",
      "Epoch 47/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.8125\n",
      "Epoch 48/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.8125\n",
      "Epoch 49/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.8125\n",
      "Epoch 50/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.7969\n",
      "Epoch 51/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 0.7969\n",
      "Epoch 52/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.8125\n",
      "Epoch 53/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8125\n",
      "Epoch 54/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.8125\n",
      "Epoch 55/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.8125\n",
      "Epoch 56/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.8125\n",
      "Epoch 57/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.8125\n",
      "Epoch 58/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6275 - val_accuracy: 0.8125\n",
      "Epoch 59/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.8125\n",
      "Epoch 60/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.7969\n",
      "Epoch 61/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6338 - val_accuracy: 0.8125\n",
      "Epoch 62/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.8125\n",
      "Epoch 64/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 0.8281\n",
      "Epoch 65/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6303 - val_accuracy: 0.8125\n",
      "Epoch 66/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.8125\n",
      "Epoch 67/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.7969\n",
      "Epoch 68/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.8125\n",
      "Epoch 69/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 0.8125\n",
      "Epoch 70/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6303 - val_accuracy: 0.8125\n",
      "Epoch 71/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.8125\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.8125\n",
      "Epoch 73/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6485 - val_accuracy: 0.8125\n",
      "Epoch 74/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.8125\n",
      "Epoch 75/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 0.8125\n",
      "Epoch 76/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.8125\n",
      "Epoch 77/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8125\n",
      "Epoch 78/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.8125\n",
      "Epoch 79/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.8125\n",
      "Epoch 80/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6646 - val_accuracy: 0.8281\n",
      "Epoch 81/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.8125\n",
      "Epoch 82/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8125\n",
      "Epoch 83/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 0.8125\n",
      "Epoch 84/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.8281\n",
      "Epoch 85/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.8438\n",
      "Epoch 86/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.8125\n",
      "Epoch 87/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.8125\n",
      "Epoch 88/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8281\n",
      "Epoch 89/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8281\n",
      "Epoch 90/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8281\n",
      "Epoch 91/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.8125\n",
      "Epoch 92/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.7969\n",
      "Epoch 93/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8125\n",
      "Epoch 94/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.8125\n",
      "Epoch 95/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8125\n",
      "Epoch 96/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6787 - val_accuracy: 0.8125\n",
      "Epoch 97/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.8125\n",
      "Epoch 98/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.8125\n",
      "Epoch 99/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8125\n",
      "Epoch 100/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 0.8125\n",
      "accuracy for model 1 is 81.25\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 556 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "556/556 [==============================] - 19s 34ms/sample - loss: 1.0055 - accuracy: 0.5989 - val_loss: 0.8999 - val_accuracy: 0.7656\n",
      "Epoch 2/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.7362 - accuracy: 0.7896 - val_loss: 1.1907 - val_accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.6621 - accuracy: 0.8112 - val_loss: 1.5147 - val_accuracy: 0.2188\n",
      "Epoch 4/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.6526 - accuracy: 0.8112 - val_loss: 1.8253 - val_accuracy: 0.2188\n",
      "Epoch 5/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.5760 - accuracy: 0.8273 - val_loss: 2.0941 - val_accuracy: 0.2188\n",
      "Epoch 6/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.5138 - accuracy: 0.8399 - val_loss: 2.6635 - val_accuracy: 0.2188\n",
      "Epoch 7/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.4006 - accuracy: 0.8975 - val_loss: 3.0270 - val_accuracy: 0.2188\n",
      "Epoch 8/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.3004 - accuracy: 0.9281 - val_loss: 2.6426 - val_accuracy: 0.2188\n",
      "Epoch 9/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.2366 - accuracy: 0.9676 - val_loss: 2.6381 - val_accuracy: 0.2188\n",
      "Epoch 10/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.1732 - accuracy: 0.9856 - val_loss: 2.8360 - val_accuracy: 0.2188\n",
      "Epoch 11/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.1280 - accuracy: 0.9946 - val_loss: 2.4451 - val_accuracy: 0.2188\n",
      "Epoch 12/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0930 - accuracy: 0.9982 - val_loss: 1.7707 - val_accuracy: 0.2188\n",
      "Epoch 13/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0696 - accuracy: 0.9982 - val_loss: 1.6854 - val_accuracy: 0.2188\n",
      "Epoch 14/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0599 - accuracy: 0.9964 - val_loss: 1.0912 - val_accuracy: 0.5156\n",
      "Epoch 15/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0566 - accuracy: 0.9964 - val_loss: 0.7200 - val_accuracy: 0.8125\n",
      "Epoch 16/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0667 - accuracy: 0.9982 - val_loss: 1.3667 - val_accuracy: 0.3281\n",
      "Epoch 17/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.7656\n",
      "Epoch 18/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.7812\n",
      "Epoch 19/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.8125\n",
      "Epoch 21/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.5452 - val_accuracy: 0.8281\n",
      "Epoch 22/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.8438\n",
      "Epoch 23/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.8438\n",
      "Epoch 24/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.5597 - val_accuracy: 0.8438\n",
      "Epoch 25/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.5141 - val_accuracy: 0.8438\n",
      "Epoch 26/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8438\n",
      "Epoch 27/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.8438\n",
      "Epoch 28/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0245 - accuracy: 0.9964 - val_loss: 0.7084 - val_accuracy: 0.8125\n",
      "Epoch 29/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.8288 - val_accuracy: 0.8125\n",
      "Epoch 30/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 0.8281\n",
      "Epoch 31/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.8281\n",
      "Epoch 32/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.8438\n",
      "Epoch 33/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 0.8281\n",
      "Epoch 34/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 0.8438\n",
      "Epoch 35/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.8125\n",
      "Epoch 36/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0132 - accuracy: 0.9982 - val_loss: 0.8419 - val_accuracy: 0.6719\n",
      "Epoch 37/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0266 - accuracy: 0.9982 - val_loss: 1.5100 - val_accuracy: 0.7656\n",
      "Epoch 38/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0398 - accuracy: 0.9982 - val_loss: 1.0512 - val_accuracy: 0.7969\n",
      "Epoch 39/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8281\n",
      "Epoch 40/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5525 - val_accuracy: 0.8438\n",
      "Epoch 42/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.8281\n",
      "Epoch 43/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.8281\n",
      "Epoch 44/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5677 - val_accuracy: 0.8438\n",
      "Epoch 45/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.8281\n",
      "Epoch 46/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6041 - val_accuracy: 0.8281\n",
      "Epoch 47/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8281\n",
      "Epoch 48/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.9130 - val_accuracy: 0.7969\n",
      "Epoch 49/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8594\n",
      "Epoch 50/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6526 - val_accuracy: 0.8594\n",
      "Epoch 52/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.8281\n",
      "Epoch 53/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6151 - val_accuracy: 0.8594\n",
      "Epoch 54/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8281\n",
      "Epoch 55/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.8281\n",
      "Epoch 56/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8281\n",
      "Epoch 57/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8438\n",
      "Epoch 58/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.8125\n",
      "Epoch 59/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.8438\n",
      "Epoch 60/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.8594\n",
      "Epoch 61/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.8438\n",
      "Epoch 63/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8438\n",
      "Epoch 64/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8438\n",
      "Epoch 65/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.8438\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8438\n",
      "Epoch 67/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8281\n",
      "Epoch 68/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8438\n",
      "Epoch 69/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.8438\n",
      "Epoch 70/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.8438\n",
      "Epoch 71/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8438\n",
      "Epoch 72/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.8125\n",
      "Epoch 73/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.8438\n",
      "Epoch 74/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8125\n",
      "Epoch 75/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8438\n",
      "Epoch 76/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8438\n",
      "Epoch 77/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.8125\n",
      "Epoch 78/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8281\n",
      "Epoch 79/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.8438\n",
      "Epoch 80/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8750\n",
      "Epoch 81/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.8281\n",
      "Epoch 82/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8967 - val_accuracy: 0.8281\n",
      "Epoch 83/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.8281\n",
      "Epoch 84/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.8281\n",
      "Epoch 85/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.8281\n",
      "Epoch 86/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.8438\n",
      "Epoch 87/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8438\n",
      "Epoch 88/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.8594\n",
      "Epoch 89/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.8438\n",
      "Epoch 90/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.8281\n",
      "Epoch 91/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.8438\n",
      "Epoch 92/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7555 - val_accuracy: 0.8438\n",
      "Epoch 93/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.8438\n",
      "Epoch 94/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8371 - val_accuracy: 0.8438\n",
      "Epoch 95/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8344 - val_accuracy: 0.8438\n",
      "Epoch 96/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7366 - val_accuracy: 0.8281\n",
      "Epoch 97/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8438\n",
      "Epoch 98/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7664 - val_accuracy: 0.8438\n",
      "Epoch 99/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.8281\n",
      "Epoch 100/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8281\n",
      "accuracy for model 2 is 82.8125\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 556 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "556/556 [==============================] - 34s 61ms/sample - loss: 1.2961 - accuracy: 0.4838 - val_loss: 0.7594 - val_accuracy: 0.8906\n",
      "Epoch 2/100\n",
      "556/556 [==============================] - 5s 10ms/sample - loss: 0.9239 - accuracy: 0.7050 - val_loss: 1.0265 - val_accuracy: 0.4531\n",
      "Epoch 3/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.7651 - accuracy: 0.8112 - val_loss: 1.3110 - val_accuracy: 0.2188\n",
      "Epoch 4/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.7075 - accuracy: 0.8129 - val_loss: 1.5633 - val_accuracy: 0.2188\n",
      "Epoch 5/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.6774 - accuracy: 0.7986 - val_loss: 1.8107 - val_accuracy: 0.2188\n",
      "Epoch 6/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.6570 - accuracy: 0.8094 - val_loss: 2.0009 - val_accuracy: 0.2188\n",
      "Epoch 7/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.6453 - accuracy: 0.8112 - val_loss: 2.1592 - val_accuracy: 0.2188\n",
      "Epoch 8/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.6006 - accuracy: 0.8183 - val_loss: 2.3124 - val_accuracy: 0.2188\n",
      "Epoch 9/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.5834 - accuracy: 0.8237 - val_loss: 2.4646 - val_accuracy: 0.2188\n",
      "Epoch 10/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.5517 - accuracy: 0.8219 - val_loss: 2.6685 - val_accuracy: 0.2188\n",
      "Epoch 11/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.5130 - accuracy: 0.8417 - val_loss: 3.0661 - val_accuracy: 0.2188\n",
      "Epoch 12/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.4200 - accuracy: 0.8687 - val_loss: 3.7166 - val_accuracy: 0.2188\n",
      "Epoch 13/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.3311 - accuracy: 0.9245 - val_loss: 3.5910 - val_accuracy: 0.2188\n",
      "Epoch 14/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.2335 - accuracy: 0.9604 - val_loss: 3.2038 - val_accuracy: 0.2188\n",
      "Epoch 15/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.2000 - accuracy: 0.9838 - val_loss: 2.8462 - val_accuracy: 0.2188\n",
      "Epoch 16/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.1492 - accuracy: 0.9928 - val_loss: 2.8609 - val_accuracy: 0.2188\n",
      "Epoch 17/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0932 - accuracy: 0.9982 - val_loss: 2.4201 - val_accuracy: 0.2188\n",
      "Epoch 18/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0836 - accuracy: 0.9982 - val_loss: 2.5714 - val_accuracy: 0.2188\n",
      "Epoch 19/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0848 - accuracy: 0.9964 - val_loss: 2.4222 - val_accuracy: 0.2188\n",
      "Epoch 20/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0657 - accuracy: 1.0000 - val_loss: 1.5561 - val_accuracy: 0.2188\n",
      "Epoch 21/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0571 - accuracy: 0.9982 - val_loss: 0.9655 - val_accuracy: 0.5156\n",
      "Epoch 22/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0575 - accuracy: 0.9964 - val_loss: 1.7970 - val_accuracy: 0.2188\n",
      "Epoch 23/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.5469\n",
      "Epoch 24/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0388 - accuracy: 1.0000 - val_loss: 1.0094 - val_accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.7916 - val_accuracy: 0.7031\n",
      "Epoch 26/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.8281\n",
      "Epoch 27/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.7812\n",
      "Epoch 28/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.8125\n",
      "Epoch 29/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.8594\n",
      "Epoch 30/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0266 - accuracy: 0.9964 - val_loss: 0.5931 - val_accuracy: 0.8125\n",
      "Epoch 31/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.5214 - val_accuracy: 0.8438\n",
      "Epoch 32/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8594\n",
      "Epoch 34/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.8594\n",
      "Epoch 35/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.8125\n",
      "Epoch 36/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.8906\n",
      "Epoch 37/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.8906\n",
      "Epoch 38/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0207 - accuracy: 0.9982 - val_loss: 0.5085 - val_accuracy: 0.8906\n",
      "Epoch 39/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.8594\n",
      "Epoch 42/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.8594\n",
      "Epoch 43/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8438\n",
      "Epoch 45/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.8594\n",
      "Epoch 47/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.8438\n",
      "Epoch 50/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.8750\n",
      "Epoch 51/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.8594\n",
      "Epoch 53/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.8438\n",
      "Epoch 54/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5211 - val_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5292 - val_accuracy: 0.8750\n",
      "Epoch 57/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.8594\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.8750\n",
      "Epoch 61/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.8750\n",
      "Epoch 63/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5249 - val_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.8750\n",
      "Epoch 66/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8750\n",
      "Epoch 67/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.8750\n",
      "Epoch 68/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5525 - val_accuracy: 0.8750\n",
      "Epoch 69/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.8750\n",
      "Epoch 71/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.8594\n",
      "Epoch 72/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8750\n",
      "Epoch 73/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.8750\n",
      "Epoch 74/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.8750\n",
      "Epoch 75/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.8750\n",
      "Epoch 76/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5897 - val_accuracy: 0.8750\n",
      "Epoch 77/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.8750\n",
      "Epoch 78/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5441 - val_accuracy: 0.8750\n",
      "Epoch 79/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.8750\n",
      "Epoch 80/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.8750\n",
      "Epoch 81/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5602 - val_accuracy: 0.8594\n",
      "Epoch 82/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.8594\n",
      "Epoch 83/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.8594\n",
      "Epoch 84/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.8594\n",
      "Epoch 86/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5668 - val_accuracy: 0.8750\n",
      "Epoch 87/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8750\n",
      "Epoch 88/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.8906\n",
      "Epoch 89/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0609 - accuracy: 0.9964 - val_loss: 0.9366 - val_accuracy: 0.8906\n",
      "Epoch 90/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0308 - accuracy: 0.9982 - val_loss: 0.8984 - val_accuracy: 0.7031\n",
      "Epoch 91/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0532 - accuracy: 0.9946 - val_loss: 0.6436 - val_accuracy: 0.8750\n",
      "Epoch 92/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0178 - accuracy: 0.9982 - val_loss: 0.5490 - val_accuracy: 0.8750\n",
      "Epoch 93/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.8281\n",
      "Epoch 94/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.7345 - val_accuracy: 0.7656\n",
      "Epoch 95/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.6837 - val_accuracy: 0.8906\n",
      "Epoch 96/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.8906\n",
      "Epoch 97/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8906\n",
      "Epoch 98/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6554 - val_accuracy: 0.8906\n",
      "Epoch 99/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6575 - val_accuracy: 0.8906\n",
      "Epoch 100/100\n",
      "556/556 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6185 - val_accuracy: 0.8750\n",
      "accuracy for model 3 is 87.5\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 557 samples, validate on 63 samples\n",
      "Epoch 1/100\n",
      "557/557 [==============================] - 36s 64ms/sample - loss: 1.0321 - accuracy: 0.6661 - val_loss: 0.7649 - val_accuracy: 0.8254\n",
      "Epoch 2/100\n",
      "557/557 [==============================] - 6s 11ms/sample - loss: 0.8268 - accuracy: 0.7504 - val_loss: 0.9545 - val_accuracy: 0.7619\n",
      "Epoch 3/100\n",
      "557/557 [==============================] - 5s 10ms/sample - loss: 0.7400 - accuracy: 0.7917 - val_loss: 1.0832 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "557/557 [==============================] - 5s 10ms/sample - loss: 0.7035 - accuracy: 0.7846 - val_loss: 1.1873 - val_accuracy: 0.3810\n",
      "Epoch 5/100\n",
      "557/557 [==============================] - 5s 10ms/sample - loss: 0.6520 - accuracy: 0.7935 - val_loss: 1.3983 - val_accuracy: 0.2222\n",
      "Epoch 6/100\n",
      "557/557 [==============================] - 5s 10ms/sample - loss: 0.6398 - accuracy: 0.8043 - val_loss: 1.4378 - val_accuracy: 0.2222\n",
      "Epoch 7/100\n",
      "557/557 [==============================] - 5s 10ms/sample - loss: 0.5514 - accuracy: 0.8348 - val_loss: 1.7632 - val_accuracy: 0.2222\n",
      "Epoch 8/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.4904 - accuracy: 0.8402 - val_loss: 2.2814 - val_accuracy: 0.2222\n",
      "Epoch 9/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.3618 - accuracy: 0.8905 - val_loss: 2.6312 - val_accuracy: 0.2222\n",
      "Epoch 10/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.2468 - accuracy: 0.9515 - val_loss: 2.7881 - val_accuracy: 0.2222\n",
      "Epoch 11/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.1980 - accuracy: 0.9749 - val_loss: 2.2971 - val_accuracy: 0.2222\n",
      "Epoch 12/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.1305 - accuracy: 0.9964 - val_loss: 2.0970 - val_accuracy: 0.2222\n",
      "Epoch 13/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.1030 - accuracy: 0.9946 - val_loss: 1.4014 - val_accuracy: 0.2381\n",
      "Epoch 14/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0950 - accuracy: 1.0000 - val_loss: 1.2490 - val_accuracy: 0.2698\n",
      "Epoch 15/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0782 - accuracy: 0.9982 - val_loss: 2.0310 - val_accuracy: 0.2222\n",
      "Epoch 16/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0780 - accuracy: 0.9946 - val_loss: 1.2226 - val_accuracy: 0.3333\n",
      "Epoch 17/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0490 - accuracy: 0.9982 - val_loss: 1.0218 - val_accuracy: 0.5873\n",
      "Epoch 18/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.8774 - val_accuracy: 0.7302\n",
      "Epoch 20/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.7937\n",
      "Epoch 21/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.6423 - val_accuracy: 0.8254\n",
      "Epoch 22/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.7937\n",
      "Epoch 23/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0326 - accuracy: 0.9982 - val_loss: 1.1841 - val_accuracy: 0.5238\n",
      "Epoch 24/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0915 - accuracy: 0.9785 - val_loss: 0.5864 - val_accuracy: 0.8730\n",
      "Epoch 25/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0375 - accuracy: 0.9982 - val_loss: 0.6552 - val_accuracy: 0.7937\n",
      "Epoch 26/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0286 - accuracy: 0.9982 - val_loss: 0.4746 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0248 - accuracy: 0.9982 - val_loss: 0.4637 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.8413\n",
      "Epoch 29/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8413\n",
      "Epoch 30/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.8413\n",
      "Epoch 31/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.8413\n",
      "Epoch 32/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.8730\n",
      "Epoch 34/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.8413\n",
      "Epoch 35/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.8730\n",
      "Epoch 36/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8730\n",
      "Epoch 37/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.8730\n",
      "Epoch 38/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.8730\n",
      "Epoch 39/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.8730\n",
      "Epoch 45/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8730\n",
      "Epoch 46/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.8730\n",
      "Epoch 47/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.8730\n",
      "Epoch 48/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8730\n",
      "Epoch 49/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.8413\n",
      "Epoch 50/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0231 - accuracy: 0.9964 - val_loss: 0.6571 - val_accuracy: 0.8730\n",
      "Epoch 51/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.8730\n",
      "Epoch 52/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.8730\n",
      "Epoch 53/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.5889 - val_accuracy: 0.8730\n",
      "Epoch 54/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.8730\n",
      "Epoch 56/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.8730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.8730\n",
      "Epoch 58/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.8730\n",
      "Epoch 59/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.8730\n",
      "Epoch 60/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.8889\n",
      "Epoch 61/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.8730\n",
      "Epoch 62/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.8730\n",
      "Epoch 63/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.8730\n",
      "Epoch 64/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.8730\n",
      "Epoch 65/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.8730\n",
      "Epoch 66/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5709 - val_accuracy: 0.8730\n",
      "Epoch 67/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.8730\n",
      "Epoch 68/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.8730\n",
      "Epoch 69/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5725 - val_accuracy: 0.8730\n",
      "Epoch 70/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.8730\n",
      "Epoch 71/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.8730\n",
      "Epoch 72/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.8730\n",
      "Epoch 73/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8730\n",
      "Epoch 74/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5610 - val_accuracy: 0.8730\n",
      "Epoch 75/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.8730\n",
      "Epoch 76/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5563 - val_accuracy: 0.8730\n",
      "Epoch 77/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.8730\n",
      "Epoch 78/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.8730\n",
      "Epoch 79/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.8730\n",
      "Epoch 80/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5693 - val_accuracy: 0.8730\n",
      "Epoch 81/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.8730\n",
      "Epoch 82/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5563 - val_accuracy: 0.8730\n",
      "Epoch 83/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.8730\n",
      "Epoch 84/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5982 - val_accuracy: 0.8730\n",
      "Epoch 85/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.8730\n",
      "Epoch 86/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.8730\n",
      "Epoch 87/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.8730\n",
      "Epoch 89/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6256 - val_accuracy: 0.8730\n",
      "Epoch 90/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5986 - val_accuracy: 0.8730\n",
      "Epoch 91/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.8730\n",
      "Epoch 92/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.8730\n",
      "Epoch 93/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 0.8730\n",
      "Epoch 94/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.8730\n",
      "Epoch 95/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6168 - val_accuracy: 0.8730\n",
      "Epoch 96/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.8730\n",
      "Epoch 97/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5941 - val_accuracy: 0.8730\n",
      "Epoch 98/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.8730\n",
      "Epoch 99/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.8730\n",
      "Epoch 100/100\n",
      "557/557 [==============================] - 5s 9ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8730\n",
      "accuracy for model 4 is 87.30158805847168\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 558 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "558/558 [==============================] - 29s 52ms/sample - loss: 1.1258 - accuracy: 0.5573 - val_loss: 0.7322 - val_accuracy: 0.8548\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 6s 10ms/sample - loss: 0.9096 - accuracy: 0.7581 - val_loss: 1.1104 - val_accuracy: 0.4355\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.7866 - accuracy: 0.7975 - val_loss: 1.5152 - val_accuracy: 0.2258\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.7354 - accuracy: 0.7993 - val_loss: 1.8607 - val_accuracy: 0.2258\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.6685 - accuracy: 0.8082 - val_loss: 2.2328 - val_accuracy: 0.2258\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.6322 - accuracy: 0.8172 - val_loss: 2.6457 - val_accuracy: 0.2258\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.6291 - accuracy: 0.8280 - val_loss: 3.1230 - val_accuracy: 0.2258\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.5469 - accuracy: 0.8351 - val_loss: 4.0325 - val_accuracy: 0.2258\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.3980 - accuracy: 0.8889 - val_loss: 3.6386 - val_accuracy: 0.2258\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.2690 - accuracy: 0.9319 - val_loss: 3.4041 - val_accuracy: 0.2258\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.1940 - accuracy: 0.9731 - val_loss: 2.8958 - val_accuracy: 0.2258\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.1451 - accuracy: 0.9875 - val_loss: 2.7241 - val_accuracy: 0.2258\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.1057 - accuracy: 0.9982 - val_loss: 2.5280 - val_accuracy: 0.2258\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0851 - accuracy: 0.9982 - val_loss: 1.7053 - val_accuracy: 0.2258\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0936 - accuracy: 0.9964 - val_loss: 2.0255 - val_accuracy: 0.2258\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0654 - accuracy: 0.9982 - val_loss: 1.7804 - val_accuracy: 0.2258\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0610 - accuracy: 0.9982 - val_loss: 1.3042 - val_accuracy: 0.3548\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0543 - accuracy: 0.9982 - val_loss: 1.2631 - val_accuracy: 0.4355\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0468 - accuracy: 0.9982 - val_loss: 1.1734 - val_accuracy: 0.4839\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0552 - accuracy: 0.9964 - val_loss: 0.9501 - val_accuracy: 0.6452\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.6935\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.7724 - val_accuracy: 0.7419\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 0.7903\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0431 - accuracy: 0.9928 - val_loss: 0.8134 - val_accuracy: 0.7258\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.7742\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.7581\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 0.8065\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.6403 - val_accuracy: 0.8065\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.6001 - val_accuracy: 0.8387\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.7903\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.7903\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.7742\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.7742\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.8065\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.7742\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.7903\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.7903\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.7434 - val_accuracy: 0.7742\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8226\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.8226\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.7903\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7405 - val_accuracy: 0.8065\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.8065\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.7742\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.7772 - val_accuracy: 0.7742\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.7742\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.7903\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.7742\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8226\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8065\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.7903\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8226\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.7928 - val_accuracy: 0.7903\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.7903\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.7903\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8281 - val_accuracy: 0.7903\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7820 - val_accuracy: 0.7903\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8306 - val_accuracy: 0.7903\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8327 - val_accuracy: 0.7742\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7852 - val_accuracy: 0.8065\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.7903\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8240 - val_accuracy: 0.7742\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8326 - val_accuracy: 0.7903\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.7903\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8531 - val_accuracy: 0.7742\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.7742\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.7903\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.8065\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8318 - val_accuracy: 0.7903\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8193 - val_accuracy: 0.7903\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.8065\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.8065\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.8065\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8369 - val_accuracy: 0.7903\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8179 - val_accuracy: 0.7903\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.7903\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8280 - val_accuracy: 0.7903\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8437 - val_accuracy: 0.7903\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8512 - val_accuracy: 0.7903\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8469 - val_accuracy: 0.7903\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8423 - val_accuracy: 0.7903\n",
      "Epoch 83/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8520 - val_accuracy: 0.7903\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.7742\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8515 - val_accuracy: 0.7903\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8344 - val_accuracy: 0.7903\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8312 - val_accuracy: 0.7903\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.7903\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.8065\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0371 - accuracy: 0.9982 - val_loss: 1.1730 - val_accuracy: 0.6935\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0180 - accuracy: 0.9982 - val_loss: 0.7829 - val_accuracy: 0.8871\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0334 - accuracy: 0.9982 - val_loss: 1.0250 - val_accuracy: 0.7258\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8226\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8226\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8387\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.8065\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.7903\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.8065\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.8226\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.8387\n",
      "accuracy for model 5 is 83.87096524238586\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 558 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "558/558 [==============================] - 21s 37ms/sample - loss: 1.1548 - accuracy: 0.5573 - val_loss: 0.7932 - val_accuracy: 0.8548\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 5s 10ms/sample - loss: 0.8411 - accuracy: 0.7204 - val_loss: 1.1131 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.7836 - accuracy: 0.7401 - val_loss: 1.3718 - val_accuracy: 0.3387\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.6971 - accuracy: 0.7921 - val_loss: 1.5955 - val_accuracy: 0.2258\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.6448 - accuracy: 0.8029 - val_loss: 1.9038 - val_accuracy: 0.2258\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.5764 - accuracy: 0.8297 - val_loss: 2.6383 - val_accuracy: 0.2258\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.4683 - accuracy: 0.8781 - val_loss: 2.9126 - val_accuracy: 0.2258\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.2869 - accuracy: 0.9373 - val_loss: 2.6825 - val_accuracy: 0.2258\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.2364 - accuracy: 0.9659 - val_loss: 2.5810 - val_accuracy: 0.2258\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.1763 - accuracy: 0.9749 - val_loss: 2.6383 - val_accuracy: 0.2258\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.1386 - accuracy: 0.9928 - val_loss: 2.5955 - val_accuracy: 0.2258\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.1319 - accuracy: 0.9892 - val_loss: 2.1339 - val_accuracy: 0.2258\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0970 - accuracy: 0.9946 - val_loss: 2.3634 - val_accuracy: 0.2258\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.1327 - accuracy: 0.9875 - val_loss: 1.0907 - val_accuracy: 0.5161\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0755 - accuracy: 0.9982 - val_loss: 1.6621 - val_accuracy: 0.2419\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0633 - accuracy: 0.9982 - val_loss: 1.7862 - val_accuracy: 0.2258\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0536 - accuracy: 0.9964 - val_loss: 0.8024 - val_accuracy: 0.7419\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0538 - accuracy: 0.9982 - val_loss: 1.7676 - val_accuracy: 0.2419\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0429 - accuracy: 0.9982 - val_loss: 0.8798 - val_accuracy: 0.7097\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.3242 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.1039 - val_accuracy: 0.5968\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.5968\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.5968\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.8890 - val_accuracy: 0.6935\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.9302 - val_accuracy: 0.7097\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.6935\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.8783 - val_accuracy: 0.7258\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.0004 - val_accuracy: 0.6774\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.9727 - val_accuracy: 0.6774\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.8541 - val_accuracy: 0.7097\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.7258\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.7097\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.8890 - val_accuracy: 0.7097\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.8812 - val_accuracy: 0.7419\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8578 - val_accuracy: 0.7258\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.7258\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.9271 - val_accuracy: 0.7258\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.8677 - val_accuracy: 0.7258\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.8502 - val_accuracy: 0.7742\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.8819 - val_accuracy: 0.7258\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8401 - val_accuracy: 0.7419\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.9150 - val_accuracy: 0.7742\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0212 - accuracy: 0.9982 - val_loss: 1.8168 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0487 - accuracy: 0.9964 - val_loss: 1.5548 - val_accuracy: 0.8871\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0334 - accuracy: 0.9964 - val_loss: 0.7421 - val_accuracy: 0.7419\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0315 - accuracy: 0.9964 - val_loss: 0.8850 - val_accuracy: 0.6774\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0589 - accuracy: 0.9946 - val_loss: 0.6568 - val_accuracy: 0.8065\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0436 - accuracy: 0.9982 - val_loss: 0.7851 - val_accuracy: 0.8065\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.7903\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0146 - accuracy: 0.9982 - val_loss: 0.7982 - val_accuracy: 0.6935\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.6935\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.7903\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.7581\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.7903\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.7903\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.7903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7640 - val_accuracy: 0.7903\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.7903\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.7903\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8277 - val_accuracy: 0.7419\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.7742\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.7833 - val_accuracy: 0.7742\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.7742\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7928 - val_accuracy: 0.7742\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7903 - val_accuracy: 0.7742\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.7581\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.7581\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8740 - val_accuracy: 0.7581\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8426 - val_accuracy: 0.7581\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.7581\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8021 - val_accuracy: 0.7742\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8042 - val_accuracy: 0.7742\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8306 - val_accuracy: 0.7742\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8610 - val_accuracy: 0.7742\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.7742\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.7742\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.7742\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7856 - val_accuracy: 0.7903\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8266 - val_accuracy: 0.7742\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 0.7742\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8229 - val_accuracy: 0.7742\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8350 - val_accuracy: 0.7581\n",
      "Epoch 83/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8492 - val_accuracy: 0.7581\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8573 - val_accuracy: 0.7581\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9040 - val_accuracy: 0.7419\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9234 - val_accuracy: 0.7581\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.7581\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.7581\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.7581\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8540 - val_accuracy: 0.7903\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.7903\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8682 - val_accuracy: 0.7581\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8808 - val_accuracy: 0.7581\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8825 - val_accuracy: 0.7581\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.7581\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9048 - val_accuracy: 0.7581\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.7581\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.7581\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8982 - val_accuracy: 0.7581\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 5s 9ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9035 - val_accuracy: 0.7581\n",
      "accuracy for model 6 is 75.80645084381104\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 559 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "559/559 [==============================] - 19s 34ms/sample - loss: 1.5888 - accuracy: 0.4079 - val_loss: 1.0596 - val_accuracy: 0.6066\n",
      "Epoch 2/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 1.1230 - accuracy: 0.5385 - val_loss: 1.2923 - val_accuracy: 0.3607\n",
      "Epoch 3/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.9457 - accuracy: 0.7245 - val_loss: 1.4632 - val_accuracy: 0.2295\n",
      "Epoch 4/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.8405 - accuracy: 0.7370 - val_loss: 1.6329 - val_accuracy: 0.2295\n",
      "Epoch 5/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.7430 - accuracy: 0.7835 - val_loss: 1.8453 - val_accuracy: 0.2295\n",
      "Epoch 6/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.6533 - accuracy: 0.8068 - val_loss: 2.1215 - val_accuracy: 0.2295\n",
      "Epoch 7/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.5890 - accuracy: 0.8354 - val_loss: 2.4870 - val_accuracy: 0.2295\n",
      "Epoch 8/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.4722 - accuracy: 0.8694 - val_loss: 2.9456 - val_accuracy: 0.2295\n",
      "Epoch 9/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.3444 - accuracy: 0.9195 - val_loss: 2.8074 - val_accuracy: 0.2295\n",
      "Epoch 10/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.2816 - accuracy: 0.9517 - val_loss: 2.4203 - val_accuracy: 0.2295\n",
      "Epoch 11/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.2312 - accuracy: 0.9678 - val_loss: 2.4775 - val_accuracy: 0.2295\n",
      "Epoch 12/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.1638 - accuracy: 0.9946 - val_loss: 2.3816 - val_accuracy: 0.2295\n",
      "Epoch 13/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.1190 - accuracy: 0.9982 - val_loss: 2.1481 - val_accuracy: 0.2295\n",
      "Epoch 14/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0960 - accuracy: 0.9982 - val_loss: 1.8785 - val_accuracy: 0.2295\n",
      "Epoch 15/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.1007 - accuracy: 1.0000 - val_loss: 1.8267 - val_accuracy: 0.2295\n",
      "Epoch 16/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0678 - accuracy: 1.0000 - val_loss: 1.7038 - val_accuracy: 0.2295\n",
      "Epoch 17/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0620 - accuracy: 1.0000 - val_loss: 1.2752 - val_accuracy: 0.2951\n",
      "Epoch 18/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0492 - accuracy: 1.0000 - val_loss: 1.2758 - val_accuracy: 0.3115\n",
      "Epoch 19/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0467 - accuracy: 1.0000 - val_loss: 1.0425 - val_accuracy: 0.4590\n",
      "Epoch 20/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.9268 - val_accuracy: 0.6066\n",
      "Epoch 21/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.8570 - val_accuracy: 0.6721\n",
      "Epoch 22/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8033\n",
      "Epoch 23/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.8487 - val_accuracy: 0.7213\n",
      "Epoch 24/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.7705\n",
      "Epoch 25/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8197\n",
      "Epoch 26/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.5157 - val_accuracy: 0.8689\n",
      "Epoch 27/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.8361\n",
      "Epoch 28/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.5405 - val_accuracy: 0.8361\n",
      "Epoch 29/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.8197\n",
      "Epoch 30/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.8197\n",
      "Epoch 31/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.8525\n",
      "Epoch 33/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.8525\n",
      "Epoch 34/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8525\n",
      "Epoch 35/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.8361\n",
      "Epoch 36/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.8361\n",
      "Epoch 37/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8361\n",
      "Epoch 38/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.8361\n",
      "Epoch 39/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8361\n",
      "Epoch 40/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.8361\n",
      "Epoch 41/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.8525\n",
      "Epoch 42/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.8525\n",
      "Epoch 43/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.8525\n",
      "Epoch 44/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.8361\n",
      "Epoch 45/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.8525\n",
      "Epoch 46/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8525\n",
      "Epoch 47/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.8525\n",
      "Epoch 48/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.8525\n",
      "Epoch 49/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.8525\n",
      "Epoch 50/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.8525\n",
      "Epoch 51/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8197\n",
      "Epoch 52/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.8361\n",
      "Epoch 53/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.8361\n",
      "Epoch 54/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8689\n",
      "Epoch 55/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.8525\n",
      "Epoch 58/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.8689\n",
      "Epoch 59/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.5209 - val_accuracy: 0.8525\n",
      "Epoch 60/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0373 - accuracy: 0.9928 - val_loss: 1.0861 - val_accuracy: 0.8689\n",
      "Epoch 61/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0240 - accuracy: 0.9982 - val_loss: 0.7359 - val_accuracy: 0.8689\n",
      "Epoch 62/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0463 - accuracy: 0.9893 - val_loss: 0.7594 - val_accuracy: 0.8033\n",
      "Epoch 63/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0463 - accuracy: 0.9964 - val_loss: 0.7057 - val_accuracy: 0.8525\n",
      "Epoch 64/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0472 - accuracy: 0.9911 - val_loss: 0.6114 - val_accuracy: 0.8525\n",
      "Epoch 65/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 0.8689\n",
      "Epoch 66/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.8361\n",
      "Epoch 67/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.8361\n",
      "Epoch 68/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.8361\n",
      "Epoch 69/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0151 - accuracy: 0.9982 - val_loss: 0.5811 - val_accuracy: 0.8689\n",
      "Epoch 70/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.8525\n",
      "Epoch 71/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.8525\n",
      "Epoch 72/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5454 - val_accuracy: 0.8033\n",
      "Epoch 73/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5533 - val_accuracy: 0.8197\n",
      "Epoch 74/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.8197\n",
      "Epoch 75/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.8197\n",
      "Epoch 76/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8197\n",
      "Epoch 77/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.8197\n",
      "Epoch 78/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.8197\n",
      "Epoch 79/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.8197\n",
      "Epoch 80/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.8197\n",
      "Epoch 81/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5211 - val_accuracy: 0.8197\n",
      "Epoch 82/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8361\n",
      "Epoch 83/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 0.8361\n",
      "Epoch 84/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.8361\n",
      "Epoch 85/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5242 - val_accuracy: 0.8361\n",
      "Epoch 86/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.8361\n",
      "Epoch 87/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5385 - val_accuracy: 0.8361\n",
      "Epoch 88/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.8361\n",
      "Epoch 89/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.8525\n",
      "Epoch 90/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8361\n",
      "Epoch 91/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8361\n",
      "Epoch 92/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.8361\n",
      "Epoch 93/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.8525\n",
      "Epoch 94/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.8361\n",
      "Epoch 95/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.8361\n",
      "Epoch 96/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8361\n",
      "Epoch 97/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5554 - val_accuracy: 0.8525\n",
      "Epoch 98/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8525\n",
      "Epoch 99/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5526 - val_accuracy: 0.8525\n",
      "Epoch 100/100\n",
      "559/559 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.8525\n",
      "accuracy for model 7 is 85.24590134620667\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "560/560 [==============================] - 21s 38ms/sample - loss: 0.9908 - accuracy: 0.6750 - val_loss: 0.9828 - val_accuracy: 0.7167\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.7879 - accuracy: 0.7964 - val_loss: 1.2053 - val_accuracy: 0.6500\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.7184 - accuracy: 0.8107 - val_loss: 1.4286 - val_accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.7128 - accuracy: 0.7982 - val_loss: 1.6280 - val_accuracy: 0.2167\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6362 - accuracy: 0.8214 - val_loss: 1.7866 - val_accuracy: 0.2167\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6317 - accuracy: 0.8089 - val_loss: 1.9199 - val_accuracy: 0.2167\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6037 - accuracy: 0.8196 - val_loss: 2.0519 - val_accuracy: 0.2167\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6320 - accuracy: 0.8107 - val_loss: 2.2504 - val_accuracy: 0.2167\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.5706 - accuracy: 0.8250 - val_loss: 2.6449 - val_accuracy: 0.2167\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.5233 - accuracy: 0.8500 - val_loss: 3.8018 - val_accuracy: 0.2167\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.4239 - accuracy: 0.8750 - val_loss: 3.2578 - val_accuracy: 0.2167\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.2980 - accuracy: 0.9286 - val_loss: 3.0933 - val_accuracy: 0.2167\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.1888 - accuracy: 0.9786 - val_loss: 3.0365 - val_accuracy: 0.2167\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.1642 - accuracy: 0.9839 - val_loss: 3.2953 - val_accuracy: 0.2167\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.1072 - accuracy: 0.9929 - val_loss: 2.8968 - val_accuracy: 0.2167\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0891 - accuracy: 0.9964 - val_loss: 2.7149 - val_accuracy: 0.2167\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0841 - accuracy: 0.9946 - val_loss: 2.1193 - val_accuracy: 0.2167\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0711 - accuracy: 0.9982 - val_loss: 2.1294 - val_accuracy: 0.2167\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0512 - accuracy: 1.0000 - val_loss: 1.9119 - val_accuracy: 0.2167\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0446 - accuracy: 0.9982 - val_loss: 2.1968 - val_accuracy: 0.2167\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0730 - accuracy: 0.9929 - val_loss: 1.2319 - val_accuracy: 0.4167\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.7833\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0359 - accuracy: 0.9982 - val_loss: 1.0950 - val_accuracy: 0.4667\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0396 - accuracy: 0.9982 - val_loss: 0.8941 - val_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.7457 - val_accuracy: 0.7167\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.7864 - val_accuracy: 0.7000\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0356 - accuracy: 0.9946 - val_loss: 0.7720 - val_accuracy: 0.7333\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0338 - accuracy: 0.9982 - val_loss: 0.5609 - val_accuracy: 0.7667\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0413 - accuracy: 0.9964 - val_loss: 0.8323 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0312 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.5833\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.5800 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.7000\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.7333\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.7167\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.6230 - val_accuracy: 0.7167\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.6833\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.6351 - val_accuracy: 0.7000\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.7333\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.7000\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6113 - val_accuracy: 0.7667\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.7333\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.7167\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.7000\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.7167\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6768 - val_accuracy: 0.7000\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.7000\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.7167\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.7167\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.7167\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.7167\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.7167\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.7000\n",
      "Epoch 56/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.7000\n",
      "Epoch 58/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.7167\n",
      "Epoch 59/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7389 - val_accuracy: 0.7000\n",
      "Epoch 60/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.6833\n",
      "Epoch 61/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.7000\n",
      "Epoch 62/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.6833\n",
      "Epoch 63/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.6833\n",
      "Epoch 64/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7387 - val_accuracy: 0.7000\n",
      "Epoch 65/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.7000\n",
      "Epoch 66/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.7000\n",
      "Epoch 67/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7394 - val_accuracy: 0.7000\n",
      "Epoch 68/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7366 - val_accuracy: 0.6833\n",
      "Epoch 69/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.6833\n",
      "Epoch 70/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.6833\n",
      "Epoch 71/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7629 - val_accuracy: 0.7000\n",
      "Epoch 72/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.7000\n",
      "Epoch 73/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.7000\n",
      "Epoch 74/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.7000\n",
      "Epoch 75/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7649 - val_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7776 - val_accuracy: 0.7000\n",
      "Epoch 77/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7744 - val_accuracy: 0.7167\n",
      "Epoch 78/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0186 - accuracy: 0.9964 - val_loss: 0.8393 - val_accuracy: 0.7833\n",
      "Epoch 79/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0380 - accuracy: 0.9929 - val_loss: 1.4224 - val_accuracy: 0.7167\n",
      "Epoch 80/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0194 - accuracy: 0.9982 - val_loss: 2.1188 - val_accuracy: 0.7000\n",
      "Epoch 81/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0612 - accuracy: 0.9893 - val_loss: 2.0633 - val_accuracy: 0.6333\n",
      "Epoch 82/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0326 - accuracy: 0.9964 - val_loss: 1.7959 - val_accuracy: 0.6167\n",
      "Epoch 83/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.0747 - val_accuracy: 0.6167\n",
      "Epoch 84/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.7685 - val_accuracy: 0.7167\n",
      "Epoch 85/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.8139 - val_accuracy: 0.7667\n",
      "Epoch 86/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.7132 - val_accuracy: 0.7167\n",
      "Epoch 87/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.7667\n",
      "Epoch 88/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.7667\n",
      "Epoch 89/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.7757 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0246 - accuracy: 0.9982 - val_loss: 1.2029 - val_accuracy: 0.7167\n",
      "Epoch 91/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0364 - accuracy: 0.9875 - val_loss: 0.8983 - val_accuracy: 0.7667\n",
      "Epoch 92/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0297 - accuracy: 0.9946 - val_loss: 0.7889 - val_accuracy: 0.7667\n",
      "Epoch 93/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.7667\n",
      "Epoch 95/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.7833\n",
      "Epoch 97/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.8000\n",
      "Epoch 98/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.7833\n",
      "Epoch 99/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.7500\n",
      "accuracy for model 8 is 75.0\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "560/560 [==============================] - 17s 30ms/sample - loss: 1.1044 - accuracy: 0.5268 - val_loss: 1.0136 - val_accuracy: 0.6833\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.8351 - accuracy: 0.7161 - val_loss: 1.2644 - val_accuracy: 0.2833\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6654 - accuracy: 0.8036 - val_loss: 1.8005 - val_accuracy: 0.2167\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6755 - accuracy: 0.8018 - val_loss: 2.2116 - val_accuracy: 0.2167\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6852 - accuracy: 0.7911 - val_loss: 2.5283 - val_accuracy: 0.2167\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6088 - accuracy: 0.8196 - val_loss: 2.7382 - val_accuracy: 0.2167\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.5928 - accuracy: 0.8143 - val_loss: 2.9122 - val_accuracy: 0.2167\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6339 - accuracy: 0.8107 - val_loss: 3.0884 - val_accuracy: 0.2167\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6195 - accuracy: 0.8161 - val_loss: 3.2401 - val_accuracy: 0.2167\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.5307 - accuracy: 0.8429 - val_loss: 3.4622 - val_accuracy: 0.2167\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.5255 - accuracy: 0.8464 - val_loss: 3.8690 - val_accuracy: 0.2167\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.3872 - accuracy: 0.8946 - val_loss: 4.0092 - val_accuracy: 0.2167\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.2563 - accuracy: 0.9589 - val_loss: 3.8404 - val_accuracy: 0.2167\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.1785 - accuracy: 0.9786 - val_loss: 3.8058 - val_accuracy: 0.2167\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.1486 - accuracy: 0.9804 - val_loss: 3.4604 - val_accuracy: 0.2167\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.1046 - accuracy: 0.9964 - val_loss: 2.9628 - val_accuracy: 0.2167\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0860 - accuracy: 1.0000 - val_loss: 2.9826 - val_accuracy: 0.2167\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0699 - accuracy: 0.9982 - val_loss: 2.6098 - val_accuracy: 0.2167\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0681 - accuracy: 0.9982 - val_loss: 2.5510 - val_accuracy: 0.2167\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0555 - accuracy: 0.9982 - val_loss: 1.9965 - val_accuracy: 0.2167\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0471 - accuracy: 0.9982 - val_loss: 2.0082 - val_accuracy: 0.2167\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0480 - accuracy: 1.0000 - val_loss: 1.6561 - val_accuracy: 0.2333\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0537 - accuracy: 0.9964 - val_loss: 1.1277 - val_accuracy: 0.5500\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.5170 - val_accuracy: 0.2500\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.1648 - val_accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.7667\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.2121 - val_accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.0347 - val_accuracy: 0.6833\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.9202 - val_accuracy: 0.6833\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.9502 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.9020 - val_accuracy: 0.6833\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.6833\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.8687 - val_accuracy: 0.7000\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8277 - val_accuracy: 0.7167\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.7579 - val_accuracy: 0.7000\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.6833\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.7333\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.8300 - val_accuracy: 0.7000\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.8153 - val_accuracy: 0.6833\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.7167\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.8496 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8258 - val_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.6833\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.8751 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.6833\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9051 - val_accuracy: 0.6500\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.7167\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.7167\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8995 - val_accuracy: 0.6833\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.6833\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.7333\n",
      "Epoch 56/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8318 - val_accuracy: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.7333\n",
      "Epoch 58/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.8334 - val_accuracy: 0.7667\n",
      "Epoch 60/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8174 - val_accuracy: 0.7333\n",
      "Epoch 61/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8347 - val_accuracy: 0.7333\n",
      "Epoch 62/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.7167\n",
      "Epoch 63/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8162 - val_accuracy: 0.7333\n",
      "Epoch 64/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8515 - val_accuracy: 0.7000\n",
      "Epoch 65/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8524 - val_accuracy: 0.7000\n",
      "Epoch 66/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8328 - val_accuracy: 0.7333\n",
      "Epoch 67/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8251 - val_accuracy: 0.7667\n",
      "Epoch 68/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8284 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8532 - val_accuracy: 0.7333\n",
      "Epoch 70/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.7000\n",
      "Epoch 71/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8492 - val_accuracy: 0.7167\n",
      "Epoch 72/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8924 - val_accuracy: 0.7667\n",
      "Epoch 73/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8667 - val_accuracy: 0.7667\n",
      "Epoch 74/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8767 - val_accuracy: 0.7667\n",
      "Epoch 76/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.7667\n",
      "Epoch 77/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8529 - val_accuracy: 0.7667\n",
      "Epoch 78/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8706 - val_accuracy: 0.7667\n",
      "Epoch 80/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8723 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.7333\n",
      "Epoch 84/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8659 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8764 - val_accuracy: 0.7333\n",
      "Epoch 86/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8919 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8792 - val_accuracy: 0.7667\n",
      "Epoch 88/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.7667\n",
      "Epoch 89/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8902 - val_accuracy: 0.7333\n",
      "Epoch 90/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.7667\n",
      "Epoch 91/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9064 - val_accuracy: 0.7167\n",
      "Epoch 93/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.7333\n",
      "Epoch 94/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.7333\n",
      "Epoch 96/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.7667\n",
      "Epoch 97/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9071 - val_accuracy: 0.7667\n",
      "Epoch 98/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9227 - val_accuracy: 0.7333\n",
      "Epoch 99/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9186 - val_accuracy: 0.7667\n",
      "Epoch 100/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.7167\n",
      "accuracy for model 9 is 71.66666388511658\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]]\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 621598, 10)        110       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 621598, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 621591, 8)         648       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 621591, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 621586, 6)         294       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 621586, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 310793, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 310793, 6)         24        \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1864758)           0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 24)                44754216  \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 44,755,896\n",
      "Trainable params: 44,755,868\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "560/560 [==============================] - 18s 33ms/sample - loss: 1.0463 - accuracy: 0.6768 - val_loss: 1.1452 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.8540 - accuracy: 0.7982 - val_loss: 1.3006 - val_accuracy: 0.4167\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.7572 - accuracy: 0.7946 - val_loss: 1.4998 - val_accuracy: 0.2167\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6846 - accuracy: 0.8036 - val_loss: 1.7194 - val_accuracy: 0.2167\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6532 - accuracy: 0.7946 - val_loss: 1.9599 - val_accuracy: 0.2167\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.6394 - accuracy: 0.8036 - val_loss: 2.2179 - val_accuracy: 0.2167\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.5737 - accuracy: 0.8214 - val_loss: 2.5514 - val_accuracy: 0.2167\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.5044 - accuracy: 0.8518 - val_loss: 2.9751 - val_accuracy: 0.2167\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.4047 - accuracy: 0.8768 - val_loss: 3.2944 - val_accuracy: 0.2167\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.3278 - accuracy: 0.8929 - val_loss: 3.0095 - val_accuracy: 0.2167\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.2657 - accuracy: 0.9304 - val_loss: 3.0203 - val_accuracy: 0.2167\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.1816 - accuracy: 0.9786 - val_loss: 2.8155 - val_accuracy: 0.2167\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.1258 - accuracy: 0.9982 - val_loss: 2.6239 - val_accuracy: 0.2167\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0995 - accuracy: 0.9982 - val_loss: 2.4864 - val_accuracy: 0.2167\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0853 - accuracy: 1.0000 - val_loss: 2.1621 - val_accuracy: 0.2167\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0582 - accuracy: 1.0000 - val_loss: 1.9726 - val_accuracy: 0.2167\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0536 - accuracy: 0.9982 - val_loss: 1.7069 - val_accuracy: 0.2167\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0429 - accuracy: 1.0000 - val_loss: 1.3534 - val_accuracy: 0.2500\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0460 - accuracy: 0.9982 - val_loss: 1.1990 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0350 - accuracy: 0.9982 - val_loss: 1.1307 - val_accuracy: 0.5667\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.1480 - val_accuracy: 0.5167\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.5833\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.6833\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.8352 - val_accuracy: 0.7333\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7167\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.7708 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.7667\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8167\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8167\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8167\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8167\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8167\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.7833\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7667\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.8167\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7333\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.7793 - val_accuracy: 0.7833\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7833\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8357 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.7667\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.7833\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8140 - val_accuracy: 0.7667\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 0.7667\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.7833\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.7667\n",
      "Epoch 56/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8495 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.8000\n",
      "Epoch 58/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.8000\n",
      "Epoch 59/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.8167\n",
      "Epoch 60/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8349 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.7833\n",
      "Epoch 62/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8380 - val_accuracy: 0.7667\n",
      "Epoch 63/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.7833\n",
      "Epoch 64/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.7667\n",
      "Epoch 65/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.8167\n",
      "Epoch 67/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.8000\n",
      "Epoch 69/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8282 - val_accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8239 - val_accuracy: 0.7833\n",
      "Epoch 71/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8221 - val_accuracy: 0.7833\n",
      "Epoch 73/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7932 - val_accuracy: 0.8167\n",
      "Epoch 74/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0040 - val_accuracy: 0.8000\n",
      "Epoch 75/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8860 - val_accuracy: 0.7833\n",
      "Epoch 77/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.7833\n",
      "Epoch 78/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8608 - val_accuracy: 0.7667\n",
      "Epoch 80/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8540 - val_accuracy: 0.8167\n",
      "Epoch 81/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0239 - val_accuracy: 0.7667\n",
      "Epoch 82/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9280 - val_accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.8000\n",
      "Epoch 84/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8433 - val_accuracy: 0.7833\n",
      "Epoch 85/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.7833\n",
      "Epoch 86/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8869 - val_accuracy: 0.7667\n",
      "Epoch 87/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.7667\n",
      "Epoch 88/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.7667\n",
      "Epoch 89/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9763 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8714 - val_accuracy: 0.8000\n",
      "Epoch 92/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.7833\n",
      "Epoch 93/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9511 - val_accuracy: 0.7667\n",
      "Epoch 94/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0088 - val_accuracy: 0.7667\n",
      "Epoch 95/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8864 - val_accuracy: 0.8167\n",
      "Epoch 96/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.8167\n",
      "Epoch 97/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9093 - val_accuracy: 0.8167\n",
      "Epoch 98/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9028 - val_accuracy: 0.8167\n",
      "Epoch 99/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.8167\n",
      "Epoch 100/100\n",
      "560/560 [==============================] - 5s 9ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.8000\n",
      "accuracy for model 10 is 80.0000011920929\n",
      "Training Testing Accuracy: 81.05% (5.12%)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3352e8dd9ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt_vcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt_pheno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SCC_CNN_model.pickle.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "best_CNN = eval_cnn(tt_vcf, tt_pheno, 10, mlb)\n",
    "import pickle\n",
    "pickle.dump(best_CNN, open(\"SCC_CNN_model.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout accuracy is 84.51613187789917\n"
     ]
    }
   ],
   "source": [
    "bs = ((ho_vcf.shape[0])/40)\n",
    "bs = round(bs)\n",
    "ho_vcf = ho_vcf.reshape(ho_vcf.shape[0], ho_vcf.shape[1],1)\n",
    "ho_pheno = mlb.transform(ho_pheno)\n",
    "_, accuracy = best_CNN.evaluate(ho_vcf, ho_pheno, batch_size=bs, verbose=0)\n",
    "print(\"Holdout accuracy is \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf = vcf.reshape(vcf.shape[0], vcf.shape[1], 1)\n",
    "pheno = pheno.reshape(pheno.shape[0], pheno.shape[1])\n",
    "estimator = KerasClassifier(build_fn=CNN_model, epochs=10, batch_size=32, verbose=1)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, vcf, pheno, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN (based off yield prediction paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "(620,)\n",
      "(620, 1)\n",
      "220000\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "(155,)\n",
      "(155, 1)\n",
      "220000\n",
      "(620, 214310)\n",
      "(155, 214310)\n"
     ]
    }
   ],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data(\"SCC_Merged_filtered.csv_train_test.csv_5pcnt.csv\", \"SCC_Merged_filtered.csv_holdout.csv_5pcnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 621607)\n",
      "(155, 214310)\n",
      "(155, 621607)\n"
     ]
    }
   ],
   "source": [
    "ohe = pickle.load(open(\"SCC_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##how to mlb both tt and ho for same scheme? do i even need to?\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb = mlb.fit(tt_pheno)\n",
    "##print(tt_pheno.shape)\n",
    "#print(ho_pheno.shape)\n",
    "#tt_pheno = mlb.transform(tt_pheno)\n",
    "#print(tt_pheno.shape)\n",
    "#ho_pheno = mlb.transform(ho_pheno)\n",
    "#print(ho_pheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My own DNN model based upon paper\n",
    "#del model #incase its stored a previous model\n",
    "#del history #for redoing shit\n",
    "\n",
    "#do batch size as 64\n",
    "#reduce the inputs by half when you read it in\n",
    "#add XGboost and RF to the one notebook\n",
    "def build_DNN_model(x_len):\n",
    "    model = Sequential()\n",
    "\n",
    "    #add first input layer, with no normalization\n",
    "    model.add(Dense(192, input_dim = x_len))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.03))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.02))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    #add output layer\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dnn(x,y,k,mlb):\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=False)\n",
    "    best_model = []\n",
    "    results = []\n",
    "    highest = 0\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        print(y.shape)\n",
    "        print(y[train])\n",
    "        if(i==1):\n",
    "            y = mlb.transform(y)\n",
    "            print(y.shape)\n",
    "            print(y[train])\n",
    "        model = build_DNN_model(x[train].shape[1])\n",
    "        bs = ((x[train].shape[0])/20)\n",
    "        bs = round(bs)\n",
    "        history = model.fit(x[train], y[train], validation_data=(x[test], y[test]), epochs=100, batch_size=bs)\n",
    "        _, accuracy = model.evaluate(x[test], y[test], batch_size=bs, verbose=0)\n",
    "        accuracy = accuracy *100\n",
    "        print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "        if(accuracy > highest):\n",
    "            highest = accuracy\n",
    "            best_model = model\n",
    "        results.append(accuracy)\n",
    "        del model\n",
    "        i = i + 1\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results))) \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]]\n",
      "(620, 4)\n",
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 556 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "556/556 [==============================] - 23s 40ms/sample - loss: 1.0833 - accuracy: 0.5863 - val_loss: 8.4311 - val_accuracy: 0.6562\n",
      "Epoch 2/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.8124 - accuracy: 0.7644 - val_loss: 5.0731 - val_accuracy: 0.6719\n",
      "Epoch 3/100\n",
      "556/556 [==============================] - 2s 4ms/sample - loss: 0.6316 - accuracy: 0.8076 - val_loss: 1.5323 - val_accuracy: 0.7656\n",
      "Epoch 4/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.6002 - accuracy: 0.8237 - val_loss: 2.1853 - val_accuracy: 0.7031\n",
      "Epoch 5/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.5044 - accuracy: 0.8345 - val_loss: 0.8450 - val_accuracy: 0.7656\n",
      "Epoch 6/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.4455 - accuracy: 0.8561 - val_loss: 0.6157 - val_accuracy: 0.8438\n",
      "Epoch 7/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3934 - accuracy: 0.8723 - val_loss: 0.8214 - val_accuracy: 0.7969\n",
      "Epoch 8/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3714 - accuracy: 0.8723 - val_loss: 1.0516 - val_accuracy: 0.6562\n",
      "Epoch 9/100\n",
      "556/556 [==============================] - 2s 4ms/sample - loss: 0.3377 - accuracy: 0.8741 - val_loss: 0.7736 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "556/556 [==============================] - 2s 4ms/sample - loss: 0.3383 - accuracy: 0.8759 - val_loss: 1.2401 - val_accuracy: 0.5781\n",
      "Epoch 11/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2740 - accuracy: 0.8957 - val_loss: 0.5928 - val_accuracy: 0.8594\n",
      "Epoch 12/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2416 - accuracy: 0.9155 - val_loss: 0.6992 - val_accuracy: 0.7656\n",
      "Epoch 13/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2407 - accuracy: 0.9173 - val_loss: 0.6826 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "556/556 [==============================] - 2s 4ms/sample - loss: 0.1970 - accuracy: 0.9442 - val_loss: 0.9524 - val_accuracy: 0.7969\n",
      "Epoch 15/100\n",
      "556/556 [==============================] - 2s 4ms/sample - loss: 0.2327 - accuracy: 0.9173 - val_loss: 0.8642 - val_accuracy: 0.7969\n",
      "Epoch 16/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2077 - accuracy: 0.9317 - val_loss: 0.9054 - val_accuracy: 0.7969\n",
      "Epoch 17/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2034 - accuracy: 0.9353 - val_loss: 0.6437 - val_accuracy: 0.7969\n",
      "Epoch 18/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1542 - accuracy: 0.9550 - val_loss: 0.6514 - val_accuracy: 0.8281\n",
      "Epoch 19/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1352 - accuracy: 0.9532 - val_loss: 0.6423 - val_accuracy: 0.7969\n",
      "Epoch 20/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1294 - accuracy: 0.9604 - val_loss: 0.6650 - val_accuracy: 0.7969\n",
      "Epoch 21/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1171 - accuracy: 0.9640 - val_loss: 0.8657 - val_accuracy: 0.7969\n",
      "Epoch 22/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1326 - accuracy: 0.9586 - val_loss: 0.9510 - val_accuracy: 0.8125\n",
      "Epoch 23/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0961 - accuracy: 0.9838 - val_loss: 0.7099 - val_accuracy: 0.8125\n",
      "Epoch 24/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0892 - accuracy: 0.9802 - val_loss: 0.9268 - val_accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0834 - accuracy: 0.9766 - val_loss: 0.8109 - val_accuracy: 0.6562\n",
      "Epoch 26/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0823 - accuracy: 0.9784 - val_loss: 0.8009 - val_accuracy: 0.8281\n",
      "Epoch 27/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0765 - accuracy: 0.9748 - val_loss: 0.8842 - val_accuracy: 0.7969\n",
      "Epoch 28/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0517 - accuracy: 0.9892 - val_loss: 0.7418 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0501 - accuracy: 0.9910 - val_loss: 0.8204 - val_accuracy: 0.6875\n",
      "Epoch 30/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0405 - accuracy: 0.9892 - val_loss: 0.7118 - val_accuracy: 0.7344\n",
      "Epoch 31/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0611 - accuracy: 0.9838 - val_loss: 1.1826 - val_accuracy: 0.4219\n",
      "Epoch 32/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0487 - accuracy: 0.9820 - val_loss: 0.7412 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.9061 - val_accuracy: 0.6719\n",
      "Epoch 34/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.8055 - val_accuracy: 0.7656\n",
      "Epoch 35/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0241 - accuracy: 0.9964 - val_loss: 0.9315 - val_accuracy: 0.6719\n",
      "Epoch 36/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0314 - accuracy: 0.9928 - val_loss: 0.8055 - val_accuracy: 0.7344\n",
      "Epoch 37/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0250 - accuracy: 0.9946 - val_loss: 1.0008 - val_accuracy: 0.6562\n",
      "Epoch 38/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0621 - accuracy: 0.9856 - val_loss: 0.8333 - val_accuracy: 0.7969\n",
      "Epoch 39/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0423 - accuracy: 0.9874 - val_loss: 0.8081 - val_accuracy: 0.7656\n",
      "Epoch 40/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0296 - accuracy: 0.9946 - val_loss: 0.7609 - val_accuracy: 0.8281\n",
      "Epoch 41/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.8146 - val_accuracy: 0.8281\n",
      "Epoch 42/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0248 - accuracy: 0.9910 - val_loss: 0.8174 - val_accuracy: 0.8125\n",
      "Epoch 43/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0120 - accuracy: 0.9964 - val_loss: 1.2327 - val_accuracy: 0.7188\n",
      "Epoch 44/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0194 - accuracy: 0.9946 - val_loss: 0.9515 - val_accuracy: 0.7188\n",
      "Epoch 45/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.8337 - val_accuracy: 0.7812\n",
      "Epoch 46/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0136 - accuracy: 0.9982 - val_loss: 0.8148 - val_accuracy: 0.7969\n",
      "Epoch 47/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0113 - accuracy: 0.9982 - val_loss: 1.0116 - val_accuracy: 0.7812\n",
      "Epoch 48/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0171 - accuracy: 0.9946 - val_loss: 1.1298 - val_accuracy: 0.6875\n",
      "Epoch 49/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.9497 - val_accuracy: 0.7344\n",
      "Epoch 50/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0201 - accuracy: 0.9964 - val_loss: 0.9824 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.9643 - val_accuracy: 0.8281\n",
      "Epoch 52/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0239 - accuracy: 0.9946 - val_loss: 1.5186 - val_accuracy: 0.6094\n",
      "Epoch 53/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0155 - accuracy: 0.9982 - val_loss: 1.2627 - val_accuracy: 0.7969\n",
      "Epoch 54/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0134 - accuracy: 0.9946 - val_loss: 1.3796 - val_accuracy: 0.6875\n",
      "Epoch 55/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0212 - accuracy: 0.9910 - val_loss: 0.9496 - val_accuracy: 0.7812\n",
      "Epoch 56/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0350 - accuracy: 0.9874 - val_loss: 1.2884 - val_accuracy: 0.7188\n",
      "Epoch 57/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0417 - accuracy: 0.9856 - val_loss: 1.1631 - val_accuracy: 0.7969\n",
      "Epoch 58/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0225 - accuracy: 0.9946 - val_loss: 1.3487 - val_accuracy: 0.7031\n",
      "Epoch 59/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.9448 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.9230 - val_accuracy: 0.7969\n",
      "Epoch 61/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.9043 - val_accuracy: 0.8438\n",
      "Epoch 62/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0099 - accuracy: 0.9964 - val_loss: 1.2533 - val_accuracy: 0.6562\n",
      "Epoch 63/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.9847 - val_accuracy: 0.5625\n",
      "Epoch 64/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0175 - accuracy: 0.9946 - val_loss: 1.2287 - val_accuracy: 0.8125\n",
      "Epoch 65/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0214 - accuracy: 0.9928 - val_loss: 2.2395 - val_accuracy: 0.5156\n",
      "Epoch 66/100\n",
      "556/556 [==============================] - 2s 4ms/sample - loss: 0.0462 - accuracy: 0.9820 - val_loss: 1.2631 - val_accuracy: 0.6719\n",
      "Epoch 67/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0100 - accuracy: 0.9982 - val_loss: 1.2229 - val_accuracy: 0.8594\n",
      "Epoch 68/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0260 - accuracy: 0.9946 - val_loss: 1.0430 - val_accuracy: 0.7812\n",
      "Epoch 69/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0166 - accuracy: 0.9946 - val_loss: 1.1989 - val_accuracy: 0.6719\n",
      "Epoch 70/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0273 - accuracy: 0.9910 - val_loss: 1.1050 - val_accuracy: 0.8281\n",
      "Epoch 71/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.9338 - val_accuracy: 0.7812\n",
      "Epoch 72/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0083 - accuracy: 0.9964 - val_loss: 1.1509 - val_accuracy: 0.7812\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.7044 - val_accuracy: 0.5781\n",
      "Epoch 74/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0541 - accuracy: 0.9820 - val_loss: 1.1564 - val_accuracy: 0.8125\n",
      "Epoch 75/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 1.0290 - val_accuracy: 0.7344\n",
      "Epoch 76/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0219 - accuracy: 0.9910 - val_loss: 1.0047 - val_accuracy: 0.7969\n",
      "Epoch 77/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.8266 - val_accuracy: 0.8438\n",
      "Epoch 78/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.8438\n",
      "Epoch 79/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.8438\n",
      "Epoch 80/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.8365 - val_accuracy: 0.8125\n",
      "Epoch 81/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.8498 - val_accuracy: 0.7812\n",
      "Epoch 82/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5729 - val_accuracy: 0.6719\n",
      "Epoch 83/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2791 - val_accuracy: 0.6875\n",
      "Epoch 84/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2282 - val_accuracy: 0.6875\n",
      "Epoch 85/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8335 - val_accuracy: 0.8281\n",
      "Epoch 86/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.8811 - val_accuracy: 0.8594\n",
      "Epoch 87/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0189 - accuracy: 0.9928 - val_loss: 0.9577 - val_accuracy: 0.8281\n",
      "Epoch 88/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.7969\n",
      "Epoch 89/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9173 - val_accuracy: 0.7969\n",
      "Epoch 90/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.8125\n",
      "Epoch 91/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.8281\n",
      "Epoch 92/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0095 - accuracy: 0.9964 - val_loss: 0.8813 - val_accuracy: 0.8594\n",
      "Epoch 93/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8826 - val_accuracy: 0.8594\n",
      "Epoch 94/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9071 - val_accuracy: 0.8281\n",
      "Epoch 95/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0120 - accuracy: 0.9946 - val_loss: 0.8925 - val_accuracy: 0.8125\n",
      "Epoch 96/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.7969\n",
      "Epoch 97/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8964 - val_accuracy: 0.8125\n",
      "Epoch 98/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0110 - accuracy: 0.9982 - val_loss: 1.0633 - val_accuracy: 0.7969\n",
      "Epoch 99/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.8448 - val_accuracy: 0.8750\n",
      "Epoch 100/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.8836 - val_accuracy: 0.8281\n",
      "accuracy for model 1 is 82.8125\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 556 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "556/556 [==============================] - 13s 23ms/sample - loss: 0.9904 - accuracy: 0.5917 - val_loss: 12.4850 - val_accuracy: 0.6562\n",
      "Epoch 2/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.7035 - accuracy: 0.7824 - val_loss: 5.1422 - val_accuracy: 0.6875\n",
      "Epoch 3/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.6838 - accuracy: 0.7770 - val_loss: 2.1579 - val_accuracy: 0.7812\n",
      "Epoch 4/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.5918 - accuracy: 0.8058 - val_loss: 2.9873 - val_accuracy: 0.6875\n",
      "Epoch 5/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.5959 - accuracy: 0.8076 - val_loss: 1.7185 - val_accuracy: 0.6875\n",
      "Epoch 6/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.5479 - accuracy: 0.8165 - val_loss: 1.4529 - val_accuracy: 0.6875\n",
      "Epoch 7/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.5555 - accuracy: 0.8094 - val_loss: 1.8116 - val_accuracy: 0.7031\n",
      "Epoch 8/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.5017 - accuracy: 0.8237 - val_loss: 1.0879 - val_accuracy: 0.7812\n",
      "Epoch 9/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.4486 - accuracy: 0.8345 - val_loss: 1.1812 - val_accuracy: 0.7812\n",
      "Epoch 10/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.4196 - accuracy: 0.8507 - val_loss: 0.7415 - val_accuracy: 0.7969\n",
      "Epoch 11/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3751 - accuracy: 0.8669 - val_loss: 0.9068 - val_accuracy: 0.7812\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3390 - accuracy: 0.8633 - val_loss: 0.8095 - val_accuracy: 0.7812\n",
      "Epoch 13/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3329 - accuracy: 0.8579 - val_loss: 0.6628 - val_accuracy: 0.7969\n",
      "Epoch 14/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3288 - accuracy: 0.8759 - val_loss: 0.9064 - val_accuracy: 0.7812\n",
      "Epoch 15/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2759 - accuracy: 0.8849 - val_loss: 0.6427 - val_accuracy: 0.7969\n",
      "Epoch 16/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2825 - accuracy: 0.8705 - val_loss: 1.1529 - val_accuracy: 0.7812\n",
      "Epoch 17/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2561 - accuracy: 0.8903 - val_loss: 1.0528 - val_accuracy: 0.7812\n",
      "Epoch 18/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2570 - accuracy: 0.8831 - val_loss: 0.6362 - val_accuracy: 0.8281\n",
      "Epoch 19/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2440 - accuracy: 0.8975 - val_loss: 0.6342 - val_accuracy: 0.7969\n",
      "Epoch 20/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2122 - accuracy: 0.9155 - val_loss: 1.0222 - val_accuracy: 0.7656\n",
      "Epoch 21/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2193 - accuracy: 0.9119 - val_loss: 1.1245 - val_accuracy: 0.7656\n",
      "Epoch 22/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1938 - accuracy: 0.9227 - val_loss: 1.0187 - val_accuracy: 0.7031\n",
      "Epoch 23/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1748 - accuracy: 0.9353 - val_loss: 0.6144 - val_accuracy: 0.7969\n",
      "Epoch 24/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1671 - accuracy: 0.9371 - val_loss: 1.2810 - val_accuracy: 0.7812\n",
      "Epoch 25/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1753 - accuracy: 0.9442 - val_loss: 1.2221 - val_accuracy: 0.7344\n",
      "Epoch 26/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1630 - accuracy: 0.9460 - val_loss: 0.8158 - val_accuracy: 0.8125\n",
      "Epoch 27/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1160 - accuracy: 0.9784 - val_loss: 0.7577 - val_accuracy: 0.8125\n",
      "Epoch 28/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1024 - accuracy: 0.9748 - val_loss: 1.4677 - val_accuracy: 0.7344\n",
      "Epoch 29/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1176 - accuracy: 0.9568 - val_loss: 1.0914 - val_accuracy: 0.7812\n",
      "Epoch 30/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0910 - accuracy: 0.9766 - val_loss: 0.6017 - val_accuracy: 0.8281\n",
      "Epoch 31/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0893 - accuracy: 0.9712 - val_loss: 0.5425 - val_accuracy: 0.7969\n",
      "Epoch 32/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1021 - accuracy: 0.9676 - val_loss: 0.6784 - val_accuracy: 0.8125\n",
      "Epoch 33/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0514 - accuracy: 0.9892 - val_loss: 1.2494 - val_accuracy: 0.7812\n",
      "Epoch 34/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0665 - accuracy: 0.9784 - val_loss: 1.1613 - val_accuracy: 0.7344\n",
      "Epoch 35/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0614 - accuracy: 0.9892 - val_loss: 2.0844 - val_accuracy: 0.2812\n",
      "Epoch 36/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0686 - accuracy: 0.9820 - val_loss: 1.8269 - val_accuracy: 0.2969\n",
      "Epoch 37/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0531 - accuracy: 0.9892 - val_loss: 1.0436 - val_accuracy: 0.6406\n",
      "Epoch 38/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0506 - accuracy: 0.9838 - val_loss: 1.1548 - val_accuracy: 0.7344\n",
      "Epoch 39/100\n",
      "556/556 [==============================] - 2s 4ms/sample - loss: 0.0371 - accuracy: 0.9910 - val_loss: 0.9404 - val_accuracy: 0.7188\n",
      "Epoch 40/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0425 - accuracy: 0.9874 - val_loss: 1.8275 - val_accuracy: 0.7031\n",
      "Epoch 41/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.7969\n",
      "Epoch 42/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0210 - accuracy: 0.9964 - val_loss: 1.0089 - val_accuracy: 0.8125\n",
      "Epoch 43/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.8822 - val_accuracy: 0.8125\n",
      "Epoch 44/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.7969\n",
      "Epoch 45/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0408 - accuracy: 0.9874 - val_loss: 1.6073 - val_accuracy: 0.7812\n",
      "Epoch 46/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.1560 - val_accuracy: 0.7656\n",
      "Epoch 47/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0268 - accuracy: 0.9928 - val_loss: 1.2153 - val_accuracy: 0.7969\n",
      "Epoch 48/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0212 - accuracy: 0.9928 - val_loss: 1.4232 - val_accuracy: 0.7656\n",
      "Epoch 49/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.9570 - val_accuracy: 0.8125\n",
      "Epoch 50/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0304 - accuracy: 0.9964 - val_loss: 1.2532 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.9428 - val_accuracy: 0.7656\n",
      "Epoch 52/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0501 - accuracy: 0.9874 - val_loss: 1.2538 - val_accuracy: 0.8125\n",
      "Epoch 53/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0273 - accuracy: 0.9928 - val_loss: 1.3056 - val_accuracy: 0.8281\n",
      "Epoch 54/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0217 - accuracy: 0.9964 - val_loss: 1.1180 - val_accuracy: 0.8281\n",
      "Epoch 55/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0436 - accuracy: 0.9820 - val_loss: 1.0944 - val_accuracy: 0.7969\n",
      "Epoch 56/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0318 - accuracy: 0.9874 - val_loss: 1.2989 - val_accuracy: 0.7969\n",
      "Epoch 57/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0181 - accuracy: 0.9946 - val_loss: 1.2419 - val_accuracy: 0.8125\n",
      "Epoch 58/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0269 - accuracy: 0.9910 - val_loss: 1.3443 - val_accuracy: 0.7812\n",
      "Epoch 59/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.8735 - val_accuracy: 0.8438\n",
      "Epoch 60/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.0127 - val_accuracy: 0.7969\n",
      "Epoch 61/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0131 - accuracy: 0.9964 - val_loss: 1.1492 - val_accuracy: 0.7969\n",
      "Epoch 62/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.2162 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3143 - val_accuracy: 0.7812\n",
      "Epoch 64/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.5376 - val_accuracy: 0.7344\n",
      "Epoch 65/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0122 - accuracy: 0.9964 - val_loss: 1.2700 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.7969\n",
      "Epoch 67/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0076 - accuracy: 0.9982 - val_loss: 1.3762 - val_accuracy: 0.7969\n",
      "Epoch 68/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0144 - accuracy: 0.9982 - val_loss: 1.7961 - val_accuracy: 0.7656\n",
      "Epoch 69/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.1056 - val_accuracy: 0.8125\n",
      "Epoch 70/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0132 - accuracy: 0.9964 - val_loss: 1.6450 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.9814 - val_accuracy: 0.8281\n",
      "Epoch 72/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0170 - accuracy: 0.9946 - val_loss: 1.3088 - val_accuracy: 0.7812\n",
      "Epoch 73/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0095 - accuracy: 0.9964 - val_loss: 2.0427 - val_accuracy: 0.7031\n",
      "Epoch 74/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0161 - accuracy: 0.9982 - val_loss: 1.0929 - val_accuracy: 0.8125\n",
      "Epoch 75/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0151 - accuracy: 0.9928 - val_loss: 1.7406 - val_accuracy: 0.7656\n",
      "Epoch 76/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0098 - accuracy: 0.9946 - val_loss: 1.5544 - val_accuracy: 0.7969\n",
      "Epoch 77/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.5046 - val_accuracy: 0.7812\n",
      "Epoch 78/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0206 - accuracy: 0.9928 - val_loss: 1.8398 - val_accuracy: 0.7812\n",
      "Epoch 79/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0312 - accuracy: 0.9892 - val_loss: 1.2359 - val_accuracy: 0.7656\n",
      "Epoch 80/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0113 - accuracy: 0.9946 - val_loss: 1.6516 - val_accuracy: 0.7812\n",
      "Epoch 81/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 1.3696 - val_accuracy: 0.7969\n",
      "Epoch 82/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0075 - accuracy: 0.9964 - val_loss: 1.2992 - val_accuracy: 0.8125\n",
      "Epoch 83/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0121 - accuracy: 0.9982 - val_loss: 1.7433 - val_accuracy: 0.7656\n",
      "Epoch 84/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 2.1063 - val_accuracy: 0.7812\n",
      "Epoch 85/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0070 - accuracy: 0.9964 - val_loss: 1.5580 - val_accuracy: 0.7969\n",
      "Epoch 86/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0069 - accuracy: 0.9982 - val_loss: 1.4984 - val_accuracy: 0.8125\n",
      "Epoch 87/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0113 - accuracy: 0.9946 - val_loss: 1.3640 - val_accuracy: 0.7969\n",
      "Epoch 88/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0067 - accuracy: 0.9964 - val_loss: 1.6794 - val_accuracy: 0.7188\n",
      "Epoch 89/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0079 - accuracy: 0.9982 - val_loss: 1.2091 - val_accuracy: 0.8125\n",
      "Epoch 90/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0017 - val_accuracy: 0.8281\n",
      "Epoch 91/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0068 - accuracy: 0.9964 - val_loss: 1.9900 - val_accuracy: 0.7812\n",
      "Epoch 92/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.6201 - val_accuracy: 0.7812\n",
      "Epoch 93/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.8125\n",
      "Epoch 94/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0047 - accuracy: 0.9982 - val_loss: 1.6877 - val_accuracy: 0.7812\n",
      "Epoch 95/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0029 - accuracy: 0.9982 - val_loss: 1.4112 - val_accuracy: 0.8125\n",
      "Epoch 96/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.7969\n",
      "Epoch 97/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0132 - accuracy: 0.9946 - val_loss: 1.5266 - val_accuracy: 0.8125\n",
      "Epoch 98/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0075 - accuracy: 0.9964 - val_loss: 2.2843 - val_accuracy: 0.7188\n",
      "Epoch 99/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0056 - accuracy: 0.9964 - val_loss: 1.9286 - val_accuracy: 0.7969\n",
      "Epoch 100/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6793 - val_accuracy: 0.7812\n",
      "accuracy for model 2 is 78.125\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 556 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "556/556 [==============================] - 12s 22ms/sample - loss: 1.1782 - accuracy: 0.5665 - val_loss: 7.9289 - val_accuracy: 0.6562\n",
      "Epoch 2/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.7575 - accuracy: 0.7464 - val_loss: 1.6124 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.6646 - accuracy: 0.7932 - val_loss: 1.2522 - val_accuracy: 0.8594\n",
      "Epoch 4/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.5567 - accuracy: 0.8237 - val_loss: 0.8824 - val_accuracy: 0.8750\n",
      "Epoch 5/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.5150 - accuracy: 0.8291 - val_loss: 0.6369 - val_accuracy: 0.8750\n",
      "Epoch 6/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.4944 - accuracy: 0.8291 - val_loss: 0.5777 - val_accuracy: 0.8750\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.4291 - accuracy: 0.8543 - val_loss: 0.4702 - val_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3782 - accuracy: 0.8615 - val_loss: 0.4588 - val_accuracy: 0.8594\n",
      "Epoch 9/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3560 - accuracy: 0.8741 - val_loss: 0.8777 - val_accuracy: 0.7031\n",
      "Epoch 10/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3588 - accuracy: 0.8705 - val_loss: 0.4636 - val_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.3075 - accuracy: 0.8795 - val_loss: 0.4186 - val_accuracy: 0.8750\n",
      "Epoch 12/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2995 - accuracy: 0.8867 - val_loss: 0.4185 - val_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2747 - accuracy: 0.8831 - val_loss: 0.4341 - val_accuracy: 0.8594\n",
      "Epoch 14/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2809 - accuracy: 0.8885 - val_loss: 0.6196 - val_accuracy: 0.7188\n",
      "Epoch 15/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2629 - accuracy: 0.8867 - val_loss: 0.4563 - val_accuracy: 0.8594\n",
      "Epoch 16/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2218 - accuracy: 0.9119 - val_loss: 0.4839 - val_accuracy: 0.8750\n",
      "Epoch 17/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2152 - accuracy: 0.9065 - val_loss: 0.4533 - val_accuracy: 0.8594\n",
      "Epoch 18/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.2170 - accuracy: 0.9137 - val_loss: 0.4752 - val_accuracy: 0.8750\n",
      "Epoch 19/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1823 - accuracy: 0.9335 - val_loss: 0.5051 - val_accuracy: 0.8281\n",
      "Epoch 20/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1781 - accuracy: 0.9388 - val_loss: 0.4464 - val_accuracy: 0.8594\n",
      "Epoch 21/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1585 - accuracy: 0.9371 - val_loss: 0.5085 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1559 - accuracy: 0.9371 - val_loss: 0.5443 - val_accuracy: 0.8125\n",
      "Epoch 23/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1212 - accuracy: 0.9640 - val_loss: 0.4618 - val_accuracy: 0.8750\n",
      "Epoch 24/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1082 - accuracy: 0.9676 - val_loss: 0.5238 - val_accuracy: 0.8594\n",
      "Epoch 25/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1216 - accuracy: 0.9622 - val_loss: 0.5812 - val_accuracy: 0.8125\n",
      "Epoch 26/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.1041 - accuracy: 0.9658 - val_loss: 0.4949 - val_accuracy: 0.8750\n",
      "Epoch 27/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0839 - accuracy: 0.9784 - val_loss: 0.5538 - val_accuracy: 0.8438\n",
      "Epoch 28/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0875 - accuracy: 0.9730 - val_loss: 0.6063 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0990 - accuracy: 0.9640 - val_loss: 0.5449 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0823 - accuracy: 0.9838 - val_loss: 0.5916 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0796 - accuracy: 0.9766 - val_loss: 0.6681 - val_accuracy: 0.8281\n",
      "Epoch 32/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0713 - accuracy: 0.9784 - val_loss: 0.6687 - val_accuracy: 0.8594\n",
      "Epoch 33/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0614 - accuracy: 0.9802 - val_loss: 0.6030 - val_accuracy: 0.8594\n",
      "Epoch 34/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0706 - accuracy: 0.9766 - val_loss: 0.5790 - val_accuracy: 0.8594\n",
      "Epoch 35/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0696 - accuracy: 0.9748 - val_loss: 0.5133 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0542 - accuracy: 0.9802 - val_loss: 0.6818 - val_accuracy: 0.8906\n",
      "Epoch 37/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.5231 - val_accuracy: 0.8906\n",
      "Epoch 38/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0551 - accuracy: 0.9766 - val_loss: 0.6208 - val_accuracy: 0.8438\n",
      "Epoch 39/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0376 - accuracy: 0.9910 - val_loss: 0.5304 - val_accuracy: 0.8438\n",
      "Epoch 40/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0353 - accuracy: 0.9892 - val_loss: 0.5715 - val_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0336 - accuracy: 0.9910 - val_loss: 0.5872 - val_accuracy: 0.8906\n",
      "Epoch 42/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.6136 - val_accuracy: 0.8438\n",
      "Epoch 43/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0318 - accuracy: 0.9892 - val_loss: 0.5406 - val_accuracy: 0.8906\n",
      "Epoch 44/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0330 - accuracy: 0.9892 - val_loss: 0.8245 - val_accuracy: 0.8594\n",
      "Epoch 45/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0236 - accuracy: 0.9892 - val_loss: 0.6945 - val_accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.6524 - val_accuracy: 0.8906\n",
      "Epoch 47/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0159 - accuracy: 0.9982 - val_loss: 0.7544 - val_accuracy: 0.8125\n",
      "Epoch 48/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.8906\n",
      "Epoch 49/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.6092 - val_accuracy: 0.8594\n",
      "Epoch 50/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.8438\n",
      "Epoch 51/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0137 - accuracy: 0.9982 - val_loss: 0.6773 - val_accuracy: 0.9062\n",
      "Epoch 52/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0327 - accuracy: 0.9964 - val_loss: 0.6719 - val_accuracy: 0.8438\n",
      "Epoch 53/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.8443 - val_accuracy: 0.7812\n",
      "Epoch 54/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.8438\n",
      "Epoch 55/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.7009 - val_accuracy: 0.8906\n",
      "Epoch 56/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.6714 - val_accuracy: 0.8594\n",
      "Epoch 57/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.6811 - val_accuracy: 0.8594\n",
      "Epoch 58/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.8810 - val_accuracy: 0.7812\n",
      "Epoch 59/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0264 - accuracy: 0.9910 - val_loss: 1.0574 - val_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.8664 - val_accuracy: 0.8281\n",
      "Epoch 61/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.6141 - val_accuracy: 0.9062\n",
      "Epoch 62/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.6052 - val_accuracy: 0.9219\n",
      "Epoch 63/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.5621 - val_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0198 - accuracy: 0.9946 - val_loss: 0.5600 - val_accuracy: 0.8906\n",
      "Epoch 65/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8438\n",
      "Epoch 66/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.6362 - val_accuracy: 0.9062\n",
      "Epoch 67/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.5922 - val_accuracy: 0.8906\n",
      "Epoch 68/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5977 - val_accuracy: 0.9062\n",
      "Epoch 69/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6514 - val_accuracy: 0.8438\n",
      "Epoch 70/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.8906\n",
      "Epoch 71/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.8030 - val_accuracy: 0.8594\n",
      "Epoch 72/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.9062\n",
      "Epoch 73/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6469 - val_accuracy: 0.8594\n",
      "Epoch 74/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.7401 - val_accuracy: 0.9062\n",
      "Epoch 75/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8906\n",
      "Epoch 76/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.8421 - val_accuracy: 0.8281\n",
      "Epoch 77/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.9738 - val_accuracy: 0.8906\n",
      "Epoch 78/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0083 - accuracy: 0.9964 - val_loss: 0.9708 - val_accuracy: 0.8906\n",
      "Epoch 79/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0074 - accuracy: 0.9946 - val_loss: 0.8220 - val_accuracy: 0.8594\n",
      "Epoch 80/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.9062 - val_accuracy: 0.8906\n",
      "Epoch 81/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0140 - accuracy: 0.9928 - val_loss: 0.8257 - val_accuracy: 0.8594\n",
      "Epoch 82/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.8750\n",
      "Epoch 83/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.8444 - val_accuracy: 0.8594\n",
      "Epoch 84/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.7123 - val_accuracy: 0.9062\n",
      "Epoch 85/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.7635 - val_accuracy: 0.9062\n",
      "Epoch 86/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9268 - val_accuracy: 0.8906\n",
      "Epoch 87/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.9336 - val_accuracy: 0.8906\n",
      "Epoch 88/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.8750\n",
      "Epoch 89/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.8906\n",
      "Epoch 90/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0036 - accuracy: 0.9982 - val_loss: 1.0198 - val_accuracy: 0.8125\n",
      "Epoch 91/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.8542 - val_accuracy: 0.8906\n",
      "Epoch 92/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.8846 - val_accuracy: 0.8906\n",
      "Epoch 93/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0078 - val_accuracy: 0.8125\n",
      "Epoch 94/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0135 - accuracy: 0.9946 - val_loss: 0.9764 - val_accuracy: 0.8281\n",
      "Epoch 95/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0106 - accuracy: 0.9946 - val_loss: 0.6734 - val_accuracy: 0.8750\n",
      "Epoch 96/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.8080 - val_accuracy: 0.8438\n",
      "Epoch 97/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.6461 - val_accuracy: 0.8594\n",
      "Epoch 98/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.8438\n",
      "Epoch 99/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8906\n",
      "Epoch 100/100\n",
      "556/556 [==============================] - 2s 3ms/sample - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.8455 - val_accuracy: 0.9062\n",
      "accuracy for model 3 is 90.625\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 557 samples, validate on 63 samples\n",
      "Epoch 1/100\n",
      "557/557 [==============================] - 13s 24ms/sample - loss: 1.3253 - accuracy: 0.3878 - val_loss: 2.9926 - val_accuracy: 0.6508\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.9332 - accuracy: 0.6912 - val_loss: 0.7112 - val_accuracy: 0.8413\n",
      "Epoch 3/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.7522 - accuracy: 0.7648 - val_loss: 0.7602 - val_accuracy: 0.8730\n",
      "Epoch 4/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.6372 - accuracy: 0.8043 - val_loss: 0.7201 - val_accuracy: 0.8095\n",
      "Epoch 5/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.5479 - accuracy: 0.8115 - val_loss: 0.5289 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.5098 - accuracy: 0.8384 - val_loss: 0.5974 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.4764 - accuracy: 0.8384 - val_loss: 0.7193 - val_accuracy: 0.7937\n",
      "Epoch 8/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.4611 - accuracy: 0.8546 - val_loss: 0.4873 - val_accuracy: 0.8413\n",
      "Epoch 9/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.4352 - accuracy: 0.8510 - val_loss: 1.0210 - val_accuracy: 0.7302\n",
      "Epoch 10/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.4185 - accuracy: 0.8600 - val_loss: 0.7225 - val_accuracy: 0.8413\n",
      "Epoch 11/100\n",
      "557/557 [==============================] - 2s 4ms/sample - loss: 0.4331 - accuracy: 0.8564 - val_loss: 0.4569 - val_accuracy: 0.8413\n",
      "Epoch 12/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.3755 - accuracy: 0.8725 - val_loss: 0.4945 - val_accuracy: 0.8413\n",
      "Epoch 13/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.3326 - accuracy: 0.8725 - val_loss: 0.5154 - val_accuracy: 0.8254\n",
      "Epoch 14/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.3446 - accuracy: 0.8761 - val_loss: 0.4784 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.3741 - accuracy: 0.8671 - val_loss: 0.4080 - val_accuracy: 0.8730\n",
      "Epoch 16/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.3108 - accuracy: 0.8833 - val_loss: 0.3695 - val_accuracy: 0.8730\n",
      "Epoch 17/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.3274 - accuracy: 0.8779 - val_loss: 0.3506 - val_accuracy: 0.8730\n",
      "Epoch 18/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.3077 - accuracy: 0.8923 - val_loss: 0.3433 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.2808 - accuracy: 0.8905 - val_loss: 0.3364 - val_accuracy: 0.8730\n",
      "Epoch 20/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.2875 - accuracy: 0.8887 - val_loss: 0.3452 - val_accuracy: 0.8730\n",
      "Epoch 21/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.2759 - accuracy: 0.8887 - val_loss: 0.3512 - val_accuracy: 0.8730\n",
      "Epoch 22/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.2812 - accuracy: 0.8941 - val_loss: 0.3740 - val_accuracy: 0.8730\n",
      "Epoch 23/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.2445 - accuracy: 0.9066 - val_loss: 0.3862 - val_accuracy: 0.8413\n",
      "Epoch 24/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.2528 - accuracy: 0.9031 - val_loss: 0.4051 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.2194 - accuracy: 0.9138 - val_loss: 0.4267 - val_accuracy: 0.8413\n",
      "Epoch 26/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1870 - accuracy: 0.9372 - val_loss: 0.4101 - val_accuracy: 0.8730\n",
      "Epoch 27/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.2124 - accuracy: 0.9156 - val_loss: 0.4429 - val_accuracy: 0.8730\n",
      "Epoch 28/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1704 - accuracy: 0.9372 - val_loss: 0.4242 - val_accuracy: 0.8730\n",
      "Epoch 29/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1559 - accuracy: 0.9515 - val_loss: 0.3854 - val_accuracy: 0.8730\n",
      "Epoch 30/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1612 - accuracy: 0.9497 - val_loss: 0.3759 - val_accuracy: 0.8889\n",
      "Epoch 31/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1494 - accuracy: 0.9569 - val_loss: 0.4635 - val_accuracy: 0.8413\n",
      "Epoch 32/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1500 - accuracy: 0.9479 - val_loss: 0.4533 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1354 - accuracy: 0.9497 - val_loss: 0.4642 - val_accuracy: 0.8730\n",
      "Epoch 34/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1300 - accuracy: 0.9587 - val_loss: 0.4722 - val_accuracy: 0.8730\n",
      "Epoch 35/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1245 - accuracy: 0.9569 - val_loss: 0.4638 - val_accuracy: 0.8730\n",
      "Epoch 36/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1095 - accuracy: 0.9749 - val_loss: 0.4698 - val_accuracy: 0.8730\n",
      "Epoch 37/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0997 - accuracy: 0.9731 - val_loss: 0.4950 - val_accuracy: 0.8730\n",
      "Epoch 38/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1078 - accuracy: 0.9677 - val_loss: 0.6883 - val_accuracy: 0.7778\n",
      "Epoch 39/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.1098 - accuracy: 0.9641 - val_loss: 0.4844 - val_accuracy: 0.8730\n",
      "Epoch 40/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0822 - accuracy: 0.9731 - val_loss: 0.5860 - val_accuracy: 0.8095\n",
      "Epoch 41/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0675 - accuracy: 0.9803 - val_loss: 0.4551 - val_accuracy: 0.8730\n",
      "Epoch 42/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0811 - accuracy: 0.9820 - val_loss: 0.6631 - val_accuracy: 0.8095\n",
      "Epoch 43/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0747 - accuracy: 0.9785 - val_loss: 0.4821 - val_accuracy: 0.8730\n",
      "Epoch 44/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0946 - accuracy: 0.9713 - val_loss: 0.5158 - val_accuracy: 0.8413\n",
      "Epoch 45/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0665 - accuracy: 0.9838 - val_loss: 0.5332 - val_accuracy: 0.8730\n",
      "Epoch 46/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0559 - accuracy: 0.9838 - val_loss: 0.5569 - val_accuracy: 0.8730\n",
      "Epoch 47/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0623 - accuracy: 0.9838 - val_loss: 0.6753 - val_accuracy: 0.7778\n",
      "Epoch 48/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0593 - accuracy: 0.9838 - val_loss: 0.5312 - val_accuracy: 0.8730\n",
      "Epoch 49/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0654 - accuracy: 0.9803 - val_loss: 0.5869 - val_accuracy: 0.8730\n",
      "Epoch 50/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.5511 - val_accuracy: 0.8730\n",
      "Epoch 51/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0517 - accuracy: 0.9803 - val_loss: 0.5594 - val_accuracy: 0.8730\n",
      "Epoch 52/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0430 - accuracy: 0.9856 - val_loss: 0.7465 - val_accuracy: 0.7937\n",
      "Epoch 53/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.5385 - val_accuracy: 0.8730\n",
      "Epoch 54/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0425 - accuracy: 0.9838 - val_loss: 0.6039 - val_accuracy: 0.8730\n",
      "Epoch 55/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0503 - accuracy: 0.9803 - val_loss: 0.6114 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0506 - accuracy: 0.9785 - val_loss: 0.8527 - val_accuracy: 0.8413\n",
      "Epoch 57/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.6468 - val_accuracy: 0.8413\n",
      "Epoch 58/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0499 - accuracy: 0.9820 - val_loss: 0.6219 - val_accuracy: 0.8730\n",
      "Epoch 59/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0324 - accuracy: 0.9928 - val_loss: 0.6632 - val_accuracy: 0.8730\n",
      "Epoch 60/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0253 - accuracy: 0.9892 - val_loss: 0.6284 - val_accuracy: 0.8730\n",
      "Epoch 61/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0433 - accuracy: 0.9874 - val_loss: 0.5589 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0308 - accuracy: 0.9892 - val_loss: 0.5579 - val_accuracy: 0.8730\n",
      "Epoch 63/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0319 - accuracy: 0.9892 - val_loss: 0.6595 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0278 - accuracy: 0.9874 - val_loss: 0.6738 - val_accuracy: 0.8730\n",
      "Epoch 65/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0200 - accuracy: 0.9946 - val_loss: 0.6754 - val_accuracy: 0.8730\n",
      "Epoch 66/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.7170 - val_accuracy: 0.8730\n",
      "Epoch 67/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0347 - accuracy: 0.9892 - val_loss: 0.7266 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0293 - accuracy: 0.9892 - val_loss: 0.7049 - val_accuracy: 0.8730\n",
      "Epoch 69/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.6473 - val_accuracy: 0.8730\n",
      "Epoch 70/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0220 - accuracy: 0.9946 - val_loss: 0.6300 - val_accuracy: 0.8730\n",
      "Epoch 71/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.6186 - val_accuracy: 0.8730\n",
      "Epoch 72/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0253 - accuracy: 0.9892 - val_loss: 0.6664 - val_accuracy: 0.8730\n",
      "Epoch 73/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0214 - accuracy: 0.9892 - val_loss: 0.7305 - val_accuracy: 0.8730\n",
      "Epoch 74/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7484 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.6900 - val_accuracy: 0.8730\n",
      "Epoch 76/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.7694 - val_accuracy: 0.8730\n",
      "Epoch 77/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0248 - accuracy: 0.9946 - val_loss: 0.8308 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.7920 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0230 - accuracy: 0.9946 - val_loss: 0.7675 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0224 - accuracy: 0.9910 - val_loss: 0.7010 - val_accuracy: 0.8730\n",
      "Epoch 81/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.8498 - val_accuracy: 0.8413\n",
      "Epoch 82/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.7934 - val_accuracy: 0.8730\n",
      "Epoch 83/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.7684 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0333 - accuracy: 0.9946 - val_loss: 0.7958 - val_accuracy: 0.8730\n",
      "Epoch 85/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0172 - accuracy: 0.9910 - val_loss: 0.8105 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0253 - accuracy: 0.9892 - val_loss: 0.7198 - val_accuracy: 0.8730\n",
      "Epoch 87/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.7439 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.7977 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.8730\n",
      "Epoch 90/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.7821 - val_accuracy: 0.8730\n",
      "Epoch 91/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.7926 - val_accuracy: 0.8889\n",
      "Epoch 92/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.7918 - val_accuracy: 0.8730\n",
      "Epoch 93/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.8537 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.8814 - val_accuracy: 0.8413\n",
      "Epoch 95/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0084 - accuracy: 0.9964 - val_loss: 0.8366 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0279 - accuracy: 0.9874 - val_loss: 0.8090 - val_accuracy: 0.8730\n",
      "Epoch 97/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0173 - accuracy: 0.9910 - val_loss: 0.7584 - val_accuracy: 0.8730\n",
      "Epoch 98/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.7731 - val_accuracy: 0.8095\n",
      "Epoch 99/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.8407 - val_accuracy: 0.8730\n",
      "Epoch 100/100\n",
      "557/557 [==============================] - 2s 3ms/sample - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.9428 - val_accuracy: 0.8254\n",
      "accuracy for model 4 is 82.53968358039856\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 558 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "558/558 [==============================] - 17s 31ms/sample - loss: 1.0146 - accuracy: 0.6667 - val_loss: 16.4402 - val_accuracy: 0.6613\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 5s 10ms/sample - loss: 0.7492 - accuracy: 0.7563 - val_loss: 7.0084 - val_accuracy: 0.6613\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.6552 - accuracy: 0.7760 - val_loss: 3.3098 - val_accuracy: 0.6613\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.6158 - accuracy: 0.8065 - val_loss: 1.6265 - val_accuracy: 0.7419\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.5580 - accuracy: 0.8190 - val_loss: 0.6554 - val_accuracy: 0.8871\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.5009 - accuracy: 0.8280 - val_loss: 0.5654 - val_accuracy: 0.8871\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.4632 - accuracy: 0.8405 - val_loss: 0.5641 - val_accuracy: 0.8710\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.4031 - accuracy: 0.8656 - val_loss: 0.5829 - val_accuracy: 0.8548\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.3806 - accuracy: 0.8656 - val_loss: 0.6184 - val_accuracy: 0.8871\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.3517 - accuracy: 0.8710 - val_loss: 0.6911 - val_accuracy: 0.7903\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.3064 - accuracy: 0.8943 - val_loss: 0.5183 - val_accuracy: 0.8871\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2919 - accuracy: 0.8871 - val_loss: 0.5545 - val_accuracy: 0.8710\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2486 - accuracy: 0.9086 - val_loss: 1.0430 - val_accuracy: 0.6613\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2464 - accuracy: 0.9086 - val_loss: 0.6744 - val_accuracy: 0.8710\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2361 - accuracy: 0.9104 - val_loss: 0.7750 - val_accuracy: 0.7742\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2114 - accuracy: 0.9194 - val_loss: 0.6146 - val_accuracy: 0.8548\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1828 - accuracy: 0.9337 - val_loss: 0.7641 - val_accuracy: 0.7742\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1513 - accuracy: 0.9391 - val_loss: 0.6947 - val_accuracy: 0.8226\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1380 - accuracy: 0.9480 - val_loss: 0.7002 - val_accuracy: 0.8226\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1134 - accuracy: 0.9624 - val_loss: 0.7468 - val_accuracy: 0.7258\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1072 - accuracy: 0.9677 - val_loss: 0.5690 - val_accuracy: 0.8387\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1045 - accuracy: 0.9749 - val_loss: 0.5921 - val_accuracy: 0.8710\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0862 - accuracy: 0.9695 - val_loss: 0.7394 - val_accuracy: 0.8065\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0605 - accuracy: 0.9839 - val_loss: 0.9521 - val_accuracy: 0.6774\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0597 - accuracy: 0.9839 - val_loss: 0.7110 - val_accuracy: 0.8548\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0921 - accuracy: 0.9803 - val_loss: 0.5998 - val_accuracy: 0.8871\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0629 - accuracy: 0.9857 - val_loss: 0.6899 - val_accuracy: 0.7903\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0422 - accuracy: 0.9928 - val_loss: 0.8174 - val_accuracy: 0.7419\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0320 - accuracy: 0.9982 - val_loss: 0.9635 - val_accuracy: 0.6774\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0370 - accuracy: 0.9946 - val_loss: 1.1635 - val_accuracy: 0.6452\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0328 - accuracy: 0.9946 - val_loss: 0.8739 - val_accuracy: 0.8387\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.7903\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0182 - accuracy: 0.9982 - val_loss: 0.8726 - val_accuracy: 0.7581\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0218 - accuracy: 0.9964 - val_loss: 0.8852 - val_accuracy: 0.7581\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8497 - val_accuracy: 0.7903\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.8651 - val_accuracy: 0.8226\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.9606 - val_accuracy: 0.8871\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0238 - accuracy: 0.9946 - val_loss: 1.0797 - val_accuracy: 0.7903\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0248 - accuracy: 0.9910 - val_loss: 0.8140 - val_accuracy: 0.8710\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0348 - accuracy: 0.9910 - val_loss: 0.8585 - val_accuracy: 0.8387\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0226 - accuracy: 0.9928 - val_loss: 1.1570 - val_accuracy: 0.7742\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.9501 - val_accuracy: 0.7903\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0406 - accuracy: 0.9875 - val_loss: 0.9308 - val_accuracy: 0.8226\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0252 - accuracy: 0.9892 - val_loss: 0.9835 - val_accuracy: 0.8226\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0188 - accuracy: 0.9964 - val_loss: 1.0616 - val_accuracy: 0.7419\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0116 - accuracy: 0.9982 - val_loss: 1.0795 - val_accuracy: 0.7581\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.9810 - val_accuracy: 0.8065\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.9681 - val_accuracy: 0.8387\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0103 - accuracy: 0.9982 - val_loss: 1.1226 - val_accuracy: 0.8065\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.9685 - val_accuracy: 0.8387\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0089 - accuracy: 0.9982 - val_loss: 1.2331 - val_accuracy: 0.8387\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0079 - accuracy: 0.9982 - val_loss: 1.2536 - val_accuracy: 0.7581\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1302 - val_accuracy: 0.8065\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0085 - accuracy: 0.9982 - val_loss: 1.0818 - val_accuracy: 0.8871\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0171 - accuracy: 0.9982 - val_loss: 1.1239 - val_accuracy: 0.8065\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0098 - accuracy: 0.9982 - val_loss: 1.3086 - val_accuracy: 0.7581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.9912 - val_accuracy: 0.8871\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0072 - accuracy: 0.9982 - val_loss: 1.0847 - val_accuracy: 0.7742\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0081 - accuracy: 0.9964 - val_loss: 1.0160 - val_accuracy: 0.8710\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0067 - accuracy: 0.9982 - val_loss: 1.1042 - val_accuracy: 0.8548\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0804 - val_accuracy: 0.8387\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.0917 - val_accuracy: 0.8387\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0063 - accuracy: 0.9964 - val_loss: 1.0208 - val_accuracy: 0.8387\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8387\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.9143 - val_accuracy: 0.8387\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0857 - val_accuracy: 0.8387\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 1.1668 - val_accuracy: 0.8065\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.8710\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 1.0018 - val_accuracy: 0.8065\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1002 - val_accuracy: 0.8065\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.7742\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.1634 - val_accuracy: 0.9032\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9133 - val_accuracy: 0.9032\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0093 - accuracy: 0.9982 - val_loss: 1.0302 - val_accuracy: 0.8226\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1671 - val_accuracy: 0.8548\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.8387\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1959 - val_accuracy: 0.8548\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1558 - val_accuracy: 0.8226\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.8065\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2275 - val_accuracy: 0.8065\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2711 - val_accuracy: 0.7903\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1668 - val_accuracy: 0.8065\n",
      "Epoch 83/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2433 - val_accuracy: 0.7742\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.4842 - val_accuracy: 0.7419\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4136 - val_accuracy: 0.8710\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.3745 - val_accuracy: 0.8710\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0133 - accuracy: 0.9964 - val_loss: 1.2956 - val_accuracy: 0.8871\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0110 - accuracy: 0.9964 - val_loss: 1.2559 - val_accuracy: 0.8548\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0205 - accuracy: 0.9964 - val_loss: 1.3523 - val_accuracy: 0.7742\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.0477 - val_accuracy: 0.8710\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1832 - val_accuracy: 0.7742\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.9795 - val_accuracy: 0.8710\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.8710\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0362 - val_accuracy: 0.8710\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.8710\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1178 - val_accuracy: 0.8548\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3437 - val_accuracy: 0.7903\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 1.3001 - val_accuracy: 0.8710\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3078 - val_accuracy: 0.8548\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 9.0725e-04 - accuracy: 1.0000 - val_loss: 1.2995 - val_accuracy: 0.8387\n",
      "accuracy for model 5 is 83.87096524238586\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 558 samples, validate on 62 samples\n",
      "Epoch 1/100\n",
      "558/558 [==============================] - 14s 25ms/sample - loss: 1.1780 - accuracy: 0.5502 - val_loss: 2.4702 - val_accuracy: 0.6613\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 2s 4ms/sample - loss: 0.7964 - accuracy: 0.7742 - val_loss: 1.7722 - val_accuracy: 0.7581\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.6438 - accuracy: 0.8082 - val_loss: 1.0676 - val_accuracy: 0.8871\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.5641 - accuracy: 0.8190 - val_loss: 0.8304 - val_accuracy: 0.8871\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.5240 - accuracy: 0.8333 - val_loss: 0.7253 - val_accuracy: 0.8871\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.4737 - accuracy: 0.8459 - val_loss: 0.6491 - val_accuracy: 0.8065\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.3977 - accuracy: 0.8602 - val_loss: 0.5772 - val_accuracy: 0.8871\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.3696 - accuracy: 0.8710 - val_loss: 0.8746 - val_accuracy: 0.6935\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.3415 - accuracy: 0.8763 - val_loss: 0.5741 - val_accuracy: 0.7903\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2973 - accuracy: 0.8853 - val_loss: 0.7245 - val_accuracy: 0.7258\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2799 - accuracy: 0.8835 - val_loss: 0.7235 - val_accuracy: 0.7581\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2718 - accuracy: 0.8996 - val_loss: 0.6130 - val_accuracy: 0.8871\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2283 - accuracy: 0.9050 - val_loss: 0.5921 - val_accuracy: 0.7903\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2283 - accuracy: 0.9068 - val_loss: 0.6134 - val_accuracy: 0.7742\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2071 - accuracy: 0.9176 - val_loss: 0.9136 - val_accuracy: 0.6935\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.2072 - accuracy: 0.9176 - val_loss: 0.5558 - val_accuracy: 0.7742\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1763 - accuracy: 0.9337 - val_loss: 0.5979 - val_accuracy: 0.8226\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1859 - accuracy: 0.9355 - val_loss: 0.9102 - val_accuracy: 0.6774\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1727 - accuracy: 0.9373 - val_loss: 0.5888 - val_accuracy: 0.8065\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1823 - accuracy: 0.9409 - val_loss: 1.1269 - val_accuracy: 0.6129\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1187 - accuracy: 0.9606 - val_loss: 0.7903 - val_accuracy: 0.7258\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.1068 - accuracy: 0.9713 - val_loss: 0.6995 - val_accuracy: 0.8387\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0829 - accuracy: 0.9731 - val_loss: 0.7288 - val_accuracy: 0.8065\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0741 - accuracy: 0.9875 - val_loss: 0.7420 - val_accuracy: 0.7903\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0494 - accuracy: 0.9910 - val_loss: 0.8564 - val_accuracy: 0.6935\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0584 - accuracy: 0.9839 - val_loss: 0.8950 - val_accuracy: 0.7581\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0542 - accuracy: 0.9821 - val_loss: 0.6726 - val_accuracy: 0.8226\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0575 - accuracy: 0.9857 - val_loss: 0.9144 - val_accuracy: 0.8710\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0480 - accuracy: 0.9839 - val_loss: 0.8787 - val_accuracy: 0.8710\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0356 - accuracy: 0.9910 - val_loss: 0.7574 - val_accuracy: 0.8226\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0287 - accuracy: 0.9946 - val_loss: 0.8776 - val_accuracy: 0.8710\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0209 - accuracy: 0.9982 - val_loss: 0.7902 - val_accuracy: 0.8387\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.8358 - val_accuracy: 0.8548\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.8849 - val_accuracy: 0.8387\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0180 - accuracy: 0.9964 - val_loss: 0.9682 - val_accuracy: 0.8065\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0207 - accuracy: 0.9946 - val_loss: 0.8544 - val_accuracy: 0.8387\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0773 - accuracy: 0.9731 - val_loss: 3.3551 - val_accuracy: 0.3710\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0363 - accuracy: 0.9892 - val_loss: 0.7494 - val_accuracy: 0.8226\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0295 - accuracy: 0.9910 - val_loss: 1.2696 - val_accuracy: 0.6290\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.9034 - val_accuracy: 0.8548\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.9533 - val_accuracy: 0.7903\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0151 - accuracy: 0.9982 - val_loss: 1.0509 - val_accuracy: 0.8065\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.9188 - val_accuracy: 0.8871\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.7581\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0108 - accuracy: 0.9982 - val_loss: 1.0031 - val_accuracy: 0.8871\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.8065\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0128 - val_accuracy: 0.8065\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0084 - accuracy: 0.9982 - val_loss: 1.0007 - val_accuracy: 0.8065\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.8065\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0083 - accuracy: 0.9982 - val_loss: 1.0811 - val_accuracy: 0.8065\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.9595 - val_accuracy: 0.8065\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.1202 - val_accuracy: 0.6935\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.0289 - val_accuracy: 0.8065\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0615 - val_accuracy: 0.8065\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.8710\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1297 - val_accuracy: 0.7903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0999 - val_accuracy: 0.8065\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0062 - accuracy: 0.9982 - val_loss: 1.7066 - val_accuracy: 0.6290\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9231 - val_accuracy: 0.8710\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.8496 - val_accuracy: 0.8226\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.7903\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9957 - val_accuracy: 0.8065\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1401 - val_accuracy: 0.7742\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2655 - val_accuracy: 0.7903\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1318 - val_accuracy: 0.8065\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0079 - accuracy: 0.9982 - val_loss: 1.2443 - val_accuracy: 0.7419\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1938 - val_accuracy: 0.8065\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0153 - accuracy: 0.9946 - val_loss: 1.0082 - val_accuracy: 0.8710\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0144 - accuracy: 0.9982 - val_loss: 1.5310 - val_accuracy: 0.6452\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0076 - accuracy: 0.9964 - val_loss: 1.1317 - val_accuracy: 0.8065\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.9718 - val_accuracy: 0.7097\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0070 - accuracy: 0.9982 - val_loss: 1.1770 - val_accuracy: 0.6935\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.8548\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.8226\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0042 - accuracy: 0.9982 - val_loss: 1.1880 - val_accuracy: 0.8387\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1884 - val_accuracy: 0.8065\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2349 - val_accuracy: 0.7903\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0112 - accuracy: 0.9946 - val_loss: 1.3629 - val_accuracy: 0.7581\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0170 - accuracy: 0.9982 - val_loss: 1.1176 - val_accuracy: 0.8226\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.4410 - val_accuracy: 0.7097\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5209 - val_accuracy: 0.7581\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0036 - accuracy: 0.9982 - val_loss: 1.1393 - val_accuracy: 0.8710\n",
      "Epoch 83/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4908 - val_accuracy: 0.6935\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0073 - accuracy: 0.9982 - val_loss: 1.4670 - val_accuracy: 0.7097\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0108 - accuracy: 0.9964 - val_loss: 1.2046 - val_accuracy: 0.8065\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0044 - accuracy: 0.9982 - val_loss: 1.1699 - val_accuracy: 0.8065\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2065 - val_accuracy: 0.8065\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 1.2745 - val_accuracy: 0.7742\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.8065\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.8548\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0833 - val_accuracy: 0.8387\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0773 - val_accuracy: 0.8065\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0039 - accuracy: 0.9982 - val_loss: 1.0338 - val_accuracy: 0.8065\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0029 - accuracy: 0.9982 - val_loss: 1.3006 - val_accuracy: 0.6935\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0230 - val_accuracy: 0.8387\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9942 - val_accuracy: 0.7419\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0184 - accuracy: 0.9964 - val_loss: 0.8138 - val_accuracy: 0.8226\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0127 - accuracy: 0.9946 - val_loss: 1.3461 - val_accuracy: 0.7903\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0093 - accuracy: 0.9946 - val_loss: 1.0350 - val_accuracy: 0.7581\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 2s 3ms/sample - loss: 0.0185 - accuracy: 0.9946 - val_loss: 1.0137 - val_accuracy: 0.8548\n",
      "accuracy for model 6 is 85.48387289047241\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 559 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "559/559 [==============================] - 18s 33ms/sample - loss: 1.0409 - accuracy: 0.6547 - val_loss: 6.7048 - val_accuracy: 0.6721\n",
      "Epoch 2/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.7439 - accuracy: 0.7800 - val_loss: 4.0181 - val_accuracy: 0.6721\n",
      "Epoch 3/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.6444 - accuracy: 0.8086 - val_loss: 1.2025 - val_accuracy: 0.8361\n",
      "Epoch 4/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.5750 - accuracy: 0.8211 - val_loss: 1.7188 - val_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.5534 - accuracy: 0.8193 - val_loss: 0.8838 - val_accuracy: 0.8525\n",
      "Epoch 6/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.4962 - accuracy: 0.8462 - val_loss: 0.5307 - val_accuracy: 0.8525\n",
      "Epoch 7/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.4573 - accuracy: 0.8533 - val_loss: 0.4178 - val_accuracy: 0.8852\n",
      "Epoch 8/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.4403 - accuracy: 0.8605 - val_loss: 0.4598 - val_accuracy: 0.8852\n",
      "Epoch 9/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.3762 - accuracy: 0.8640 - val_loss: 0.4811 - val_accuracy: 0.8525\n",
      "Epoch 10/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.3470 - accuracy: 0.8712 - val_loss: 0.5330 - val_accuracy: 0.8197\n",
      "Epoch 11/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.3196 - accuracy: 0.8801 - val_loss: 0.6626 - val_accuracy: 0.7705\n",
      "Epoch 12/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.3314 - accuracy: 0.8855 - val_loss: 0.5726 - val_accuracy: 0.7705\n",
      "Epoch 13/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.2508 - accuracy: 0.9088 - val_loss: 0.4327 - val_accuracy: 0.8852\n",
      "Epoch 14/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.2113 - accuracy: 0.9213 - val_loss: 0.7405 - val_accuracy: 0.8525\n",
      "Epoch 15/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.1855 - accuracy: 0.9284 - val_loss: 0.4277 - val_accuracy: 0.8689\n",
      "Epoch 16/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.1909 - accuracy: 0.9267 - val_loss: 0.4309 - val_accuracy: 0.8689\n",
      "Epoch 17/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.1541 - accuracy: 0.9428 - val_loss: 0.4782 - val_accuracy: 0.8689\n",
      "Epoch 18/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.1275 - accuracy: 0.9589 - val_loss: 0.4239 - val_accuracy: 0.8852\n",
      "Epoch 19/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.1056 - accuracy: 0.9678 - val_loss: 0.5020 - val_accuracy: 0.8852\n",
      "Epoch 20/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.1221 - accuracy: 0.9714 - val_loss: 0.4775 - val_accuracy: 0.8852\n",
      "Epoch 21/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0863 - accuracy: 0.9767 - val_loss: 0.5276 - val_accuracy: 0.8689\n",
      "Epoch 22/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0769 - accuracy: 0.9803 - val_loss: 0.5636 - val_accuracy: 0.8689\n",
      "Epoch 23/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0827 - accuracy: 0.9732 - val_loss: 0.5204 - val_accuracy: 0.8689\n",
      "Epoch 24/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0530 - accuracy: 0.9875 - val_loss: 0.7110 - val_accuracy: 0.8525\n",
      "Epoch 25/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0599 - accuracy: 0.9875 - val_loss: 0.5710 - val_accuracy: 0.8361\n",
      "Epoch 26/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0382 - accuracy: 0.9928 - val_loss: 0.5384 - val_accuracy: 0.8689\n",
      "Epoch 27/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0426 - accuracy: 0.9911 - val_loss: 0.6658 - val_accuracy: 0.8197\n",
      "Epoch 28/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0564 - accuracy: 0.9821 - val_loss: 0.5946 - val_accuracy: 0.8361\n",
      "Epoch 29/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.5927 - val_accuracy: 0.8689\n",
      "Epoch 30/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0323 - accuracy: 0.9928 - val_loss: 0.5869 - val_accuracy: 0.8525\n",
      "Epoch 31/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0406 - accuracy: 0.9857 - val_loss: 0.6620 - val_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0437 - accuracy: 0.9875 - val_loss: 0.7208 - val_accuracy: 0.8689\n",
      "Epoch 33/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.8136 - val_accuracy: 0.8689\n",
      "Epoch 34/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0190 - accuracy: 0.9982 - val_loss: 0.6554 - val_accuracy: 0.8689\n",
      "Epoch 35/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0268 - accuracy: 0.9946 - val_loss: 0.6072 - val_accuracy: 0.8525\n",
      "Epoch 36/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.8525\n",
      "Epoch 37/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0154 - accuracy: 0.9982 - val_loss: 0.6361 - val_accuracy: 0.8689\n",
      "Epoch 38/100\n",
      "559/559 [==============================] - 2s 4ms/sample - loss: 0.0297 - accuracy: 0.9946 - val_loss: 0.8661 - val_accuracy: 0.8033\n",
      "Epoch 39/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0213 - accuracy: 0.9964 - val_loss: 0.8559 - val_accuracy: 0.8852\n",
      "Epoch 40/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0248 - accuracy: 0.9946 - val_loss: 0.7461 - val_accuracy: 0.8852\n",
      "Epoch 41/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0283 - accuracy: 0.9893 - val_loss: 0.7859 - val_accuracy: 0.8361\n",
      "Epoch 42/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.6804 - val_accuracy: 0.8525\n",
      "Epoch 43/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.7254 - val_accuracy: 0.8852\n",
      "Epoch 44/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0313 - accuracy: 0.9928 - val_loss: 0.9251 - val_accuracy: 0.8197\n",
      "Epoch 45/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0154 - accuracy: 0.9946 - val_loss: 1.5812 - val_accuracy: 0.5574\n",
      "Epoch 46/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0145 - accuracy: 0.9982 - val_loss: 0.6482 - val_accuracy: 0.7869\n",
      "Epoch 47/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.6044 - val_accuracy: 0.8689\n",
      "Epoch 48/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0221 - accuracy: 0.9964 - val_loss: 0.7261 - val_accuracy: 0.8361\n",
      "Epoch 49/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0188 - accuracy: 0.9928 - val_loss: 0.7864 - val_accuracy: 0.8525\n",
      "Epoch 50/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.8679 - val_accuracy: 0.8689\n",
      "Epoch 51/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.7816 - val_accuracy: 0.8525\n",
      "Epoch 52/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.8423 - val_accuracy: 0.8361\n",
      "Epoch 53/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.8557 - val_accuracy: 0.8852\n",
      "Epoch 54/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.8689\n",
      "Epoch 55/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.8844 - val_accuracy: 0.8689\n",
      "Epoch 56/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.8068 - val_accuracy: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0201 - accuracy: 0.9946 - val_loss: 0.7044 - val_accuracy: 0.8525\n",
      "Epoch 58/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.8189 - val_accuracy: 0.8689\n",
      "Epoch 59/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.8974 - val_accuracy: 0.8525\n",
      "Epoch 60/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0152 - accuracy: 0.9982 - val_loss: 0.8821 - val_accuracy: 0.8197\n",
      "Epoch 61/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.8518 - val_accuracy: 0.8525\n",
      "Epoch 62/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0187 - accuracy: 0.9964 - val_loss: 0.8191 - val_accuracy: 0.8525\n",
      "Epoch 63/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8286 - val_accuracy: 0.8361\n",
      "Epoch 64/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0114 - accuracy: 0.9946 - val_loss: 0.8990 - val_accuracy: 0.8852\n",
      "Epoch 65/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.9642 - val_accuracy: 0.7705\n",
      "Epoch 66/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0209 - accuracy: 0.9911 - val_loss: 0.8837 - val_accuracy: 0.8197\n",
      "Epoch 67/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.8309 - val_accuracy: 0.8361\n",
      "Epoch 68/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.8977 - val_accuracy: 0.8852\n",
      "Epoch 69/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.8187 - val_accuracy: 0.8197\n",
      "Epoch 70/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.8309 - val_accuracy: 0.8361\n",
      "Epoch 71/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0118 - accuracy: 0.9982 - val_loss: 1.0160 - val_accuracy: 0.8197\n",
      "Epoch 72/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0101 - accuracy: 0.9946 - val_loss: 1.0121 - val_accuracy: 0.8197\n",
      "Epoch 73/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.9277 - val_accuracy: 0.8361\n",
      "Epoch 74/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0144 - accuracy: 0.9964 - val_loss: 1.0322 - val_accuracy: 0.8689\n",
      "Epoch 75/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0071 - accuracy: 0.9982 - val_loss: 1.0015 - val_accuracy: 0.8852\n",
      "Epoch 76/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.9109 - val_accuracy: 0.8033\n",
      "Epoch 77/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0099 - accuracy: 0.9982 - val_loss: 1.0442 - val_accuracy: 0.8852\n",
      "Epoch 78/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9737 - val_accuracy: 0.8852\n",
      "Epoch 79/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9201 - val_accuracy: 0.8689\n",
      "Epoch 80/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9367 - val_accuracy: 0.8689\n",
      "Epoch 81/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8900 - val_accuracy: 0.8689\n",
      "Epoch 82/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8377 - val_accuracy: 0.8689\n",
      "Epoch 83/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8635 - val_accuracy: 0.8852\n",
      "Epoch 84/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.8857 - val_accuracy: 0.8852\n",
      "Epoch 85/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.8835 - val_accuracy: 0.9016\n",
      "Epoch 86/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.8795 - val_accuracy: 0.8525\n",
      "Epoch 87/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0092 - accuracy: 0.9946 - val_loss: 0.8650 - val_accuracy: 0.8689\n",
      "Epoch 88/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.9209 - val_accuracy: 0.8525\n",
      "Epoch 89/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.9070 - val_accuracy: 0.8852\n",
      "Epoch 90/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0182 - accuracy: 0.9964 - val_loss: 0.9293 - val_accuracy: 0.8689\n",
      "Epoch 91/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.8499 - val_accuracy: 0.8197\n",
      "Epoch 92/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.8525\n",
      "Epoch 93/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.9592 - val_accuracy: 0.8689\n",
      "Epoch 94/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0117 - accuracy: 0.9928 - val_loss: 0.7444 - val_accuracy: 0.8361\n",
      "Epoch 95/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.7471 - val_accuracy: 0.8689\n",
      "Epoch 96/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.9383 - val_accuracy: 0.9016\n",
      "Epoch 97/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.9560 - val_accuracy: 0.8852\n",
      "Epoch 98/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0163 - accuracy: 0.9946 - val_loss: 1.2200 - val_accuracy: 0.7377\n",
      "Epoch 99/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0070 - accuracy: 0.9982 - val_loss: 1.5933 - val_accuracy: 0.8689\n",
      "Epoch 100/100\n",
      "559/559 [==============================] - 2s 3ms/sample - loss: 0.0117 - accuracy: 0.9964 - val_loss: 1.2885 - val_accuracy: 0.8197\n",
      "accuracy for model 7 is 81.96721076965332\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "560/560 [==============================] - 14s 26ms/sample - loss: 0.8327 - accuracy: 0.7661 - val_loss: 10.5102 - val_accuracy: 0.6833\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 4s 8ms/sample - loss: 0.6342 - accuracy: 0.8018 - val_loss: 7.8485 - val_accuracy: 0.6833\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.6264 - accuracy: 0.7946 - val_loss: 5.7412 - val_accuracy: 0.6833\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.5467 - accuracy: 0.8250 - val_loss: 2.9220 - val_accuracy: 0.6833\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.5028 - accuracy: 0.8339 - val_loss: 2.3070 - val_accuracy: 0.6833\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.4826 - accuracy: 0.8482 - val_loss: 1.2544 - val_accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.4211 - accuracy: 0.8696 - val_loss: 0.8500 - val_accuracy: 0.7333\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3640 - accuracy: 0.8821 - val_loss: 0.6616 - val_accuracy: 0.7833\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3132 - accuracy: 0.8786 - val_loss: 0.5701 - val_accuracy: 0.8167\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2843 - accuracy: 0.9054 - val_loss: 0.7565 - val_accuracy: 0.8167\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2388 - accuracy: 0.9179 - val_loss: 0.5731 - val_accuracy: 0.7833\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2117 - accuracy: 0.9179 - val_loss: 0.5509 - val_accuracy: 0.8167\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1871 - accuracy: 0.9304 - val_loss: 0.7572 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1877 - accuracy: 0.9304 - val_loss: 0.6699 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1738 - accuracy: 0.9357 - val_loss: 0.6207 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1590 - accuracy: 0.9375 - val_loss: 0.5420 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1201 - accuracy: 0.9589 - val_loss: 0.7198 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1019 - accuracy: 0.9679 - val_loss: 1.1466 - val_accuracy: 0.7333\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1124 - accuracy: 0.9589 - val_loss: 0.8721 - val_accuracy: 0.6500\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0896 - accuracy: 0.9732 - val_loss: 0.6653 - val_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0851 - accuracy: 0.9750 - val_loss: 1.1197 - val_accuracy: 0.7667\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0708 - accuracy: 0.9804 - val_loss: 1.1340 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0608 - accuracy: 0.9839 - val_loss: 0.8160 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0494 - accuracy: 0.9893 - val_loss: 0.9694 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0471 - accuracy: 0.9911 - val_loss: 0.8877 - val_accuracy: 0.8167\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0427 - accuracy: 0.9911 - val_loss: 1.0081 - val_accuracy: 0.7833\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.7323 - val_accuracy: 0.7333\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0242 - accuracy: 0.9946 - val_loss: 0.7128 - val_accuracy: 0.7833\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0580 - accuracy: 0.9857 - val_loss: 0.8490 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0522 - accuracy: 0.9857 - val_loss: 1.6440 - val_accuracy: 0.7167\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.7501 - val_accuracy: 0.7667\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0224 - accuracy: 0.9946 - val_loss: 0.7563 - val_accuracy: 0.7833\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0232 - accuracy: 0.9964 - val_loss: 0.8535 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0267 - accuracy: 0.9929 - val_loss: 0.9812 - val_accuracy: 0.7833\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.8791 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0142 - accuracy: 0.9982 - val_loss: 0.9759 - val_accuracy: 0.7833\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0168 - accuracy: 0.9982 - val_loss: 0.8817 - val_accuracy: 0.7833\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0210 - accuracy: 0.9964 - val_loss: 1.2894 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0416 - accuracy: 0.9875 - val_loss: 1.0220 - val_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0288 - accuracy: 0.9875 - val_loss: 1.0110 - val_accuracy: 0.7167\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0187 - accuracy: 0.9929 - val_loss: 1.0352 - val_accuracy: 0.8167\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.8399 - val_accuracy: 0.7833\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.8359 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0142 - accuracy: 0.9929 - val_loss: 0.8378 - val_accuracy: 0.8167\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0227 - accuracy: 0.9946 - val_loss: 0.8736 - val_accuracy: 0.7667\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.8210 - val_accuracy: 0.7000\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0400 - accuracy: 0.9839 - val_loss: 0.8158 - val_accuracy: 0.7667\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0434 - accuracy: 0.9893 - val_loss: 0.8283 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0409 - accuracy: 0.9875 - val_loss: 1.1583 - val_accuracy: 0.7667\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0379 - accuracy: 0.9893 - val_loss: 1.2709 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0131 - accuracy: 0.9964 - val_loss: 1.3930 - val_accuracy: 0.7167\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0907 - val_accuracy: 0.7333\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.9980 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.0178 - val_accuracy: 0.7833\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.9264 - val_accuracy: 0.7167\n",
      "Epoch 56/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0115 - accuracy: 0.9982 - val_loss: 1.8220 - val_accuracy: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0244 - accuracy: 0.9929 - val_loss: 1.2793 - val_accuracy: 0.7333\n",
      "Epoch 58/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0420 - accuracy: 0.9857 - val_loss: 1.3947 - val_accuracy: 0.7333\n",
      "Epoch 59/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0111 - accuracy: 0.9982 - val_loss: 1.3902 - val_accuracy: 0.7833\n",
      "Epoch 60/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.2872 - val_accuracy: 0.7833\n",
      "Epoch 61/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0120 - accuracy: 0.9964 - val_loss: 1.3780 - val_accuracy: 0.7667\n",
      "Epoch 62/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0133 - accuracy: 0.9964 - val_loss: 1.3738 - val_accuracy: 0.7833\n",
      "Epoch 63/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.9600 - val_accuracy: 0.7333\n",
      "Epoch 64/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0539 - val_accuracy: 0.7833\n",
      "Epoch 65/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0073 - accuracy: 0.9982 - val_loss: 1.3358 - val_accuracy: 0.7833\n",
      "Epoch 66/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0086 - accuracy: 0.9946 - val_loss: 1.4694 - val_accuracy: 0.7833\n",
      "Epoch 67/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0082 - accuracy: 0.9964 - val_loss: 1.0005 - val_accuracy: 0.7833\n",
      "Epoch 68/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0066 - accuracy: 0.9964 - val_loss: 1.1553 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0080 - accuracy: 0.9982 - val_loss: 1.2953 - val_accuracy: 0.7000\n",
      "Epoch 70/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0089 - accuracy: 0.9964 - val_loss: 1.2819 - val_accuracy: 0.7833\n",
      "Epoch 71/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 1.1548 - val_accuracy: 0.7333\n",
      "Epoch 72/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0091 - accuracy: 0.9964 - val_loss: 1.2535 - val_accuracy: 0.7667\n",
      "Epoch 73/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.4407 - val_accuracy: 0.7667\n",
      "Epoch 74/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5181 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0108 - accuracy: 0.9982 - val_loss: 1.3863 - val_accuracy: 0.7333\n",
      "Epoch 76/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3977 - val_accuracy: 0.7333\n",
      "Epoch 77/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3802 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0052 - accuracy: 0.9982 - val_loss: 1.3610 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 1.2646 - val_accuracy: 0.7833\n",
      "Epoch 80/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0099 - accuracy: 0.9964 - val_loss: 1.8773 - val_accuracy: 0.7167\n",
      "Epoch 81/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.4339 - val_accuracy: 0.7833\n",
      "Epoch 82/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0075 - accuracy: 0.9964 - val_loss: 1.1288 - val_accuracy: 0.8167\n",
      "Epoch 83/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0092 - accuracy: 0.9982 - val_loss: 1.2056 - val_accuracy: 0.8167\n",
      "Epoch 84/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3679 - val_accuracy: 0.7667\n",
      "Epoch 85/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 1.2284 - val_accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0041 - accuracy: 0.9982 - val_loss: 1.2038 - val_accuracy: 0.8000\n",
      "Epoch 87/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0090 - accuracy: 0.9964 - val_loss: 1.4217 - val_accuracy: 0.8167\n",
      "Epoch 88/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0074 - accuracy: 0.9982 - val_loss: 1.2853 - val_accuracy: 0.7667\n",
      "Epoch 89/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.6990 - val_accuracy: 0.7667\n",
      "Epoch 90/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0102 - accuracy: 0.9964 - val_loss: 1.1949 - val_accuracy: 0.7000\n",
      "Epoch 91/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0070 - accuracy: 0.9982 - val_loss: 1.1917 - val_accuracy: 0.7833\n",
      "Epoch 92/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2627 - val_accuracy: 0.7167\n",
      "Epoch 94/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0033 - accuracy: 0.9982 - val_loss: 1.1958 - val_accuracy: 0.7167\n",
      "Epoch 95/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.7333\n",
      "Epoch 96/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.7167\n",
      "Epoch 97/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2087 - val_accuracy: 0.7333\n",
      "Epoch 98/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 6.3593e-04 - accuracy: 1.0000 - val_loss: 1.3583 - val_accuracy: 0.7667\n",
      "Epoch 99/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 7.0290e-04 - accuracy: 1.0000 - val_loss: 1.3696 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6270 - val_accuracy: 0.7833\n",
      "accuracy for model 8 is 78.33333611488342\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "560/560 [==============================] - 16s 29ms/sample - loss: 1.0981 - accuracy: 0.5964 - val_loss: 2.4819 - val_accuracy: 0.6833\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.7334 - accuracy: 0.8018 - val_loss: 1.9478 - val_accuracy: 0.7167\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.5834 - accuracy: 0.8304 - val_loss: 1.6513 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.5284 - accuracy: 0.8304 - val_loss: 2.0859 - val_accuracy: 0.6833\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.5247 - accuracy: 0.8304 - val_loss: 1.1808 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.4711 - accuracy: 0.8482 - val_loss: 0.7739 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.4200 - accuracy: 0.8607 - val_loss: 0.7448 - val_accuracy: 0.7667\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3855 - accuracy: 0.8607 - val_loss: 0.8100 - val_accuracy: 0.7833\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3470 - accuracy: 0.8643 - val_loss: 0.6859 - val_accuracy: 0.7333\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3158 - accuracy: 0.8821 - val_loss: 0.8608 - val_accuracy: 0.7833\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3243 - accuracy: 0.8786 - val_loss: 1.6079 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2801 - accuracy: 0.8857 - val_loss: 0.9640 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2663 - accuracy: 0.8911 - val_loss: 1.0009 - val_accuracy: 0.7667\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2528 - accuracy: 0.8964 - val_loss: 0.7136 - val_accuracy: 0.7667\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2316 - accuracy: 0.9036 - val_loss: 1.4219 - val_accuracy: 0.7333\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2362 - accuracy: 0.8946 - val_loss: 1.5498 - val_accuracy: 0.7333\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2257 - accuracy: 0.9161 - val_loss: 0.8491 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1997 - accuracy: 0.9250 - val_loss: 0.8032 - val_accuracy: 0.7167\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1697 - accuracy: 0.9393 - val_loss: 1.4157 - val_accuracy: 0.7333\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1809 - accuracy: 0.9321 - val_loss: 0.8467 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1550 - accuracy: 0.9393 - val_loss: 0.8779 - val_accuracy: 0.6833\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1307 - accuracy: 0.9679 - val_loss: 1.4565 - val_accuracy: 0.7167\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1406 - accuracy: 0.9536 - val_loss: 0.9071 - val_accuracy: 0.5833\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1251 - accuracy: 0.9643 - val_loss: 1.6510 - val_accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1059 - accuracy: 0.9679 - val_loss: 1.1927 - val_accuracy: 0.6833\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1082 - accuracy: 0.9625 - val_loss: 1.6255 - val_accuracy: 0.7167\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0750 - accuracy: 0.9804 - val_loss: 1.0113 - val_accuracy: 0.5667\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0667 - accuracy: 0.9839 - val_loss: 1.4444 - val_accuracy: 0.7333\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0753 - accuracy: 0.9804 - val_loss: 1.4868 - val_accuracy: 0.7167\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0632 - accuracy: 0.9786 - val_loss: 1.5629 - val_accuracy: 0.7167\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0494 - accuracy: 0.9893 - val_loss: 1.8170 - val_accuracy: 0.7333\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0357 - accuracy: 0.9911 - val_loss: 1.5889 - val_accuracy: 0.7167\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0478 - accuracy: 0.9857 - val_loss: 1.4745 - val_accuracy: 0.7000\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0498 - accuracy: 0.9821 - val_loss: 1.2177 - val_accuracy: 0.6167\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0332 - accuracy: 0.9929 - val_loss: 1.6483 - val_accuracy: 0.7167\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0316 - accuracy: 0.9929 - val_loss: 1.5798 - val_accuracy: 0.7167\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0431 - accuracy: 0.9875 - val_loss: 1.7319 - val_accuracy: 0.7167\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0262 - accuracy: 0.9946 - val_loss: 1.7384 - val_accuracy: 0.7167\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0173 - accuracy: 0.9946 - val_loss: 1.9280 - val_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0250 - accuracy: 0.9911 - val_loss: 1.5116 - val_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0361 - accuracy: 0.9875 - val_loss: 1.6898 - val_accuracy: 0.6833\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0195 - accuracy: 0.9946 - val_loss: 1.6010 - val_accuracy: 0.7000\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0141 - accuracy: 0.9964 - val_loss: 1.7481 - val_accuracy: 0.7167\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0361 - accuracy: 0.9911 - val_loss: 1.4563 - val_accuracy: 0.6333\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0144 - accuracy: 0.9964 - val_loss: 2.5931 - val_accuracy: 0.7167\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0196 - accuracy: 0.9964 - val_loss: 1.5743 - val_accuracy: 0.6500\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0328 - accuracy: 0.9929 - val_loss: 2.0164 - val_accuracy: 0.7333\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0445 - accuracy: 0.9875 - val_loss: 1.9635 - val_accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0573 - accuracy: 0.9821 - val_loss: 1.3972 - val_accuracy: 0.6333\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0435 - accuracy: 0.9857 - val_loss: 1.1226 - val_accuracy: 0.7667\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0140 - accuracy: 0.9946 - val_loss: 1.6269 - val_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0218 - accuracy: 0.9929 - val_loss: 2.0286 - val_accuracy: 0.6333\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0205 - accuracy: 0.9929 - val_loss: 2.0167 - val_accuracy: 0.7000\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.8233 - val_accuracy: 0.7333\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0172 - accuracy: 0.9964 - val_loss: 1.9449 - val_accuracy: 0.7000\n",
      "Epoch 56/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0095 - accuracy: 0.9982 - val_loss: 1.9197 - val_accuracy: 0.7167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0152 - accuracy: 0.9964 - val_loss: 2.8481 - val_accuracy: 0.7167\n",
      "Epoch 58/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.9814 - val_accuracy: 0.7000\n",
      "Epoch 59/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.1390 - val_accuracy: 0.7167\n",
      "Epoch 60/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0105 - accuracy: 0.9946 - val_loss: 1.6868 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0106 - accuracy: 0.9964 - val_loss: 2.6258 - val_accuracy: 0.7000\n",
      "Epoch 62/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.2094 - val_accuracy: 0.7000\n",
      "Epoch 63/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.3879 - val_accuracy: 0.7333\n",
      "Epoch 64/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0074 - accuracy: 0.9982 - val_loss: 1.8112 - val_accuracy: 0.7333\n",
      "Epoch 65/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0200 - accuracy: 0.9929 - val_loss: 2.1086 - val_accuracy: 0.7000\n",
      "Epoch 66/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0096 - accuracy: 0.9964 - val_loss: 1.9465 - val_accuracy: 0.6833\n",
      "Epoch 67/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5374 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0202 - accuracy: 0.9964 - val_loss: 2.2099 - val_accuracy: 0.6833\n",
      "Epoch 69/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0199 - accuracy: 0.9929 - val_loss: 2.0637 - val_accuracy: 0.7000\n",
      "Epoch 70/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0199 - accuracy: 0.9911 - val_loss: 2.1026 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0200 - accuracy: 0.9929 - val_loss: 2.2132 - val_accuracy: 0.7000\n",
      "Epoch 72/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0137 - accuracy: 0.9964 - val_loss: 2.7300 - val_accuracy: 0.7167\n",
      "Epoch 73/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 2.4812 - val_accuracy: 0.7000\n",
      "Epoch 74/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0603 - val_accuracy: 0.6833\n",
      "Epoch 75/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0046 - accuracy: 0.9982 - val_loss: 2.0996 - val_accuracy: 0.6833\n",
      "Epoch 76/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0246 - accuracy: 0.9964 - val_loss: 2.0399 - val_accuracy: 0.6833\n",
      "Epoch 77/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1295 - val_accuracy: 0.7167\n",
      "Epoch 78/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0055 - accuracy: 0.9964 - val_loss: 2.7091 - val_accuracy: 0.7167\n",
      "Epoch 79/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5183 - val_accuracy: 0.7167\n",
      "Epoch 80/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.1635 - val_accuracy: 0.7167\n",
      "Epoch 81/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1024 - val_accuracy: 0.6833\n",
      "Epoch 82/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9239 - val_accuracy: 0.6833\n",
      "Epoch 83/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0069 - accuracy: 0.9982 - val_loss: 2.1227 - val_accuracy: 0.7167\n",
      "Epoch 84/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.0344 - val_accuracy: 0.7000\n",
      "Epoch 85/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8880 - val_accuracy: 0.6833\n",
      "Epoch 86/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4181 - val_accuracy: 0.7167\n",
      "Epoch 87/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4489 - val_accuracy: 0.7167\n",
      "Epoch 88/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0108 - accuracy: 0.9982 - val_loss: 2.8270 - val_accuracy: 0.7167\n",
      "Epoch 89/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0132 - accuracy: 0.9964 - val_loss: 2.0022 - val_accuracy: 0.7167\n",
      "Epoch 90/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9048 - val_accuracy: 0.7167\n",
      "Epoch 91/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 2.6104 - val_accuracy: 0.7000\n",
      "Epoch 92/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1787 - val_accuracy: 0.7000\n",
      "Epoch 93/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0072 - accuracy: 0.9982 - val_loss: 1.9771 - val_accuracy: 0.7333\n",
      "Epoch 94/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0125 - accuracy: 0.9946 - val_loss: 1.7407 - val_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0299 - accuracy: 0.9857 - val_loss: 2.5703 - val_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0137 - accuracy: 0.9964 - val_loss: 2.3242 - val_accuracy: 0.6500\n",
      "Epoch 97/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0183 - accuracy: 0.9964 - val_loss: 1.7205 - val_accuracy: 0.6167\n",
      "Epoch 98/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0095 - accuracy: 0.9982 - val_loss: 1.7225 - val_accuracy: 0.6500\n",
      "Epoch 99/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0167 - accuracy: 0.9911 - val_loss: 2.1827 - val_accuracy: 0.7167\n",
      "Epoch 100/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0138 - accuracy: 0.9964 - val_loss: 2.3065 - val_accuracy: 0.7000\n",
      "accuracy for model 9 is 69.9999988079071\n",
      "(620, 4)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 192)               119348736 \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 119,384,500\n",
      "Trainable params: 119,384,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "560/560 [==============================] - 23s 41ms/sample - loss: 1.0660 - accuracy: 0.6000 - val_loss: 14.2311 - val_accuracy: 0.6833\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.6545 - accuracy: 0.7768 - val_loss: 6.5999 - val_accuracy: 0.6833\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.6035 - accuracy: 0.8125 - val_loss: 2.5370 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.5626 - accuracy: 0.8179 - val_loss: 0.8571 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.4575 - accuracy: 0.8464 - val_loss: 1.7619 - val_accuracy: 0.7000\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.4333 - accuracy: 0.8429 - val_loss: 0.6663 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3720 - accuracy: 0.8732 - val_loss: 0.9162 - val_accuracy: 0.7167\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3469 - accuracy: 0.8714 - val_loss: 0.9035 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3558 - accuracy: 0.8750 - val_loss: 0.6095 - val_accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.3107 - accuracy: 0.8875 - val_loss: 0.9054 - val_accuracy: 0.6833\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2872 - accuracy: 0.8929 - val_loss: 0.6041 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2455 - accuracy: 0.9089 - val_loss: 0.6941 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2352 - accuracy: 0.9018 - val_loss: 0.7648 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2019 - accuracy: 0.9143 - val_loss: 0.8681 - val_accuracy: 0.7833\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.2111 - accuracy: 0.9232 - val_loss: 0.9516 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1823 - accuracy: 0.9339 - val_loss: 0.7661 - val_accuracy: 0.7833\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1658 - accuracy: 0.9429 - val_loss: 0.6978 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1342 - accuracy: 0.9500 - val_loss: 0.8177 - val_accuracy: 0.7000\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.1126 - accuracy: 0.9536 - val_loss: 0.7710 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0965 - accuracy: 0.9750 - val_loss: 0.9094 - val_accuracy: 0.6833\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0860 - accuracy: 0.9875 - val_loss: 0.8028 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0826 - accuracy: 0.9821 - val_loss: 0.9916 - val_accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0880 - accuracy: 0.9804 - val_loss: 0.7790 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0827 - accuracy: 0.9750 - val_loss: 0.7706 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0818 - accuracy: 0.9750 - val_loss: 0.9523 - val_accuracy: 0.6500\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0454 - accuracy: 0.9893 - val_loss: 1.0247 - val_accuracy: 0.7333\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0533 - accuracy: 0.9893 - val_loss: 0.8436 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0395 - accuracy: 0.9929 - val_loss: 1.0387 - val_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0433 - accuracy: 0.9946 - val_loss: 0.9866 - val_accuracy: 0.6333\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0329 - accuracy: 0.9946 - val_loss: 1.0398 - val_accuracy: 0.6833\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0312 - accuracy: 0.9929 - val_loss: 1.1028 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0612 - accuracy: 0.9786 - val_loss: 0.8925 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0532 - accuracy: 0.9821 - val_loss: 1.2940 - val_accuracy: 0.7333\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0255 - accuracy: 0.9964 - val_loss: 1.1528 - val_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0551 - accuracy: 0.9804 - val_loss: 1.5816 - val_accuracy: 0.5500\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0308 - accuracy: 0.9893 - val_loss: 1.2483 - val_accuracy: 0.7333\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0310 - accuracy: 0.9946 - val_loss: 1.1030 - val_accuracy: 0.7000\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0316 - accuracy: 0.9929 - val_loss: 1.1166 - val_accuracy: 0.7000\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0313 - accuracy: 0.9893 - val_loss: 1.1765 - val_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.1132 - val_accuracy: 0.7333\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0176 - accuracy: 0.9982 - val_loss: 1.2736 - val_accuracy: 0.7167\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0278 - accuracy: 0.9893 - val_loss: 1.5519 - val_accuracy: 0.5833\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0172 - accuracy: 0.9964 - val_loss: 1.5118 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0121 - accuracy: 0.9946 - val_loss: 1.2995 - val_accuracy: 0.7000\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4000 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.5627 - val_accuracy: 0.6500\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0145 - accuracy: 0.9964 - val_loss: 1.4743 - val_accuracy: 0.6500\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0113 - accuracy: 0.9982 - val_loss: 1.2897 - val_accuracy: 0.6833\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0183 - accuracy: 0.9964 - val_loss: 1.3428 - val_accuracy: 0.6333\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.5201 - val_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0219 - accuracy: 0.9929 - val_loss: 1.4203 - val_accuracy: 0.6167\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0276 - accuracy: 0.9911 - val_loss: 1.3511 - val_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0227 - accuracy: 0.9929 - val_loss: 1.4834 - val_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0108 - accuracy: 0.9982 - val_loss: 1.5303 - val_accuracy: 0.6500\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.4158 - val_accuracy: 0.7000\n",
      "Epoch 56/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4053 - val_accuracy: 0.6833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0205 - accuracy: 0.9946 - val_loss: 1.5170 - val_accuracy: 0.6500\n",
      "Epoch 58/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0097 - accuracy: 0.9982 - val_loss: 1.3883 - val_accuracy: 0.7167\n",
      "Epoch 59/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3605 - val_accuracy: 0.7167\n",
      "Epoch 60/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0203 - accuracy: 0.9946 - val_loss: 1.3557 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0215 - accuracy: 0.9946 - val_loss: 1.6577 - val_accuracy: 0.6167\n",
      "Epoch 62/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0150 - accuracy: 0.9946 - val_loss: 1.6132 - val_accuracy: 0.6833\n",
      "Epoch 63/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0088 - accuracy: 0.9982 - val_loss: 1.4943 - val_accuracy: 0.7333\n",
      "Epoch 64/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0150 - accuracy: 0.9929 - val_loss: 2.4162 - val_accuracy: 0.7167\n",
      "Epoch 65/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0144 - accuracy: 0.9964 - val_loss: 1.8040 - val_accuracy: 0.6333\n",
      "Epoch 66/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0124 - accuracy: 0.9946 - val_loss: 1.5209 - val_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 1.5069 - val_accuracy: 0.7000\n",
      "Epoch 68/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0226 - accuracy: 0.9929 - val_loss: 1.6794 - val_accuracy: 0.7167\n",
      "Epoch 69/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0176 - accuracy: 0.9929 - val_loss: 1.3535 - val_accuracy: 0.7833\n",
      "Epoch 70/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0233 - accuracy: 0.9929 - val_loss: 1.2522 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.7327 - val_accuracy: 0.7333\n",
      "Epoch 72/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0104 - accuracy: 0.9964 - val_loss: 1.6298 - val_accuracy: 0.5167\n",
      "Epoch 73/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 1.3618 - val_accuracy: 0.6500\n",
      "Epoch 74/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0160 - accuracy: 0.9946 - val_loss: 1.6270 - val_accuracy: 0.5833\n",
      "Epoch 75/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.5350 - val_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0091 - accuracy: 0.9964 - val_loss: 1.4963 - val_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4555 - val_accuracy: 0.6500\n",
      "Epoch 78/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6832 - val_accuracy: 0.7333\n",
      "Epoch 79/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0092 - accuracy: 0.9982 - val_loss: 1.6175 - val_accuracy: 0.7167\n",
      "Epoch 80/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0039 - accuracy: 0.9982 - val_loss: 1.6478 - val_accuracy: 0.6500\n",
      "Epoch 81/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7702 - val_accuracy: 0.7000\n",
      "Epoch 82/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0067 - accuracy: 0.9982 - val_loss: 1.6301 - val_accuracy: 0.7000\n",
      "Epoch 83/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0087 - accuracy: 0.9964 - val_loss: 1.7850 - val_accuracy: 0.7167\n",
      "Epoch 84/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0185 - accuracy: 0.9946 - val_loss: 1.5247 - val_accuracy: 0.7000\n",
      "Epoch 85/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3990 - val_accuracy: 0.7000\n",
      "Epoch 86/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0115 - accuracy: 0.9964 - val_loss: 1.5184 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0102 - accuracy: 0.9946 - val_loss: 1.5409 - val_accuracy: 0.7167\n",
      "Epoch 88/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0182 - accuracy: 0.9946 - val_loss: 2.3942 - val_accuracy: 0.7167\n",
      "Epoch 89/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0159 - accuracy: 0.9964 - val_loss: 1.4065 - val_accuracy: 0.6833\n",
      "Epoch 90/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 2.0050 - val_accuracy: 0.7167\n",
      "Epoch 91/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0147 - accuracy: 0.9964 - val_loss: 1.4083 - val_accuracy: 0.7167\n",
      "Epoch 92/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0080 - accuracy: 0.9964 - val_loss: 1.4814 - val_accuracy: 0.6833\n",
      "Epoch 93/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0073 - accuracy: 0.9964 - val_loss: 1.2361 - val_accuracy: 0.7667\n",
      "Epoch 94/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2719 - val_accuracy: 0.7833\n",
      "Epoch 95/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0043 - accuracy: 0.9982 - val_loss: 1.1845 - val_accuracy: 0.7833\n",
      "Epoch 96/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.0752 - val_accuracy: 0.7167\n",
      "Epoch 97/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0088 - accuracy: 0.9982 - val_loss: 1.6015 - val_accuracy: 0.6833\n",
      "Epoch 98/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1120 - val_accuracy: 0.5833\n",
      "Epoch 99/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0049 - accuracy: 0.9982 - val_loss: 1.3859 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "560/560 [==============================] - 2s 3ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4409 - val_accuracy: 0.7667\n",
      "accuracy for model 10 is 76.66666507720947\n",
      "Training Testing Accuracy: 81.04% (5.32%)\n"
     ]
    }
   ],
   "source": [
    "best_DNN = eval_dnn(tt_vcf, tt_pheno, 10, mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6f7025b4f06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_DNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SCC_DNN_model.pickle.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(best_DNN, open(\"SCC_DNN_model.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout accuracy is 83.87096524238586\n"
     ]
    }
   ],
   "source": [
    "bs = ((ho_vcf.shape[0])/40)\n",
    "bs = round(bs)\n",
    "ho_pheno = mlb.transform(ho_pheno)\n",
    "_, accuracy = best_DNN.evaluate(ho_vcf, ho_pheno, batch_size=bs, verbose=0)\n",
    "print(\"Holdout accuracy is \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in from file\n",
    "#boy did this get messy lmao\n",
    "my_list = []\n",
    "#import label and one hotencoders\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "#reads it in chunks\n",
    "x=0\n",
    "flag = 0\n",
    "#drop half the data for memory problems >:(\n",
    "for chunk in pd.read_csv(\"SCC_filtered_5pcnt.csv\", chunksize=500, index_col=\"Unnamed: 0\"):\n",
    "    x=x+500\n",
    "    chunk = chunk.T\n",
    "    #checks if its the last chunk as Value is the last column\n",
    "    if 'Value' in chunk.columns:\n",
    "        #does the selecting of pheno array for application ML\n",
    "        chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "        pheno = chunk[\"Value\"].to_numpy()\n",
    "        #reshapes it so its not a 1D array\n",
    "        print(pheno.shape)\n",
    "        pheno = np.reshape(pheno,(len(pheno),1))\n",
    "        print(pheno.shape)\n",
    "        chunk = chunk.drop(columns=['Value'])\n",
    "    #applies label and OHE to each chunk, won't include Value column as it'd been dropped\n",
    "    headers = chunk.columns\n",
    "    row_idx = chunk.index\n",
    "    chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "    chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "    chunk = chunk.apply(lambda col: le.fit_transform(col))\n",
    "    chunk = ohe.fit_transform(chunk)\n",
    "    print(chunk.shape)\n",
    "    if(flag==0):\n",
    "        my_list.append(chunk)\n",
    "        print(str(x))\n",
    "        flag = 1\n",
    "    else:\n",
    "        flag = 0\n",
    "#concats the chunks back in to prevent pandas having a heart attack\n",
    "#print(pheno.shape)\n",
    "#my_list.append(pheno)\n",
    "vcf = np.concatenate(my_list, axis = 1)\n",
    "print(vcf)\n",
    "print(pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the values into a onehot encoded array of each output\n",
    "#eg. a range of 0,1,2,3 for SCC is converted into 1,0,0,0  0,1,0,0  0,0,1,0  0,0,0,1\n",
    "mlb = MultiLabelBinarizer()\n",
    "pheno = mlb.fit_transform(pheno)\n",
    "print(pheno)\n",
    "print(pheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide up the training and testing data here\n",
    "X_train, X_test, y_train, y_test = train_test_split(vcf, pheno, test_size=0.2, random_state=27022013)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My own DNN model based upon paper\n",
    "#del model #incase its stored a previous model\n",
    "#del history #for redoing shit\n",
    "\n",
    "#do batch size as 64\n",
    "#reduce the inputs by half when you read it in\n",
    "#add XGboost and RF to the one notebook\n",
    "def DNN_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    #add first input layer, with no normalization\n",
    "    model.add(Dense(100, input_dim = X_train.shape[1], kernel_initializer='glorot_normal', activity_regularizer=l1(0.0001)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #add 21 hidden layers with l2 regularization and batch Normalization before activation\n",
    "    i = 0\n",
    "    while(i < 21):\n",
    "            model.add(Dense(50, kernel_initializer='glorot_normal', activity_regularizer=l2(0.0001)))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation('relu'))\n",
    "            i = i + 1\n",
    "\n",
    "    #add output layer\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=250, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test, batch_size=64, verbose=0)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf = vcf.reshape(vcf.shape[0], vcf.shape[1])\n",
    "pheno = pheno.reshape(pheno.shape[0], pheno.shape[1])\n",
    "estimator = KerasClassifier(build_fn=DNN_model, epochs=200, batch_size=64, verbose=1)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, vcf, pheno, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
