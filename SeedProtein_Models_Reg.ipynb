{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT STATMENTS FOR ALL MODLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.3)\n",
      "Requirement already satisfied: sklearn in ./.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: xgboost in ./.local/lib/python3.6/site-packages (1.3.1)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.6/site-packages (3.3.3)\n",
      "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0+nv)\n",
      "Requirement already satisfied: keras==2.2.4 in ./.local/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: fastai in ./.local/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (2.8.1)\n",
      "Requirement already satisfied: scikit-optimize in ./.local/lib/python3.6/site-packages (0.8.1)\n",
      "Requirement already satisfied: scikit-learn==0.21 in ./.local/lib/python3.6/site-packages (0.21.0)\n",
      "Requirement already satisfied: seaborn in ./.local/lib/python3.6/site-packages (0.11.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./.local/lib/python3.6/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./.local/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.local/lib/python3.6/site-packages (from matplotlib) (8.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.6/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.11.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: spacy in ./.local/lib/python3.6/site-packages (from fastai) (2.3.5)\n",
      "Requirement already satisfied: torch<1.8,>=1.7.0 in ./.local/lib/python3.6/site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastai) (20.0.2)\n",
      "Requirement already satisfied: torchvision<0.9,>=0.8 in ./.local/lib/python3.6/site-packages (from fastai) (0.8.2)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in ./.local/lib/python3.6/site-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.8 in ./.local/lib/python3.6/site-packages (from fastai) (1.3.18)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.6/site-packages (from fastai) (20.8)\n",
      "Requirement already satisfied: pyaml>=16.9 in ./.local/lib/python3.6/site-packages (from scikit-optimize) (20.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.6/site-packages (from scikit-optimize) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (46.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.11.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (7.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (0.7.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (2.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (4.43.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.6/site-packages (from spacy->fastai) (3.0.5)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.6/site-packages (from torch<1.8,>=1.7.0->fastai) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in ./.local/lib/python3.6/site-packages (from torch<1.8,>=1.7.0->fastai) (0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai) (1.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!TMPDIR=/home/mgill/ pip install --cache-dir=/home/mgill/ --build /home/mgill/ pandas numpy sklearn xgboost matplotlib tensorflow==2.1.0 keras==2.2.4 fastai python-dateutil scikit-optimize scikit-learn==0.21 seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Activation\n",
    "from math import sqrt\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.optimizers import Adam\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import interp\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_prep_data(tt_file, ho_file):\n",
    "    imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "    my_list = []\n",
    "    x = 0 \n",
    "    for chunk in pd.read_csv(tt_file, chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "        x=x+10000\n",
    "        chunk = chunk.T\n",
    "        if 'Value' in chunk.columns:\n",
    "            #does the selecting of pheno array for application ML\n",
    "            chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "            tt_pheno = chunk[\"Value\"].to_numpy()\n",
    "            #reshapes it so its not a 1D array\n",
    "            print(tt_pheno.shape)\n",
    "            tt_pheno = np.reshape(tt_pheno,(len(tt_pheno),1))\n",
    "            print(tt_pheno.shape)\n",
    "            chunk = chunk.drop(columns=['Value'])\n",
    "        headers = chunk.columns\n",
    "        row_idx = chunk.index\n",
    "        chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "        #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "        chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "        my_list.append(chunk)\n",
    "        print(x)\n",
    "    tt_vcf = pd.concat(my_list, axis = 1)\n",
    "    my_list = []\n",
    "    x=0\n",
    "    for chunk in pd.read_csv(ho_file, chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "        x=x+10000\n",
    "        chunk = chunk.T\n",
    "        if 'Value' in chunk.columns:\n",
    "            #does the selecting of pheno array for application ML\n",
    "            chunk[\"Value\"] = pd.to_numeric(chunk[\"Value\"], downcast=\"float\")\n",
    "            ho_pheno = chunk[\"Value\"].to_numpy()\n",
    "            #reshapes it so its not a 1D array\n",
    "            print(ho_pheno.shape)\n",
    "            ho_pheno = np.reshape(ho_pheno,(len(ho_pheno),1))\n",
    "            print(ho_pheno.shape)\n",
    "            chunk = chunk.drop(columns=['Value'])\n",
    "        headers = chunk.columns\n",
    "        row_idx = chunk.index\n",
    "        chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "        #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "        chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "        my_list.append(chunk)\n",
    "        print(x)\n",
    "    ho_vcf = pd.concat(my_list, axis = 1)\n",
    "    print(tt_vcf.shape)\n",
    "    print(ho_vcf.shape)\n",
    "    return tt_vcf, ho_vcf, tt_pheno, ho_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data(\"Pro_Merged_filtered.csv_train_test.csv_5pcnt.csv\", \"Pro_Merged_filtered.csv_holdout.csv_5pcnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "ohe = ohe.fit(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ohe, open(\"Pro_ohe.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if need or have new holdout data etc.\n",
    "ohe = pickle.load(open(\"Pro_ohe.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_snp_from_header(ohe,snp_num):\n",
    "    count = 0\n",
    "    snp = \"Not found\"\n",
    "    found = False\n",
    "    i = 0\n",
    "    while i < len(ohe.categories_) and (found == False):\n",
    "        j = 0\n",
    "        while j < len(ohe.categories_[i]):\n",
    "            if(count == snp_num):\n",
    "                snp = ohe.categories_[i][j]\n",
    "                found = True\n",
    "                break\n",
    "            count = count + 1\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    return snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING IF IT WORKS\n",
    "my_snp = find_snp_from_header(ohe, 108005)\n",
    "print(my_snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_vcf.shape)\n",
    "print(tt_pheno.shape)\n",
    "seed = randint(0,5000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tt_vcf, tt_pheno, test_size=0.2, random_state=seed)\n",
    "print(X_test.shape)\n",
    "print(\"seed is \" + str(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'max_depth': Integer(0, 50),\n",
    "        'max_delta_step': Integer(0, 20),\n",
    "        'subsample': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': Real(0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': Real(1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 5),\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'scale_pos_weight': Real(1e-6, 500, 'log-uniform')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    \"\"\"\n",
    "    Callback meant to view scores after\n",
    "    each iteration while performing Bayesian\n",
    "    Optimization in Skopt\"\"\"\n",
    "    score = xgb_bayes_search.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "    if score >= 0.98:\n",
    "        print('Interrupting!')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgbreg = xgb.XGBRegressor()\n",
    "xgb_bayes_search = BayesSearchCV(xgbreg, space, n_iter=32, # specify how many iterations\n",
    "                                    scoring=None, n_jobs=1, cv=5, verbose=3, random_state=42, n_points=12,\n",
    "                                 refit=True)\n",
    "xgb_bayes_search.fit(X_train, y_train.ravel(), callback = on_step)\n",
    "print(xgb_bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure all the data has remained the same\n",
    "np.isnan(X_train).any()\n",
    "np.isnan(y_train).any()\n",
    "\n",
    "np.isinf(X_train).any()\n",
    "np.isinf(y_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bayes_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##START HERE\n",
    "\n",
    "#xgbreg = xgb_bayes_search.best_estimator_ #xgb.XGBRegressor(#n_estimators=100, nthread=-1) \n",
    "#best_params = xgb_bayes_search.best_params_\n",
    "\n",
    "best_params = OrderedDict([('colsample_bylevel', 0.88542798001491),\n",
    "             ('colsample_bytree', 0.15107725561517718),\n",
    "             ('gamma', 0.09274068410384222),\n",
    "             ('learning_rate', 0.11437510345794359),\n",
    "             ('max_delta_step', 0),\n",
    "             ('max_depth', 6),\n",
    "             ('min_child_weight', 5),\n",
    "             ('n_estimators', 200),\n",
    "             ('reg_alpha', 1.2952579279714691e-08),\n",
    "             ('reg_lambda', 0.45707493844512304),\n",
    "             ('scale_pos_weight', 10.561837873121673),\n",
    "             ('subsample', 0.9105119208713889)])\n",
    "xgbreg = xgb.XGBRegressor(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgbreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_k_fold(m, x, y, k):\n",
    "    #model: xgboost model, should be with the best params available\n",
    "    #x: input data (eg. all samples and SNPS)\n",
    "    #y: labels\n",
    "    #k: number of folds for cross validation\n",
    "    cv = KFold(n_splits=k,shuffle=True)\n",
    "  #  fig1 = plt.figure(figsize=[12,12])\n",
    "\n",
    "   # tprs = []\n",
    "   # aucs = []\n",
    "    results = []\n",
    "   # mean_fpr = np.linspace(0,1,100)\n",
    "    low = 100\n",
    "    best = m\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        #print(y[test])\n",
    "        m.fit(x[train],y[train].ravel())\n",
    "        print(\"fitting done. Processing fold accuracy + checking best model\")\n",
    "        #predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        all_preds = [x for x in m.predict(x[test])]\n",
    "        ss = sqrt(mean_squared_error(all_preds, y[test]))\n",
    "        rr = r2_score(all_preds, y[test])\n",
    "        mm = np.mean(y[test])\n",
    "        error_mean = ((ss/mm)*100)\n",
    "        print(\"R^2 Value is: \" + str(rr))\n",
    "        print(\"RMSE for dataset is:\" +str(ss) + \"& mean of this fold is \" + str(mm))\n",
    "        print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")\n",
    "        if(error_mean < low):\n",
    "            low = error_mean\n",
    "            best = m\n",
    "        results.append(error_mean)\n",
    "        i= i+1\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = eval_k_fold(xgbreg, tt_vcf, tt_pheno, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = [x for x in best_model.predict(ho_vcf)]\n",
    "ss = sqrt(mean_squared_error(all_preds, ho_pheno))\n",
    "rr = r2_score(all_preds, ho_pheno)\n",
    "mm = np.mean(ho_pheno)\n",
    "error_mean = ((ss/mm)*100)\n",
    "print(\"R^2 Value of Holdout: %.2f\" % rr)\n",
    "print(\"RMSE of Holdout: %.2f\" % ss)\n",
    "print(\"Mean of Holdout: %.2f\" % mm)\n",
    "print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x, plot_y = list(), list()\n",
    "\n",
    "ho_pheno = ho_pheno.ravel()\n",
    "\n",
    "for counter, i in enumerate(ho_pheno):\n",
    "    if counter <= 5:\n",
    "        print(counter, i, all_preds[counter])\n",
    "    #zoom in a bit closer\n",
    "    if(all_preds[counter] > 9):\n",
    "        plot_x.append(i)\n",
    "        plot_y.append(all_preds[counter])\n",
    "    \n",
    "#plt.plot(plot_x, plot_y, '.')\n",
    "thisplot = pd.DataFrame({'Protein':plot_x, 'preds':plot_y})\n",
    "#sns.jointplot(x=\"Oil\", y=\"preds\", data=thisplot, kind='reg' , joint_kws={'scatter_kws': {'alpha': 0.2}})\n",
    "sns.regplot(x=\"Protein\", y=\"preds\", data=thisplot)\n",
    "plt.xlabel('Real Seed Protein %')\n",
    "plt.ylabel('Predicted Seed Protein %')\n",
    "plt.title(\"XGBoost Seed Protein Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open(\"Protein_kfold_10_XGB.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only load if not generated in same session\n",
    "best_model = pickle.load(open(\"Protein_kfold_10_XGB.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "#best_model = pickle.load(open(\"Oil_kfold_10_tt_from_all.pickle.dat\", \"rb\"))\n",
    "plt.figure(figsize = (20, 20))\n",
    "plot_importance(best_model, max_num_features=15, importance_type='gain', height=0.3)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function essentially returns an array of dataframe headers the length of OHE'd input SNPs for training data\n",
    "#EG. It will be able to determine that feature 357310 is Gm13_17683957 but not what allele it is\n",
    "#eg. feature 357309 357310 and 357311 may all be one hot encoded versions of all possible values of Gm13_17683957\n",
    "#iterating through the saved OHE will by able to determine what specific allele the feature is but cannot determine\n",
    "#what SNP header it belongs to. Therefore combining these two methods you can determine both allele and SNP\n",
    "snp = []\n",
    "imp = SimpleImputer(missing_values='./.', strategy='most_frequent')\n",
    "fs_ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "x = 0\n",
    "n_headers = []\n",
    "le = LabelEncoder()\n",
    "#while (i < 10):\n",
    "for chunk in pd.read_csv(\"Pro_Merged_filtered.csv_train_test.csv_5pcnt.csv\", chunksize=10000, index_col=\"Unnamed: 0\"):\n",
    "    chunk = chunk.T\n",
    "    if 'Value' in chunk.columns:\n",
    "        print(\"dropping value so it doesn't include that in headers\")\n",
    "        chunk = chunk.drop(columns=['Value'])\n",
    "    headers = chunk.columns\n",
    "    row_idx = chunk.index\n",
    "    chunk = imp.fit_transform(chunk) #SHOULD TURN ./. into the most common for each column\n",
    "    #since imputing makes a numpy array have to turn back into PD for label encoding\n",
    "    chunk = pd.DataFrame(data = chunk, index = row_idx, columns = headers)\n",
    "    chunk = chunk.apply(lambda col: le.fit_transform(col))\n",
    "    c_headers = chunk.columns\n",
    "    y = 0\n",
    "    for column in chunk:\n",
    "        d = (chunk[column].nunique())\n",
    "        n_headers.extend([c_headers[y] for i in range(d)])\n",
    "        #print(n_headers)\n",
    "        #print(l)\n",
    "        #n_headers.append(c_headers[y] * d)\n",
    "        #print(n_headers)\n",
    "        y = y + 1\n",
    "    #to double check that it would indeed be one hot encoded with this amount of columns\n",
    "    chunk = fs_ohe.fit_transform(chunk)\n",
    "    x = x + chunk.shape[1]\n",
    "    print(\"my X value is: \" + str(x))\n",
    "    print(chunk.shape)\n",
    "    print(\"my header list is: \" + str(len(n_headers)))\n",
    "print(len(n_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "snp_label = []\n",
    "fs = [307765,214473,469017,416842,468934,88673,468572,607723,96913,350580,61561,217747,608270,370000,480970]\n",
    "scores = [358.9,353.2,293.6,285.56,278,269.5,225,169.2,163.9,160.5,146,145.1,144.4,136.8,135.6]\n",
    "for jj in fs:\n",
    "    jj_allele = find_snp_from_header(ohe, jj)\n",
    "    this_snp = (n_headers[jj] + ' ('+str(jj_allele)+')')\n",
    "    print(this_snp)\n",
    "    snp_label.append(this_snp)\n",
    "snp_label.reverse()\n",
    "scores.reverse()\n",
    "print(len(scores))\n",
    "print(len(snp_label))\n",
    "plt.barh(snp_label,scores)\n",
    "plt.title('SNP Importance XGBoost Seed Protein')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = best_model.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_f_header(fn,n_headers,ohe):\n",
    "    fn = fn[1:]\n",
    "    fn = int(fn)\n",
    "    allele = find_snp_from_header(ohe, fn)\n",
    "    this_snp = (n_headers[fn] + ' ('+str(allele)+')')\n",
    "    return this_snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert feature to actual SNP name\n",
    "i = 0\n",
    "new_dict = {}\n",
    "for key in my_dict:\n",
    "    new_key = rename_f_header(key, n_headers, ohe)\n",
    "    new_dict[new_key] = my_dict[key]\n",
    "    i = i + 1\n",
    "    print(str(i))\n",
    "    if(my_dict):\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fi = pd.Series(new_dict)\n",
    "print(new_fi)\n",
    "df = new_fi.to_frame()\n",
    "df = df.rename(columns = {0:'F_Score(GAIN)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "indexes = df.nlargest(20, \"F_Score(GAIN)\").index\n",
    "values = df.nlargest(20, \"F_Score(GAIN)\").values.ravel()\n",
    "indexes = indexes[::-1]\n",
    "values = values[::-1]\n",
    "plt.barh(indexes, values)\n",
    "plt.title('SNP Importance XGBoost Seed Protein')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(10, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "indexes = df.nlargest(20, \"F_Score(GAIN)\").index\n",
    "values = df.nlargest(20, \"F_Score(GAIN)\").values.ravel()\n",
    "indexes = indexes[::-1]\n",
    "values = values[::-1]\n",
    "r_i = []\n",
    "r_v = []\n",
    "b_i = []\n",
    "b_v = []\n",
    "g_i = []\n",
    "g_v = []\n",
    "y_i = []\n",
    "y_v = []\n",
    "bl_i = []\n",
    "bl_v = []\n",
    "p_i = []\n",
    "p_v = []\n",
    "br_i = []\n",
    "br_v = []\n",
    "pu_i = []\n",
    "pu_v = []\n",
    "i = 0\n",
    "while i < len(indexes):\n",
    "    if('Gm16' in indexes[i]):\n",
    "        r_i.append(indexes[i])\n",
    "        r_v.append(values[i])\n",
    "    elif('Gm20' in indexes[i]):\n",
    "        b_i.append(indexes[i])\n",
    "        b_v.append(values[i])\n",
    "    elif('Gm15' in indexes[i]):\n",
    "        g_i.append(indexes[i])\n",
    "        g_v.append(values[i])\n",
    "    elif('Gm03' in indexes[i]):\n",
    "        y_i.append(indexes[i])\n",
    "        y_v.append(values[i])\n",
    "    elif('Gm08' in indexes[i]):\n",
    "        p_i.append(indexes[i])\n",
    "        p_v.append(values[i])\n",
    "    elif('Gm04' in indexes[i]):\n",
    "        br_i.append(indexes[i])\n",
    "        br_v.append(values[i])\n",
    "    elif('Gm13' in indexes[i]):\n",
    "        pu_i.append(indexes[i])\n",
    "        pu_v.append(values[i])\n",
    "    else:\n",
    "        bl_i.append(indexes[i])\n",
    "        bl_v.append(values[i])\n",
    "    i = i + 1\n",
    "plt.barh(bl_i, bl_v, color=\"black\")\n",
    "plt.barh(br_i, br_v, color=\"brown\")\n",
    "plt.barh(pu_i, pu_v, color=\"purple\")\n",
    "plt.barh(g_i, g_v, color=\"green\")\n",
    "plt.barh(y_i, y_v, color=\"yellow\")\n",
    "plt.barh(p_i, p_v, color=\"orange\")\n",
    "plt.barh(b_i, b_v, color=\"blue\")\n",
    "plt.barh(r_i, r_v, color=\"red\")\n",
    "plt.title('SNP Importance XGBoost Seed Protein')\n",
    "plt.ylabel('SNP Label')\n",
    "plt.xlabel('Relative F_Score (GAIN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data(\"Pro_Merged_filtered.csv_train_test.csv_5pcnt.csv\", \"Pro_Merged_filtered.csv_holdout.csv_5pcnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pickle.load(open(\"Pro_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=16, max_features = 'sqrt',n_jobs=-1, verbose = 1)\n",
    "#trains the model, and makes the y shape as (m,) instead of (m,1)\n",
    "#model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = eval_k_fold(model, tt_vcf, tt_pheno, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = [x for x in best_rf_model.predict(ho_vcf)]\n",
    "ss = sqrt(mean_squared_error(all_preds, ho_pheno))\n",
    "rr = r2_score(all_preds, ho_pheno)\n",
    "mm = np.mean(ho_pheno)\n",
    "error_mean = ((ss/mm)*100)\n",
    "print(\"R^2 Value of Holdout: %.2f\" % rr)\n",
    "print(\"RMSE of Holdout: %.2f\" % ss)\n",
    "print(\"Mean of Holdout: %.2f\" % mm)\n",
    "print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_rf_model, open(\"Protein_kfold_10_RF.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only load if not generated in same session\n",
    "best_rf_model = pickle.load(open(\"Protein_kfold_10_RF.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model (based upon Philipp's CNN + some changes from yield paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data('Pro_Merged_filtered.csv_train_test.csv_5pcnt.csv', 'Pro_Merged_filtered.csv_holdout.csv_5pcnt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pickle.load(open(\"Pro_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN_model(train_size):    \n",
    "    #del model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=14, \n",
    "                     input_shape=(train_size, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=10, kernel_size=10, \n",
    "                     input_shape=(12, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=8, kernel_size=8, \n",
    "                     input_shape=(10, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
    "\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, \n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_CNN(x, y, k):\n",
    "    #model: xgboost model, should be with the best params available\n",
    "    #x: input data (eg. all samples and SNPS)\n",
    "    #y: labels\n",
    "    #k: number of folds for cross validation\n",
    "    cv = KFold(n_splits=k,shuffle=True)\n",
    "  #  fig1 = plt.figure(figsize=[12,12])\n",
    "\n",
    "   # tprs = []\n",
    "   # aucs = []\n",
    "    results = []\n",
    "   # mean_fpr = np.linspace(0,1,100)\n",
    "    low = 100\n",
    "    best = []\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        m = build_CNN_model(x.shape[1])\n",
    "        print(\"Fold:\" + str(i))\n",
    "        x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "        bs = ((x[train].shape[0])/50)\n",
    "        bs = round(bs)\n",
    "        m.fit(x[train],y[train].ravel(), validation_data=(x[test], y[test]), epochs=100, batch_size=bs)\n",
    "        print(\"fitting done. Processing fold accuracy + checking best model\")\n",
    "        #predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        all_preds = [x for x in m.predict(x[test])]\n",
    "        ss = sqrt(mean_squared_error(all_preds, y[test]))\n",
    "        rr = r2_score(all_preds, y[test])\n",
    "        mm = np.mean(y[test])\n",
    "        error_mean = ((ss/mm)*100)\n",
    "        print(\"R^2 Value is: \" + str(rr))\n",
    "        print(\"RMSE for dataset is:\" +str(ss) + \"& mean of this fold is \" + str(mm))\n",
    "        print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")\n",
    "        if(error_mean < low):\n",
    "            low = error_mean\n",
    "            best = m\n",
    "        results.append(error_mean)\n",
    "        i= i+1\n",
    "        del m\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_model = build_CNN_model()\n",
    "best_model = eval_CNN(tt_vcf, tt_pheno, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open(\"Oil_kfold_10_CNN.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_CNN = pickle.load(open(\"Oil_kfold_10_CNN.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ho_vcf = ho_vcf.reshape(ho_vcf.shape[0], ho_vcf.shape[1], 1)\n",
    "all_preds = [x for x in best_model.predict(ho_vcf)]\n",
    "ss = sqrt(mean_squared_error(all_preds, ho_pheno))\n",
    "rr = r2_score(all_preds, ho_pheno)\n",
    "mm = np.mean(ho_pheno)\n",
    "error_mean = ((ss/mm)*100)\n",
    "print(\"R^2 Value of Holdout: %.2f\" % rr)\n",
    "print(\"RMSE of Holdout: %.2f\" % ss)\n",
    "print(\"Mean of Holdout: %.2f\" % mm)\n",
    "print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x, plot_y = list(), list()\n",
    "\n",
    "ho_pheno = ho_pheno.ravel()\n",
    "print(np.isinf(ho_pheno).any())\n",
    "print(np.isinf(all_preds).any())\n",
    "for counter, i in enumerate(ho_pheno):\n",
    "    if counter <= 5:\n",
    "        print(counter, i, all_preds[counter])\n",
    "    #zoom in a bit closer\n",
    "    if(all_preds[counter] > 9):\n",
    "        plot_x.append(i)\n",
    "        plot_y.append(all_preds[counter])\n",
    "    \n",
    "#plt.plot(plot_x, plot_y, '.')\n",
    "thisplot = pd.DataFrame({'Oil':plot_x, 'preds':plot_y})\n",
    "#sns.jointplot(x=\"Oil\", y=\"preds\", data=thisplot, kind='reg' , joint_kws={'scatter_kws': {'alpha': 0.2}})\n",
    "sns.regplot(x=\"Oil\", y=\"preds\", data=thisplot)\n",
    "plt.xlabel('Real Seed Oil %')\n",
    "plt.ylabel('Predicted Seed Oil %')\n",
    "plt.title(\"XGBoost Seed Oil Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(12, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "x_ax = range(len(ho_pheno))\n",
    "print(x_ax)\n",
    "plt.plot(x_ax, ho_pheno, label=\"Actual %\")\n",
    "plt.plot(x_ax, all_preds, label=\"Predicted %\") \n",
    "\n",
    "plt.title(\"Seed Oil % Predicted vs Actual\")\n",
    "plt.xlabel('Validation Sample')\n",
    "plt.ylabel('Seed Oil Percentage')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = [x[0] for x in model.predict(X_test)]\n",
    "sqrt(mean_squared_error(all_preds, y_test))\n",
    "r2_score(all_preds, y_test)\n",
    "vcf = vcf.reshape(vcf.shape[0], vcf.shape[1], 1)\n",
    "d = {'targs': [x for x in pheno], 'preds': [x[0] for x in model.predict(vcf)]}\n",
    "\n",
    "testdf = pd.DataFrame(data=d)\n",
    "testdf['minus'] = testdf['targs'] - testdf['preds']\n",
    "\n",
    "ss = sqrt(mean_squared_error(testdf[\"preds\"], testdf['targs']))\n",
    "mm = np.mean(pheno)\n",
    "print(\"RMSE for dataset is:\" +str(ss) + \"& pheno is \" + str(mm))\n",
    "print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN model\n",
    "#### Model Based upon: Crop Yield Prediction Using Deep Neural Networks(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "(753,)\n",
      "(753, 1)\n",
      "220000\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "(189,)\n",
      "(189, 1)\n",
      "220000\n",
      "(753, 213713)\n",
      "(189, 213713)\n"
     ]
    }
   ],
   "source": [
    "tt_vcf, ho_vcf, tt_pheno, ho_pheno = new_prep_data('Pro_Merged_filtered.csv_train_test.csv_5pcnt.csv', 'Pro_Merged_filtered.csv_holdout.csv_5pcnt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753, 620940)\n",
      "(189, 213713)\n",
      "(189, 620940)\n"
     ]
    }
   ],
   "source": [
    "ohe = pickle.load(open(\"Pro_ohe.dat\", \"rb\"))\n",
    "tt_vcf = ohe.transform(tt_vcf)\n",
    "print(tt_vcf.shape)\n",
    "print(ho_vcf.shape)\n",
    "ho_vcf = ohe.transform(ho_vcf)\n",
    "print(ho_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My own DNN model based upon paper\n",
    "#del model #incase its stored a previous model\n",
    "#del history #for redoing shit\n",
    "\n",
    "#do batch size as 64\n",
    "#reduce the inputs by half when you read it in\n",
    "#add XGboost and RF to the one notebook\n",
    "def build_DNN_model(x_len):\n",
    "    model = Sequential()\n",
    "\n",
    "    #add first input layer, with no normalization\n",
    "    model.add(Dense(200, input_dim = x_len))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.03))\n",
    "    \n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.02))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    #add output layer\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_DNN(x, y, k):\n",
    "    #model: xgboost model, should be with the best params available\n",
    "    #x: input data (eg. all samples and SNPS)\n",
    "    #y: labels\n",
    "    #k: number of folds for cross validation\n",
    "    cv = KFold(n_splits=k,shuffle=True)\n",
    "  #  fig1 = plt.figure(figsize=[12,12])\n",
    "\n",
    "   # tprs = []\n",
    "   # aucs = []\n",
    "    results = []\n",
    "   # mean_fpr = np.linspace(0,1,100)\n",
    "    low = 100\n",
    "    best = []\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        m = build_DNN_model(x.shape[1])\n",
    "        print(\"Fold:\" + str(i))\n",
    "        bs = ((x[train].shape[0])/50)\n",
    "        bs = round(bs)\n",
    "        m.fit(x[train],y[train].ravel(), validation_data=(x[test], y[test]), epochs=100, batch_size=bs)\n",
    "        print(\"fitting done. Processing fold accuracy + checking best model\")\n",
    "        #predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        all_preds = [x for x in m.predict(x[test])]\n",
    "        ss = sqrt(mean_squared_error(all_preds, y[test]))\n",
    "        rr = r2_score(all_preds, y[test])\n",
    "        mm = np.mean(y[test])\n",
    "        error_mean = ((ss/mm)*100)\n",
    "        print(\"R^2 Value is: \" + str(rr))\n",
    "        print(\"RMSE for dataset is:\" +str(ss) + \"& mean of this fold is \" + str(mm))\n",
    "        print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")\n",
    "        if(error_mean < low):\n",
    "            low = error_mean\n",
    "            best = m\n",
    "        results.append(error_mean)\n",
    "        i= i+1\n",
    "        del m\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:1\n",
      "Train on 677 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "677/677 [==============================] - 24s 35ms/sample - loss: 1758.7408 - root_mean_squared_error: 41.9373 - val_loss: 1038.1020 - val_root_mean_squared_error: 32.2196\n",
      "Epoch 2/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 1193.5111 - root_mean_squared_error: 34.5472 - val_loss: 380.8248 - val_root_mean_squared_error: 19.5147\n",
      "Epoch 3/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 454.7634 - root_mean_squared_error: 21.3252 - val_loss: 103.9697 - val_root_mean_squared_error: 10.1966\n",
      "Epoch 4/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 133.8716 - root_mean_squared_error: 11.5703 - val_loss: 33.3701 - val_root_mean_squared_error: 5.7767\n",
      "Epoch 5/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 131.8117 - root_mean_squared_error: 11.4809 - val_loss: 20.8301 - val_root_mean_squared_error: 4.5640\n",
      "Epoch 6/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 66.2614 - root_mean_squared_error: 8.1401 - val_loss: 21.6060 - val_root_mean_squared_error: 4.6482\n",
      "Epoch 7/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 95.3935 - root_mean_squared_error: 9.7670 - val_loss: 22.6471 - val_root_mean_squared_error: 4.7589\n",
      "Epoch 8/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 66.8452 - root_mean_squared_error: 8.1759 - val_loss: 22.6224 - val_root_mean_squared_error: 4.7563\n",
      "Epoch 9/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 61.4111 - root_mean_squared_error: 7.8365 - val_loss: 24.8878 - val_root_mean_squared_error: 4.9888\n",
      "Epoch 10/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 49.1419 - root_mean_squared_error: 7.0101 - val_loss: 37.9937 - val_root_mean_squared_error: 6.1639\n",
      "Epoch 11/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 45.3608 - root_mean_squared_error: 6.7350 - val_loss: 17.8990 - val_root_mean_squared_error: 4.2307\n",
      "Epoch 12/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 38.0055 - root_mean_squared_error: 6.1649 - val_loss: 11.3048 - val_root_mean_squared_error: 3.3623\n",
      "Epoch 13/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 32.5758 - root_mean_squared_error: 5.7075 - val_loss: 11.6656 - val_root_mean_squared_error: 3.4155\n",
      "Epoch 14/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 29.1024 - root_mean_squared_error: 5.3947 - val_loss: 14.4017 - val_root_mean_squared_error: 3.7950\n",
      "Epoch 15/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 28.6041 - root_mean_squared_error: 5.3483 - val_loss: 16.4969 - val_root_mean_squared_error: 4.0616\n",
      "Epoch 16/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 23.2412 - root_mean_squared_error: 4.8209 - val_loss: 15.3217 - val_root_mean_squared_error: 3.9143\n",
      "Epoch 17/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 22.3338 - root_mean_squared_error: 4.7259 - val_loss: 14.4938 - val_root_mean_squared_error: 3.8071\n",
      "Epoch 18/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 19.8020 - root_mean_squared_error: 4.4499 - val_loss: 8.1724 - val_root_mean_squared_error: 2.8587\n",
      "Epoch 19/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 15.2060 - root_mean_squared_error: 3.8995 - val_loss: 7.2424 - val_root_mean_squared_error: 2.6912\n",
      "Epoch 20/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 14.7615 - root_mean_squared_error: 3.8421 - val_loss: 6.9469 - val_root_mean_squared_error: 2.6357\n",
      "Epoch 21/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 11.5302 - root_mean_squared_error: 3.3956 - val_loss: 6.4376 - val_root_mean_squared_error: 2.5372\n",
      "Epoch 22/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 14.1414 - root_mean_squared_error: 3.7605 - val_loss: 7.3407 - val_root_mean_squared_error: 2.7094\n",
      "Epoch 23/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 13.1332 - root_mean_squared_error: 3.6240 - val_loss: 6.2998 - val_root_mean_squared_error: 2.5099\n",
      "Epoch 24/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 11.8601 - root_mean_squared_error: 3.4439 - val_loss: 6.2779 - val_root_mean_squared_error: 2.5056\n",
      "Epoch 25/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 10.4488 - root_mean_squared_error: 3.2325 - val_loss: 5.8239 - val_root_mean_squared_error: 2.4133\n",
      "Epoch 26/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 10.0158 - root_mean_squared_error: 3.1648 - val_loss: 6.1610 - val_root_mean_squared_error: 2.4821\n",
      "Epoch 27/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 10.9077 - root_mean_squared_error: 3.3027 - val_loss: 7.7202 - val_root_mean_squared_error: 2.7785\n",
      "Epoch 28/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 9.4119 - root_mean_squared_error: 3.0679 - val_loss: 6.1524 - val_root_mean_squared_error: 2.4804\n",
      "Epoch 29/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 9.8646 - root_mean_squared_error: 3.1408 - val_loss: 6.4457 - val_root_mean_squared_error: 2.5388\n",
      "Epoch 30/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.3947 - root_mean_squared_error: 2.8974 - val_loss: 5.4276 - val_root_mean_squared_error: 2.3297\n",
      "Epoch 31/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.8943 - root_mean_squared_error: 2.8097 - val_loss: 5.8850 - val_root_mean_squared_error: 2.4259\n",
      "Epoch 32/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.7778 - root_mean_squared_error: 2.7889 - val_loss: 6.8410 - val_root_mean_squared_error: 2.6155\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.3742 - root_mean_squared_error: 2.7155 - val_loss: 6.3556 - val_root_mean_squared_error: 2.5210\n",
      "Epoch 34/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.6718 - root_mean_squared_error: 2.7698 - val_loss: 5.6687 - val_root_mean_squared_error: 2.3809\n",
      "Epoch 35/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.9272 - root_mean_squared_error: 2.6319 - val_loss: 5.5979 - val_root_mean_squared_error: 2.3660\n",
      "Epoch 36/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.9470 - root_mean_squared_error: 2.8190 - val_loss: 5.8490 - val_root_mean_squared_error: 2.4185\n",
      "Epoch 37/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.5769 - root_mean_squared_error: 2.5645 - val_loss: 6.0165 - val_root_mean_squared_error: 2.4529\n",
      "Epoch 38/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.9091 - root_mean_squared_error: 2.6285 - val_loss: 5.9528 - val_root_mean_squared_error: 2.4398\n",
      "Epoch 39/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.4762 - root_mean_squared_error: 2.5448 - val_loss: 6.0351 - val_root_mean_squared_error: 2.4567\n",
      "Epoch 40/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.2287 - root_mean_squared_error: 2.4957 - val_loss: 5.7838 - val_root_mean_squared_error: 2.4049\n",
      "Epoch 41/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.0556 - root_mean_squared_error: 2.6562 - val_loss: 25.9061 - val_root_mean_squared_error: 5.0898\n",
      "Epoch 42/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.8971 - root_mean_squared_error: 2.9828 - val_loss: 12.1796 - val_root_mean_squared_error: 3.4899\n",
      "Epoch 43/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 9.2560 - root_mean_squared_error: 3.0424 - val_loss: 31.3086 - val_root_mean_squared_error: 5.5954\n",
      "Epoch 44/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 8.0107 - root_mean_squared_error: 2.8303 - val_loss: 11.5571 - val_root_mean_squared_error: 3.3996\n",
      "Epoch 45/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 7.3585 - root_mean_squared_error: 2.7127 - val_loss: 7.0198 - val_root_mean_squared_error: 2.6495\n",
      "Epoch 46/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.1990 - root_mean_squared_error: 2.4898 - val_loss: 5.9035 - val_root_mean_squared_error: 2.4297\n",
      "Epoch 47/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.8424 - root_mean_squared_error: 2.4171 - val_loss: 5.7870 - val_root_mean_squared_error: 2.4056\n",
      "Epoch 48/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.6112 - root_mean_squared_error: 2.3688 - val_loss: 5.6833 - val_root_mean_squared_error: 2.3840\n",
      "Epoch 49/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.4136 - root_mean_squared_error: 2.3267 - val_loss: 9.4939 - val_root_mean_squared_error: 3.0812\n",
      "Epoch 50/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.3869 - root_mean_squared_error: 2.7179 - val_loss: 12.4526 - val_root_mean_squared_error: 3.5288\n",
      "Epoch 51/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.0875 - root_mean_squared_error: 2.4673 - val_loss: 5.6566 - val_root_mean_squared_error: 2.3784\n",
      "Epoch 52/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.0414 - root_mean_squared_error: 2.4579 - val_loss: 5.6835 - val_root_mean_squared_error: 2.3840\n",
      "Epoch 53/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.6758 - root_mean_squared_error: 2.3824 - val_loss: 5.3708 - val_root_mean_squared_error: 2.3175\n",
      "Epoch 54/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.5672 - root_mean_squared_error: 2.3595 - val_loss: 5.5643 - val_root_mean_squared_error: 2.3589\n",
      "Epoch 55/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 4.6257 - root_mean_squared_error: 2.1507 - val_loss: 5.5815 - val_root_mean_squared_error: 2.3625\n",
      "Epoch 56/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 5.3562 - root_mean_squared_error: 2.3143 - val_loss: 5.6840 - val_root_mean_squared_error: 2.3841\n",
      "Epoch 57/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 4.6844 - root_mean_squared_error: 2.1644 - val_loss: 5.3929 - val_root_mean_squared_error: 2.3223\n",
      "Epoch 58/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.8085 - root_mean_squared_error: 2.1928 - val_loss: 6.2654 - val_root_mean_squared_error: 2.5031\n",
      "Epoch 59/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.4225 - root_mean_squared_error: 2.1030 - val_loss: 5.6310 - val_root_mean_squared_error: 2.3730\n",
      "Epoch 60/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.7664 - root_mean_squared_error: 2.1832 - val_loss: 8.6040 - val_root_mean_squared_error: 2.9333\n",
      "Epoch 61/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.5614 - root_mean_squared_error: 2.1357 - val_loss: 5.4855 - val_root_mean_squared_error: 2.3421\n",
      "Epoch 62/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 4.0930 - root_mean_squared_error: 2.0231 - val_loss: 7.8467 - val_root_mean_squared_error: 2.8012\n",
      "Epoch 63/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.4376 - root_mean_squared_error: 2.1066 - val_loss: 9.2495 - val_root_mean_squared_error: 3.0413\n",
      "Epoch 64/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.9471 - root_mean_squared_error: 1.9867 - val_loss: 5.9337 - val_root_mean_squared_error: 2.4359\n",
      "Epoch 65/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.8493 - root_mean_squared_error: 1.9620 - val_loss: 6.7975 - val_root_mean_squared_error: 2.6072\n",
      "Epoch 66/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.7584 - root_mean_squared_error: 1.9387 - val_loss: 6.1570 - val_root_mean_squared_error: 2.4813\n",
      "Epoch 67/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.6448 - root_mean_squared_error: 1.9091 - val_loss: 6.2109 - val_root_mean_squared_error: 2.4922\n",
      "Epoch 68/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.1704 - root_mean_squared_error: 1.7806 - val_loss: 6.2269 - val_root_mean_squared_error: 2.4954\n",
      "Epoch 69/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.4874 - root_mean_squared_error: 1.8675 - val_loss: 6.3270 - val_root_mean_squared_error: 2.5154\n",
      "Epoch 70/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.1869 - root_mean_squared_error: 1.7852 - val_loss: 5.8260 - val_root_mean_squared_error: 2.4137\n",
      "Epoch 71/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.7841 - root_mean_squared_error: 1.6686 - val_loss: 5.0918 - val_root_mean_squared_error: 2.2565\n",
      "Epoch 72/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.0644 - root_mean_squared_error: 1.7505 - val_loss: 6.0806 - val_root_mean_squared_error: 2.4659\n",
      "Epoch 73/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.7825 - root_mean_squared_error: 1.6681 - val_loss: 5.6434 - val_root_mean_squared_error: 2.3756\n",
      "Epoch 74/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.9875 - root_mean_squared_error: 1.7284 - val_loss: 6.3825 - val_root_mean_squared_error: 2.5264\n",
      "Epoch 75/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.5706 - root_mean_squared_error: 1.6033 - val_loss: 5.8367 - val_root_mean_squared_error: 2.4159\n",
      "Epoch 76/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.7714 - root_mean_squared_error: 1.6647 - val_loss: 6.8785 - val_root_mean_squared_error: 2.6227\n",
      "Epoch 77/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.1188 - root_mean_squared_error: 1.7660 - val_loss: 7.3544 - val_root_mean_squared_error: 2.7119\n",
      "Epoch 78/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.8776 - root_mean_squared_error: 1.6964 - val_loss: 5.5838 - val_root_mean_squared_error: 2.3630\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.5479 - root_mean_squared_error: 1.5962 - val_loss: 6.7730 - val_root_mean_squared_error: 2.6025\n",
      "Epoch 80/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.6843 - root_mean_squared_error: 1.6384 - val_loss: 5.5559 - val_root_mean_squared_error: 2.3571\n",
      "Epoch 81/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.0614 - root_mean_squared_error: 1.7497 - val_loss: 7.9882 - val_root_mean_squared_error: 2.8263\n",
      "Epoch 82/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.4620 - root_mean_squared_error: 1.5691 - val_loss: 6.4406 - val_root_mean_squared_error: 2.5378\n",
      "Epoch 83/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.2925 - root_mean_squared_error: 1.8145 - val_loss: 6.8125 - val_root_mean_squared_error: 2.6101\n",
      "Epoch 84/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.3182 - root_mean_squared_error: 1.5226 - val_loss: 6.1022 - val_root_mean_squared_error: 2.4703\n",
      "Epoch 85/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.5029 - root_mean_squared_error: 1.5821 - val_loss: 8.8803 - val_root_mean_squared_error: 2.9800\n",
      "Epoch 86/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.0062 - root_mean_squared_error: 1.4164 - val_loss: 5.7320 - val_root_mean_squared_error: 2.3942\n",
      "Epoch 87/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.7873 - root_mean_squared_error: 1.3369 - val_loss: 5.5308 - val_root_mean_squared_error: 2.3518\n",
      "Epoch 88/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.1249 - root_mean_squared_error: 1.4577 - val_loss: 6.1579 - val_root_mean_squared_error: 2.4815\n",
      "Epoch 89/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.0173 - root_mean_squared_error: 1.4203 - val_loss: 5.9482 - val_root_mean_squared_error: 2.4389\n",
      "Epoch 90/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.2746 - root_mean_squared_error: 1.5082 - val_loss: 7.3175 - val_root_mean_squared_error: 2.7051\n",
      "Epoch 91/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.4811 - root_mean_squared_error: 1.5751 - val_loss: 5.7666 - val_root_mean_squared_error: 2.4014\n",
      "Epoch 92/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.0828 - root_mean_squared_error: 1.4432 - val_loss: 5.8489 - val_root_mean_squared_error: 2.4184\n",
      "Epoch 93/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.5025 - root_mean_squared_error: 1.5819 - val_loss: 5.4861 - val_root_mean_squared_error: 2.3423\n",
      "Epoch 94/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.8529 - root_mean_squared_error: 1.3612 - val_loss: 5.4277 - val_root_mean_squared_error: 2.3298\n",
      "Epoch 95/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.2960 - root_mean_squared_error: 1.5153 - val_loss: 5.7063 - val_root_mean_squared_error: 2.3888\n",
      "Epoch 96/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.4223 - root_mean_squared_error: 1.5564 - val_loss: 12.6754 - val_root_mean_squared_error: 3.5603\n",
      "Epoch 97/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.7059 - root_mean_squared_error: 1.6450 - val_loss: 5.7619 - val_root_mean_squared_error: 2.4004\n",
      "Epoch 98/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.1914 - root_mean_squared_error: 1.4803 - val_loss: 5.8782 - val_root_mean_squared_error: 2.4245\n",
      "Epoch 99/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.0163 - root_mean_squared_error: 1.4200 - val_loss: 5.7163 - val_root_mean_squared_error: 2.3909\n",
      "Epoch 100/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.7250 - root_mean_squared_error: 1.3134 - val_loss: 6.3675 - val_root_mean_squared_error: 2.5234\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -0.26417962861997135\n",
      "RMSE for dataset is:2.523392242876139& mean of this fold is 44.67763\n",
      "this is 5.647999155364537% of the mean pheno data\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:2\n",
      "Train on 677 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "677/677 [==============================] - 13s 19ms/sample - loss: 1793.6444 - root_mean_squared_error: 42.3514 - val_loss: 1094.0235 - val_root_mean_squared_error: 33.0760\n",
      "Epoch 2/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1355.4657 - root_mean_squared_error: 36.8167 - val_loss: 570.9701 - val_root_mean_squared_error: 23.8950\n",
      "Epoch 3/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 654.8430 - root_mean_squared_error: 25.5899 - val_loss: 1396.9131 - val_root_mean_squared_error: 37.3753\n",
      "Epoch 4/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 251.8631 - root_mean_squared_error: 15.8702 - val_loss: 1177.9978 - val_root_mean_squared_error: 34.3220\n",
      "Epoch 5/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 175.7572 - root_mean_squared_error: 13.2573 - val_loss: 700.6247 - val_root_mean_squared_error: 26.4693\n",
      "Epoch 6/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 124.9143 - root_mean_squared_error: 11.1765 - val_loss: 110.2146 - val_root_mean_squared_error: 10.4983\n",
      "Epoch 7/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 116.3273 - root_mean_squared_error: 10.7855 - val_loss: 24.3053 - val_root_mean_squared_error: 4.9300\n",
      "Epoch 8/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 89.5668 - root_mean_squared_error: 9.4640 - val_loss: 33.4348 - val_root_mean_squared_error: 5.7823\n",
      "Epoch 9/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 60.2101 - root_mean_squared_error: 7.7595 - val_loss: 19.5299 - val_root_mean_squared_error: 4.4193\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 2s 4ms/sample - loss: 60.8029 - root_mean_squared_error: 7.7976 - val_loss: 17.5687 - val_root_mean_squared_error: 4.1915\n",
      "Epoch 11/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 58.4784 - root_mean_squared_error: 7.6471 - val_loss: 26.9720 - val_root_mean_squared_error: 5.1935\n",
      "Epoch 12/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 43.2538 - root_mean_squared_error: 6.5768 - val_loss: 29.0390 - val_root_mean_squared_error: 5.3888\n",
      "Epoch 13/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 35.9471 - root_mean_squared_error: 5.9956 - val_loss: 33.0134 - val_root_mean_squared_error: 5.7457\n",
      "Epoch 14/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 27.3686 - root_mean_squared_error: 5.2315 - val_loss: 12.2757 - val_root_mean_squared_error: 3.5037\n",
      "Epoch 15/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 28.4022 - root_mean_squared_error: 5.3294 - val_loss: 21.7330 - val_root_mean_squared_error: 4.6619\n",
      "Epoch 16/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 25.3727 - root_mean_squared_error: 5.0371 - val_loss: 30.9537 - val_root_mean_squared_error: 5.5636\n",
      "Epoch 17/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 20.4273 - root_mean_squared_error: 4.5197 - val_loss: 15.5135 - val_root_mean_squared_error: 3.9387\n",
      "Epoch 18/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 17.8362 - root_mean_squared_error: 4.2233 - val_loss: 13.3326 - val_root_mean_squared_error: 3.6514\n",
      "Epoch 19/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 18.4574 - root_mean_squared_error: 4.2962 - val_loss: 7.4477 - val_root_mean_squared_error: 2.7291\n",
      "Epoch 20/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 18.6327 - root_mean_squared_error: 4.3166 - val_loss: 7.6135 - val_root_mean_squared_error: 2.7593\n",
      "Epoch 21/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 15.8990 - root_mean_squared_error: 3.9874 - val_loss: 7.8246 - val_root_mean_squared_error: 2.7972\n",
      "Epoch 22/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 12.0787 - root_mean_squared_error: 3.4754 - val_loss: 11.2480 - val_root_mean_squared_error: 3.3538\n",
      "Epoch 23/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 12.9666 - root_mean_squared_error: 3.6009 - val_loss: 7.4480 - val_root_mean_squared_error: 2.7291\n",
      "Epoch 24/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 12.3668 - root_mean_squared_error: 3.5166 - val_loss: 8.4786 - val_root_mean_squared_error: 2.9118\n",
      "Epoch 25/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 13.4633 - root_mean_squared_error: 3.6692 - val_loss: 6.6099 - val_root_mean_squared_error: 2.5710\n",
      "Epoch 26/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 12.6526 - root_mean_squared_error: 3.5570 - val_loss: 7.3952 - val_root_mean_squared_error: 2.7194\n",
      "Epoch 27/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 11.8423 - root_mean_squared_error: 3.4413 - val_loss: 6.8204 - val_root_mean_squared_error: 2.6116\n",
      "Epoch 28/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 11.6940 - root_mean_squared_error: 3.4197 - val_loss: 9.0484 - val_root_mean_squared_error: 3.0081\n",
      "Epoch 29/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 10.5032 - root_mean_squared_error: 3.2409 - val_loss: 7.7044 - val_root_mean_squared_error: 2.7757\n",
      "Epoch 30/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 9.3795 - root_mean_squared_error: 3.0626 - val_loss: 13.6721 - val_root_mean_squared_error: 3.6976\n",
      "Epoch 31/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 9.6858 - root_mean_squared_error: 3.1122 - val_loss: 8.3007 - val_root_mean_squared_error: 2.8811\n",
      "Epoch 32/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 9.3405 - root_mean_squared_error: 3.0562 - val_loss: 7.1097 - val_root_mean_squared_error: 2.6664\n",
      "Epoch 33/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 9.3812 - root_mean_squared_error: 3.0629 - val_loss: 6.9776 - val_root_mean_squared_error: 2.6415\n",
      "Epoch 34/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.9515 - root_mean_squared_error: 2.8198 - val_loss: 6.1792 - val_root_mean_squared_error: 2.4858\n",
      "Epoch 35/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.7137 - root_mean_squared_error: 2.9519 - val_loss: 9.4044 - val_root_mean_squared_error: 3.0667\n",
      "Epoch 36/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.1229 - root_mean_squared_error: 2.8501 - val_loss: 6.4367 - val_root_mean_squared_error: 2.5371\n",
      "Epoch 37/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.8878 - root_mean_squared_error: 2.9812 - val_loss: 8.5784 - val_root_mean_squared_error: 2.9289\n",
      "Epoch 38/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.2380 - root_mean_squared_error: 2.8702 - val_loss: 6.5906 - val_root_mean_squared_error: 2.5672\n",
      "Epoch 39/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.3007 - root_mean_squared_error: 2.8811 - val_loss: 7.4220 - val_root_mean_squared_error: 2.7243\n",
      "Epoch 40/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.8478 - root_mean_squared_error: 2.8014 - val_loss: 7.0450 - val_root_mean_squared_error: 2.6543\n",
      "Epoch 41/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.2831 - root_mean_squared_error: 2.6987 - val_loss: 7.1798 - val_root_mean_squared_error: 2.6795\n",
      "Epoch 42/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.0928 - root_mean_squared_error: 2.6632 - val_loss: 6.7618 - val_root_mean_squared_error: 2.6003\n",
      "Epoch 43/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.6987 - root_mean_squared_error: 2.7747 - val_loss: 6.9761 - val_root_mean_squared_error: 2.6412\n",
      "Epoch 44/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.3571 - root_mean_squared_error: 2.5213 - val_loss: 6.4512 - val_root_mean_squared_error: 2.5399\n",
      "Epoch 45/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.7161 - root_mean_squared_error: 2.5915 - val_loss: 7.9315 - val_root_mean_squared_error: 2.8163\n",
      "Epoch 46/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.8051 - root_mean_squared_error: 2.4094 - val_loss: 5.9913 - val_root_mean_squared_error: 2.4477\n",
      "Epoch 47/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.2498 - root_mean_squared_error: 2.2912 - val_loss: 9.1815 - val_root_mean_squared_error: 3.0301\n",
      "Epoch 48/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.9695 - root_mean_squared_error: 2.4433 - val_loss: 6.0839 - val_root_mean_squared_error: 2.4666\n",
      "Epoch 49/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.9778 - root_mean_squared_error: 2.4449 - val_loss: 6.3615 - val_root_mean_squared_error: 2.5222\n",
      "Epoch 50/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.9389 - root_mean_squared_error: 2.4370 - val_loss: 10.0052 - val_root_mean_squared_error: 3.1631\n",
      "Epoch 51/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.0312 - root_mean_squared_error: 2.4558 - val_loss: 6.8474 - val_root_mean_squared_error: 2.6168\n",
      "Epoch 52/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.7401 - root_mean_squared_error: 2.1772 - val_loss: 7.8866 - val_root_mean_squared_error: 2.8083\n",
      "Epoch 53/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.7492 - root_mean_squared_error: 2.1793 - val_loss: 10.9287 - val_root_mean_squared_error: 3.3059\n",
      "Epoch 54/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.0337 - root_mean_squared_error: 2.2436 - val_loss: 9.2980 - val_root_mean_squared_error: 3.0493\n",
      "Epoch 55/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.3979 - root_mean_squared_error: 2.3233 - val_loss: 8.2061 - val_root_mean_squared_error: 2.8646\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.1673 - root_mean_squared_error: 2.2732 - val_loss: 14.5998 - val_root_mean_squared_error: 3.8210\n",
      "Epoch 57/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.9578 - root_mean_squared_error: 2.2266 - val_loss: 7.3293 - val_root_mean_squared_error: 2.7073\n",
      "Epoch 58/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.9930 - root_mean_squared_error: 2.2345 - val_loss: 5.9636 - val_root_mean_squared_error: 2.4420\n",
      "Epoch 59/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.2375 - root_mean_squared_error: 2.0585 - val_loss: 5.6023 - val_root_mean_squared_error: 2.3669\n",
      "Epoch 60/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.0072 - root_mean_squared_error: 2.2377 - val_loss: 8.0985 - val_root_mean_squared_error: 2.8458\n",
      "Epoch 61/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.3672 - root_mean_squared_error: 2.0898 - val_loss: 7.7881 - val_root_mean_squared_error: 2.7907\n",
      "Epoch 62/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.1773 - root_mean_squared_error: 2.0438 - val_loss: 6.7971 - val_root_mean_squared_error: 2.6071\n",
      "Epoch 63/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.8828 - root_mean_squared_error: 1.9705 - val_loss: 5.6833 - val_root_mean_squared_error: 2.3840\n",
      "Epoch 64/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.0773 - root_mean_squared_error: 2.0192 - val_loss: 5.8889 - val_root_mean_squared_error: 2.4267\n",
      "Epoch 65/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.8036 - root_mean_squared_error: 1.9503 - val_loss: 8.2489 - val_root_mean_squared_error: 2.8721\n",
      "Epoch 66/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.8551 - root_mean_squared_error: 1.9634 - val_loss: 8.3375 - val_root_mean_squared_error: 2.8875\n",
      "Epoch 67/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.2001 - root_mean_squared_error: 1.7889 - val_loss: 7.3236 - val_root_mean_squared_error: 2.7062\n",
      "Epoch 68/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.5931 - root_mean_squared_error: 1.8956 - val_loss: 9.0781 - val_root_mean_squared_error: 3.0130\n",
      "Epoch 69/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.3673 - root_mean_squared_error: 1.8350 - val_loss: 6.5896 - val_root_mean_squared_error: 2.5670\n",
      "Epoch 70/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.3023 - root_mean_squared_error: 1.8172 - val_loss: 5.9507 - val_root_mean_squared_error: 2.4394\n",
      "Epoch 71/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.8061 - root_mean_squared_error: 1.6751 - val_loss: 8.8253 - val_root_mean_squared_error: 2.9707\n",
      "Epoch 72/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.9004 - root_mean_squared_error: 1.7031 - val_loss: 6.5866 - val_root_mean_squared_error: 2.5664\n",
      "Epoch 73/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.8008 - root_mean_squared_error: 1.6736 - val_loss: 6.5251 - val_root_mean_squared_error: 2.5544\n",
      "Epoch 74/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.7717 - root_mean_squared_error: 1.6648 - val_loss: 9.3557 - val_root_mean_squared_error: 3.0587\n",
      "Epoch 75/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.6425 - root_mean_squared_error: 1.6256 - val_loss: 6.3093 - val_root_mean_squared_error: 2.5118\n",
      "Epoch 76/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.6698 - root_mean_squared_error: 1.9157 - val_loss: 7.9697 - val_root_mean_squared_error: 2.8231\n",
      "Epoch 77/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.5798 - root_mean_squared_error: 1.6062 - val_loss: 6.8676 - val_root_mean_squared_error: 2.6206\n",
      "Epoch 78/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.5017 - root_mean_squared_error: 1.5817 - val_loss: 5.7957 - val_root_mean_squared_error: 2.4074\n",
      "Epoch 79/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.6112 - root_mean_squared_error: 1.6159 - val_loss: 10.0089 - val_root_mean_squared_error: 3.1637\n",
      "Epoch 80/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.6506 - root_mean_squared_error: 1.6281 - val_loss: 5.8999 - val_root_mean_squared_error: 2.4290\n",
      "Epoch 81/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.3106 - root_mean_squared_error: 1.5201 - val_loss: 7.1794 - val_root_mean_squared_error: 2.6794\n",
      "Epoch 82/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.7584 - root_mean_squared_error: 1.9387 - val_loss: 37.5055 - val_root_mean_squared_error: 6.1242\n",
      "Epoch 83/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.7422 - root_mean_squared_error: 1.9345 - val_loss: 6.2758 - val_root_mean_squared_error: 2.5051\n",
      "Epoch 84/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.8332 - root_mean_squared_error: 1.6832 - val_loss: 7.7209 - val_root_mean_squared_error: 2.7786\n",
      "Epoch 85/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.4136 - root_mean_squared_error: 1.5536 - val_loss: 7.6777 - val_root_mean_squared_error: 2.7709\n",
      "Epoch 86/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.7743 - root_mean_squared_error: 1.6656 - val_loss: 8.3870 - val_root_mean_squared_error: 2.8960\n",
      "Epoch 87/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.0304 - root_mean_squared_error: 1.7408 - val_loss: 9.3468 - val_root_mean_squared_error: 3.0573\n",
      "Epoch 88/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.8352 - root_mean_squared_error: 1.3547 - val_loss: 8.4352 - val_root_mean_squared_error: 2.9043\n",
      "Epoch 89/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.2588 - root_mean_squared_error: 1.5029 - val_loss: 7.4328 - val_root_mean_squared_error: 2.7263\n",
      "Epoch 90/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.0854 - root_mean_squared_error: 1.4441 - val_loss: 6.1501 - val_root_mean_squared_error: 2.4799\n",
      "Epoch 91/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.0969 - root_mean_squared_error: 1.4481 - val_loss: 7.0236 - val_root_mean_squared_error: 2.6502\n",
      "Epoch 92/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.2432 - root_mean_squared_error: 1.4977 - val_loss: 5.8430 - val_root_mean_squared_error: 2.4172\n",
      "Epoch 93/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.6755 - root_mean_squared_error: 1.2944 - val_loss: 6.2451 - val_root_mean_squared_error: 2.4990\n",
      "Epoch 94/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.9682 - root_mean_squared_error: 1.4029 - val_loss: 5.8342 - val_root_mean_squared_error: 2.4154\n",
      "Epoch 95/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.8885 - root_mean_squared_error: 1.3742 - val_loss: 6.0034 - val_root_mean_squared_error: 2.4502\n",
      "Epoch 96/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.8717 - root_mean_squared_error: 1.3681 - val_loss: 6.3478 - val_root_mean_squared_error: 2.5195\n",
      "Epoch 97/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.2788 - root_mean_squared_error: 1.5096 - val_loss: 6.1680 - val_root_mean_squared_error: 2.4836\n",
      "Epoch 98/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.8191 - root_mean_squared_error: 1.3487 - val_loss: 6.5851 - val_root_mean_squared_error: 2.5662\n",
      "Epoch 99/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.8823 - root_mean_squared_error: 1.3720 - val_loss: 6.9157 - val_root_mean_squared_error: 2.6298\n",
      "Epoch 100/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.6883 - root_mean_squared_error: 1.2993 - val_loss: 6.4576 - val_root_mean_squared_error: 2.5412\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -0.33130988264169603\n",
      "RMSE for dataset is:2.5411845099045656& mean of this fold is 44.250004\n",
      "this is 5.742789357818163% of the mean pheno data\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 677 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "677/677 [==============================] - 12s 18ms/sample - loss: 1880.6744 - root_mean_squared_error: 43.3667 - val_loss: 1365.5313 - val_root_mean_squared_error: 36.9531\n",
      "Epoch 2/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 1498.1004 - root_mean_squared_error: 38.7053 - val_loss: 688.3342 - val_root_mean_squared_error: 26.2361\n",
      "Epoch 3/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 936.9100 - root_mean_squared_error: 30.6090 - val_loss: 429.8154 - val_root_mean_squared_error: 20.7320\n",
      "Epoch 4/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 458.8263 - root_mean_squared_error: 21.4202 - val_loss: 267.1035 - val_root_mean_squared_error: 16.3433\n",
      "Epoch 5/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 271.5730 - root_mean_squared_error: 16.4795 - val_loss: 139.4592 - val_root_mean_squared_error: 11.8093\n",
      "Epoch 6/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 151.6115 - root_mean_squared_error: 12.3131 - val_loss: 60.1021 - val_root_mean_squared_error: 7.7526\n",
      "Epoch 7/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 101.2359 - root_mean_squared_error: 10.0616 - val_loss: 34.8670 - val_root_mean_squared_error: 5.9048\n",
      "Epoch 8/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 88.3398 - root_mean_squared_error: 9.3989 - val_loss: 23.9486 - val_root_mean_squared_error: 4.8937\n",
      "Epoch 9/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 72.2419 - root_mean_squared_error: 8.4995 - val_loss: 17.0658 - val_root_mean_squared_error: 4.1311\n",
      "Epoch 10/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 80.0532 - root_mean_squared_error: 8.9472 - val_loss: 51.2416 - val_root_mean_squared_error: 7.1583\n",
      "Epoch 11/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 65.8836 - root_mean_squared_error: 8.1169 - val_loss: 83.5480 - val_root_mean_squared_error: 9.1405\n",
      "Epoch 12/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 40.6518 - root_mean_squared_error: 6.3759 - val_loss: 32.1856 - val_root_mean_squared_error: 5.6732\n",
      "Epoch 13/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 28.5997 - root_mean_squared_error: 5.3479 - val_loss: 22.6051 - val_root_mean_squared_error: 4.7545\n",
      "Epoch 14/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 27.4664 - root_mean_squared_error: 5.2408 - val_loss: 23.5880 - val_root_mean_squared_error: 4.8567\n",
      "Epoch 15/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 20.1069 - root_mean_squared_error: 4.4841 - val_loss: 18.9323 - val_root_mean_squared_error: 4.3511\n",
      "Epoch 16/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 21.7013 - root_mean_squared_error: 4.6585 - val_loss: 13.2456 - val_root_mean_squared_error: 3.6394\n",
      "Epoch 17/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 15.4329 - root_mean_squared_error: 3.9285 - val_loss: 14.8678 - val_root_mean_squared_error: 3.8559\n",
      "Epoch 18/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 17.0473 - root_mean_squared_error: 4.1288 - val_loss: 15.7518 - val_root_mean_squared_error: 3.9689\n",
      "Epoch 19/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 15.1372 - root_mean_squared_error: 3.8907 - val_loss: 8.9644 - val_root_mean_squared_error: 2.9941\n",
      "Epoch 20/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 14.7603 - root_mean_squared_error: 3.8419 - val_loss: 7.9647 - val_root_mean_squared_error: 2.8222\n",
      "Epoch 21/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 13.2082 - root_mean_squared_error: 3.6343 - val_loss: 7.9669 - val_root_mean_squared_error: 2.8226\n",
      "Epoch 22/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 11.2740 - root_mean_squared_error: 3.3577 - val_loss: 7.5191 - val_root_mean_squared_error: 2.7421\n",
      "Epoch 23/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 11.2689 - root_mean_squared_error: 3.3569 - val_loss: 10.7737 - val_root_mean_squared_error: 3.2823\n",
      "Epoch 24/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 10.9943 - root_mean_squared_error: 3.3158 - val_loss: 8.0623 - val_root_mean_squared_error: 2.8394\n",
      "Epoch 25/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 11.3344 - root_mean_squared_error: 3.3667 - val_loss: 8.4092 - val_root_mean_squared_error: 2.8999\n",
      "Epoch 26/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 11.7399 - root_mean_squared_error: 3.4263 - val_loss: 9.0849 - val_root_mean_squared_error: 3.0141\n",
      "Epoch 27/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 10.4785 - root_mean_squared_error: 3.2371 - val_loss: 7.6668 - val_root_mean_squared_error: 2.7689\n",
      "Epoch 28/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 10.7608 - root_mean_squared_error: 3.2804 - val_loss: 7.9703 - val_root_mean_squared_error: 2.8232\n",
      "Epoch 29/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 9.3845 - root_mean_squared_error: 3.0634 - val_loss: 7.6892 - val_root_mean_squared_error: 2.7729\n",
      "Epoch 30/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 14.2872 - root_mean_squared_error: 3.7798 - val_loss: 18.5772 - val_root_mean_squared_error: 4.3101\n",
      "Epoch 31/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 13.0783 - root_mean_squared_error: 3.6164 - val_loss: 7.7533 - val_root_mean_squared_error: 2.7845\n",
      "Epoch 32/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.9223 - root_mean_squared_error: 2.9870 - val_loss: 8.9474 - val_root_mean_squared_error: 2.9912\n",
      "Epoch 33/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 9.0534 - root_mean_squared_error: 3.0089 - val_loss: 7.8509 - val_root_mean_squared_error: 2.8019\n",
      "Epoch 34/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.8793 - root_mean_squared_error: 2.9798 - val_loss: 7.1613 - val_root_mean_squared_error: 2.6761\n",
      "Epoch 35/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 9.7844 - root_mean_squared_error: 3.1280 - val_loss: 8.8469 - val_root_mean_squared_error: 2.9744\n",
      "Epoch 36/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 9.0355 - root_mean_squared_error: 3.0059 - val_loss: 8.1909 - val_root_mean_squared_error: 2.8620\n",
      "Epoch 37/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 8.1937 - root_mean_squared_error: 2.8625 - val_loss: 8.3795 - val_root_mean_squared_error: 2.8947\n",
      "Epoch 38/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 8.1656 - root_mean_squared_error: 2.8576 - val_loss: 8.5767 - val_root_mean_squared_error: 2.9286\n",
      "Epoch 39/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.3073 - root_mean_squared_error: 2.7032 - val_loss: 8.5819 - val_root_mean_squared_error: 2.9295\n",
      "Epoch 40/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.9300 - root_mean_squared_error: 2.8160 - val_loss: 8.4750 - val_root_mean_squared_error: 2.9112\n",
      "Epoch 41/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.6554 - root_mean_squared_error: 2.7668 - val_loss: 7.2740 - val_root_mean_squared_error: 2.6970\n",
      "Epoch 42/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.2987 - root_mean_squared_error: 2.7016 - val_loss: 7.8262 - val_root_mean_squared_error: 2.7975\n",
      "Epoch 43/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.6334 - root_mean_squared_error: 2.5755 - val_loss: 8.0507 - val_root_mean_squared_error: 2.8374\n",
      "Epoch 44/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.0020 - root_mean_squared_error: 2.4499 - val_loss: 7.6741 - val_root_mean_squared_error: 2.7702\n",
      "Epoch 45/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.2446 - root_mean_squared_error: 2.4989 - val_loss: 7.2671 - val_root_mean_squared_error: 2.6958\n",
      "Epoch 46/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 8.5019 - root_mean_squared_error: 2.9158 - val_loss: 10.6944 - val_root_mean_squared_error: 3.2702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 7.7650 - root_mean_squared_error: 2.7866 - val_loss: 9.9315 - val_root_mean_squared_error: 3.1514\n",
      "Epoch 48/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.0263 - root_mean_squared_error: 2.4548 - val_loss: 7.5075 - val_root_mean_squared_error: 2.7400\n",
      "Epoch 49/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.1121 - root_mean_squared_error: 2.4723 - val_loss: 7.5217 - val_root_mean_squared_error: 2.7426\n",
      "Epoch 50/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.6898 - root_mean_squared_error: 2.5865 - val_loss: 7.5656 - val_root_mean_squared_error: 2.7506\n",
      "Epoch 51/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.6690 - root_mean_squared_error: 2.5824 - val_loss: 8.8875 - val_root_mean_squared_error: 2.9812\n",
      "Epoch 52/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.1501 - root_mean_squared_error: 2.2694 - val_loss: 7.8727 - val_root_mean_squared_error: 2.8058\n",
      "Epoch 53/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.5443 - root_mean_squared_error: 2.3546 - val_loss: 7.7749 - val_root_mean_squared_error: 2.7884\n",
      "Epoch 54/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.5009 - root_mean_squared_error: 2.3454 - val_loss: 7.7239 - val_root_mean_squared_error: 2.7792\n",
      "Epoch 55/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 5.5875 - root_mean_squared_error: 2.3638 - val_loss: 7.7037 - val_root_mean_squared_error: 2.7755\n",
      "Epoch 56/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 4.8627 - root_mean_squared_error: 2.2052 - val_loss: 8.1635 - val_root_mean_squared_error: 2.8572\n",
      "Epoch 57/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 5.2432 - root_mean_squared_error: 2.2898 - val_loss: 8.0751 - val_root_mean_squared_error: 2.8417\n",
      "Epoch 58/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 6.1155 - root_mean_squared_error: 2.4730 - val_loss: 7.3569 - val_root_mean_squared_error: 2.7124\n",
      "Epoch 59/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.0652 - root_mean_squared_error: 2.2506 - val_loss: 7.7011 - val_root_mean_squared_error: 2.7751\n",
      "Epoch 60/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.4302 - root_mean_squared_error: 2.3303 - val_loss: 8.2495 - val_root_mean_squared_error: 2.8722\n",
      "Epoch 61/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.8889 - root_mean_squared_error: 2.2111 - val_loss: 8.7545 - val_root_mean_squared_error: 2.9588\n",
      "Epoch 62/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.4112 - root_mean_squared_error: 2.1003 - val_loss: 7.5780 - val_root_mean_squared_error: 2.7528\n",
      "Epoch 63/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.5261 - root_mean_squared_error: 2.1275 - val_loss: 7.8318 - val_root_mean_squared_error: 2.7985\n",
      "Epoch 64/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.7847 - root_mean_squared_error: 1.9454 - val_loss: 7.9670 - val_root_mean_squared_error: 2.8226\n",
      "Epoch 65/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.9579 - root_mean_squared_error: 1.9895 - val_loss: 8.0250 - val_root_mean_squared_error: 2.8328\n",
      "Epoch 66/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.7509 - root_mean_squared_error: 1.9367 - val_loss: 16.0475 - val_root_mean_squared_error: 4.0059\n",
      "Epoch 67/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 4.2563 - root_mean_squared_error: 2.0631 - val_loss: 11.3427 - val_root_mean_squared_error: 3.3679\n",
      "Epoch 68/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 4.0259 - root_mean_squared_error: 2.0065 - val_loss: 7.8671 - val_root_mean_squared_error: 2.8048\n",
      "Epoch 69/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.7054 - root_mean_squared_error: 1.9249 - val_loss: 7.5151 - val_root_mean_squared_error: 2.7414\n",
      "Epoch 70/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.3622 - root_mean_squared_error: 1.8336 - val_loss: 7.7822 - val_root_mean_squared_error: 2.7897\n",
      "Epoch 71/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.3441 - root_mean_squared_error: 1.8287 - val_loss: 7.4545 - val_root_mean_squared_error: 2.7303\n",
      "Epoch 72/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.9111 - root_mean_squared_error: 1.7062 - val_loss: 8.1313 - val_root_mean_squared_error: 2.8515\n",
      "Epoch 73/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.0565 - root_mean_squared_error: 1.7483 - val_loss: 8.1753 - val_root_mean_squared_error: 2.8592\n",
      "Epoch 74/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.9958 - root_mean_squared_error: 1.7308 - val_loss: 7.6497 - val_root_mean_squared_error: 2.7658\n",
      "Epoch 75/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.2693 - root_mean_squared_error: 1.8081 - val_loss: 8.9380 - val_root_mean_squared_error: 2.9896\n",
      "Epoch 76/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.3153 - root_mean_squared_error: 1.8208 - val_loss: 9.1241 - val_root_mean_squared_error: 3.0206\n",
      "Epoch 77/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.1644 - root_mean_squared_error: 1.7789 - val_loss: 7.6719 - val_root_mean_squared_error: 2.7698\n",
      "Epoch 78/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.1226 - root_mean_squared_error: 1.7671 - val_loss: 8.2992 - val_root_mean_squared_error: 2.8808\n",
      "Epoch 79/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.8185 - root_mean_squared_error: 1.6788 - val_loss: 8.0521 - val_root_mean_squared_error: 2.8376\n",
      "Epoch 80/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.4853 - root_mean_squared_error: 1.5765 - val_loss: 9.1962 - val_root_mean_squared_error: 3.0325\n",
      "Epoch 81/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.8402 - root_mean_squared_error: 1.6853 - val_loss: 8.6130 - val_root_mean_squared_error: 2.9348\n",
      "Epoch 82/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.4935 - root_mean_squared_error: 1.5791 - val_loss: 8.9800 - val_root_mean_squared_error: 2.9967\n",
      "Epoch 83/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 6.1724 - root_mean_squared_error: 2.4844 - val_loss: 17.9547 - val_root_mean_squared_error: 4.2373\n",
      "Epoch 84/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 5.6042 - root_mean_squared_error: 2.3673 - val_loss: 9.1476 - val_root_mean_squared_error: 3.0245\n",
      "Epoch 85/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 3.1254 - root_mean_squared_error: 1.7679 - val_loss: 8.5911 - val_root_mean_squared_error: 2.9311\n",
      "Epoch 86/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.7013 - root_mean_squared_error: 1.6436 - val_loss: 8.8859 - val_root_mean_squared_error: 2.9809\n",
      "Epoch 87/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 3.2098 - root_mean_squared_error: 1.7916 - val_loss: 9.1195 - val_root_mean_squared_error: 3.0199\n",
      "Epoch 88/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.1711 - root_mean_squared_error: 1.4735 - val_loss: 8.0022 - val_root_mean_squared_error: 2.8288\n",
      "Epoch 89/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.5722 - root_mean_squared_error: 1.6038 - val_loss: 8.1412 - val_root_mean_squared_error: 2.8533\n",
      "Epoch 90/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.8548 - root_mean_squared_error: 1.6896 - val_loss: 9.1677 - val_root_mean_squared_error: 3.0278\n",
      "Epoch 91/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.0287 - root_mean_squared_error: 1.4243 - val_loss: 8.8197 - val_root_mean_squared_error: 2.9698\n",
      "Epoch 92/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.3613 - root_mean_squared_error: 1.5367 - val_loss: 8.7638 - val_root_mean_squared_error: 2.9604\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.7755 - root_mean_squared_error: 1.6660 - val_loss: 8.3542 - val_root_mean_squared_error: 2.8904\n",
      "Epoch 94/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 2.2520 - root_mean_squared_error: 1.5007 - val_loss: 8.0830 - val_root_mean_squared_error: 2.8431\n",
      "Epoch 95/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 1.9248 - root_mean_squared_error: 1.3874 - val_loss: 8.4137 - val_root_mean_squared_error: 2.9006\n",
      "Epoch 96/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 1.8151 - root_mean_squared_error: 1.3473 - val_loss: 7.7211 - val_root_mean_squared_error: 2.7787\n",
      "Epoch 97/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 2.4673 - root_mean_squared_error: 1.5708 - val_loss: 7.8967 - val_root_mean_squared_error: 2.8101\n",
      "Epoch 98/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.9006 - root_mean_squared_error: 1.3786 - val_loss: 8.1024 - val_root_mean_squared_error: 2.8465\n",
      "Epoch 99/100\n",
      "677/677 [==============================] - 3s 4ms/sample - loss: 1.6509 - root_mean_squared_error: 1.2849 - val_loss: 8.1462 - val_root_mean_squared_error: 2.8542\n",
      "Epoch 100/100\n",
      "677/677 [==============================] - 2s 4ms/sample - loss: 1.9437 - root_mean_squared_error: 1.3942 - val_loss: 8.6859 - val_root_mean_squared_error: 2.9472\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -0.2991878531139751\n",
      "RMSE for dataset is:2.9471853762269014& mean of this fold is 44.221054\n",
      "this is 6.66466559364509% of the mean pheno data\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:4\n",
      "Train on 678 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "678/678 [==============================] - 12s 18ms/sample - loss: 1877.6710 - root_mean_squared_error: 43.3321 - val_loss: 1738.7202 - val_root_mean_squared_error: 41.6980\n",
      "Epoch 2/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1515.8650 - root_mean_squared_error: 38.9341 - val_loss: 1338.7046 - val_root_mean_squared_error: 36.5883\n",
      "Epoch 3/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 922.1940 - root_mean_squared_error: 30.3676 - val_loss: 484.9276 - val_root_mean_squared_error: 22.0211\n",
      "Epoch 4/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 401.8860 - root_mean_squared_error: 20.0471 - val_loss: 361.9360 - val_root_mean_squared_error: 19.0246\n",
      "Epoch 5/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 161.2474 - root_mean_squared_error: 12.6983 - val_loss: 436.6708 - val_root_mean_squared_error: 20.8967\n",
      "Epoch 6/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 139.4743 - root_mean_squared_error: 11.8099 - val_loss: 303.9114 - val_root_mean_squared_error: 17.4331\n",
      "Epoch 7/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 77.1105 - root_mean_squared_error: 8.7813 - val_loss: 204.4832 - val_root_mean_squared_error: 14.2998\n",
      "Epoch 8/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 58.4866 - root_mean_squared_error: 7.6477 - val_loss: 120.9042 - val_root_mean_squared_error: 10.9956\n",
      "Epoch 9/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 31.0185 - root_mean_squared_error: 5.5694 - val_loss: 116.3188 - val_root_mean_squared_error: 10.7851\n",
      "Epoch 10/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 18.8575 - root_mean_squared_error: 4.3425 - val_loss: 99.9271 - val_root_mean_squared_error: 9.9964\n",
      "Epoch 11/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 15.8288 - root_mean_squared_error: 3.9785 - val_loss: 81.4870 - val_root_mean_squared_error: 9.0270\n",
      "Epoch 12/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 14.7884 - root_mean_squared_error: 3.8456 - val_loss: 36.6673 - val_root_mean_squared_error: 6.0554\n",
      "Epoch 13/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 12.0920 - root_mean_squared_error: 3.4774 - val_loss: 24.2532 - val_root_mean_squared_error: 4.9248\n",
      "Epoch 14/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 10.7770 - root_mean_squared_error: 3.2828 - val_loss: 14.0976 - val_root_mean_squared_error: 3.7547\n",
      "Epoch 15/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 14.7381 - root_mean_squared_error: 3.8390 - val_loss: 22.3590 - val_root_mean_squared_error: 4.7285\n",
      "Epoch 16/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 17.8631 - root_mean_squared_error: 4.2265 - val_loss: 14.5349 - val_root_mean_squared_error: 3.8125\n",
      "Epoch 17/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 14.7830 - root_mean_squared_error: 3.8449 - val_loss: 12.8941 - val_root_mean_squared_error: 3.5908\n",
      "Epoch 18/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 13.7098 - root_mean_squared_error: 3.7027 - val_loss: 8.4002 - val_root_mean_squared_error: 2.8983\n",
      "Epoch 19/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 13.0976 - root_mean_squared_error: 3.6191 - val_loss: 9.4505 - val_root_mean_squared_error: 3.0742\n",
      "Epoch 20/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.9211 - root_mean_squared_error: 3.4527 - val_loss: 8.4088 - val_root_mean_squared_error: 2.8998\n",
      "Epoch 21/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 12.1587 - root_mean_squared_error: 3.4869 - val_loss: 8.7851 - val_root_mean_squared_error: 2.9640\n",
      "Epoch 22/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 10.3715 - root_mean_squared_error: 3.2205 - val_loss: 8.6955 - val_root_mean_squared_error: 2.9488\n",
      "Epoch 23/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.3631 - root_mean_squared_error: 3.2192 - val_loss: 11.1883 - val_root_mean_squared_error: 3.3449\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.3428 - root_mean_squared_error: 3.0566 - val_loss: 9.6724 - val_root_mean_squared_error: 3.1100\n",
      "Epoch 25/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.2834 - root_mean_squared_error: 3.3591 - val_loss: 7.8435 - val_root_mean_squared_error: 2.8006\n",
      "Epoch 26/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.7308 - root_mean_squared_error: 3.4250 - val_loss: 15.4622 - val_root_mean_squared_error: 3.9322\n",
      "Epoch 27/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.1665 - root_mean_squared_error: 3.0276 - val_loss: 7.8880 - val_root_mean_squared_error: 2.8086\n",
      "Epoch 28/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.8305 - root_mean_squared_error: 2.9716 - val_loss: 8.8269 - val_root_mean_squared_error: 2.9710\n",
      "Epoch 29/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.0931 - root_mean_squared_error: 3.0155 - val_loss: 7.5824 - val_root_mean_squared_error: 2.7536\n",
      "Epoch 30/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.8016 - root_mean_squared_error: 2.7931 - val_loss: 7.3559 - val_root_mean_squared_error: 2.7122\n",
      "Epoch 31/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.5763 - root_mean_squared_error: 2.9285 - val_loss: 7.9790 - val_root_mean_squared_error: 2.8247\n",
      "Epoch 32/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.9822 - root_mean_squared_error: 2.8253 - val_loss: 7.7402 - val_root_mean_squared_error: 2.7821\n",
      "Epoch 33/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.1274 - root_mean_squared_error: 2.8509 - val_loss: 7.9007 - val_root_mean_squared_error: 2.8108\n",
      "Epoch 34/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.6849 - root_mean_squared_error: 2.7722 - val_loss: 9.3130 - val_root_mean_squared_error: 3.0517\n",
      "Epoch 35/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.3532 - root_mean_squared_error: 2.7117 - val_loss: 7.6608 - val_root_mean_squared_error: 2.7678\n",
      "Epoch 36/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.0259 - root_mean_squared_error: 2.6506 - val_loss: 8.0283 - val_root_mean_squared_error: 2.8334\n",
      "Epoch 37/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.9055 - root_mean_squared_error: 2.6278 - val_loss: 8.2020 - val_root_mean_squared_error: 2.8639\n",
      "Epoch 38/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.1035 - root_mean_squared_error: 2.6652 - val_loss: 9.0748 - val_root_mean_squared_error: 3.0124\n",
      "Epoch 39/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.1539 - root_mean_squared_error: 2.6747 - val_loss: 8.8921 - val_root_mean_squared_error: 2.9820\n",
      "Epoch 40/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.6017 - root_mean_squared_error: 2.7571 - val_loss: 7.8614 - val_root_mean_squared_error: 2.8038\n",
      "Epoch 41/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.5337 - root_mean_squared_error: 2.7448 - val_loss: 7.3495 - val_root_mean_squared_error: 2.7110\n",
      "Epoch 42/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.1204 - root_mean_squared_error: 2.8496 - val_loss: 7.4140 - val_root_mean_squared_error: 2.7229\n",
      "Epoch 43/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.2793 - root_mean_squared_error: 2.6980 - val_loss: 7.2631 - val_root_mean_squared_error: 2.6950\n",
      "Epoch 44/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.7586 - root_mean_squared_error: 2.5997 - val_loss: 7.6361 - val_root_mean_squared_error: 2.7634\n",
      "Epoch 45/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.4728 - root_mean_squared_error: 2.5442 - val_loss: 10.6194 - val_root_mean_squared_error: 3.2587\n",
      "Epoch 46/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.2739 - root_mean_squared_error: 2.5048 - val_loss: 7.5914 - val_root_mean_squared_error: 2.7552\n",
      "Epoch 47/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.2959 - root_mean_squared_error: 2.7011 - val_loss: 9.0185 - val_root_mean_squared_error: 3.0031\n",
      "Epoch 48/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.9874 - root_mean_squared_error: 2.4469 - val_loss: 8.8396 - val_root_mean_squared_error: 2.9731\n",
      "Epoch 49/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.3421 - root_mean_squared_error: 2.5184 - val_loss: 8.1489 - val_root_mean_squared_error: 2.8546\n",
      "Epoch 50/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.2409 - root_mean_squared_error: 2.4982 - val_loss: 8.7614 - val_root_mean_squared_error: 2.9600\n",
      "Epoch 51/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.9022 - root_mean_squared_error: 2.4294 - val_loss: 9.4673 - val_root_mean_squared_error: 3.0769\n",
      "Epoch 52/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.2679 - root_mean_squared_error: 2.5036 - val_loss: 9.8079 - val_root_mean_squared_error: 3.1318\n",
      "Epoch 53/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.0716 - root_mean_squared_error: 2.4641 - val_loss: 7.4837 - val_root_mean_squared_error: 2.7356\n",
      "Epoch 54/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.7743 - root_mean_squared_error: 2.4030 - val_loss: 7.7060 - val_root_mean_squared_error: 2.7760\n",
      "Epoch 55/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.2135 - root_mean_squared_error: 2.2833 - val_loss: 8.1250 - val_root_mean_squared_error: 2.8504\n",
      "Epoch 56/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.9074 - root_mean_squared_error: 2.4305 - val_loss: 9.0173 - val_root_mean_squared_error: 3.0029\n",
      "Epoch 57/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.3383 - root_mean_squared_error: 2.3105 - val_loss: 8.7478 - val_root_mean_squared_error: 2.9577\n",
      "Epoch 58/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.1115 - root_mean_squared_error: 2.2609 - val_loss: 13.2944 - val_root_mean_squared_error: 3.6461\n",
      "Epoch 59/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.9993 - root_mean_squared_error: 2.2359 - val_loss: 7.5744 - val_root_mean_squared_error: 2.7522\n",
      "Epoch 60/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.5934 - root_mean_squared_error: 2.3650 - val_loss: 7.3557 - val_root_mean_squared_error: 2.7121\n",
      "Epoch 61/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.7380 - root_mean_squared_error: 2.1767 - val_loss: 7.6559 - val_root_mean_squared_error: 2.7669\n",
      "Epoch 62/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.0151 - root_mean_squared_error: 2.2394 - val_loss: 8.4487 - val_root_mean_squared_error: 2.9067\n",
      "Epoch 63/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.0442 - root_mean_squared_error: 2.2459 - val_loss: 7.9144 - val_root_mean_squared_error: 2.8132\n",
      "Epoch 64/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.6095 - root_mean_squared_error: 2.1470 - val_loss: 13.6170 - val_root_mean_squared_error: 3.6901\n",
      "Epoch 65/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.4481 - root_mean_squared_error: 2.1090 - val_loss: 7.7073 - val_root_mean_squared_error: 2.7762\n",
      "Epoch 66/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.3212 - root_mean_squared_error: 2.0788 - val_loss: 9.5205 - val_root_mean_squared_error: 3.0855\n",
      "Epoch 67/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.3119 - root_mean_squared_error: 2.0765 - val_loss: 7.8316 - val_root_mean_squared_error: 2.7985\n",
      "Epoch 68/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.0100 - root_mean_squared_error: 2.0025 - val_loss: 7.6396 - val_root_mean_squared_error: 2.7640\n",
      "Epoch 69/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.5486 - root_mean_squared_error: 2.1327 - val_loss: 7.6628 - val_root_mean_squared_error: 2.7682\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.8567 - root_mean_squared_error: 1.9639 - val_loss: 7.3963 - val_root_mean_squared_error: 2.7196\n",
      "Epoch 71/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.3683 - root_mean_squared_error: 1.8353 - val_loss: 8.1518 - val_root_mean_squared_error: 2.8551\n",
      "Epoch 72/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.0997 - root_mean_squared_error: 2.0248 - val_loss: 7.3483 - val_root_mean_squared_error: 2.7108\n",
      "Epoch 73/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.2188 - root_mean_squared_error: 1.7941 - val_loss: 7.6354 - val_root_mean_squared_error: 2.7632\n",
      "Epoch 74/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.9177 - root_mean_squared_error: 1.9793 - val_loss: 8.3469 - val_root_mean_squared_error: 2.8891\n",
      "Epoch 75/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1869 - root_mean_squared_error: 1.7852 - val_loss: 7.3409 - val_root_mean_squared_error: 2.7094\n",
      "Epoch 76/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.2305 - root_mean_squared_error: 2.0568 - val_loss: 8.7270 - val_root_mean_squared_error: 2.9542\n",
      "Epoch 77/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.5545 - root_mean_squared_error: 1.8853 - val_loss: 7.6625 - val_root_mean_squared_error: 2.7681\n",
      "Epoch 78/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1820 - root_mean_squared_error: 1.7838 - val_loss: 7.5743 - val_root_mean_squared_error: 2.7521\n",
      "Epoch 79/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.9291 - root_mean_squared_error: 1.9822 - val_loss: 7.3585 - val_root_mean_squared_error: 2.7127\n",
      "Epoch 80/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8954 - root_mean_squared_error: 1.7016 - val_loss: 9.7721 - val_root_mean_squared_error: 3.1260\n",
      "Epoch 81/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.2761 - root_mean_squared_error: 1.8100 - val_loss: 7.9010 - val_root_mean_squared_error: 2.8109\n",
      "Epoch 82/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.9904 - root_mean_squared_error: 1.7293 - val_loss: 7.6078 - val_root_mean_squared_error: 2.7582\n",
      "Epoch 83/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.0650 - root_mean_squared_error: 1.7507 - val_loss: 7.5534 - val_root_mean_squared_error: 2.7484\n",
      "Epoch 84/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1545 - root_mean_squared_error: 1.7761 - val_loss: 8.7111 - val_root_mean_squared_error: 2.9515\n",
      "Epoch 85/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.6235 - root_mean_squared_error: 1.6197 - val_loss: 8.1326 - val_root_mean_squared_error: 2.8518\n",
      "Epoch 86/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.8114 - root_mean_squared_error: 1.6767 - val_loss: 7.4604 - val_root_mean_squared_error: 2.7314\n",
      "Epoch 87/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8098 - root_mean_squared_error: 1.6763 - val_loss: 7.3772 - val_root_mean_squared_error: 2.7161\n",
      "Epoch 88/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4268 - root_mean_squared_error: 1.5578 - val_loss: 8.7426 - val_root_mean_squared_error: 2.9568\n",
      "Epoch 89/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.7154 - root_mean_squared_error: 1.6478 - val_loss: 7.6615 - val_root_mean_squared_error: 2.7679\n",
      "Epoch 90/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.3905 - root_mean_squared_error: 1.5461 - val_loss: 7.7065 - val_root_mean_squared_error: 2.7761\n",
      "Epoch 91/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.7405 - root_mean_squared_error: 1.6555 - val_loss: 7.5665 - val_root_mean_squared_error: 2.7507\n",
      "Epoch 92/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.4664 - root_mean_squared_error: 1.8618 - val_loss: 9.1200 - val_root_mean_squared_error: 3.0199\n",
      "Epoch 93/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2740 - root_mean_squared_error: 1.5080 - val_loss: 7.8476 - val_root_mean_squared_error: 2.8014\n",
      "Epoch 94/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.2838 - root_mean_squared_error: 1.5112 - val_loss: 7.8031 - val_root_mean_squared_error: 2.7934\n",
      "Epoch 95/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2022 - root_mean_squared_error: 1.4840 - val_loss: 7.7691 - val_root_mean_squared_error: 2.7873\n",
      "Epoch 96/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.0717 - root_mean_squared_error: 1.4393 - val_loss: 8.5583 - val_root_mean_squared_error: 2.9255\n",
      "Epoch 97/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.9681 - root_mean_squared_error: 1.4029 - val_loss: 8.6437 - val_root_mean_squared_error: 2.9400\n",
      "Epoch 98/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2748 - root_mean_squared_error: 1.5082 - val_loss: 8.0447 - val_root_mean_squared_error: 2.8363\n",
      "Epoch 99/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.0278 - root_mean_squared_error: 1.4240 - val_loss: 7.5655 - val_root_mean_squared_error: 2.7505\n",
      "Epoch 100/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.2979 - root_mean_squared_error: 1.5159 - val_loss: 7.4935 - val_root_mean_squared_error: 2.7374\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -1.3075080934743393\n",
      "RMSE for dataset is:2.737424185761229& mean of this fold is 44.81333\n",
      "this is 6.1085040718477845% of the mean pheno data\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:5\n",
      "Train on 678 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "678/678 [==============================] - 13s 18ms/sample - loss: 1701.3416 - root_mean_squared_error: 41.2473 - val_loss: 1155.0680 - val_root_mean_squared_error: 33.9863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1085.6726 - root_mean_squared_error: 32.9495 - val_loss: 206.0086 - val_root_mean_squared_error: 14.3530\n",
      "Epoch 3/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 450.5256 - root_mean_squared_error: 21.2256 - val_loss: 692.4554 - val_root_mean_squared_error: 26.3145\n",
      "Epoch 4/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 216.7036 - root_mean_squared_error: 14.7209 - val_loss: 131.0858 - val_root_mean_squared_error: 11.4493\n",
      "Epoch 5/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 148.6281 - root_mean_squared_error: 12.1913 - val_loss: 48.7448 - val_root_mean_squared_error: 6.9817\n",
      "Epoch 6/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 84.1603 - root_mean_squared_error: 9.1739 - val_loss: 47.5863 - val_root_mean_squared_error: 6.8983\n",
      "Epoch 7/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 93.2708 - root_mean_squared_error: 9.6577 - val_loss: 29.7433 - val_root_mean_squared_error: 5.4537\n",
      "Epoch 8/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 85.1578 - root_mean_squared_error: 9.2281 - val_loss: 27.0699 - val_root_mean_squared_error: 5.2029\n",
      "Epoch 9/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 61.7766 - root_mean_squared_error: 7.8598 - val_loss: 23.3551 - val_root_mean_squared_error: 4.8327\n",
      "Epoch 10/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 81.1967 - root_mean_squared_error: 9.0109 - val_loss: 37.6527 - val_root_mean_squared_error: 6.1362\n",
      "Epoch 11/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 53.6186 - root_mean_squared_error: 7.3225 - val_loss: 45.8415 - val_root_mean_squared_error: 6.7706\n",
      "Epoch 12/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 48.9063 - root_mean_squared_error: 6.9933 - val_loss: 28.6320 - val_root_mean_squared_error: 5.3509\n",
      "Epoch 13/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 48.7366 - root_mean_squared_error: 6.9812 - val_loss: 66.2684 - val_root_mean_squared_error: 8.1405\n",
      "Epoch 14/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 29.9809 - root_mean_squared_error: 5.4755 - val_loss: 44.3816 - val_root_mean_squared_error: 6.6620\n",
      "Epoch 15/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 29.4719 - root_mean_squared_error: 5.4288 - val_loss: 26.6712 - val_root_mean_squared_error: 5.1644\n",
      "Epoch 16/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 27.4104 - root_mean_squared_error: 5.2355 - val_loss: 19.0053 - val_root_mean_squared_error: 4.3595\n",
      "Epoch 17/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 34.8176 - root_mean_squared_error: 5.9006 - val_loss: 17.2008 - val_root_mean_squared_error: 4.1474\n",
      "Epoch 18/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 25.8243 - root_mean_squared_error: 5.0818 - val_loss: 31.6745 - val_root_mean_squared_error: 5.6280\n",
      "Epoch 19/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 23.0251 - root_mean_squared_error: 4.7984 - val_loss: 13.0714 - val_root_mean_squared_error: 3.6154\n",
      "Epoch 20/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 20.3441 - root_mean_squared_error: 4.5104 - val_loss: 12.1043 - val_root_mean_squared_error: 3.4791\n",
      "Epoch 21/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 20.0614 - root_mean_squared_error: 4.4790 - val_loss: 23.3313 - val_root_mean_squared_error: 4.8303\n",
      "Epoch 22/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 19.6726 - root_mean_squared_error: 4.4354 - val_loss: 13.2073 - val_root_mean_squared_error: 3.6342\n",
      "Epoch 23/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 15.5960 - root_mean_squared_error: 3.9492 - val_loss: 11.0085 - val_root_mean_squared_error: 3.3179\n",
      "Epoch 24/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 14.5943 - root_mean_squared_error: 3.8202 - val_loss: 14.5671 - val_root_mean_squared_error: 3.8167\n",
      "Epoch 25/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 16.9941 - root_mean_squared_error: 4.1224 - val_loss: 11.0630 - val_root_mean_squared_error: 3.3261\n",
      "Epoch 26/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 13.0037 - root_mean_squared_error: 3.6061 - val_loss: 7.9398 - val_root_mean_squared_error: 2.8178\n",
      "Epoch 27/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 15.4268 - root_mean_squared_error: 3.9277 - val_loss: 7.7530 - val_root_mean_squared_error: 2.7844\n",
      "Epoch 28/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.4208 - root_mean_squared_error: 3.3795 - val_loss: 8.6221 - val_root_mean_squared_error: 2.9363\n",
      "Epoch 29/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.6581 - root_mean_squared_error: 3.4144 - val_loss: 9.6554 - val_root_mean_squared_error: 3.1073\n",
      "Epoch 30/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 12.8375 - root_mean_squared_error: 3.5829 - val_loss: 18.6014 - val_root_mean_squared_error: 4.3129\n",
      "Epoch 31/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 13.1545 - root_mean_squared_error: 3.6269 - val_loss: 12.5782 - val_root_mean_squared_error: 3.5466\n",
      "Epoch 32/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.4032 - root_mean_squared_error: 3.2254 - val_loss: 9.4300 - val_root_mean_squared_error: 3.0708\n",
      "Epoch 33/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.3438 - root_mean_squared_error: 3.3680 - val_loss: 15.3080 - val_root_mean_squared_error: 3.9125\n",
      "Epoch 34/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.5047 - root_mean_squared_error: 3.3919 - val_loss: 21.9964 - val_root_mean_squared_error: 4.6900\n",
      "Epoch 35/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 10.9418 - root_mean_squared_error: 3.3078 - val_loss: 10.3475 - val_root_mean_squared_error: 3.2168\n",
      "Epoch 36/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 10.5197 - root_mean_squared_error: 3.2434 - val_loss: 9.1880 - val_root_mean_squared_error: 3.0312\n",
      "Epoch 37/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.0790 - root_mean_squared_error: 3.0131 - val_loss: 8.8266 - val_root_mean_squared_error: 2.9710\n",
      "Epoch 38/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 14.4382 - root_mean_squared_error: 3.7998 - val_loss: 33.7926 - val_root_mean_squared_error: 5.8131\n",
      "Epoch 39/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 16.2539 - root_mean_squared_error: 4.0316 - val_loss: 20.0568 - val_root_mean_squared_error: 4.4785\n",
      "Epoch 40/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 10.1469 - root_mean_squared_error: 3.1854 - val_loss: 11.2284 - val_root_mean_squared_error: 3.3509\n",
      "Epoch 41/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.3907 - root_mean_squared_error: 3.0644 - val_loss: 7.1037 - val_root_mean_squared_error: 2.6653\n",
      "Epoch 42/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.1899 - root_mean_squared_error: 3.0315 - val_loss: 7.1974 - val_root_mean_squared_error: 2.6828\n",
      "Epoch 43/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.5783 - root_mean_squared_error: 2.9289 - val_loss: 7.2390 - val_root_mean_squared_error: 2.6905\n",
      "Epoch 44/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.6786 - root_mean_squared_error: 2.9460 - val_loss: 6.6188 - val_root_mean_squared_error: 2.5727\n",
      "Epoch 45/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.1008 - root_mean_squared_error: 3.0168 - val_loss: 7.3760 - val_root_mean_squared_error: 2.7159\n",
      "Epoch 46/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.0864 - root_mean_squared_error: 2.6620 - val_loss: 10.5187 - val_root_mean_squared_error: 3.2433\n",
      "Epoch 47/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.2547 - root_mean_squared_error: 2.6935 - val_loss: 6.9776 - val_root_mean_squared_error: 2.6415\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.1220 - root_mean_squared_error: 2.6687 - val_loss: 5.4686 - val_root_mean_squared_error: 2.3385\n",
      "Epoch 49/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.5092 - root_mean_squared_error: 2.5513 - val_loss: 6.2880 - val_root_mean_squared_error: 2.5076\n",
      "Epoch 50/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.9984 - root_mean_squared_error: 2.6455 - val_loss: 6.4517 - val_root_mean_squared_error: 2.5400\n",
      "Epoch 51/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.7115 - root_mean_squared_error: 2.5907 - val_loss: 9.3793 - val_root_mean_squared_error: 3.0626\n",
      "Epoch 52/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.9694 - root_mean_squared_error: 2.4432 - val_loss: 6.6216 - val_root_mean_squared_error: 2.5732\n",
      "Epoch 53/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.8874 - root_mean_squared_error: 2.6244 - val_loss: 6.8060 - val_root_mean_squared_error: 2.6088\n",
      "Epoch 54/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.5679 - root_mean_squared_error: 2.3596 - val_loss: 6.1203 - val_root_mean_squared_error: 2.4739\n",
      "Epoch 55/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.4035 - root_mean_squared_error: 2.5305 - val_loss: 7.7823 - val_root_mean_squared_error: 2.7897\n",
      "Epoch 56/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.4643 - root_mean_squared_error: 2.5425 - val_loss: 7.1791 - val_root_mean_squared_error: 2.6794\n",
      "Epoch 57/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.0505 - root_mean_squared_error: 2.4598 - val_loss: 8.1464 - val_root_mean_squared_error: 2.8542\n",
      "Epoch 58/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.5907 - root_mean_squared_error: 2.3645 - val_loss: 6.1398 - val_root_mean_squared_error: 2.4779\n",
      "Epoch 59/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.1225 - root_mean_squared_error: 2.2633 - val_loss: 6.7680 - val_root_mean_squared_error: 2.6015\n",
      "Epoch 60/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.3434 - root_mean_squared_error: 2.3116 - val_loss: 8.2940 - val_root_mean_squared_error: 2.8799\n",
      "Epoch 61/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.7192 - root_mean_squared_error: 2.1724 - val_loss: 14.7824 - val_root_mean_squared_error: 3.8448\n",
      "Epoch 62/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.7125 - root_mean_squared_error: 2.1708 - val_loss: 9.9382 - val_root_mean_squared_error: 3.1525\n",
      "Epoch 63/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.8242 - root_mean_squared_error: 2.1964 - val_loss: 6.6088 - val_root_mean_squared_error: 2.5708\n",
      "Epoch 64/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.3691 - root_mean_squared_error: 2.0902 - val_loss: 8.5237 - val_root_mean_squared_error: 2.9195\n",
      "Epoch 65/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.7924 - root_mean_squared_error: 2.6062 - val_loss: 11.8246 - val_root_mean_squared_error: 3.4387\n",
      "Epoch 66/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.7275 - root_mean_squared_error: 2.5938 - val_loss: 9.4856 - val_root_mean_squared_error: 3.0799\n",
      "Epoch 67/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.9673 - root_mean_squared_error: 2.6396 - val_loss: 5.8907 - val_root_mean_squared_error: 2.4271\n",
      "Epoch 68/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.6528 - root_mean_squared_error: 2.1570 - val_loss: 9.8271 - val_root_mean_squared_error: 3.1348\n",
      "Epoch 69/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.3907 - root_mean_squared_error: 2.0954 - val_loss: 7.4931 - val_root_mean_squared_error: 2.7374\n",
      "Epoch 70/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.8456 - root_mean_squared_error: 2.2013 - val_loss: 7.9462 - val_root_mean_squared_error: 2.8189\n",
      "Epoch 71/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.2639 - root_mean_squared_error: 2.0649 - val_loss: 7.9895 - val_root_mean_squared_error: 2.8266\n",
      "Epoch 72/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.3594 - root_mean_squared_error: 2.0879 - val_loss: 7.8927 - val_root_mean_squared_error: 2.8094\n",
      "Epoch 73/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.1815 - root_mean_squared_error: 2.0449 - val_loss: 7.4312 - val_root_mean_squared_error: 2.7260\n",
      "Epoch 74/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.0345 - root_mean_squared_error: 1.7420 - val_loss: 7.9228 - val_root_mean_squared_error: 2.8148\n",
      "Epoch 75/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.4841 - root_mean_squared_error: 1.8666 - val_loss: 8.9164 - val_root_mean_squared_error: 2.9860\n",
      "Epoch 76/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.5444 - root_mean_squared_error: 1.8826 - val_loss: 8.6503 - val_root_mean_squared_error: 2.9411\n",
      "Epoch 77/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.2886 - root_mean_squared_error: 1.8135 - val_loss: 6.7759 - val_root_mean_squared_error: 2.6031\n",
      "Epoch 78/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.5769 - root_mean_squared_error: 2.1394 - val_loss: 7.6744 - val_root_mean_squared_error: 2.7703\n",
      "Epoch 79/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.1031 - root_mean_squared_error: 1.7616 - val_loss: 8.2687 - val_root_mean_squared_error: 2.8755\n",
      "Epoch 80/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.0088 - root_mean_squared_error: 1.7346 - val_loss: 8.7395 - val_root_mean_squared_error: 2.9563\n",
      "Epoch 81/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.4987 - root_mean_squared_error: 1.8705 - val_loss: 10.0336 - val_root_mean_squared_error: 3.1676\n",
      "Epoch 82/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.4661 - root_mean_squared_error: 1.8617 - val_loss: 7.4470 - val_root_mean_squared_error: 2.7289\n",
      "Epoch 83/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.3788 - root_mean_squared_error: 1.8381 - val_loss: 8.3801 - val_root_mean_squared_error: 2.8948\n",
      "Epoch 84/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.3507 - root_mean_squared_error: 1.8305 - val_loss: 8.5069 - val_root_mean_squared_error: 2.9167\n",
      "Epoch 85/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.3993 - root_mean_squared_error: 1.8437 - val_loss: 7.7315 - val_root_mean_squared_error: 2.7806\n",
      "Epoch 86/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.7977 - root_mean_squared_error: 1.6726 - val_loss: 6.5400 - val_root_mean_squared_error: 2.5573\n",
      "Epoch 87/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.0439 - root_mean_squared_error: 1.7447 - val_loss: 6.7088 - val_root_mean_squared_error: 2.5901\n",
      "Epoch 88/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6533 - root_mean_squared_error: 1.6289 - val_loss: 6.6880 - val_root_mean_squared_error: 2.5861\n",
      "Epoch 89/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6692 - root_mean_squared_error: 1.6338 - val_loss: 8.3824 - val_root_mean_squared_error: 2.8952\n",
      "Epoch 90/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.0823 - root_mean_squared_error: 1.7556 - val_loss: 8.4748 - val_root_mean_squared_error: 2.9111\n",
      "Epoch 91/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.5565 - root_mean_squared_error: 1.5989 - val_loss: 10.7516 - val_root_mean_squared_error: 3.2790\n",
      "Epoch 92/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.9521 - root_mean_squared_error: 1.7182 - val_loss: 9.0038 - val_root_mean_squared_error: 3.0006\n",
      "Epoch 93/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6252 - root_mean_squared_error: 1.6203 - val_loss: 8.8693 - val_root_mean_squared_error: 2.9781\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.5776 - root_mean_squared_error: 1.6055 - val_loss: 8.5567 - val_root_mean_squared_error: 2.9252\n",
      "Epoch 95/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.7133 - root_mean_squared_error: 1.9270 - val_loss: 10.1606 - val_root_mean_squared_error: 3.1876\n",
      "Epoch 96/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.2044 - root_mean_squared_error: 1.7901 - val_loss: 8.1931 - val_root_mean_squared_error: 2.8624\n",
      "Epoch 97/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.9050 - root_mean_squared_error: 1.7044 - val_loss: 9.4584 - val_root_mean_squared_error: 3.0755\n",
      "Epoch 98/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4290 - root_mean_squared_error: 1.5585 - val_loss: 14.3472 - val_root_mean_squared_error: 3.7878\n",
      "Epoch 99/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1292 - root_mean_squared_error: 1.4592 - val_loss: 9.6259 - val_root_mean_squared_error: 3.1026\n",
      "Epoch 100/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.2249 - root_mean_squared_error: 1.4916 - val_loss: 6.8925 - val_root_mean_squared_error: 2.6254\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -0.6729682321378498\n",
      "RMSE for dataset is:2.625355106131088& mean of this fold is 43.962666\n",
      "this is 5.97178326840927% of the mean pheno data\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:6\n",
      "Train on 678 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "678/678 [==============================] - 12s 18ms/sample - loss: 1888.9514 - root_mean_squared_error: 43.4621 - val_loss: 1166.2700 - val_root_mean_squared_error: 34.1507\n",
      "Epoch 2/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1537.1117 - root_mean_squared_error: 39.2060 - val_loss: 813.0578 - val_root_mean_squared_error: 28.5142\n",
      "Epoch 3/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 983.4564 - root_mean_squared_error: 31.3601 - val_loss: 254.0442 - val_root_mean_squared_error: 15.9388\n",
      "Epoch 4/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 394.8671 - root_mean_squared_error: 19.8713 - val_loss: 185.3220 - val_root_mean_squared_error: 13.6133\n",
      "Epoch 5/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 178.7399 - root_mean_squared_error: 13.3694 - val_loss: 95.7264 - val_root_mean_squared_error: 9.7840\n",
      "Epoch 6/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 109.7607 - root_mean_squared_error: 10.4767 - val_loss: 60.1848 - val_root_mean_squared_error: 7.7579\n",
      "Epoch 7/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 81.6031 - root_mean_squared_error: 9.0334 - val_loss: 73.1352 - val_root_mean_squared_error: 8.5519\n",
      "Epoch 8/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 97.1995 - root_mean_squared_error: 9.8590 - val_loss: 25.8343 - val_root_mean_squared_error: 5.0827\n",
      "Epoch 9/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 81.7171 - root_mean_squared_error: 9.0398 - val_loss: 28.0011 - val_root_mean_squared_error: 5.2916\n",
      "Epoch 10/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 62.8161 - root_mean_squared_error: 7.9257 - val_loss: 36.1381 - val_root_mean_squared_error: 6.0115\n",
      "Epoch 11/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 58.7495 - root_mean_squared_error: 7.6648 - val_loss: 50.0149 - val_root_mean_squared_error: 7.0721\n",
      "Epoch 12/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 54.1670 - root_mean_squared_error: 7.3598 - val_loss: 55.3971 - val_root_mean_squared_error: 7.4429\n",
      "Epoch 13/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 51.1922 - root_mean_squared_error: 7.1549 - val_loss: 26.5977 - val_root_mean_squared_error: 5.1573\n",
      "Epoch 14/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 43.5047 - root_mean_squared_error: 6.5958 - val_loss: 38.3344 - val_root_mean_squared_error: 6.1915\n",
      "Epoch 15/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 35.9593 - root_mean_squared_error: 5.9966 - val_loss: 60.6830 - val_root_mean_squared_error: 7.7899\n",
      "Epoch 16/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 32.9176 - root_mean_squared_error: 5.7374 - val_loss: 61.2206 - val_root_mean_squared_error: 7.8244\n",
      "Epoch 17/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 26.1817 - root_mean_squared_error: 5.1168 - val_loss: 39.3830 - val_root_mean_squared_error: 6.2756\n",
      "Epoch 18/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 27.5971 - root_mean_squared_error: 5.2533 - val_loss: 44.6926 - val_root_mean_squared_error: 6.6853\n",
      "Epoch 19/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 17.1650 - root_mean_squared_error: 4.1431 - val_loss: 10.4377 - val_root_mean_squared_error: 3.2307\n",
      "Epoch 20/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 19.4462 - root_mean_squared_error: 4.4098 - val_loss: 14.5512 - val_root_mean_squared_error: 3.8146\n",
      "Epoch 21/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 17.6418 - root_mean_squared_error: 4.2002 - val_loss: 9.9039 - val_root_mean_squared_error: 3.1471\n",
      "Epoch 22/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 15.4977 - root_mean_squared_error: 3.9367 - val_loss: 9.9677 - val_root_mean_squared_error: 3.1572\n",
      "Epoch 23/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 14.1607 - root_mean_squared_error: 3.7631 - val_loss: 8.5977 - val_root_mean_squared_error: 2.9322\n",
      "Epoch 24/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 14.1242 - root_mean_squared_error: 3.7582 - val_loss: 7.8624 - val_root_mean_squared_error: 2.8040\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 14.7914 - root_mean_squared_error: 3.8460 - val_loss: 9.3037 - val_root_mean_squared_error: 3.0502\n",
      "Epoch 26/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 17.8610 - root_mean_squared_error: 4.2262 - val_loss: 11.5219 - val_root_mean_squared_error: 3.3944\n",
      "Epoch 27/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 10.1444 - root_mean_squared_error: 3.1850 - val_loss: 10.1966 - val_root_mean_squared_error: 3.1932\n",
      "Epoch 28/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.5841 - root_mean_squared_error: 3.4035 - val_loss: 8.8815 - val_root_mean_squared_error: 2.9802\n",
      "Epoch 29/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 10.8287 - root_mean_squared_error: 3.2907 - val_loss: 6.7107 - val_root_mean_squared_error: 2.5905\n",
      "Epoch 30/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.1192 - root_mean_squared_error: 3.3346 - val_loss: 8.2927 - val_root_mean_squared_error: 2.8797\n",
      "Epoch 31/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.8650 - root_mean_squared_error: 3.1409 - val_loss: 7.0389 - val_root_mean_squared_error: 2.6531\n",
      "Epoch 32/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 12.3831 - root_mean_squared_error: 3.5190 - val_loss: 8.4454 - val_root_mean_squared_error: 2.9061\n",
      "Epoch 33/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.3912 - root_mean_squared_error: 2.8968 - val_loss: 8.5750 - val_root_mean_squared_error: 2.9283\n",
      "Epoch 34/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.5113 - root_mean_squared_error: 2.9174 - val_loss: 7.9083 - val_root_mean_squared_error: 2.8122\n",
      "Epoch 35/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.2128 - root_mean_squared_error: 2.8658 - val_loss: 12.0574 - val_root_mean_squared_error: 3.4724\n",
      "Epoch 36/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.5784 - root_mean_squared_error: 2.9289 - val_loss: 7.6198 - val_root_mean_squared_error: 2.7604\n",
      "Epoch 37/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.5873 - root_mean_squared_error: 2.9304 - val_loss: 6.7149 - val_root_mean_squared_error: 2.5913\n",
      "Epoch 38/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.7155 - root_mean_squared_error: 2.9522 - val_loss: 7.6050 - val_root_mean_squared_error: 2.7577\n",
      "Epoch 39/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.8672 - root_mean_squared_error: 2.9778 - val_loss: 7.2884 - val_root_mean_squared_error: 2.6997\n",
      "Epoch 40/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.6956 - root_mean_squared_error: 2.5876 - val_loss: 7.2924 - val_root_mean_squared_error: 2.7004\n",
      "Epoch 41/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.9691 - root_mean_squared_error: 2.9948 - val_loss: 9.3993 - val_root_mean_squared_error: 3.0658\n",
      "Epoch 42/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.8872 - root_mean_squared_error: 2.4264 - val_loss: 9.9550 - val_root_mean_squared_error: 3.1552\n",
      "Epoch 43/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.5039 - root_mean_squared_error: 2.3460 - val_loss: 7.1889 - val_root_mean_squared_error: 2.6812\n",
      "Epoch 44/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.0076 - root_mean_squared_error: 2.4510 - val_loss: 6.4485 - val_root_mean_squared_error: 2.5394\n",
      "Epoch 45/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.0354 - root_mean_squared_error: 2.2440 - val_loss: 7.7723 - val_root_mean_squared_error: 2.7879\n",
      "Epoch 46/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.3224 - root_mean_squared_error: 2.3070 - val_loss: 9.3077 - val_root_mean_squared_error: 3.0509\n",
      "Epoch 47/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.0729 - root_mean_squared_error: 2.2523 - val_loss: 8.6829 - val_root_mean_squared_error: 2.9467\n",
      "Epoch 48/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.0111 - root_mean_squared_error: 2.0028 - val_loss: 7.0059 - val_root_mean_squared_error: 2.6469\n",
      "Epoch 49/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.1542 - root_mean_squared_error: 2.2703 - val_loss: 12.7868 - val_root_mean_squared_error: 3.5759\n",
      "Epoch 50/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.8239 - root_mean_squared_error: 2.1963 - val_loss: 8.2283 - val_root_mean_squared_error: 2.8685\n",
      "Epoch 51/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.8872 - root_mean_squared_error: 2.2107 - val_loss: 13.6235 - val_root_mean_squared_error: 3.6910\n",
      "Epoch 52/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.3189 - root_mean_squared_error: 2.3063 - val_loss: 6.9567 - val_root_mean_squared_error: 2.6375\n",
      "Epoch 53/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.6284 - root_mean_squared_error: 2.1514 - val_loss: 6.9676 - val_root_mean_squared_error: 2.6396\n",
      "Epoch 54/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.3434 - root_mean_squared_error: 2.0841 - val_loss: 7.0072 - val_root_mean_squared_error: 2.6471\n",
      "Epoch 55/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.2607 - root_mean_squared_error: 2.0641 - val_loss: 7.7756 - val_root_mean_squared_error: 2.7885\n",
      "Epoch 56/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.0917 - root_mean_squared_error: 2.2565 - val_loss: 7.7612 - val_root_mean_squared_error: 2.7859\n",
      "Epoch 57/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.9454 - root_mean_squared_error: 1.9863 - val_loss: 7.1307 - val_root_mean_squared_error: 2.6703\n",
      "Epoch 58/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.4823 - root_mean_squared_error: 2.1171 - val_loss: 7.2466 - val_root_mean_squared_error: 2.6920\n",
      "Epoch 59/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.8409 - root_mean_squared_error: 1.9598 - val_loss: 8.0578 - val_root_mean_squared_error: 2.8386\n",
      "Epoch 60/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.3445 - root_mean_squared_error: 1.8288 - val_loss: 8.4450 - val_root_mean_squared_error: 2.9060\n",
      "Epoch 61/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.2955 - root_mean_squared_error: 2.0726 - val_loss: 6.6250 - val_root_mean_squared_error: 2.5739\n",
      "Epoch 62/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.6837 - root_mean_squared_error: 1.9193 - val_loss: 7.1463 - val_root_mean_squared_error: 2.6733\n",
      "Epoch 63/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.0078 - root_mean_squared_error: 1.7343 - val_loss: 7.1775 - val_root_mean_squared_error: 2.6791\n",
      "Epoch 64/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.4241 - root_mean_squared_error: 1.8504 - val_loss: 7.8168 - val_root_mean_squared_error: 2.7958\n",
      "Epoch 65/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8357 - root_mean_squared_error: 1.6839 - val_loss: 8.2743 - val_root_mean_squared_error: 2.8765\n",
      "Epoch 66/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.5323 - root_mean_squared_error: 1.8794 - val_loss: 7.2959 - val_root_mean_squared_error: 2.7011\n",
      "Epoch 67/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.5254 - root_mean_squared_error: 1.5891 - val_loss: 7.7635 - val_root_mean_squared_error: 2.7863\n",
      "Epoch 68/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.6156 - root_mean_squared_error: 1.6173 - val_loss: 7.9754 - val_root_mean_squared_error: 2.8241\n",
      "Epoch 69/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.4883 - root_mean_squared_error: 1.8677 - val_loss: 8.1169 - val_root_mean_squared_error: 2.8490\n",
      "Epoch 70/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.7487 - root_mean_squared_error: 1.6579 - val_loss: 7.6083 - val_root_mean_squared_error: 2.7583\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.5636 - root_mean_squared_error: 1.6011 - val_loss: 7.6654 - val_root_mean_squared_error: 2.7686\n",
      "Epoch 72/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.4603 - root_mean_squared_error: 1.5685 - val_loss: 7.8879 - val_root_mean_squared_error: 2.8085\n",
      "Epoch 73/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6502 - root_mean_squared_error: 1.6279 - val_loss: 7.5231 - val_root_mean_squared_error: 2.7428\n",
      "Epoch 74/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.4405 - root_mean_squared_error: 1.5622 - val_loss: 7.5407 - val_root_mean_squared_error: 2.7460\n",
      "Epoch 75/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.4744 - root_mean_squared_error: 1.5730 - val_loss: 8.7196 - val_root_mean_squared_error: 2.9529\n",
      "Epoch 76/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.4154 - root_mean_squared_error: 1.5542 - val_loss: 7.3411 - val_root_mean_squared_error: 2.7094\n",
      "Epoch 77/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.2157 - root_mean_squared_error: 1.4885 - val_loss: 8.0332 - val_root_mean_squared_error: 2.8343\n",
      "Epoch 78/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1751 - root_mean_squared_error: 1.4748 - val_loss: 7.5751 - val_root_mean_squared_error: 2.7523\n",
      "Epoch 79/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.9855 - root_mean_squared_error: 1.4091 - val_loss: 6.6395 - val_root_mean_squared_error: 2.5767\n",
      "Epoch 80/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.3709 - root_mean_squared_error: 1.5398 - val_loss: 7.8182 - val_root_mean_squared_error: 2.7961\n",
      "Epoch 81/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1074 - root_mean_squared_error: 1.4517 - val_loss: 7.9845 - val_root_mean_squared_error: 2.8257\n",
      "Epoch 82/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1688 - root_mean_squared_error: 1.4727 - val_loss: 8.0673 - val_root_mean_squared_error: 2.8403\n",
      "Epoch 83/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.9672 - root_mean_squared_error: 1.4026 - val_loss: 9.9821 - val_root_mean_squared_error: 3.1594\n",
      "Epoch 84/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.2753 - root_mean_squared_error: 1.5084 - val_loss: 7.7861 - val_root_mean_squared_error: 2.7904\n",
      "Epoch 85/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.9757 - root_mean_squared_error: 1.4056 - val_loss: 7.4837 - val_root_mean_squared_error: 2.7356\n",
      "Epoch 86/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2734 - root_mean_squared_error: 1.5078 - val_loss: 8.5473 - val_root_mean_squared_error: 2.9236\n",
      "Epoch 87/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1379 - root_mean_squared_error: 1.4621 - val_loss: 7.5127 - val_root_mean_squared_error: 2.7409\n",
      "Epoch 88/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.7938 - root_mean_squared_error: 1.3393 - val_loss: 8.3561 - val_root_mean_squared_error: 2.8907\n",
      "Epoch 89/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1397 - root_mean_squared_error: 1.4628 - val_loss: 7.1115 - val_root_mean_squared_error: 2.6667\n",
      "Epoch 90/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.7355 - root_mean_squared_error: 1.3174 - val_loss: 7.7965 - val_root_mean_squared_error: 2.7922\n",
      "Epoch 91/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.5035 - root_mean_squared_error: 1.2262 - val_loss: 7.8239 - val_root_mean_squared_error: 2.7971\n",
      "Epoch 92/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.7351 - root_mean_squared_error: 1.3172 - val_loss: 7.7836 - val_root_mean_squared_error: 2.7899\n",
      "Epoch 93/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.5419 - root_mean_squared_error: 1.2417 - val_loss: 7.0342 - val_root_mean_squared_error: 2.6522\n",
      "Epoch 94/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.6322 - root_mean_squared_error: 1.2776 - val_loss: 8.0481 - val_root_mean_squared_error: 2.8369\n",
      "Epoch 95/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.9831 - root_mean_squared_error: 1.4082 - val_loss: 7.7250 - val_root_mean_squared_error: 2.7794\n",
      "Epoch 96/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.5919 - root_mean_squared_error: 1.2617 - val_loss: 7.7001 - val_root_mean_squared_error: 2.7749\n",
      "Epoch 97/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.2528 - root_mean_squared_error: 1.1193 - val_loss: 8.2555 - val_root_mean_squared_error: 2.8732\n",
      "Epoch 98/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.3263 - root_mean_squared_error: 1.1516 - val_loss: 7.9245 - val_root_mean_squared_error: 2.8151\n",
      "Epoch 99/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.2948 - root_mean_squared_error: 1.1379 - val_loss: 7.4485 - val_root_mean_squared_error: 2.7292\n",
      "Epoch 100/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.5015 - root_mean_squared_error: 1.2253 - val_loss: 8.7954 - val_root_mean_squared_error: 2.9657\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -0.23436140060241528\n",
      "RMSE for dataset is:2.9657029426067982& mean of this fold is 44.114666\n",
      "this is 6.7227142637960435% of the mean pheno data\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:7\n",
      "Train on 678 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "678/678 [==============================] - 14s 20ms/sample - loss: 1765.8090 - root_mean_squared_error: 42.0215 - val_loss: 378.3387 - val_root_mean_squared_error: 19.4509\n",
      "Epoch 2/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1275.8299 - root_mean_squared_error: 35.7188 - val_loss: 493.8900 - val_root_mean_squared_error: 22.2236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 547.2842 - root_mean_squared_error: 23.3941 - val_loss: 159.9577 - val_root_mean_squared_error: 12.6474\n",
      "Epoch 4/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 190.0571 - root_mean_squared_error: 13.7861 - val_loss: 125.8108 - val_root_mean_squared_error: 11.2165\n",
      "Epoch 5/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 155.7883 - root_mean_squared_error: 12.4815 - val_loss: 104.3139 - val_root_mean_squared_error: 10.2134\n",
      "Epoch 6/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 98.4492 - root_mean_squared_error: 9.9222 - val_loss: 63.0069 - val_root_mean_squared_error: 7.9377\n",
      "Epoch 7/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 104.0137 - root_mean_squared_error: 10.1987 - val_loss: 24.5749 - val_root_mean_squared_error: 4.9573\n",
      "Epoch 8/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 71.4906 - root_mean_squared_error: 8.4552 - val_loss: 27.9466 - val_root_mean_squared_error: 5.2865\n",
      "Epoch 9/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 70.7842 - root_mean_squared_error: 8.4133 - val_loss: 27.7871 - val_root_mean_squared_error: 5.2713\n",
      "Epoch 10/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 65.9176 - root_mean_squared_error: 8.1190 - val_loss: 22.2864 - val_root_mean_squared_error: 4.7208\n",
      "Epoch 11/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 72.7908 - root_mean_squared_error: 8.5317 - val_loss: 39.2150 - val_root_mean_squared_error: 6.2622\n",
      "Epoch 12/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 61.3847 - root_mean_squared_error: 7.8348 - val_loss: 56.8577 - val_root_mean_squared_error: 7.5404\n",
      "Epoch 13/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 50.9850 - root_mean_squared_error: 7.1404 - val_loss: 39.1409 - val_root_mean_squared_error: 6.2563\n",
      "Epoch 14/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 40.2608 - root_mean_squared_error: 6.3451 - val_loss: 41.7086 - val_root_mean_squared_error: 6.4582\n",
      "Epoch 15/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 35.0524 - root_mean_squared_error: 5.9205 - val_loss: 35.1831 - val_root_mean_squared_error: 5.9315\n",
      "Epoch 16/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 34.9078 - root_mean_squared_error: 5.9083 - val_loss: 32.4937 - val_root_mean_squared_error: 5.7003\n",
      "Epoch 17/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 25.8463 - root_mean_squared_error: 5.0839 - val_loss: 21.8716 - val_root_mean_squared_error: 4.6767\n",
      "Epoch 18/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 22.6758 - root_mean_squared_error: 4.7619 - val_loss: 19.8174 - val_root_mean_squared_error: 4.4517\n",
      "Epoch 19/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 19.7145 - root_mean_squared_error: 4.4401 - val_loss: 13.1058 - val_root_mean_squared_error: 3.6202\n",
      "Epoch 20/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 18.0930 - root_mean_squared_error: 4.2536 - val_loss: 13.6806 - val_root_mean_squared_error: 3.6987\n",
      "Epoch 21/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 16.6167 - root_mean_squared_error: 4.0764 - val_loss: 10.3785 - val_root_mean_squared_error: 3.2216\n",
      "Epoch 22/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 15.2564 - root_mean_squared_error: 3.9059 - val_loss: 10.7310 - val_root_mean_squared_error: 3.2758\n",
      "Epoch 23/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 14.4394 - root_mean_squared_error: 3.7999 - val_loss: 13.7252 - val_root_mean_squared_error: 3.7048\n",
      "Epoch 24/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 13.5753 - root_mean_squared_error: 3.6845 - val_loss: 11.7551 - val_root_mean_squared_error: 3.4286\n",
      "Epoch 25/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 12.9595 - root_mean_squared_error: 3.5999 - val_loss: 10.4882 - val_root_mean_squared_error: 3.2385\n",
      "Epoch 26/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.7314 - root_mean_squared_error: 3.4251 - val_loss: 11.0923 - val_root_mean_squared_error: 3.3305\n",
      "Epoch 27/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 12.5298 - root_mean_squared_error: 3.5397 - val_loss: 13.4552 - val_root_mean_squared_error: 3.6681\n",
      "Epoch 28/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.4462 - root_mean_squared_error: 3.3832 - val_loss: 10.7280 - val_root_mean_squared_error: 3.2754\n",
      "Epoch 29/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.7209 - root_mean_squared_error: 3.4236 - val_loss: 15.1298 - val_root_mean_squared_error: 3.8897\n",
      "Epoch 30/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.8107 - root_mean_squared_error: 3.2880 - val_loss: 11.4073 - val_root_mean_squared_error: 3.3775\n",
      "Epoch 31/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.1767 - root_mean_squared_error: 3.0293 - val_loss: 9.5877 - val_root_mean_squared_error: 3.0964\n",
      "Epoch 32/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.3339 - root_mean_squared_error: 2.8869 - val_loss: 9.3259 - val_root_mean_squared_error: 3.0538\n",
      "Epoch 33/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.6279 - root_mean_squared_error: 2.9373 - val_loss: 9.3489 - val_root_mean_squared_error: 3.0576\n",
      "Epoch 34/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.0444 - root_mean_squared_error: 2.8363 - val_loss: 9.9867 - val_root_mean_squared_error: 3.1602\n",
      "Epoch 35/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.5261 - root_mean_squared_error: 2.9200 - val_loss: 10.2399 - val_root_mean_squared_error: 3.2000\n",
      "Epoch 36/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.5933 - root_mean_squared_error: 2.5677 - val_loss: 11.1325 - val_root_mean_squared_error: 3.3365\n",
      "Epoch 37/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.6893 - root_mean_squared_error: 2.7730 - val_loss: 11.2557 - val_root_mean_squared_error: 3.3550\n",
      "Epoch 38/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.4105 - root_mean_squared_error: 2.5319 - val_loss: 9.6631 - val_root_mean_squared_error: 3.1086\n",
      "Epoch 39/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.4683 - root_mean_squared_error: 2.7328 - val_loss: 12.3993 - val_root_mean_squared_error: 3.5213\n",
      "Epoch 40/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.9915 - root_mean_squared_error: 2.6441 - val_loss: 9.5574 - val_root_mean_squared_error: 3.0915\n",
      "Epoch 41/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.4911 - root_mean_squared_error: 2.5478 - val_loss: 8.9140 - val_root_mean_squared_error: 2.9856\n",
      "Epoch 42/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.2284 - root_mean_squared_error: 2.4957 - val_loss: 8.8559 - val_root_mean_squared_error: 2.9759\n",
      "Epoch 43/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.7212 - root_mean_squared_error: 2.5925 - val_loss: 9.9200 - val_root_mean_squared_error: 3.1496\n",
      "Epoch 44/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.1448 - root_mean_squared_error: 2.4789 - val_loss: 9.1636 - val_root_mean_squared_error: 3.0271\n",
      "Epoch 45/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.9102 - root_mean_squared_error: 2.4311 - val_loss: 9.1523 - val_root_mean_squared_error: 3.0253\n",
      "Epoch 46/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.9784 - root_mean_squared_error: 2.2312 - val_loss: 8.1547 - val_root_mean_squared_error: 2.8556\n",
      "Epoch 47/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.6614 - root_mean_squared_error: 2.9430 - val_loss: 10.9720 - val_root_mean_squared_error: 3.3124\n",
      "Epoch 48/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.6454 - root_mean_squared_error: 2.7650 - val_loss: 7.8249 - val_root_mean_squared_error: 2.7973\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.0624 - root_mean_squared_error: 2.4622 - val_loss: 7.5774 - val_root_mean_squared_error: 2.7527\n",
      "Epoch 50/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.3426 - root_mean_squared_error: 2.5185 - val_loss: 7.6014 - val_root_mean_squared_error: 2.7571\n",
      "Epoch 51/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.4672 - root_mean_squared_error: 2.7326 - val_loss: 25.6129 - val_root_mean_squared_error: 5.0609\n",
      "Epoch 52/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.3102 - root_mean_squared_error: 2.5120 - val_loss: 8.4507 - val_root_mean_squared_error: 2.9070\n",
      "Epoch 53/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.9369 - root_mean_squared_error: 2.4366 - val_loss: 7.4464 - val_root_mean_squared_error: 2.7288\n",
      "Epoch 54/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.6734 - root_mean_squared_error: 2.1618 - val_loss: 7.2087 - val_root_mean_squared_error: 2.6849\n",
      "Epoch 55/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.3906 - root_mean_squared_error: 2.0954 - val_loss: 6.7848 - val_root_mean_squared_error: 2.6048\n",
      "Epoch 56/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.0354 - root_mean_squared_error: 2.2440 - val_loss: 7.0073 - val_root_mean_squared_error: 2.6471\n",
      "Epoch 57/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.2983 - root_mean_squared_error: 2.0732 - val_loss: 7.0084 - val_root_mean_squared_error: 2.6473\n",
      "Epoch 58/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.7627 - root_mean_squared_error: 2.1824 - val_loss: 7.4058 - val_root_mean_squared_error: 2.7214\n",
      "Epoch 59/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.3713 - root_mean_squared_error: 2.0908 - val_loss: 7.5617 - val_root_mean_squared_error: 2.7499\n",
      "Epoch 60/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.8651 - root_mean_squared_error: 2.4218 - val_loss: 22.5350 - val_root_mean_squared_error: 4.7471\n",
      "Epoch 61/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.1349 - root_mean_squared_error: 2.4769 - val_loss: 16.1078 - val_root_mean_squared_error: 4.0134\n",
      "Epoch 62/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.4846 - root_mean_squared_error: 2.1177 - val_loss: 11.3768 - val_root_mean_squared_error: 3.3729\n",
      "Epoch 63/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.0745 - root_mean_squared_error: 2.0186 - val_loss: 8.0892 - val_root_mean_squared_error: 2.8441\n",
      "Epoch 64/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.8368 - root_mean_squared_error: 1.9588 - val_loss: 7.2704 - val_root_mean_squared_error: 2.6964\n",
      "Epoch 65/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.7900 - root_mean_squared_error: 1.9468 - val_loss: 8.6365 - val_root_mean_squared_error: 2.9388\n",
      "Epoch 66/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.9092 - root_mean_squared_error: 1.9772 - val_loss: 7.7718 - val_root_mean_squared_error: 2.7878\n",
      "Epoch 67/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.6926 - root_mean_squared_error: 1.9216 - val_loss: 6.8911 - val_root_mean_squared_error: 2.6251\n",
      "Epoch 68/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.2822 - root_mean_squared_error: 1.8117 - val_loss: 7.4888 - val_root_mean_squared_error: 2.7366\n",
      "Epoch 69/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.3165 - root_mean_squared_error: 2.0776 - val_loss: 7.2973 - val_root_mean_squared_error: 2.7014\n",
      "Epoch 70/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.5189 - root_mean_squared_error: 1.8759 - val_loss: 7.0098 - val_root_mean_squared_error: 2.6476\n",
      "Epoch 71/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.5273 - root_mean_squared_error: 1.8781 - val_loss: 7.8252 - val_root_mean_squared_error: 2.7974\n",
      "Epoch 72/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.5145 - root_mean_squared_error: 2.1247 - val_loss: 7.7113 - val_root_mean_squared_error: 2.7769\n",
      "Epoch 73/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.7222 - root_mean_squared_error: 2.1731 - val_loss: 7.1332 - val_root_mean_squared_error: 2.6708\n",
      "Epoch 74/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.0823 - root_mean_squared_error: 1.7557 - val_loss: 6.9846 - val_root_mean_squared_error: 2.6428\n",
      "Epoch 75/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.9871 - root_mean_squared_error: 1.7283 - val_loss: 7.1236 - val_root_mean_squared_error: 2.6690\n",
      "Epoch 76/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.0457 - root_mean_squared_error: 2.0114 - val_loss: 6.8834 - val_root_mean_squared_error: 2.6236\n",
      "Epoch 77/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1643 - root_mean_squared_error: 1.7788 - val_loss: 7.4709 - val_root_mean_squared_error: 2.7333\n",
      "Epoch 78/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.6686 - root_mean_squared_error: 1.6336 - val_loss: 7.2003 - val_root_mean_squared_error: 2.6833\n",
      "Epoch 79/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.1631 - root_mean_squared_error: 1.7785 - val_loss: 7.2018 - val_root_mean_squared_error: 2.6836\n",
      "Epoch 80/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8891 - root_mean_squared_error: 1.6997 - val_loss: 7.5140 - val_root_mean_squared_error: 2.7412\n",
      "Epoch 81/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.1353 - root_mean_squared_error: 1.7707 - val_loss: 7.0216 - val_root_mean_squared_error: 2.6498\n",
      "Epoch 82/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4516 - root_mean_squared_error: 1.5658 - val_loss: 7.4832 - val_root_mean_squared_error: 2.7355\n",
      "Epoch 83/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.3039 - root_mean_squared_error: 1.8177 - val_loss: 7.1482 - val_root_mean_squared_error: 2.6736\n",
      "Epoch 84/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8445 - root_mean_squared_error: 1.6866 - val_loss: 7.1050 - val_root_mean_squared_error: 2.6655\n",
      "Epoch 85/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.2319 - root_mean_squared_error: 1.7977 - val_loss: 7.2331 - val_root_mean_squared_error: 2.6894\n",
      "Epoch 86/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.9193 - root_mean_squared_error: 1.9797 - val_loss: 7.3421 - val_root_mean_squared_error: 2.7096\n",
      "Epoch 87/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.2856 - root_mean_squared_error: 1.8126 - val_loss: 6.8168 - val_root_mean_squared_error: 2.6109\n",
      "Epoch 88/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8675 - root_mean_squared_error: 1.6934 - val_loss: 7.4497 - val_root_mean_squared_error: 2.7294\n",
      "Epoch 89/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6546 - root_mean_squared_error: 1.6293 - val_loss: 7.2529 - val_root_mean_squared_error: 2.6931\n",
      "Epoch 90/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.7657 - root_mean_squared_error: 1.6630 - val_loss: 7.8621 - val_root_mean_squared_error: 2.8040\n",
      "Epoch 91/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.2826 - root_mean_squared_error: 1.5108 - val_loss: 7.2586 - val_root_mean_squared_error: 2.6942\n",
      "Epoch 92/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.6450 - root_mean_squared_error: 2.1552 - val_loss: 7.9083 - val_root_mean_squared_error: 2.8122\n",
      "Epoch 93/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1430 - root_mean_squared_error: 1.7729 - val_loss: 7.4591 - val_root_mean_squared_error: 2.7311\n",
      "Epoch 94/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.3287 - root_mean_squared_error: 2.0806 - val_loss: 7.1176 - val_root_mean_squared_error: 2.6679\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6648 - root_mean_squared_error: 1.6324 - val_loss: 7.9881 - val_root_mean_squared_error: 2.8263\n",
      "Epoch 96/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8800 - root_mean_squared_error: 1.6971 - val_loss: 7.2123 - val_root_mean_squared_error: 2.6856\n",
      "Epoch 97/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.0163 - root_mean_squared_error: 1.7368 - val_loss: 6.9285 - val_root_mean_squared_error: 2.6322\n",
      "Epoch 98/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2780 - root_mean_squared_error: 1.5093 - val_loss: 7.2186 - val_root_mean_squared_error: 2.6868\n",
      "Epoch 99/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.9638 - root_mean_squared_error: 1.4014 - val_loss: 7.0373 - val_root_mean_squared_error: 2.6528\n",
      "Epoch 100/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1393 - root_mean_squared_error: 1.4626 - val_loss: 7.0977 - val_root_mean_squared_error: 2.6641\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -0.3688521814253698\n",
      "RMSE for dataset is:2.664147607780714& mean of this fold is 44.568\n",
      "this is 5.9777139659623995% of the mean pheno data\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:8\n",
      "Train on 678 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "678/678 [==============================] - 13s 19ms/sample - loss: 1883.0389 - root_mean_squared_error: 43.3940 - val_loss: 321.1565 - val_root_mean_squared_error: 17.9208\n",
      "Epoch 2/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1575.2051 - root_mean_squared_error: 39.6889 - val_loss: 333.9146 - val_root_mean_squared_error: 18.2733\n",
      "Epoch 3/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 969.1212 - root_mean_squared_error: 31.1307 - val_loss: 333.5962 - val_root_mean_squared_error: 18.2646\n",
      "Epoch 4/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 323.3718 - root_mean_squared_error: 17.9825 - val_loss: 293.2555 - val_root_mean_squared_error: 17.1247\n",
      "Epoch 5/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 101.6030 - root_mean_squared_error: 10.0798 - val_loss: 48.4677 - val_root_mean_squared_error: 6.9619\n",
      "Epoch 6/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 60.7725 - root_mean_squared_error: 7.7957 - val_loss: 84.7831 - val_root_mean_squared_error: 9.2078\n",
      "Epoch 7/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 49.7799 - root_mean_squared_error: 7.0555 - val_loss: 820.2561 - val_root_mean_squared_error: 28.6401\n",
      "Epoch 8/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 38.6503 - root_mean_squared_error: 6.2169 - val_loss: 97.3474 - val_root_mean_squared_error: 9.8665\n",
      "Epoch 9/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 24.5495 - root_mean_squared_error: 4.9547 - val_loss: 40.0811 - val_root_mean_squared_error: 6.3310\n",
      "Epoch 10/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 25.3280 - root_mean_squared_error: 5.0327 - val_loss: 17.8222 - val_root_mean_squared_error: 4.2216\n",
      "Epoch 11/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 18.2419 - root_mean_squared_error: 4.2711 - val_loss: 16.0531 - val_root_mean_squared_error: 4.0066\n",
      "Epoch 12/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 16.0027 - root_mean_squared_error: 4.0003 - val_loss: 17.6401 - val_root_mean_squared_error: 4.2000\n",
      "Epoch 13/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 15.2533 - root_mean_squared_error: 3.9055 - val_loss: 10.6342 - val_root_mean_squared_error: 3.2610\n",
      "Epoch 14/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 14.2612 - root_mean_squared_error: 3.7764 - val_loss: 14.7347 - val_root_mean_squared_error: 3.8386\n",
      "Epoch 15/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.9756 - root_mean_squared_error: 3.1584 - val_loss: 9.1652 - val_root_mean_squared_error: 3.0274\n",
      "Epoch 16/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.8951 - root_mean_squared_error: 3.3008 - val_loss: 10.4106 - val_root_mean_squared_error: 3.2266\n",
      "Epoch 17/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.4172 - root_mean_squared_error: 3.2276 - val_loss: 8.3843 - val_root_mean_squared_error: 2.8956\n",
      "Epoch 18/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.3210 - root_mean_squared_error: 3.2126 - val_loss: 7.7613 - val_root_mean_squared_error: 2.7859\n",
      "Epoch 19/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.1674 - root_mean_squared_error: 3.0278 - val_loss: 7.5906 - val_root_mean_squared_error: 2.7551\n",
      "Epoch 20/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.6020 - root_mean_squared_error: 3.0987 - val_loss: 7.7616 - val_root_mean_squared_error: 2.7860\n",
      "Epoch 21/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.5826 - root_mean_squared_error: 3.2531 - val_loss: 8.0897 - val_root_mean_squared_error: 2.8442\n",
      "Epoch 22/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.3497 - root_mean_squared_error: 2.8896 - val_loss: 11.3592 - val_root_mean_squared_error: 3.3703\n",
      "Epoch 23/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.1157 - root_mean_squared_error: 2.8488 - val_loss: 8.2615 - val_root_mean_squared_error: 2.8743\n",
      "Epoch 24/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.0171 - root_mean_squared_error: 2.8314 - val_loss: 8.9877 - val_root_mean_squared_error: 2.9979\n",
      "Epoch 25/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.7462 - root_mean_squared_error: 2.7832 - val_loss: 8.8624 - val_root_mean_squared_error: 2.9770\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.4759 - root_mean_squared_error: 2.7342 - val_loss: 8.8778 - val_root_mean_squared_error: 2.9796\n",
      "Epoch 27/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.8463 - root_mean_squared_error: 2.9743 - val_loss: 9.3249 - val_root_mean_squared_error: 3.0537\n",
      "Epoch 28/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.5231 - root_mean_squared_error: 2.7428 - val_loss: 10.3098 - val_root_mean_squared_error: 3.2109\n",
      "Epoch 29/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.0643 - root_mean_squared_error: 2.8398 - val_loss: 8.6784 - val_root_mean_squared_error: 2.9459\n",
      "Epoch 30/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.7875 - root_mean_squared_error: 2.7906 - val_loss: 7.4617 - val_root_mean_squared_error: 2.7316\n",
      "Epoch 31/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.8040 - root_mean_squared_error: 2.7936 - val_loss: 8.4795 - val_root_mean_squared_error: 2.9120\n",
      "Epoch 32/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.0837 - root_mean_squared_error: 2.6615 - val_loss: 8.4566 - val_root_mean_squared_error: 2.9080\n",
      "Epoch 33/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.2242 - root_mean_squared_error: 2.4948 - val_loss: 7.4311 - val_root_mean_squared_error: 2.7260\n",
      "Epoch 34/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.1732 - root_mean_squared_error: 2.6783 - val_loss: 8.3710 - val_root_mean_squared_error: 2.8933\n",
      "Epoch 35/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.9497 - root_mean_squared_error: 2.6362 - val_loss: 8.6097 - val_root_mean_squared_error: 2.9342\n",
      "Epoch 36/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.3904 - root_mean_squared_error: 2.5279 - val_loss: 7.3391 - val_root_mean_squared_error: 2.7091\n",
      "Epoch 37/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.3624 - root_mean_squared_error: 2.5224 - val_loss: 6.8931 - val_root_mean_squared_error: 2.6255\n",
      "Epoch 38/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.6618 - root_mean_squared_error: 2.3795 - val_loss: 7.0958 - val_root_mean_squared_error: 2.6638\n",
      "Epoch 39/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.3377 - root_mean_squared_error: 2.3104 - val_loss: 7.9339 - val_root_mean_squared_error: 2.8167\n",
      "Epoch 40/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.5419 - root_mean_squared_error: 2.3541 - val_loss: 8.4764 - val_root_mean_squared_error: 2.9114\n",
      "Epoch 41/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.9048 - root_mean_squared_error: 2.4300 - val_loss: 7.4490 - val_root_mean_squared_error: 2.7293\n",
      "Epoch 42/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.6719 - root_mean_squared_error: 2.1615 - val_loss: 10.5962 - val_root_mean_squared_error: 3.2552\n",
      "Epoch 43/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.2304 - root_mean_squared_error: 2.2870 - val_loss: 7.2746 - val_root_mean_squared_error: 2.6971\n",
      "Epoch 44/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.0306 - root_mean_squared_error: 2.2429 - val_loss: 6.9015 - val_root_mean_squared_error: 2.6271\n",
      "Epoch 45/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.0424 - root_mean_squared_error: 2.2455 - val_loss: 7.1030 - val_root_mean_squared_error: 2.6651\n",
      "Epoch 46/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.8901 - root_mean_squared_error: 2.2114 - val_loss: 7.8648 - val_root_mean_squared_error: 2.8044\n",
      "Epoch 47/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.6447 - root_mean_squared_error: 2.1552 - val_loss: 7.3382 - val_root_mean_squared_error: 2.7089\n",
      "Epoch 48/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.2104 - root_mean_squared_error: 2.0519 - val_loss: 6.7786 - val_root_mean_squared_error: 2.6036\n",
      "Epoch 49/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.8672 - root_mean_squared_error: 2.2062 - val_loss: 6.9243 - val_root_mean_squared_error: 2.6314\n",
      "Epoch 50/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.9177 - root_mean_squared_error: 1.9793 - val_loss: 7.1888 - val_root_mean_squared_error: 2.6812\n",
      "Epoch 51/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.1063 - root_mean_squared_error: 2.0264 - val_loss: 7.2602 - val_root_mean_squared_error: 2.6945\n",
      "Epoch 52/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.1638 - root_mean_squared_error: 2.0405 - val_loss: 6.8817 - val_root_mean_squared_error: 2.6233\n",
      "Epoch 53/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.3077 - root_mean_squared_error: 1.8187 - val_loss: 7.1701 - val_root_mean_squared_error: 2.6777\n",
      "Epoch 54/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.4865 - root_mean_squared_error: 2.1181 - val_loss: 7.3681 - val_root_mean_squared_error: 2.7144\n",
      "Epoch 55/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.6362 - root_mean_squared_error: 1.9069 - val_loss: 6.9414 - val_root_mean_squared_error: 2.6346\n",
      "Epoch 56/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.8811 - root_mean_squared_error: 1.9701 - val_loss: 6.9091 - val_root_mean_squared_error: 2.6285\n",
      "Epoch 57/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.4317 - root_mean_squared_error: 1.8525 - val_loss: 6.8355 - val_root_mean_squared_error: 2.6145\n",
      "Epoch 58/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.5396 - root_mean_squared_error: 1.8814 - val_loss: 6.8597 - val_root_mean_squared_error: 2.6191\n",
      "Epoch 59/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.2557 - root_mean_squared_error: 2.0629 - val_loss: 8.2107 - val_root_mean_squared_error: 2.8654\n",
      "Epoch 60/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.8249 - root_mean_squared_error: 1.9557 - val_loss: 8.5750 - val_root_mean_squared_error: 2.9283\n",
      "Epoch 61/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.0798 - root_mean_squared_error: 2.0199 - val_loss: 7.9404 - val_root_mean_squared_error: 2.8179\n",
      "Epoch 62/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.9289 - root_mean_squared_error: 2.6323 - val_loss: 22.5516 - val_root_mean_squared_error: 4.7488\n",
      "Epoch 63/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.2586 - root_mean_squared_error: 2.2932 - val_loss: 9.1043 - val_root_mean_squared_error: 3.0173\n",
      "Epoch 64/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.6583 - root_mean_squared_error: 2.1583 - val_loss: 9.7034 - val_root_mean_squared_error: 3.1150\n",
      "Epoch 65/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.1830 - root_mean_squared_error: 2.0452 - val_loss: 8.8797 - val_root_mean_squared_error: 2.9799\n",
      "Epoch 66/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.2438 - root_mean_squared_error: 1.8011 - val_loss: 7.9787 - val_root_mean_squared_error: 2.8247\n",
      "Epoch 67/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.1363 - root_mean_squared_error: 2.0338 - val_loss: 11.8661 - val_root_mean_squared_error: 3.4447\n",
      "Epoch 68/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1016 - root_mean_squared_error: 1.7611 - val_loss: 7.5290 - val_root_mean_squared_error: 2.7439\n",
      "Epoch 69/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1372 - root_mean_squared_error: 1.7712 - val_loss: 7.9145 - val_root_mean_squared_error: 2.8133\n",
      "Epoch 70/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.2260 - root_mean_squared_error: 1.7961 - val_loss: 7.0240 - val_root_mean_squared_error: 2.6503\n",
      "Epoch 71/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.0926 - root_mean_squared_error: 1.7586 - val_loss: 9.8546 - val_root_mean_squared_error: 3.1392\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1231 - root_mean_squared_error: 1.7672 - val_loss: 8.4183 - val_root_mean_squared_error: 2.9014\n",
      "Epoch 73/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.6695 - root_mean_squared_error: 1.6338 - val_loss: 7.7600 - val_root_mean_squared_error: 2.7857\n",
      "Epoch 74/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.8839 - root_mean_squared_error: 1.6982 - val_loss: 7.8093 - val_root_mean_squared_error: 2.7945\n",
      "Epoch 75/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.6060 - root_mean_squared_error: 1.6143 - val_loss: 6.9480 - val_root_mean_squared_error: 2.6359\n",
      "Epoch 76/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.5076 - root_mean_squared_error: 1.5835 - val_loss: 7.1123 - val_root_mean_squared_error: 2.6669\n",
      "Epoch 77/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2962 - root_mean_squared_error: 1.5153 - val_loss: 8.0354 - val_root_mean_squared_error: 2.8347\n",
      "Epoch 78/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.1958 - root_mean_squared_error: 1.4818 - val_loss: 6.9156 - val_root_mean_squared_error: 2.6297\n",
      "Epoch 79/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.7071 - root_mean_squared_error: 1.6453 - val_loss: 7.0115 - val_root_mean_squared_error: 2.6479\n",
      "Epoch 80/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.3893 - root_mean_squared_error: 1.5457 - val_loss: 7.5239 - val_root_mean_squared_error: 2.7430\n",
      "Epoch 81/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.6280 - root_mean_squared_error: 1.6211 - val_loss: 7.0453 - val_root_mean_squared_error: 2.6543\n",
      "Epoch 82/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2862 - root_mean_squared_error: 1.5120 - val_loss: 8.8262 - val_root_mean_squared_error: 2.9709\n",
      "Epoch 83/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4786 - root_mean_squared_error: 1.5744 - val_loss: 14.1695 - val_root_mean_squared_error: 3.7642\n",
      "Epoch 84/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.1376 - root_mean_squared_error: 1.4620 - val_loss: 11.7415 - val_root_mean_squared_error: 3.4266\n",
      "Epoch 85/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.5278 - root_mean_squared_error: 1.5899 - val_loss: 7.3465 - val_root_mean_squared_error: 2.7104\n",
      "Epoch 86/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.9981 - root_mean_squared_error: 1.4135 - val_loss: 7.9457 - val_root_mean_squared_error: 2.8188\n",
      "Epoch 87/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4713 - root_mean_squared_error: 1.5720 - val_loss: 9.3924 - val_root_mean_squared_error: 3.0647\n",
      "Epoch 88/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2318 - root_mean_squared_error: 1.4939 - val_loss: 7.4639 - val_root_mean_squared_error: 2.7320\n",
      "Epoch 89/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4290 - root_mean_squared_error: 1.5585 - val_loss: 7.9811 - val_root_mean_squared_error: 2.8251\n",
      "Epoch 90/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.9635 - root_mean_squared_error: 1.4012 - val_loss: 7.4471 - val_root_mean_squared_error: 2.7289\n",
      "Epoch 91/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.7151 - root_mean_squared_error: 1.3096 - val_loss: 7.2292 - val_root_mean_squared_error: 2.6887\n",
      "Epoch 92/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.3176 - root_mean_squared_error: 1.5224 - val_loss: 8.5879 - val_root_mean_squared_error: 2.9305\n",
      "Epoch 93/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.7874 - root_mean_squared_error: 1.3369 - val_loss: 7.5774 - val_root_mean_squared_error: 2.7527\n",
      "Epoch 94/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2088 - root_mean_squared_error: 1.4862 - val_loss: 7.4000 - val_root_mean_squared_error: 2.7203\n",
      "Epoch 95/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.7161 - root_mean_squared_error: 1.6481 - val_loss: 142.1126 - val_root_mean_squared_error: 11.9211\n",
      "Epoch 96/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.0104 - root_mean_squared_error: 2.0026 - val_loss: 11.4526 - val_root_mean_squared_error: 3.3842\n",
      "Epoch 97/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.5280 - root_mean_squared_error: 1.8783 - val_loss: 7.1852 - val_root_mean_squared_error: 2.6805\n",
      "Epoch 98/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.5592 - root_mean_squared_error: 1.5998 - val_loss: 6.8449 - val_root_mean_squared_error: 2.6163\n",
      "Epoch 99/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.5741 - root_mean_squared_error: 1.8905 - val_loss: 7.1990 - val_root_mean_squared_error: 2.6831\n",
      "Epoch 100/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.4151 - root_mean_squared_error: 1.8480 - val_loss: 13.9687 - val_root_mean_squared_error: 3.7375\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -3.3084208051657926\n",
      "RMSE for dataset is:3.7374671041514542& mean of this fold is 44.392\n",
      "this is 8.419236006566233% of the mean pheno data\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:9\n",
      "Train on 678 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "678/678 [==============================] - 14s 20ms/sample - loss: 1848.8857 - root_mean_squared_error: 42.9987 - val_loss: 1072.7422 - val_root_mean_squared_error: 32.7527\n",
      "Epoch 2/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1460.9504 - root_mean_squared_error: 38.2224 - val_loss: 486.3538 - val_root_mean_squared_error: 22.0534\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 3s 4ms/sample - loss: 844.7579 - root_mean_squared_error: 29.0647 - val_loss: 327.6957 - val_root_mean_squared_error: 18.1024\n",
      "Epoch 4/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 302.4061 - root_mean_squared_error: 17.3898 - val_loss: 219.6721 - val_root_mean_squared_error: 14.8213\n",
      "Epoch 5/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 94.0099 - root_mean_squared_error: 9.6959 - val_loss: 77.6746 - val_root_mean_squared_error: 8.8133\n",
      "Epoch 6/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 61.5132 - root_mean_squared_error: 7.8430 - val_loss: 158.5557 - val_root_mean_squared_error: 12.5919\n",
      "Epoch 7/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 42.3776 - root_mean_squared_error: 6.5098 - val_loss: 94.6783 - val_root_mean_squared_error: 9.7303\n",
      "Epoch 8/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 32.0874 - root_mean_squared_error: 5.6646 - val_loss: 23.6855 - val_root_mean_squared_error: 4.8668\n",
      "Epoch 9/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 28.7963 - root_mean_squared_error: 5.3662 - val_loss: 13.8821 - val_root_mean_squared_error: 3.7259\n",
      "Epoch 10/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 23.0757 - root_mean_squared_error: 4.8037 - val_loss: 12.9407 - val_root_mean_squared_error: 3.5973\n",
      "Epoch 11/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 20.1584 - root_mean_squared_error: 4.4898 - val_loss: 11.9435 - val_root_mean_squared_error: 3.4559\n",
      "Epoch 12/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 19.0006 - root_mean_squared_error: 4.3590 - val_loss: 39.6892 - val_root_mean_squared_error: 6.2999\n",
      "Epoch 13/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 14.8186 - root_mean_squared_error: 3.8495 - val_loss: 11.4705 - val_root_mean_squared_error: 3.3868\n",
      "Epoch 14/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.7821 - root_mean_squared_error: 3.4325 - val_loss: 9.3055 - val_root_mean_squared_error: 3.0505\n",
      "Epoch 15/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 12.6051 - root_mean_squared_error: 3.5504 - val_loss: 9.8684 - val_root_mean_squared_error: 3.1414\n",
      "Epoch 16/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.6424 - root_mean_squared_error: 3.4121 - val_loss: 7.7717 - val_root_mean_squared_error: 2.7878\n",
      "Epoch 17/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.4072 - root_mean_squared_error: 3.3774 - val_loss: 8.0991 - val_root_mean_squared_error: 2.8459\n",
      "Epoch 18/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.1865 - root_mean_squared_error: 3.0309 - val_loss: 7.4576 - val_root_mean_squared_error: 2.7309\n",
      "Epoch 19/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.7364 - root_mean_squared_error: 3.1203 - val_loss: 6.6237 - val_root_mean_squared_error: 2.5737\n",
      "Epoch 20/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.4744 - root_mean_squared_error: 2.9111 - val_loss: 7.1838 - val_root_mean_squared_error: 2.6803\n",
      "Epoch 21/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.6464 - root_mean_squared_error: 3.1059 - val_loss: 7.4046 - val_root_mean_squared_error: 2.7211\n",
      "Epoch 22/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.2793 - root_mean_squared_error: 3.0462 - val_loss: 8.1280 - val_root_mean_squared_error: 2.8510\n",
      "Epoch 23/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 10.0203 - root_mean_squared_error: 3.1655 - val_loss: 6.6621 - val_root_mean_squared_error: 2.5811\n",
      "Epoch 24/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.3576 - root_mean_squared_error: 2.8909 - val_loss: 12.0067 - val_root_mean_squared_error: 3.4651\n",
      "Epoch 25/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.6266 - root_mean_squared_error: 2.9371 - val_loss: 8.5562 - val_root_mean_squared_error: 2.9251\n",
      "Epoch 26/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.8896 - root_mean_squared_error: 2.9815 - val_loss: 7.9897 - val_root_mean_squared_error: 2.8266\n",
      "Epoch 27/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.1442 - root_mean_squared_error: 2.6729 - val_loss: 6.8828 - val_root_mean_squared_error: 2.6235\n",
      "Epoch 28/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.9401 - root_mean_squared_error: 2.6344 - val_loss: 7.1790 - val_root_mean_squared_error: 2.6794\n",
      "Epoch 29/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 7.2903 - root_mean_squared_error: 2.7001 - val_loss: 6.7295 - val_root_mean_squared_error: 2.5941\n",
      "Epoch 30/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.6189 - root_mean_squared_error: 2.5727 - val_loss: 6.1684 - val_root_mean_squared_error: 2.4836\n",
      "Epoch 31/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.2115 - root_mean_squared_error: 2.4923 - val_loss: 5.9831 - val_root_mean_squared_error: 2.4460\n",
      "Epoch 32/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.7624 - root_mean_squared_error: 2.4005 - val_loss: 6.2219 - val_root_mean_squared_error: 2.4944\n",
      "Epoch 33/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 6.0067 - root_mean_squared_error: 2.4509 - val_loss: 6.0645 - val_root_mean_squared_error: 2.4626\n",
      "Epoch 34/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.1601 - root_mean_squared_error: 2.4819 - val_loss: 7.7626 - val_root_mean_squared_error: 2.7861\n",
      "Epoch 35/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.7354 - root_mean_squared_error: 2.3949 - val_loss: 7.6657 - val_root_mean_squared_error: 2.7687\n",
      "Epoch 36/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.4718 - root_mean_squared_error: 2.3392 - val_loss: 10.8497 - val_root_mean_squared_error: 3.2939\n",
      "Epoch 37/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.8554 - root_mean_squared_error: 2.4198 - val_loss: 16.1393 - val_root_mean_squared_error: 4.0174\n",
      "Epoch 38/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.4974 - root_mean_squared_error: 2.3447 - val_loss: 7.8555 - val_root_mean_squared_error: 2.8028\n",
      "Epoch 39/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 5.3062 - root_mean_squared_error: 2.3035 - val_loss: 6.2328 - val_root_mean_squared_error: 2.4966\n",
      "Epoch 40/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.7976 - root_mean_squared_error: 2.1903 - val_loss: 6.4614 - val_root_mean_squared_error: 2.5419\n",
      "Epoch 41/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.7865 - root_mean_squared_error: 2.1878 - val_loss: 7.7013 - val_root_mean_squared_error: 2.7751\n",
      "Epoch 42/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.6369 - root_mean_squared_error: 2.1533 - val_loss: 6.3699 - val_root_mean_squared_error: 2.5239\n",
      "Epoch 43/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.4727 - root_mean_squared_error: 2.1149 - val_loss: 8.6341 - val_root_mean_squared_error: 2.9384\n",
      "Epoch 44/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.2063 - root_mean_squared_error: 2.0509 - val_loss: 6.4747 - val_root_mean_squared_error: 2.5445\n",
      "Epoch 45/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.4683 - root_mean_squared_error: 2.1138 - val_loss: 7.8083 - val_root_mean_squared_error: 2.7943\n",
      "Epoch 46/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.3872 - root_mean_squared_error: 2.0946 - val_loss: 9.5538 - val_root_mean_squared_error: 3.0909\n",
      "Epoch 47/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 4.1435 - root_mean_squared_error: 2.0356 - val_loss: 10.6832 - val_root_mean_squared_error: 3.2685\n",
      "Epoch 48/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.2742 - root_mean_squared_error: 1.8095 - val_loss: 9.0545 - val_root_mean_squared_error: 3.0091\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.9165 - root_mean_squared_error: 1.9790 - val_loss: 6.8578 - val_root_mean_squared_error: 2.6187\n",
      "Epoch 50/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.8734 - root_mean_squared_error: 1.9681 - val_loss: 7.6756 - val_root_mean_squared_error: 2.7705\n",
      "Epoch 51/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.7435 - root_mean_squared_error: 1.9348 - val_loss: 7.2389 - val_root_mean_squared_error: 2.6905\n",
      "Epoch 52/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.2476 - root_mean_squared_error: 1.8021 - val_loss: 6.6536 - val_root_mean_squared_error: 2.5795\n",
      "Epoch 53/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.2022 - root_mean_squared_error: 1.7895 - val_loss: 8.4307 - val_root_mean_squared_error: 2.9036\n",
      "Epoch 54/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8966 - root_mean_squared_error: 1.7019 - val_loss: 8.5388 - val_root_mean_squared_error: 2.9221\n",
      "Epoch 55/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.4576 - root_mean_squared_error: 1.8595 - val_loss: 7.0392 - val_root_mean_squared_error: 2.6531\n",
      "Epoch 56/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6578 - root_mean_squared_error: 1.6303 - val_loss: 7.3395 - val_root_mean_squared_error: 2.7092\n",
      "Epoch 57/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 3.6345 - root_mean_squared_error: 1.9064 - val_loss: 6.5922 - val_root_mean_squared_error: 2.5675\n",
      "Epoch 58/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.9578 - root_mean_squared_error: 1.7198 - val_loss: 6.6728 - val_root_mean_squared_error: 2.5832\n",
      "Epoch 59/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.7460 - root_mean_squared_error: 1.6571 - val_loss: 8.7045 - val_root_mean_squared_error: 2.9503\n",
      "Epoch 60/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.9602 - root_mean_squared_error: 1.7205 - val_loss: 8.7082 - val_root_mean_squared_error: 2.9510\n",
      "Epoch 61/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.7283 - root_mean_squared_error: 1.6517 - val_loss: 8.8302 - val_root_mean_squared_error: 2.9716\n",
      "Epoch 62/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6635 - root_mean_squared_error: 1.6320 - val_loss: 7.7122 - val_root_mean_squared_error: 2.7771\n",
      "Epoch 63/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.7795 - root_mean_squared_error: 1.6672 - val_loss: 6.9647 - val_root_mean_squared_error: 2.6391\n",
      "Epoch 64/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.3360 - root_mean_squared_error: 1.5284 - val_loss: 10.4337 - val_root_mean_squared_error: 3.2301\n",
      "Epoch 65/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.8717 - root_mean_squared_error: 1.6946 - val_loss: 7.4589 - val_root_mean_squared_error: 2.7311\n",
      "Epoch 66/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1156 - root_mean_squared_error: 1.7651 - val_loss: 7.6522 - val_root_mean_squared_error: 2.7663\n",
      "Epoch 67/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.7847 - root_mean_squared_error: 1.6687 - val_loss: 6.6078 - val_root_mean_squared_error: 2.5706\n",
      "Epoch 68/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4087 - root_mean_squared_error: 1.5520 - val_loss: 6.0598 - val_root_mean_squared_error: 2.4617\n",
      "Epoch 69/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.7024 - root_mean_squared_error: 1.6439 - val_loss: 9.2537 - val_root_mean_squared_error: 3.0420\n",
      "Epoch 70/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.2394 - root_mean_squared_error: 1.4964 - val_loss: 6.1014 - val_root_mean_squared_error: 2.4701\n",
      "Epoch 71/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1198 - root_mean_squared_error: 1.4559 - val_loss: 8.1604 - val_root_mean_squared_error: 2.8566\n",
      "Epoch 72/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.0577 - root_mean_squared_error: 1.4345 - val_loss: 6.1439 - val_root_mean_squared_error: 2.4787\n",
      "Epoch 73/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4301 - root_mean_squared_error: 1.5589 - val_loss: 7.5283 - val_root_mean_squared_error: 2.7438\n",
      "Epoch 74/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8175 - root_mean_squared_error: 1.6785 - val_loss: 7.1695 - val_root_mean_squared_error: 2.6776\n",
      "Epoch 75/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.3420 - root_mean_squared_error: 1.5303 - val_loss: 8.0482 - val_root_mean_squared_error: 2.8369\n",
      "Epoch 76/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2233 - root_mean_squared_error: 1.4911 - val_loss: 6.4440 - val_root_mean_squared_error: 2.5385\n",
      "Epoch 77/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.8803 - root_mean_squared_error: 1.3712 - val_loss: 6.2017 - val_root_mean_squared_error: 2.4903\n",
      "Epoch 78/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.6985 - root_mean_squared_error: 1.6427 - val_loss: 6.8292 - val_root_mean_squared_error: 2.6133\n",
      "Epoch 79/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2906 - root_mean_squared_error: 1.5135 - val_loss: 6.5957 - val_root_mean_squared_error: 2.5682\n",
      "Epoch 80/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.9652 - root_mean_squared_error: 1.4019 - val_loss: 6.3795 - val_root_mean_squared_error: 2.5258\n",
      "Epoch 81/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1900 - root_mean_squared_error: 1.4799 - val_loss: 7.5408 - val_root_mean_squared_error: 2.7460\n",
      "Epoch 82/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.8562 - root_mean_squared_error: 1.3624 - val_loss: 6.7030 - val_root_mean_squared_error: 2.5890\n",
      "Epoch 83/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.1359 - root_mean_squared_error: 1.4615 - val_loss: 6.5295 - val_root_mean_squared_error: 2.5553\n",
      "Epoch 84/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.8034 - root_mean_squared_error: 1.6743 - val_loss: 6.6773 - val_root_mean_squared_error: 2.5840\n",
      "Epoch 85/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.6788 - root_mean_squared_error: 1.2957 - val_loss: 6.8516 - val_root_mean_squared_error: 2.6175\n",
      "Epoch 86/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.3661 - root_mean_squared_error: 1.5382 - val_loss: 8.1522 - val_root_mean_squared_error: 2.8552\n",
      "Epoch 87/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 2.0660 - root_mean_squared_error: 1.4374 - val_loss: 6.4854 - val_root_mean_squared_error: 2.5466\n",
      "Epoch 88/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.1647 - root_mean_squared_error: 1.4713 - val_loss: 8.3223 - val_root_mean_squared_error: 2.8848\n",
      "Epoch 89/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.9552 - root_mean_squared_error: 1.3983 - val_loss: 8.0967 - val_root_mean_squared_error: 2.8455\n",
      "Epoch 90/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.9992 - root_mean_squared_error: 1.4139 - val_loss: 7.3793 - val_root_mean_squared_error: 2.7165\n",
      "Epoch 91/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2017 - root_mean_squared_error: 1.4838 - val_loss: 6.6030 - val_root_mean_squared_error: 2.5696\n",
      "Epoch 92/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.3741 - root_mean_squared_error: 1.5408 - val_loss: 8.1950 - val_root_mean_squared_error: 2.8627\n",
      "Epoch 93/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2417 - root_mean_squared_error: 1.4972 - val_loss: 6.5858 - val_root_mean_squared_error: 2.5663\n",
      "Epoch 94/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.8249 - root_mean_squared_error: 1.3509 - val_loss: 8.3247 - val_root_mean_squared_error: 2.8853\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.8095 - root_mean_squared_error: 1.3452 - val_loss: 9.3351 - val_root_mean_squared_error: 3.0553\n",
      "Epoch 96/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2849 - root_mean_squared_error: 1.5116 - val_loss: 6.4615 - val_root_mean_squared_error: 2.5419\n",
      "Epoch 97/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.7958 - root_mean_squared_error: 1.3401 - val_loss: 6.4085 - val_root_mean_squared_error: 2.5315\n",
      "Epoch 98/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.9441 - root_mean_squared_error: 1.3943 - val_loss: 6.5587 - val_root_mean_squared_error: 2.5610\n",
      "Epoch 99/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.4556 - root_mean_squared_error: 1.2065 - val_loss: 7.1276 - val_root_mean_squared_error: 2.6698\n",
      "Epoch 100/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 1.3179 - root_mean_squared_error: 1.1480 - val_loss: 7.0852 - val_root_mean_squared_error: 2.6618\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -0.22439895400841436\n",
      "RMSE for dataset is:2.6618137209436092& mean of this fold is 44.496\n",
      "this is 5.982141805332308% of the mean pheno data\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 200)               124188200 \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 124,217,517\n",
      "Trainable params: 124,217,453\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold:10\n",
      "Train on 678 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "678/678 [==============================] - 19s 28ms/sample - loss: 1916.9517 - root_mean_squared_error: 43.7830 - val_loss: 1066.9834 - val_root_mean_squared_error: 32.6647\n",
      "Epoch 2/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1622.9486 - root_mean_squared_error: 40.2858 - val_loss: 1049.9993 - val_root_mean_squared_error: 32.4037\n",
      "Epoch 3/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1085.4176 - root_mean_squared_error: 32.9457 - val_loss: 382.8764 - val_root_mean_squared_error: 19.5672\n",
      "Epoch 4/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 499.9536 - root_mean_squared_error: 22.3596 - val_loss: 338.8256 - val_root_mean_squared_error: 18.4072\n",
      "Epoch 5/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 265.6590 - root_mean_squared_error: 16.2990 - val_loss: 145.3278 - val_root_mean_squared_error: 12.0552\n",
      "Epoch 6/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 166.9438 - root_mean_squared_error: 12.9207 - val_loss: 341.7509 - val_root_mean_squared_error: 18.4865\n",
      "Epoch 7/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 122.0555 - root_mean_squared_error: 11.0479 - val_loss: 118.7006 - val_root_mean_squared_error: 10.8950\n",
      "Epoch 8/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 85.0013 - root_mean_squared_error: 9.2196 - val_loss: 46.8953 - val_root_mean_squared_error: 6.8480\n",
      "Epoch 9/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 96.2970 - root_mean_squared_error: 9.8131 - val_loss: 52.2056 - val_root_mean_squared_error: 7.2253\n",
      "Epoch 10/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 107.6580 - root_mean_squared_error: 10.3758 - val_loss: 36.8539 - val_root_mean_squared_error: 6.0707\n",
      "Epoch 11/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 103.3625 - root_mean_squared_error: 10.1667 - val_loss: 52.2129 - val_root_mean_squared_error: 7.2259\n",
      "Epoch 12/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 67.2554 - root_mean_squared_error: 8.2009 - val_loss: 22.2154 - val_root_mean_squared_error: 4.7133\n",
      "Epoch 13/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 64.5382 - root_mean_squared_error: 8.0336 - val_loss: 28.1695 - val_root_mean_squared_error: 5.3075\n",
      "Epoch 14/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 49.7177 - root_mean_squared_error: 7.0511 - val_loss: 19.6807 - val_root_mean_squared_error: 4.4363\n",
      "Epoch 15/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 41.9175 - root_mean_squared_error: 6.4744 - val_loss: 16.3526 - val_root_mean_squared_error: 4.0438\n",
      "Epoch 16/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 28.6118 - root_mean_squared_error: 5.3490 - val_loss: 19.9657 - val_root_mean_squared_error: 4.4683\n",
      "Epoch 17/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 21.0118 - root_mean_squared_error: 4.5839 - val_loss: 29.7191 - val_root_mean_squared_error: 5.4515\n",
      "Epoch 18/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 18.8703 - root_mean_squared_error: 4.3440 - val_loss: 10.6867 - val_root_mean_squared_error: 3.2691\n",
      "Epoch 19/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 19.8610 - root_mean_squared_error: 4.4566 - val_loss: 10.1893 - val_root_mean_squared_error: 3.1921\n",
      "Epoch 20/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 16.5421 - root_mean_squared_error: 4.0672 - val_loss: 9.9179 - val_root_mean_squared_error: 3.1493\n",
      "Epoch 21/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 12.6483 - root_mean_squared_error: 3.5564 - val_loss: 9.2552 - val_root_mean_squared_error: 3.0422\n",
      "Epoch 22/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.5701 - root_mean_squared_error: 3.4015 - val_loss: 11.2878 - val_root_mean_squared_error: 3.3597\n",
      "Epoch 23/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.4120 - root_mean_squared_error: 3.2268 - val_loss: 15.2643 - val_root_mean_squared_error: 3.9070\n",
      "Epoch 24/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.4657 - root_mean_squared_error: 3.3861 - val_loss: 10.9700 - val_root_mean_squared_error: 3.3121\n",
      "Epoch 25/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 12.3872 - root_mean_squared_error: 3.5195 - val_loss: 9.5302 - val_root_mean_squared_error: 3.0871\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.0706 - root_mean_squared_error: 3.1734 - val_loss: 9.5423 - val_root_mean_squared_error: 3.0891\n",
      "Epoch 27/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.3128 - root_mean_squared_error: 3.3634 - val_loss: 9.0208 - val_root_mean_squared_error: 3.0035\n",
      "Epoch 28/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.7205 - root_mean_squared_error: 3.2742 - val_loss: 17.1665 - val_root_mean_squared_error: 4.1432\n",
      "Epoch 29/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.1139 - root_mean_squared_error: 3.3338 - val_loss: 10.3250 - val_root_mean_squared_error: 3.2132\n",
      "Epoch 30/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 10.4307 - root_mean_squared_error: 3.2297 - val_loss: 10.1341 - val_root_mean_squared_error: 3.1834\n",
      "Epoch 31/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 11.2381 - root_mean_squared_error: 3.3523 - val_loss: 9.8131 - val_root_mean_squared_error: 3.1326\n",
      "Epoch 32/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.8083 - root_mean_squared_error: 3.1318 - val_loss: 10.0258 - val_root_mean_squared_error: 3.1663\n",
      "Epoch 33/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.1125 - root_mean_squared_error: 3.0187 - val_loss: 9.5107 - val_root_mean_squared_error: 3.0839\n",
      "Epoch 34/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.4918 - root_mean_squared_error: 2.9141 - val_loss: 9.8289 - val_root_mean_squared_error: 3.1351\n",
      "Epoch 35/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 9.5769 - root_mean_squared_error: 3.0947 - val_loss: 18.1194 - val_root_mean_squared_error: 4.2567\n",
      "Epoch 36/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 8.3096 - root_mean_squared_error: 2.8826 - val_loss: 10.4841 - val_root_mean_squared_error: 3.2379\n",
      "Epoch 37/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.7279 - root_mean_squared_error: 2.7799 - val_loss: 8.4826 - val_root_mean_squared_error: 2.9125\n",
      "Epoch 38/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.4108 - root_mean_squared_error: 3.0677 - val_loss: 8.7639 - val_root_mean_squared_error: 2.9604\n",
      "Epoch 39/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.6542 - root_mean_squared_error: 2.7666 - val_loss: 8.7195 - val_root_mean_squared_error: 2.9529\n",
      "Epoch 40/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.5125 - root_mean_squared_error: 2.7409 - val_loss: 9.7606 - val_root_mean_squared_error: 3.1242\n",
      "Epoch 41/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 8.7301 - root_mean_squared_error: 2.9547 - val_loss: 15.5836 - val_root_mean_squared_error: 3.9476\n",
      "Epoch 42/100\n",
      "678/678 [==============================] - 2s 4ms/sample - loss: 11.2967 - root_mean_squared_error: 3.3611 - val_loss: 13.9610 - val_root_mean_squared_error: 3.7364\n",
      "Epoch 43/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 9.0692 - root_mean_squared_error: 3.0115 - val_loss: 9.3077 - val_root_mean_squared_error: 3.0508\n",
      "Epoch 44/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.4295 - root_mean_squared_error: 2.7257 - val_loss: 11.9132 - val_root_mean_squared_error: 3.4515\n",
      "Epoch 45/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.2486 - root_mean_squared_error: 2.4997 - val_loss: 10.1146 - val_root_mean_squared_error: 3.1804\n",
      "Epoch 46/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.7116 - root_mean_squared_error: 2.5907 - val_loss: 9.0645 - val_root_mean_squared_error: 3.0107\n",
      "Epoch 47/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.7822 - root_mean_squared_error: 2.6043 - val_loss: 18.1252 - val_root_mean_squared_error: 4.2574\n",
      "Epoch 48/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 7.8162 - root_mean_squared_error: 2.7957 - val_loss: 12.8077 - val_root_mean_squared_error: 3.5788\n",
      "Epoch 49/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.9558 - root_mean_squared_error: 2.2262 - val_loss: 13.4269 - val_root_mean_squared_error: 3.6643\n",
      "Epoch 50/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.7189 - root_mean_squared_error: 2.5921 - val_loss: 15.4014 - val_root_mean_squared_error: 3.9245\n",
      "Epoch 51/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.9998 - root_mean_squared_error: 2.4495 - val_loss: 10.0155 - val_root_mean_squared_error: 3.1647\n",
      "Epoch 52/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.6009 - root_mean_squared_error: 2.1450 - val_loss: 11.2389 - val_root_mean_squared_error: 3.3525\n",
      "Epoch 53/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.6711 - root_mean_squared_error: 2.1613 - val_loss: 11.2289 - val_root_mean_squared_error: 3.3510\n",
      "Epoch 54/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.3460 - root_mean_squared_error: 2.3121 - val_loss: 12.3087 - val_root_mean_squared_error: 3.5084\n",
      "Epoch 55/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.6548 - root_mean_squared_error: 2.1575 - val_loss: 13.6396 - val_root_mean_squared_error: 3.6932\n",
      "Epoch 56/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.1747 - root_mean_squared_error: 2.2748 - val_loss: 9.2376 - val_root_mean_squared_error: 3.0393\n",
      "Epoch 57/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.2523 - root_mean_squared_error: 2.2918 - val_loss: 12.7273 - val_root_mean_squared_error: 3.5675\n",
      "Epoch 58/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.5678 - root_mean_squared_error: 2.3596 - val_loss: 16.4311 - val_root_mean_squared_error: 4.0535\n",
      "Epoch 59/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.6706 - root_mean_squared_error: 2.5828 - val_loss: 11.9185 - val_root_mean_squared_error: 3.4523\n",
      "Epoch 60/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 6.8418 - root_mean_squared_error: 2.6157 - val_loss: 26.8896 - val_root_mean_squared_error: 5.1855\n",
      "Epoch 61/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 5.1651 - root_mean_squared_error: 2.2727 - val_loss: 10.7168 - val_root_mean_squared_error: 3.2736\n",
      "Epoch 62/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.4250 - root_mean_squared_error: 2.1036 - val_loss: 11.2594 - val_root_mean_squared_error: 3.3555\n",
      "Epoch 63/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.1804 - root_mean_squared_error: 2.0446 - val_loss: 10.6569 - val_root_mean_squared_error: 3.2645\n",
      "Epoch 64/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.5815 - root_mean_squared_error: 1.8925 - val_loss: 13.3908 - val_root_mean_squared_error: 3.6593\n",
      "Epoch 65/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.4185 - root_mean_squared_error: 2.1020 - val_loss: 8.9685 - val_root_mean_squared_error: 2.9947\n",
      "Epoch 66/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.3616 - root_mean_squared_error: 2.0884 - val_loss: 11.7203 - val_root_mean_squared_error: 3.4235\n",
      "Epoch 67/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.8512 - root_mean_squared_error: 2.2025 - val_loss: 11.4150 - val_root_mean_squared_error: 3.3786\n",
      "Epoch 68/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.0766 - root_mean_squared_error: 1.7540 - val_loss: 10.1047 - val_root_mean_squared_error: 3.1788\n",
      "Epoch 69/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.5862 - root_mean_squared_error: 1.8937 - val_loss: 9.7313 - val_root_mean_squared_error: 3.1195\n",
      "Epoch 70/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.0087 - root_mean_squared_error: 2.0022 - val_loss: 11.6110 - val_root_mean_squared_error: 3.4075\n",
      "Epoch 71/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.6917 - root_mean_squared_error: 1.9214 - val_loss: 9.6360 - val_root_mean_squared_error: 3.1042\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.9673 - root_mean_squared_error: 1.9918 - val_loss: 10.3240 - val_root_mean_squared_error: 3.2131\n",
      "Epoch 73/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.4429 - root_mean_squared_error: 1.8555 - val_loss: 9.5923 - val_root_mean_squared_error: 3.0971\n",
      "Epoch 74/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 4.0308 - root_mean_squared_error: 2.0077 - val_loss: 10.2618 - val_root_mean_squared_error: 3.2034\n",
      "Epoch 75/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.3931 - root_mean_squared_error: 1.8420 - val_loss: 11.0780 - val_root_mean_squared_error: 3.3284\n",
      "Epoch 76/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.5857 - root_mean_squared_error: 1.6080 - val_loss: 11.6573 - val_root_mean_squared_error: 3.4143\n",
      "Epoch 77/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.7155 - root_mean_squared_error: 1.6479 - val_loss: 8.6056 - val_root_mean_squared_error: 2.9335\n",
      "Epoch 78/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1126 - root_mean_squared_error: 1.7643 - val_loss: 11.0044 - val_root_mean_squared_error: 3.3173\n",
      "Epoch 79/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4798 - root_mean_squared_error: 1.5747 - val_loss: 10.5239 - val_root_mean_squared_error: 3.2441\n",
      "Epoch 80/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.9642 - root_mean_squared_error: 1.7217 - val_loss: 11.4147 - val_root_mean_squared_error: 3.3786\n",
      "Epoch 81/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.1169 - root_mean_squared_error: 1.7655 - val_loss: 8.6657 - val_root_mean_squared_error: 2.9438\n",
      "Epoch 82/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.6397 - root_mean_squared_error: 1.9078 - val_loss: 9.4479 - val_root_mean_squared_error: 3.0737\n",
      "Epoch 83/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.9084 - root_mean_squared_error: 1.7054 - val_loss: 9.9134 - val_root_mean_squared_error: 3.1486\n",
      "Epoch 84/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.2545 - root_mean_squared_error: 1.8040 - val_loss: 8.3077 - val_root_mean_squared_error: 2.8823\n",
      "Epoch 85/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.5735 - root_mean_squared_error: 1.6042 - val_loss: 9.7359 - val_root_mean_squared_error: 3.1202\n",
      "Epoch 86/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4881 - root_mean_squared_error: 1.5774 - val_loss: 8.3084 - val_root_mean_squared_error: 2.8824\n",
      "Epoch 87/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.3112 - root_mean_squared_error: 1.5203 - val_loss: 9.8577 - val_root_mean_squared_error: 3.1397\n",
      "Epoch 88/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.4564 - root_mean_squared_error: 1.5673 - val_loss: 9.8851 - val_root_mean_squared_error: 3.1441\n",
      "Epoch 89/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 3.0683 - root_mean_squared_error: 1.7517 - val_loss: 8.8746 - val_root_mean_squared_error: 2.9790\n",
      "Epoch 90/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.1502 - root_mean_squared_error: 1.4664 - val_loss: 10.8375 - val_root_mean_squared_error: 3.2920\n",
      "Epoch 91/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.8194 - root_mean_squared_error: 1.3488 - val_loss: 10.8916 - val_root_mean_squared_error: 3.3002\n",
      "Epoch 92/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.0782 - root_mean_squared_error: 1.4416 - val_loss: 9.1021 - val_root_mean_squared_error: 3.0170\n",
      "Epoch 93/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.0864 - root_mean_squared_error: 1.4444 - val_loss: 11.0061 - val_root_mean_squared_error: 3.3175\n",
      "Epoch 94/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.7423 - root_mean_squared_error: 1.3200 - val_loss: 9.5229 - val_root_mean_squared_error: 3.0859\n",
      "Epoch 95/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.2288 - root_mean_squared_error: 1.4929 - val_loss: 11.3763 - val_root_mean_squared_error: 3.3729\n",
      "Epoch 96/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.3095 - root_mean_squared_error: 1.5197 - val_loss: 9.6282 - val_root_mean_squared_error: 3.1029\n",
      "Epoch 97/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.9955 - root_mean_squared_error: 1.4126 - val_loss: 10.8569 - val_root_mean_squared_error: 3.2950\n",
      "Epoch 98/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 1.9502 - root_mean_squared_error: 1.3965 - val_loss: 9.8587 - val_root_mean_squared_error: 3.1399\n",
      "Epoch 99/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.0089 - root_mean_squared_error: 1.4174 - val_loss: 12.9581 - val_root_mean_squared_error: 3.5997\n",
      "Epoch 100/100\n",
      "678/678 [==============================] - 3s 4ms/sample - loss: 2.0579 - root_mean_squared_error: 1.4345 - val_loss: 11.8477 - val_root_mean_squared_error: 3.4421\n",
      "fitting done. Processing fold accuracy + checking best model\n",
      "R^2 Value is: -2.7458333022932044\n",
      "RMSE for dataset is:3.442051457899862& mean of this fold is 44.90933\n",
      "this is 7.664446510066386% of the mean pheno data\n",
      "Training Testing Accuracy: 6.49% (0.86%)\n"
     ]
    }
   ],
   "source": [
    "#my_model = build_CNN_model()\n",
    "best_DNN = eval_DNN(tt_vcf, tt_pheno, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Value of Holdout: -0.94\n",
      "RMSE of Holdout: 3.11\n",
      "Mean of Holdout: 44.92\n",
      "this is 6.913757869520916% of the mean pheno data\n"
     ]
    }
   ],
   "source": [
    "#ho_vcf = ho_vcf.reshape(ho_vcf.shape[0], ho_vcf.shape[1], 1)\n",
    "all_preds = [x for x in best_DNN.predict(ho_vcf)]\n",
    "ss = sqrt(mean_squared_error(all_preds, ho_pheno))\n",
    "rr = r2_score(all_preds, ho_pheno)\n",
    "mm = np.mean(ho_pheno)\n",
    "error_mean = ((ss/mm)*100)\n",
    "print(\"R^2 Value of Holdout: %.2f\" % rr)\n",
    "print(\"RMSE of Holdout: %.2f\" % ss)\n",
    "print(\"Mean of Holdout: %.2f\" % mm)\n",
    "print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x, plot_y = list(), list()\n",
    "\n",
    "ho_pheno = ho_pheno.ravel()\n",
    "\n",
    "for counter, i in enumerate(ho_pheno):\n",
    "    if counter <= 5:\n",
    "        print(counter, i, all_preds[counter])\n",
    "    #zoom in a bit closer\n",
    "    if(all_preds[counter] > 9):\n",
    "        plot_x.append(i)\n",
    "        plot_y.append(all_preds[counter])\n",
    "    \n",
    "#plt.plot(plot_x, plot_y, '.')\n",
    "thisplot = pd.DataFrame({'Oil':plot_x, 'preds':plot_y})\n",
    "#sns.jointplot(x=\"Oil\", y=\"preds\", data=thisplot, kind='reg' , joint_kws={'scatter_kws': {'alpha': 0.2}})\n",
    "sns.regplot(x=\"Oil\", y=\"preds\", data=thisplot)\n",
    "plt.xlabel('Real Seed Oil %')\n",
    "plt.ylabel('Predicted Seed Oil %')\n",
    "plt.title(\"DNN Seed Oil Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(12, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "x_ax = range(len(ho_pheno))\n",
    "print(x_ax)\n",
    "plt.plot(x_ax, ho_pheno, label=\"Actual %\")\n",
    "plt.plot(x_ax, all_preds, label=\"Predicted %\") \n",
    "\n",
    "plt.title(\"Seed Oil % Predicted vs Actual\")\n",
    "plt.xlabel('Validation Sample')\n",
    "plt.ylabel('Seed Oil Percentage')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_DNN, open(\"Oil_kfold_10_DNN.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_DNN = pickle.load(open(\"Oil_kfold_10_DNN.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=ho_pheno\n",
    "x_ax = range(len(y_test))\n",
    "print(x_ax)\n",
    "plt.plot(x_ax, y_test, label=\"original\")\n",
    "plt.plot(x_ax, all_preds, label=\"predicted\") \n",
    "\n",
    "plt.title(\"Test and predicted data\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "i = 0\n",
    "interval = 65\n",
    "while(i<len(y_test)):\n",
    "    i = i + interval\n",
    "    if(i>len(y_test)):\n",
    "        my_range = range(i-interval,len(y_test))\n",
    "    else:\n",
    "        my_range = range(i-interval,i)\n",
    "    plt.plot(my_range, y_test[my_range], label=\"original\")\n",
    "    plt.plot(my_range, all_preds[my_range], label=\"predicted\") \n",
    "\n",
    "    plt.title(\"Test and predicted data\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'targs': [x for x in pheno], 'preds': [x[0] for x in model.predict(vcf)]}\n",
    "\n",
    "testdf = pd.DataFrame(data=d)\n",
    "testdf['minus'] = testdf['targs'] - testdf['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = sqrt(mean_squared_error(testdf[\"preds\"], testdf['targs']))\n",
    "mm = np.mean(pheno)\n",
    "print(\"RMSE for dataset is:\" +str(ss) + \"& pheno is \" + str(mm))\n",
    "print(\"this is \"+ str((ss/mm)*100) + \"% of the mean pheno data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
